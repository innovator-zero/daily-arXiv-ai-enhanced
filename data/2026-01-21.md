<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 266]
- [cs.LG](#cs.LG) [Total: 185]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: SimCLR自监督预训练在农业病害分类中比分层架构设计带来更大提升，证明领域数据收集比架构选择更重要


<details>
  <summary>Details</summary>
Motivation: 研究领域特定自监督预训练对农业病害分类的影响，探索分层视觉Transformer在农业领域的应用

Method: 使用SimCLR在3000张无标签农业图像上进行自监督预训练，采用分层视觉Transformer（HVT）架构，在三个数据集上进行评估

Result: SimCLR预训练带来+4.57%准确率提升，超过分层架构设计的+3.70%增益；HVT-Base在相同参数量下比Swin-Base提升+1.68%

Conclusion: 自监督预训练收益是架构无关的，实践者应优先考虑领域数据收集而非架构选择，分层Transformer在农业病害分类中表现优异

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [2] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 该研究提出了一种基于3D TransUNet的深度学习框架，能够从常规T1加权MRI中合成高质量的扩散MRI指标（FA和MD），从而在不增加扫描时间的情况下获得微观结构信息，显著提升了阿尔茨海默病和轻度认知障碍的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）是一种渐进性神经退行性疾病，病理变化在临床症状出现前多年就已开始，早期检测对及时干预至关重要。虽然T1加权MRI在临床中常规使用，但它主要检测宏观结构变化，这些变化通常在疾病晚期才出现。扩散MRI（dMRI）对早期微观结构异常更敏感，但扫描时间长且易受运动伪影影响，限制了其在临床中的常规应用。

Method: 提出了一种3D TransUNet图像合成框架，该框架能够直接从T1加权MRI预测扩散MRI指标图，包括分数各向异性（FA）和平均扩散率（MD）。该模型结合了Transformer和U-Net架构的优势，生成高质量的合成扩散指标图。

Result: 模型生成的FA和MD图与真实dMRI数据具有高度一致性，结构相似性指数（SSIM）超过0.93，皮尔逊相关系数大于0.94。当将这些合成特征整合到多模态诊断模型中时，AD分类准确率提高了5%（从78.75%提升至83.75%），更重要的是，轻度认知障碍（MCI）检测准确率提高了12.5%。

Conclusion: 该研究表明，高质量的扩散微观结构信息可以从常规获取的T1加权MRI中推断出来，有效地将多模态成像的优势转移到没有扩散数据的临床环境中。通过减少扫描时间同时保留互补的结构和微观结构信息，该方法有望提高AD诊断的可及性、效率和准确性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [3] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++：一种基于分层约束神经高斯表示的RGB-D SLAM系统，通过渐进位姿优化和动态神经表示图提升结构一致性和抗噪能力，实现高精度3D重建和真实感渲染。


<details>
  <summary>Details</summary>
Motivation: 当前SLAM方法在深度噪声存在时难以保持结构一致性和鲁棒的位姿估计，限制了机器人技术和增强现实中的实时3D重建应用。

Method: 1. 采用分层约束神经高斯表示来保持结构关系并生成高斯基元进行场景建图；2. 使用渐进位姿优化来减轻深度传感器噪声；3. 利用动态神经表示图根据局部几何复杂度调整高斯节点分布。

Result: 实验结果表明，PointSLAM++在重建精度和渲染质量上优于现有的基于3DGS的SLAM方法，展示了其在大规模AR和机器人应用中的优势。

Conclusion: PointSLAM++通过结合分层约束神经高斯表示、渐进位姿优化和动态神经表示图，实现了高精度3D建图和真实感场景渲染，有效解决了深度噪声下的结构一致性和位姿估计问题。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [4] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 提出基于单类自动编码器的历史绘画认证框架，在数据稀缺环境下使用手工特征实现艺术家作品验证，取得83.3%真实接受率和9.5%错误接受率。


<details>
  <summary>Details</summary>
Motivation: 解决文化遗产领域纸质作品认证和归属的持续挑战，特别是在参考语料库小、风格线索主要通过线条和有限色调变化表达的情况下，需要一种能够补充传统鉴赏方法的计算框架。

Method: 采用基于单类自动编码器的验证框架，使用从多个博物馆收藏中获取的真实素描训练艺术家特定验证器。特征向量包括傅里叶域能量、香农熵、全局对比度、基于GLCM的同质性以及分形复杂度的盒计数估计。在生物特征识别风格协议下进行真伪试验评估。

Result: 在900个验证决策中（90个真实试验和810个冒名试验），汇总系统在选定操作点达到83.3%的真实接受率和9.5%的错误接受率。不同艺术家表现差异显著，某些验证器接近零错误接受率，而其他验证器存在较高混淆性。错误接受的成对归因显示与风格接近性和共享绘画惯例一致的结构化错误路径。

Conclusion: 该方法旨在补充而非取代传统鉴赏，为历史素描归属中常见的数据稀缺环境提供可重复的定量证据。研究同时强调了需要更好地控制数字化伪影和阈值校准。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [5] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: 该论文提出SLT（单层Transformer），通过蒸馏FreeFlow模型的28层Transformer块为单个共享DiT块，将参数量从675M压缩到4.3M，用于快速筛选高质量初始噪声点，提升一步生成模型的稳定性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配方法将扩散模型的迭代生成过程压缩到几步甚至一步，但一步生成模型如FreeFlow对初始噪声质量敏感，低质量初始噪声会导致生成质量波动。需要一种高效方法来筛选高质量初始噪声点。

Method: 将FreeFlow的28层Transformer架构视为ODE的欧拉离散化方案，蒸馏出单层共享DiT块（SLT）。训练时匹配教师模型在多个深度补丁的中间特征，融合补丁级表示，同时对齐教师的最终速度预测。

Result: 成功将675M参数的DiT-XL/2压缩到4.3M的SLT。在相当于教师模型两次随机采样时间内，SLT能进行超过100次噪声筛选，为教师模型选择高质量初始点，显著提高一步生成的稳定性和平均质量。

Conclusion: SLT通过极简参数实现快速噪声筛选，有效避免低质量初始噪声导致的生成波动，提升了一步生成模型的实用性和可靠性，为高质量图像生成提供了高效解决方案。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [6] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: CCPO提出了一种坐标压缩策略优化框架，通过坐标感知空间压缩和多轮交互来减少GUI智能体中的上下文膨胀，实现高效的任务完成。


<details>
  <summary>Details</summary>
Motivation: 多轮GUI智能体在完成任务时会积累大量交互历史，导致严重的上下文膨胀问题。现有方法要么通过截断牺牲长期上下文，要么通过令牌剪枝破坏空间结构，无法同时保持上下文完整性和结构信息。

Method: 提出坐标压缩策略优化（CCPO）框架，包含两个核心组件：1) 坐标感知空间压缩（CASC），通过聚合多轮滚动的坐标信息来捕捉目标相关区域，并逐步缩小历史注意力集中在关键视觉区域；2) 基于距离的优势函数，提供基于距离而非二元正确性的细粒度学习信号。

Result: 在四个基准测试中达到最先进性能，实现高达55%的令牌压缩和3.8倍的训练加速。

Conclusion: CCPO通过将视觉压缩与策略优化相结合，有效解决了多轮GUI智能体的上下文膨胀问题，在保持性能的同时显著提高了计算效率。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [7] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP是一个融合场景图和常识图的多模态大语言模型框架，通过查询驱动的检索-融合管道解决VQA中的知识幻觉和细粒度视觉感知不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在视觉问答中存在两个主要问题：知识幻觉（生成不准确的外部知识）和细粒度视觉感知不足。作者发现场景图和常识图分别能提供互补的解决方案——场景图捕捉细粒度视觉细节，常识图提供丰富的外部知识。但以往研究通常将它们孤立处理，忽略了它们的协同潜力。

Method: KG-ViP提出一个统一的框架，通过新颖的检索-融合管道将场景图和常识图融合。该管道利用查询作为语义桥梁，逐步整合两种图结构，合成统一的结构化上下文，以促进可靠的多模态推理。

Result: 在FVQA 2.0+和MVQA基准测试上的广泛实验表明，KG-ViP显著优于现有的VQA方法。

Conclusion: 通过融合场景图和常识图，KG-ViP有效解决了多模态大语言模型在视觉问答中的知识幻觉和细粒度视觉感知不足问题，展示了两种图结构协同作用的强大潜力。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [8] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: ViEBench是一个用于评估视觉语言模型忠实视觉推理能力的基准测试，包含200个多场景高分辨率图像和专家标注的视觉证据，通过双轴矩阵提供细粒度评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要依赖结果导向的准确性，缺乏评估模型是否能够准确利用细粒度视觉线索进行多步推理的能力，因此需要一种能够验证推理过程真实性的评估方法。

Method: 提出ViEBench基准，包含200个多场景高分辨率图像和专家标注的视觉证据，将任务按难度分为感知和推理两个维度，并引入双轴矩阵提供四个诊断象限的细粒度评估指标。

Result: 实验发现：(1) VLM有时能在基于无关区域的情况下得出正确答案；(2) 模型可能成功定位正确证据但仍无法利用它得出准确结论。这些发现表明ViEBench能更全面地评估模型推理能力。

Conclusion: ViEBench能够作为一个更可解释和实用的基准测试，全面评估视觉语言模型的忠实视觉推理能力，为模型行为提供透明诊断。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [9] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 提出基于多模态LLM智能体的自动问题发现方法，用于短视频平台快速发现新兴内容问题并更新标注策略，显著提升发现效果和治理效率。


<details>
  <summary>Details</summary>
Motivation: 短视频平台内容趋势快速演变，每天出现现有标注策略未覆盖的新兴问题。传统人工发现问题速度太慢，导致标注策略更新延迟，对有效内容治理构成重大挑战。

Method: 基于多模态LLM智能体的自动问题发现方法：自动召回包含潜在新问题的短视频，采用两阶段聚类策略分组（每个聚类对应一个新发现的问题），智能体从这些聚类生成更新的标注策略。

Result: 方法已部署到实际系统：离线实验显示新兴问题发现效果显著提升（F1分数提高超过20%）；在线实验显示后续问题治理性能增强（问题视频观看量减少约15%）；相比人工发现问题，大幅减少时间成本并加速标注策略迭代。

Conclusion: 基于多模态LLM智能体的自动问题发现方法能有效应对短视频平台内容治理挑战，实现快速、高效的新兴问题发现和策略更新，显著优于传统人工方法。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [10] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: Anon-NET是一个统一框架，用于面部视频匿名化，在保护隐私的同时保留年龄、性别、种族、姿态和表情等属性，通过扩散模型和视频驱动动画实现身份混淆。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉下游任务（如表情识别、人员跟踪、动作识别）中分析视频时，需要保护个人隐私，同时保留重要的视觉属性。

Method: 使用扩散生成模型进行面部修复，通过高级属性识别和运动感知的表情迁移引导；然后通过视频驱动动画对去身份化的面部进行动画处理。

Result: 在VoxCeleb2、CelebV-HQ和HDTF数据集上的实验表明，Anon-NET能有效混淆身份，同时保持视觉真实性和时间一致性。

Conclusion: Anon-NET提供了一个有效的面部视频匿名化解决方案，在保护隐私的同时保留了重要的视觉属性，适用于多种计算机视觉任务。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [11] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

TL;DR: 本文提出一个诊断微基准测试来分析视觉语言代理的自我纠正能力，发现任务成功率与纠正成功率存在显著差距，纠正效果在三次尝试后饱和，语义漂移是主要失败原因。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型使得视觉语言代理能够将复杂视觉任务分解为可执行的工具计划，但当前基准测试对迭代自我纠正能力的评估有限，其定量限制和主要推理瓶颈尚未得到充分表征。

Method: 引入诊断微基准测试，将任务成功率与纠正成功率解耦分析，量化纠正的递减回报，建立失败分类法来识别主要瓶颈（特别是语义漂移）。

Result: 任务成功率为62%，但纠正成功率仅为25-33%，表明初始能力不能预测修复能力；纠正效果在三次重试后饱和；语义漂移约占失败原因的28%，是主要的推理瓶颈。

Conclusion: 通过分离语义漂移这一关键推理瓶颈，该基准测试为构建状态感知、可信赖的多模态代理提供了一个可复现的框架。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [12] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: 提出MDDC数据校正框架，通过自动错误分析和数据质量优化提升边缘设备杂草检测性能，在固定轻量模型下实现5-25%的mAP提升


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的农业杂草检测面临模型容量、计算资源和实时推理延迟的严格限制，无法通过模型扩展或集成来提升性能，需要新的解决方案

Method: 提出模型驱动数据校正(MDDC)框架，包含自动化错误分析（将检测错误分为四类：假阴性、假阳性、类别混淆和定位错误），并通过结构化训练-修复-再训练流程进行版本控制数据管理

Result: 在多个杂草检测数据集上，使用固定轻量检测器(YOLOv8n)实现了5-25%的mAP@0.5提升，表明数据质量优化能有效缓解固定模型容量下的性能瓶颈

Conclusion: 系统化的数据质量优化可以在不改变模型架构的情况下显著提升边缘设备杂草检测性能，为资源受限场景提供有效解决方案

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [13] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT提出了一种无需采样的动态注意力框架，通过两阶段过程准确建模注意力模式演化，解决了DiT视频生成中自注意力二次复杂度的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散变换器在视频生成方面取得了进展，但自注意力的二次复杂度限制了实际部署。现有稀疏注意力方法要么依赖过于简化的静态模式，要么需要计算昂贵的采样操作来实现动态稀疏性，导致模式预测不准确和生成质量下降。

Method: MOD-DiT采用两阶段方法：1)利用早期去噪步骤的先验信息，通过分布式混合方法建模高效的线性近似模型，预测特定去噪区间的掩码模式；2)在线块掩码策略动态应用这些预测的掩码，同时保持历史稀疏信息，无需重复采样操作。

Result: 在多个基准测试和模型架构上，MOD-DiT都表现出一致的加速和质量改进，验证了其在高效高质量视频生成方面的有效性，同时克服了传统稀疏注意力方法的计算限制。

Conclusion: MOD-DiT成功解决了DiT视频生成中的计算瓶颈问题，通过采样自由的动态注意力框架实现了高效的注意力模式建模，为实际部署提供了可行的解决方案。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [14] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 本研究提出了一个基于物理的合成模拟框架(PSSF)，用于生成可控的膝关节X光扫描图像，以解决真实患者数据获取困难的问题，并用于训练机器学习模型进行骨关节炎评估。


<details>
  <summary>Details</summary>
Motivation: 膝关节骨关节炎(OA)是全球致残的主要原因，目前主要依赖主观的放射学分级（如Kellgren-Lawrence量表）。人工智能和影像组学提供了定量评估工具，但需要大量高质量标注的X光图像数据集，而这些数据因隐私、管理和资源限制而难以获取。

Method: 1. 开发基于物理的合成模拟框架(PSSF)：一个从参数化解剖模型（远端股骨和近端胫骨）生成膝关节前后位X光投影的2D模拟器
2. 创建虚拟队列：180名受试者（260个膝盖），每个膝盖在三种协议下成像（参考、低剂量和几何偏移）
3. 自动定位内侧关节区域，使用IBSI进行预处理和特征提取
4. 使用三种机器学习模型（逻辑回归、随机森林、梯度提升）训练二元（KL-like "0" vs. "2"）和三分类（0-2）预测模型
5. 在IBSI协议内、跨协议和多协议场景下评估模型鲁棒性
6. 使用组内相关系数评估特征在不同采集条件下的稳定性

Result: 研究通过PSSF成功生成了可控的合成X光图像数据集，并验证了基于这些合成数据训练的机器学习模型在骨关节炎评估中的可行性。通过IBSI协议内、跨协议和多协议场景的评估，证明了模型的鲁棒性。特征稳定性分析表明特征在不同采集条件下具有良好的一致性。

Conclusion: 基于物理的合成模拟框架为解决医学影像数据获取的隐私和资源限制问题提供了有效解决方案。生成的合成数据可以用于训练稳健的机器学习模型进行骨关节炎评估，为未来医学影像分析提供了新的数据生成途径。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [15] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: 提出基于视觉的置信度估计框架，通过物体检测进行几何验证来预测何时信任VLM的空间预测，相比基于文本的自评估方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在多模态任务中表现出色，但在空间推理方面存在系统性失败（准确率仅49%-54%）。为了在机器人和自主系统中安全部署，需要预测何时信任VLM的空间预测，而不是接受所有输出。

Method: 提出基于视觉的置信度估计框架，通过物体检测进行独立的几何验证。融合四个信号：VLM声称与坐标之间的几何对齐、空间重叠引起的模糊性、检测质量以及VLM内部不确定性，使用梯度提升进行融合。

Result: 在BLIP-2上达到0.674 AUROC（比基于文本的基线提升34.0%），在CLIP上达到0.583 AUROC（提升16.1%）。在60%目标准确率下，覆盖率从27.6%提升到61.9%（2.2倍改进）。特征分析显示视觉信号贡献87.4%的重要性，VLM置信度仅贡献12.7%。

Conclusion: 外部几何验证优于自评估，能够可靠地构建场景图，通过置信度剪枝将精度从52.1%提升到78.3%，同时保留68.2%的边。该框架为安全部署VLM提供了有效方法。

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [16] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: 提出IMSAHLO框架，通过多尺度注意力机制和混合损失优化，解决荧光显微镜神经元分割中的细胞密度不均、形态复杂和类别不平衡等挑战。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜神经元分割面临密集与稀疏细胞共存、形态复杂重叠、类别不平衡等挑战，传统深度学习模型难以保持拓扑细节和准确边界划分。

Method: 提出IMSAHLO框架，包含多尺度密集块(MSDBs)捕获不同感受野特征，分层注意力(HA)机制聚焦形态特征，以及结合Tversky损失、Focal损失、中心线Dice损失和轮廓加权边界损失的混合损失函数。

Result: 在FNC数据集上，IMSAHLO在密集和稀疏细胞案例中达到81.4%精度、82.7%宏观F1分数、83.3%微观F1分数和99.5%平衡准确率，优于现有最优方法。

Conclusion: 该工作为生物医学成像建立了可推广的分割模型基础，推动AI辅助分析向高通量神经生物学流程发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [17] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 研究发现文本到图像生成AI存在系统性"算法外貌主义"偏见，将面部吸引力与正面属性关联，并在性别分类任务中表现出显著性别偏见，揭示了AI视觉系统中的不平等问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示文本到图像生成AI系统中存在的"算法外貌主义"问题——基于外貌的系统性偏见偏好，以及这种偏见如何在下游性别分类任务中加剧社会不平等。

Method: 通过分析使用Stable Diffusion 2.1和3.5 Medium生成的26,400张合成人脸图像，研究生成AI模型如何将面部吸引力与正面属性关联，并测试三种性别分类算法在不同属性输入下的表现。

Result: 研究发现：1）生成AI模型系统性编码吸引力-正面属性关联；2）性别分类系统存在显著偏见，女性面孔特别是带有负面属性的女性面孔误分类率远高于男性；3）新版模型通过年龄同质化、性别化暴露模式和地理简化加剧了美学约束。

Conclusion: 算法外貌主义是跨AI视觉系统运作的系统性基础设施，通过表征和识别两方面加剧现有不平等。研究发现生成AI模型复制而非纠正社会偏见，需要更公平的AI系统设计。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [18] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出PSSI相似度指标，结合MeanShift和MaxST的交互式图分割方法，在分割质量和计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户交互敏感、前景背景颜色相似时性能下降等问题，关键在于图中边权重的相似度度量。

Method: 提出Pixel Segment Similarity Index (PSSI)相似度指标，利用通道间相似度的调和均值结合像素强度和空间平滑特征；采用MeanShift进行底层分割，构建像素-段图，用PSSI计算边权重；使用Maximum Spanning Tree (MaxST)进行分割。

Result: 在GrabCut和Images250数据集上，PSSI-MaxST方法在Jaccard Index (IoU)、F1分数、执行时间和平均误差(ME)等指标上均优于AMOE、OneCut、SSNCut等现有图分割方法。

Conclusion: PSSI相似度指标结合MeanShift和MaxST的方法能有效捕获颜色相似性、平滑性、纹理、形状和强局部连通性，显著提升了交互式图分割的性能和效率。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [19] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

TL;DR: 提出了Masked Binary U-Net (MBU-Net)，通过成本感知掩码策略实现高精度二值化分割网络，配合GPU执行框架实现实时性能


<details>
  <summary>Details</summary>
Motivation: 在AR/VR、机器人、无人机等边缘设备上实现实时图像分割面临计算、内存和功耗限制。现有二值化网络存在严重精度下降问题，且缺乏端到端的GPU高效实现

Method: 1. 基于两个观察设计：明确零状态的重要性，以及各层量化敏感性均匀。2. 提出成本感知掩码策略，优先掩码对精度-成本比最高的位置。3. 开发GPU执行框架，通过减法位编码方案将MBU-Net映射到Tensor Core

Result: 在3个分割基准测试中，MBU-Net达到接近全精度准确率（平均下降3%），相比16位浮点U-Net实现2.04倍加速和3.54倍能耗降低

Conclusion: MBU-Net通过掩码二值化权重结合二值激活，在保持高精度的同时实现了边缘设备上的实时分割性能，为资源受限场景提供了实用解决方案

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [20] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级热成像目标检测模型LTV-YOLO，专门用于在低光照和恶劣天气条件下检测儿童和青少年等弱势道路使用者，优化了边缘设备的实时性能。


<details>
  <summary>Details</summary>
Motivation: 在低光照和恶劣天气条件下，传统RGB相机难以可靠检测儿童和青少年等弱势道路使用者，这对计算机视觉、监控和自动驾驶系统的安全至关重要。

Method: 基于YOLO11架构定制热成像检测模型LTV-YOLO，采用长波红外热成像技术，集成深度可分离卷积和特征金字塔网络，针对小尺度、部分遮挡和热特征明显的弱势道路使用者进行优化。

Result: LTV-YOLO在计算效率、准确性和实时性能方面表现优异，能够在边缘设备上实现对弱势道路使用者的可靠检测，特别是在学校区域、自主导航和智慧城市基础设施中。

Conclusion: 该研究为智能交通系统提供了一种实用且可扩展的解决方案，专门针对年轻和小型弱势道路使用者的热成像检测，在恶劣环境条件下具有创新性和实际应用价值。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [21] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 这篇综述论文分析了无人机在AEC+FM领域基础设施检测中的应用，总结了数据采集、建模、缺陷检测和决策支持的方法，提出了融合多模态数据的框架，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机正在改变基础设施检测方式，但现有方法在实时处理、多模态数据融合和泛化能力方面仍面临挑战，需要系统性的工作流程框架来提升检测的准确性和可靠性。

Method: 综合分析了150多项研究，提出集成RGB图像、LiDAR和热感应的多模态数据融合框架，采用基于Transformer的架构，结合动态路径规划优化检测流程。

Result: 无人机在结构健康监测、灾害响应、城市基础设施管理、能源效率评估和文化遗产保护等方面已证明价值，提出的框架能有效检测结构缺陷、热异常和几何不一致问题。

Conclusion: 未来研究方向包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合，以进一步优化现代基础设施检测流程。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [22] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX是一个新型医学视觉语言模型解释框架，通过多尺度注意力、文本引导空间先验和层一致性分析，生成精确、稳定且临床相关的梯度归因图，提升放射学AI的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型解释方法存在空间不精确、缺乏解剖学基础、注意力粒度有限等关键限制，难以提供忠实且临床有意义的解释，阻碍了放射学AI应用的信任和透明度。

Method: MATEX结合多层注意力展开、文本引导空间先验和层一致性分析，通过解剖学信息空间推理生成精确的梯度归因图，解决了现有方法的局限性。

Result: 在MS-CXR数据集上评估，MATEX在空间精确性和与专家标注结果的对齐方面均优于最先进的M2IB方法，证明了其优越性能。

Conclusion: MATEX能够提供更忠实和可解释的模型解释，有潜力增强放射学AI应用的信任和透明度，为医学视觉语言模型的临床部署提供了重要支持。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [23] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合外围低分辨率场景要点信息和注视点高分辨率信息，生成与人类潜在场景表征对齐的图像变形体，用于研究人类场景理解机制。


<details>
  <summary>Details</summary>
Motivation: 人类视觉系统通过结合外围低分辨率"要点"信息和注视点高分辨率信息来构建连贯的场景理解。为了研究这种人类场景表征机制，需要生成与人类潜在场景表征对齐的图像。

Method: 开发MetamerGen——一种潜在扩散模型，采用双流表示方法：使用DINOv2令牌融合注视区域的详细特征和外围退化的场景上下文特征，解决从高分辨率（注视）和低分辨率（外围）输入生成图像的新颖图像合成问题。

Result: 通过相同-不同行为实验验证，MetamerGen生成的图像在感知上与人类潜在场景表征对齐，能够生成真正的场景变形体。分析发现，当生成场景以观看者自身注视区域为条件时，高级语义对齐最能预测变形体性质。

Conclusion: MetamerGen是理解场景理解的强大工具，概念验证分析揭示了在多个视觉处理层次上影响人类判断的具体特征，为研究人类视觉场景表征机制提供了新方法。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [24] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 论文介绍了共形点和校准圆锥的概念及其相互关系，这些概念有助于图像几何的可视化，并为计算图像中的角度和方向提供了直观方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发更直观的几何可视化工具，特别是在图像几何分析中，帮助理解和计算角度、方向等几何属性。

Method: 通过引入共形点和校准圆锥的数学概念，建立它们之间的关系，并将其应用于图像几何分析中。

Result: 提出了基于共形点和校准圆锥的几何可视化框架，能够直观地计算图像中的角度和方向等几何信息。

Conclusion: 共形点和校准圆锥为图像几何分析提供了有效的可视化工具，简化了几何计算过程，具有实际应用价值。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [25] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

TL;DR: 该研究利用手写运动作为行为生物特征，通过训练浅层循环神经网络来区分真实人类手写与人工合成的手写轨迹，在多个数据集和合成器上取得了优异的检测性能。


<details>
  <summary>Details</summary>
Motivation: 手写运动可以作为独特的行为生物特征来验证设备或应用的真实用户身份，这本质上是一个反向图灵测试——计算机需要检测输入是由人类还是人工生成的。研究旨在为需要验证人类存在的计算机系统提供额外安全层。

Method: 使用10个公开手写符号数据集（包括孤立字符、数字、手势、指向轨迹和签名），通过7种不同的合成器（包括运动学理论Sigma h模型、生成对抗网络、Transformers和扩散模型）人工重现。训练一个浅层循环神经网络，使用非特征化的轨迹数据作为输入进行检测。

Result: 模型在所有合成器和数据集上平均达到98.3%的ROC曲线下面积（AUC）和1.4%的等错误率。在少样本设置中，仅使用10%的数据训练就能在剩余90%的测试数据上取得优异性能。在域外设置中也表现出非常有竞争力的结果。

Conclusion: 该研究展示了利用手写运动作为行为生物特征来检测人工合成手写的有效性，为计算机系统验证人类存在提供了额外安全层，能够有效防范攻击者。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [26] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的半监督域泛化方法，通过将模型中间特征与视觉语言模型的语义丰富特征空间对齐来提升域不变性，结合数据增强和正则化策略实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确性而忽视训练数据的最大化利用，限制了性能提升潜力。作者认为需要重新思考SSDG问题的核心挑战。

Method: 1）将模型中间特征与视觉语言模型的语义丰富、泛化性强的特征空间对齐以促进域不变性；2）采用有效的图像级增强和输出级正则化策略来提高数据利用率和减少过拟合。

Result: 在四个基准测试上与现有SSDG基线方法对比，该方法在定性和定量上都达到了最先进的性能表现。

Conclusion: 通过特征对齐、数据增强和正则化的综合策略，实现了对SSDG问题的新颖解决方案，在多个基准上取得最优结果，代码将公开。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [27] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: 本文提出了SpaRRTa基准测试，用于评估视觉基础模型的空间关系识别能力，揭示现有模型在空间推理方面的显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型（如DINO和CLIP）在语义理解方面表现出色，但空间推理能力有限，这限制了它们在具身系统中的应用。虽然已有研究将3D任务（如深度估计）纳入训练，但模型在其他空间任务上的表现不一致，需要评估这些模型是否真正具备空间感知能力。

Method: 提出了空间关系识别任务（SpaRRTa）基准测试，生成大量具有可控物体布局的逼真图像和空间标注，用于评估视觉基础模型识别图像中物体相对位置的能力。

Result: 对多种最先进的视觉基础模型进行评估，揭示了它们在空间推理能力上存在显著差异，并分析了支持或阻碍空间感知的机制。

Conclusion: SpaRRTa基准测试有助于指导未来具备空间感知能力的视觉模型的发展，为评估和提升模型的空间理解能力提供了有效工具。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [28] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出一种解耦分类架构的视觉搜索系统，使用无分类区域提议和统一嵌入进行相似性检索，并结合LLM作为评估框架来提升电商风格驱动领域的搜索质量


<details>
  <summary>Details</summary>
Motivation: 现有电商视觉搜索系统通常将目标检测与基于分类法的分类耦合，并依赖可能有噪声的目录数据进行评估，这限制了系统的鲁棒性和可扩展性

Method: 1. 分类解耦架构：使用无分类区域提议和统一嵌入进行相似性检索；2. LLM-as-a-Judge框架：以零样本方式评估查询-结果对的细微视觉相似性和类别相关性

Result: 在全球家居用品平台上大规模部署后，系统提高了检索质量，带来可测量的客户参与度提升，离线评估指标与真实世界结果强相关

Conclusion: 该解耦架构结合LLM评估框架为电商视觉搜索提供了更灵活、可泛化的解决方案，有效克服了传统方法的评估瓶颈和噪声限制

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [29] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

TL;DR: 本文提出studentSplat，一种用于单视图3D场景重建的3D高斯泼溅方法，通过教师-学生架构和推断网络解决单视图的尺度模糊和推断问题。


<details>
  <summary>Details</summary>
Motivation: 单视图3D场景重建因单视图固有的模糊性而研究不足，现有方法主要关注多视图3D场景重建或单视图3D物体重建，但单视图3D场景重建仍面临尺度模糊和推断困难的问题。

Method: 1) 教师-学生架构：多视图教师模型在训练期间为单视图学生模型提供几何监督，解决尺度模糊并确保几何有效性；2) 推断网络：完成缺失的场景上下文，实现高质量的外推。

Result: studentSplat在单视图新视角重建质量上达到最先进水平，在场景级别上与多视图方法性能相当，同时在自监督单视图深度估计任务上也表现出竞争力。

Conclusion: studentSplat是一种有效的单视图3D高斯泼溅方法，能够解决单视图重建中的尺度模糊和推断问题，为通用单视图3D理解任务展示了潜力。

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [30] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集来训练目标检测器的新方法，使用CycleGAN和AdaIN进行无监督图像翻译，相比现有特征对齐方法更简单、可解释性更强。


<details>
  <summary>Details</summary>
Motivation: 当前无监督域自适应目标检测方法主要采用中间特征对齐，虽然效果好但实现复杂、难以解释，且性能仍与目标域训练的上界有差距。需要一种更简单、更可解释且能进一步提升性能的方法。

Method: 使用CycleGAN和AdaIN两种无监督图像翻译模型，仅利用源域标注数据和目标域非标注数据，生成目标域的人工数据集，然后在该数据集上训练目标检测器。

Result: 在自动驾驶真实场景实验中，该方法显著提升性能，在多数情况下超越现有最先进方法，进一步缩小了与目标域训练上界的差距。

Conclusion: 通过生成目标域人工数据集的方法，提供了一种比特征对齐更简单、更可解释且更有效的无监督域自适应解决方案，在真实场景中取得了优异效果。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [31] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 本研究提出了一种基于F.A.S.T.评估的多模态深度学习框架，用于快速、无创的卒中筛查，通过融合面部表情、语音信号和上半身运动信息，在自收集数据集上达到95.83%准确率。


<details>
  <summary>Details</summary>
Motivation: 早期识别卒中症状对于及时干预和改善患者预后至关重要，尤其是在院前环境中。当前需要快速、非侵入性的自动筛查方法来提高诊断的鲁棒性。

Method: 提出多模态深度学习框架：1) 面部动态使用基于关键点的特征和Transformer架构捕捉时间依赖；2) 语音信号转换为梅尔频谱图，使用Audio Spectrogram Transformer处理；3) 上半身姿态序列使用MLP-Mixer网络分析时空运动模式；4) 通过注意力融合机制整合多模态特征。

Result: 在包含222个视频、37名受试者的自收集数据集上，多模态模型性能优于单模态基线，达到95.83%准确率和96.00% F1分数，成功检测出测试集中所有卒中病例，在敏感性和特异性间取得良好平衡。

Conclusion: 研究证明了多模态学习和迁移学习在早期卒中筛查中的潜力，但强调需要更大、更具临床代表性的数据集来支持可靠的现实世界部署。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [32] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: 提出RemoteVAR框架，基于视觉自回归模型进行遥感变化检测，通过多分辨率融合特征和交叉注意力机制解决自回归模型在密集预测任务中的局限性，在标准基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感变化检测在环境监测和灾害评估中很重要，但现有的视觉自回归模型在像素级判别任务中存在可控性弱、密集预测性能不佳和暴露偏差等问题，需要专门针对变化检测任务的改进。

Method: 通过交叉注意力将自回归预测条件化于多分辨率融合的双时相特征，并设计了专门用于变化图预测的自回归训练策略，构建了RemoteVAR框架。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散模型和Transformer的基线方法取得了一致且显著的改进，为遥感变化检测提供了有竞争力的自回归替代方案。

Conclusion: RemoteVAR成功解决了视觉自回归模型在密集预测任务中的局限性，为遥感变化检测任务提供了一个有效的自回归框架，代码将开源供社区使用。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [33] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 基于EfficientNetB4的双任务模型，同时实现空中物体分类和威胁等级预测，在自建AODTA数据集上分别达到96%和90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着商用飞机、无人机等空中平台的快速普及，对实时自动威胁评估系统的需求日益增长。现有方法依赖人工监控，存在可扩展性差和操作效率低的问题。

Method: 提出基于EfficientNetB4的双任务模型，同时执行空中物体分类和威胁等级预测。为解决数据稀缺问题，整合多个公开源构建了AODTA数据集。在AVD数据集和AODTA数据集上进行基准测试，并与ResNet-50基线模型对比。

Result: EfficientNetB4模型在物体分类上达到96%准确率，威胁等级预测达到90%准确率，均优于ResNet-50基线模型。虽然标题提及检测，但研究聚焦于使用已有数据集提供的预定位图像进行分类和威胁推断。

Conclusion: 该双任务模型展示了在监视、防御和空域管理应用中的潜力，通过高效的同时分类和威胁评估，可提升自动化监控系统的效率。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [34] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究探讨了光强编码函数对中心/周边视网膜模型颜色恒常性性能的影响，发现Naka-Rushton函数结合双对立色平面表示能提供最佳的颜色辨别性能。


<details>
  <summary>Details</summary>
Motivation: 颜色是物体识别等视觉功能的重要信息来源，但易受光照颜色影响。颜色恒常性是视觉系统使用颜色信息的重要特性，而中心/周边视网膜模型是受视觉神经系统颜色恒常性启发的经典模型。本研究旨在探究不同光强编码函数对该模型颜色恒常性性能的影响。

Method: 使用两种光强编码函数：原始C/S视网膜模型中的对数函数和视网膜光感受器响应模型Naka-Rushton函数。使用可变颜色LED以不同光照颜色照射视觉目标，通过各模型计算的颜色信息评估对不同光照下目标颜色的辨别能力。颜色信息采用HSV色彩空间和基于经典对立色理论的色彩平面表示。

Result: 结果显示，Naka-Rushton函数与双对立色平面表示的组合提供了最优异的颜色辨别性能。

Conclusion: 对于中心/周边视网膜模型的颜色恒常性性能，Naka-Rushton光强编码函数结合双对立色平面表示是最有效的组合，这为改进基于颜色恒常性的视觉系统提供了重要参考。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [35] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: 提出一种无需训练的开放词汇目标检测方法GW-VLM，通过多尺度视觉语言搜索和上下文概念提示，结合预训练的视觉语言模型和大语言模型实现"猜猜看"式的目标检测


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法通常忽视根据预训练基础模型建立对任何对象认知的通用理解。尽管大规模预训练已构建了具有零样本能力的多功能基础模型，但如何利用这些模型形成通用理解范式仍被忽略

Method: 提出GW-VLM框架，包含：1) 多尺度视觉语言搜索(MS-VLS)：利用类无关目标检测结果，通过多尺度视觉语言软对齐生成片段；2) 上下文概念提示(CCP)：基于MS-VLS形成概念流，使大语言模型理解片段以进行开放词汇检测

Result: 在自然场景数据集(COCO val、Pascal VOC)和遥感数据集(DIOR、NWPU-10)上的实验表明，GW-VLM无需任何训练步骤即可实现优于现有最先进方法的开放词汇检测性能

Conclusion: GW-VLM通过创新的"猜猜看"范式，成功将预训练的视觉语言模型和大语言模型结合，实现了无需训练的开放词汇目标检测，为通用对象理解提供了新思路

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [36] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

TL;DR: 紧凑型CNN在孟加拉国五个现实图像数据集上表现出高分类精度、快速收敛和低计算开销，适合小类图像分类任务。


<details>
  <summary>Details</summary>
Motivation: 传统CNN在图像识别任务中表现优异，但架构复杂，在小数据集上容易过拟合。本研究旨在评估紧凑型CNN在小类图像分类任务中的适用性。

Method: 使用紧凑型卷积神经网络在五个孟加拉国公开现实图像数据集上进行评估，数据集包括城市侵占、车辆检测、道路损坏和农业作物等场景。

Result: 模型表现出高分类准确率、高效收敛和低计算开销。定量指标和显著性分析表明模型能有效捕捉判别性特征，在不同场景中具有良好泛化能力。

Conclusion: 流线型CNN架构适合小类图像分类任务，在现实世界应用中表现出鲁棒性和实用性。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [37] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩子空间干预来消除人脸伪造检测中虚假相关性的方法，只需0.43M可训练参数就在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 人脸伪造检测的泛化问题源于虚假相关性因素（伪造无关信息）通过"后门路径"导致有偏学习。现有方法需要识别具体的虚假相关性并设计针对性解决方案，但虚假相关性源于不可观测的混杂因素，逐一识别和处理不切实际。

Method: 提出表示空间干预范式：将各种实例级虚假相关性统一建模为低秩子空间进行干预。通过正交低秩投影将虚假相关特征分解到低秩子空间，从原始表示中移除该子空间，训练其正交补空间来捕捉伪造相关特征。低秩投影移除有效消除了虚假相关性因素。

Result: 仅需0.43M可训练参数就在多个基准测试中达到最先进性能，表现出优秀的鲁棒性和泛化能力。

Conclusion: 通过将虚假相关性统一建模为低秩子空间并进行干预，能够有效消除伪造无关信息的影响，使分类决策基于真实的伪造线索，解决了人脸伪造检测的泛化问题。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [38] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 使用Gabor滤波器作为CNN预处理，可提升边缘设备上机器人视觉应用的准确性和泛化性能，同时减少模型大小


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需要小型架构，机器人视觉应用需要在有限数据条件下高效训练。视觉神经系统（VNS）从少量视觉经验中学习的能力符合这些要求

Method: 使用Gabor滤波器（VNS特征提取器模型）作为CNN的预处理，在有限条件下采集的图像数据集上训练CNN，评估其在不同条件下的泛化能力

Result: Gabor滤波器预处理显著提升了CNN的泛化性能，并有助于减小CNN的规模

Conclusion: 仿生视觉处理（Gabor滤波器）是提升边缘设备CNN性能的有效方法，特别适合数据有限的机器人视觉应用

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [39] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene提出了一种为SfM优化的图像检索方法，通过子图训练策略和DiVLAD聚合器学习更具几何匹配性的全局描述符，在GL3D数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的图像检索方法主要关注语义相似性，而SfM中更需要关注几何匹配性的图像对。传统方法使用二分类（重叠vs非重叠）监督过于粗糙，无法捕捉几何关系的细微差异。

Method: 1) 子图训练策略：超越孤立图像对，利用带权重的几何重叠关系进行细粒度监督，使用软监督对比损失；2) DiVLAD聚合器：基于DINO的VLAD聚合器，利用ViT最后一层的多头注意力图；3) 可学习门控机制：自适应融合语义显著线索和视觉特征，生成更具判别性的全局描述符。

Result: 在GL3D数据集上达到最先进性能，显著优于NetVLAD，同时仅增加少量可训练参数。提出的训练策略在不同聚合技术上都带来一致性能提升。

Conclusion: SupScene通过细粒度几何监督和注意力引导的特征聚合，为SfM任务提供了更有效的图像检索解决方案，在保持参数效率的同时显著提升性能。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [40] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: LMGait：一种语言引导和运动感知的步态识别框架，通过步态相关语言提示来捕捉关键运动特征，解决现有方法过度拟合静态噪声的问题。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法通常依赖复杂架构直接从图像提取特征，并通过池化操作获得序列级表示。这种设计容易过度拟合静态噪声（如服装），同时未能有效捕捉动态运动区域。

Method: 提出LMGait框架，利用设计的步态相关语言提示来捕捉步态序列中的关键运动特征。通过语言引导和运动感知机制改进特征提取。

Result: 从摘要中未提供具体实验结果，但该方法旨在解决现有步态识别方法的局限性，特别是对静态噪声的过度拟合问题。

Conclusion: LMGait框架通过语言引导和运动感知方法，能够更有效地捕捉步态序列中的动态运动特征，减少对静态噪声的依赖，提升步态识别性能。

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [41] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

TL;DR: 本文提出了一种用于早产儿脑MRI白质和灰质分割的Hierarchical Dense Attention Network，通过3D空间-通道注意力机制和注意力引导的密集上采样策略，解决了早产儿脑组织等信号强度下的分割难题。


<details>
  <summary>Details</summary>
Motivation: 早产儿面临神经发育迟缓的高风险，需要早期识别和干预。虽然基于深度学习的脑MRI体积分割为评估新生儿神经发育提供了有前景的途径，但由于早产儿早期脑发育过程中白质和灰质在MRI上具有相似的信号强度（等信号表现），实现准确分割仍然具有挑战性。

Method: 提出了一种名为Hierarchical Dense Attention Network的新型分割神经网络。该架构结合了3D空间-通道注意力机制和注意力引导的密集上采样策略，以增强低对比度体积数据中的特征区分能力。

Result: 定量实验表明，该方法在分割性能上优于最先进的基线方法，有效解决了等信号组织区分的挑战。应用该算法证实，早产儿的白质和灰质体积显著低于足月儿，为早产相关的神经发育迟缓提供了额外的影像学证据。

Conclusion: 该研究提出的Hierarchical Dense Attention Network能够有效解决早产儿脑MRI中白质和灰质等信号强度下的分割难题，为早产儿神经发育评估提供了可靠的工具，并证实了早产儿脑组织体积减少的影像学特征。

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [42] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 本文提出针对盒自由模型水印解码器的梯度攻击防御机制DGS，通过重定向和缩放梯度来防止水印移除器训练收敛，在多种应用场景中实现100%防御成功率。


<details>
  <summary>Details</summary>
Motivation: 当前盒自由模型水印技术主要关注编码器的鲁棒性，而解码器被忽视，存在通过查询响应获取梯度来训练水印移除器的攻击。需要保护解码器免受此类梯度泄露攻击。

Method: 提出Decoder Gradient Shields (DGS)防御机制家族，包括输出层DGS-O、输入层DGS-I和层间DGS-L。DGS-O有闭式解，所有DGS都有可证明的性能保证。通过对水印通道梯度泄露查询的梯度进行重定向和缩放联合设计，防止水印移除器达到低损失值训练收敛。

Result: 在去雨和图像生成任务中使用最先进的盒自由水印技术进行实验，DGS在所有设置下均实现100%的防御成功率，同时保持解码器输出的图像质量。

Conclusion: DGS机制有效解决了盒自由模型水印解码器的梯度攻击问题，为深度神经网络知识产权保护提供了可靠的防御方案，在多种应用场景中展现了卓越的防御性能。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [43] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 本文提出了一种在树莓派5边缘设备上部署的实时多模态视觉框架，通过自适应调度机制集成目标检测、人脸识别和情绪分析，相比连续处理减少65%计算负载。


<details>
  <summary>Details</summary>
Motivation: 现有智能监控系统通常独立处理感知任务（如目标检测、人脸识别、情绪分析），缺乏统一的、基于上下文触发的自适应运行时调度器，这限制了系统在低功耗边缘设备上的整体理解能力和效率。

Method: 1. 集成目标检测（YOLOv8n）、特定人脸识别（基于FaceNet的自定义嵌入系统）和情绪检测（DeepFace CNN）的统一流水线；2. 核心是自适应调度机制，根据上下文触发选择性地激活不同模块；3. 部署在树莓派5边缘平台上。

Result: 1. 计算负载减少65%（相比连续处理）；2. 目标检测平均精度0.861；3. 人脸识别准确率88%；4. 情绪检测特定情绪的AUC高达0.97；5. 系统运行速度5.6帧/秒。

Conclusion: 上下文感知调度是实现低成本边缘硬件上复杂多模态AI的关键，使智能感知更易获得且更注重隐私保护。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [44] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: 本文提出AVIR框架解决多页文档视觉问答中的计算效率和注意力机制失效问题，通过轻量级检索模型评分、聚类筛选页面，无需微调大模型，减少70%页面需求，在多个基准上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 多页文档视觉问答面临两个主要挑战：1）长文档计算资源消耗大；2）注意力机制在大规模视觉语言模型中效率降低。需要一种既能减少计算成本又能保持性能的解决方案。

Method: 提出自适应视觉文档内检索（AVIR）框架：1）轻量级检索模型对每页进行问题相关性评分；2）根据评分分布进行页面聚类自适应选择相关内容；3）通过Top-K筛选保持上下文紧凑；4）短文档使用相关性概率阈值选择页面；5）仅将选定页面输入冻结的大规模视觉语言模型生成答案。

Result: 1）将问答所需平均页面数减少70%；2）在MP-DocVQA数据集上达到84.58%的ANLS分数，超越先前方法；3）计算成本显著降低；4）在SlideVQA和DUDE基准测试中也验证了有效性。

Conclusion: AVIR框架通过智能页面选择和检索机制，有效解决了多页文档视觉问答中的计算和注意力效率问题，无需微调大模型即可取得优异性能，为长文档理解提供了高效解决方案。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [45] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR是一个面向虚假新闻视频检测的测试时适应框架，通过检索引导的适应范式解决训练与测试新闻主题分布不一致的问题，能够适应新兴事件和未见主题的虚假新闻视频检测。


<details>
  <summary>Details</summary>
Motivation: 现有虚假新闻视频检测方法假设训练和测试阶段新闻主题分布一致，无法检测与新兴事件和未见主题相关的虚假新闻视频。这在实际应用中存在严重局限，因为虚假新闻往往围绕突发新闻事件传播。

Method: 提出RADAR框架，包含三个核心模块：1) 基于熵选择的检索机制，为目标域视频提供稳定（低熵）、相关的参考样本；2) 稳定锚点引导的对齐模块，通过分布级匹配将不稳定实例的表征与源域对齐；3) 目标域感知的自训练范式，生成由稳定参考增强的信息性伪标签，适应快速变化的标签分布。

Result: 大量实验表明，RADAR在测试时虚假新闻视频检测方面取得了优越性能，能够对未见虚假新闻视频主题实现强大的即时适应能力。

Conclusion: RADAR是首个支持测试时适应未见新闻视频的虚假新闻视频检测框架，通过创新的检索引导适应范式解决了领域适应中的关键挑战，为处理新兴事件和未见主题的虚假新闻检测提供了有效解决方案。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [46] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 该论文提出了一种基于AI-IoT的智能轮椅系统，整合了手势控制、物体检测、超声波避障和生命体征监测，旨在为残障和老年人提供经济实惠、安全的辅助移动方案。


<details>
  <summary>Details</summary>
Motivation: 残障人士和老年人口增长需要经济实惠的智能轮椅，传统轮椅缺乏动态功能，现有智能轮椅成本高、功能单一且健康监测集成不足。

Method: 采用模块化低成本架构，集成手套手势控制实现免手导航，使用YOLOv8进行实时物体检测并提供听觉反馈，超声波传感器用于即时碰撞避免，持续监测心率、血氧、心电图、体温等生命体征并上传至ThingSpeak平台。

Result: 手势控制成功率95.5%，超声波障碍检测准确率94%，YOLOv8物体检测精度91.5%、召回率90.2%、F1分数90.8%，系统有效增强了用户自主性和安全性。

Conclusion: 该集成多模态方法提供了实用、可扩展且经济实惠的解决方案，通过桥接创新研究与实际部署，显著提升了用户的自主性、安全性和独立性。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [47] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

TL;DR: 提出了一个结合解剖先验的结构图推理框架，用于可解释的视觉诊断，通过将卷积特征图重构为图结构并引入自定义结构传播机制，实现节点级病灶感知和图级诊断推理。


<details>
  <summary>Details</summary>
Motivation: 当前基于卷积神经网络的视觉诊断方法缺乏对解剖结构的显式建模和可解释性，无法提供结构化的推理过程。需要一种能够结合领域知识（如解剖先验）并提供内在可解释性的框架。

Method: 1. 将卷积特征图重新解释为补丁级图结构，节点编码外观和空间坐标，边反映局部结构邻接关系；2. 引入自定义结构传播机制，显式建模相对空间关系作为推理过程的一部分；3. 支持节点级病灶感知预测和图级诊断推理；4. 通过学习节点重要性分数实现内在可解释性，无需后处理可视化技术。

Result: 通过胸部X光案例研究验证了方法，展示了结构先验如何引导关系推理并提高可解释性。框架是领域无关的，适用于更广泛的基于图推理的人工智能系统。

Conclusion: 该工作为结构感知和可解释学习提供了图作为计算基板的新思路，通过结合解剖先验和自定义图推理机制，实现了既准确又可解释的视觉诊断方法，具有广泛的适用性。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [48] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

TL;DR: 本文针对驾驶员行为监测中相似动作难以区分的问题，提出了DAOS数据集和AOR-Net模型，通过建模人-物关系实现细粒度行为识别。


<details>
  <summary>Details</summary>
Motivation: 驾驶员行为监测中，上半身动作相似度高，传统方法难以区分。人类区分这些动作依赖于物体信息（如手机vs方向盘），但现有数据集缺乏准确的物体位置标注或未将物体与动作关联，限制了可靠的行为识别。

Method: 1. 提出DAOS数据集：包含9,787个视频片段，标注36种细粒度驾驶员行为和15种物体类别，总计超过250万个物体实例，提供多模态（RGB、IR、深度）和多视角（前、面部、左、右）数据。
2. 提出AOR-Net模型：通过多层次推理和链式动作提示机制建模动作、物体及其关系的逻辑关联；引入Mixture of Thoughts模块动态选择各阶段关键知识，增强物体丰富和稀缺条件下的鲁棒性。

Result: 大量实验表明，AOR-Net模型在多个数据集上优于其他最先进方法。

Conclusion: 通过引入DAOS数据集和AOR-Net模型，有效解决了驾驶员行为监测中相似动作区分困难的问题，证明了建模人-物关系对于细粒度行为识别的重要性。

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [49] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: 本文提出了SMc2f方法，通过视觉语言模型粗过滤、建立案例数据库、文本-轨迹对比学习，显著提升了自动驾驶场景挖掘的检索质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有场景挖掘方法（如RefAV）存在局限性：依赖轨迹标签检索，忽略了自然语言与原始RGB图像的直接联系；依赖上游3D目标检测和跟踪的质量；轨迹数据不准确导致时空定位错误。这些问题影响了自动驾驶安全验证的可靠性。

Method: 提出粗到精的SMc2f管道：1）使用视觉语言模型进行粗粒度图像-文本过滤；2）在RefAV基础上构建成功挖掘案例数据库，自动检索示例进行少样本学习；3）引入文本-轨迹对比学习，在共享嵌入空间中拉近匹配对、推开不匹配对，生成细粒度匹配器来优化LLM的候选轨迹。

Result: 在公开数据集上的实验表明，该方法在检索质量和效率方面都取得了显著提升。

Conclusion: SMc2f方法通过结合视觉语言模型和对比学习，解决了现有场景挖掘方法的局限性，为自动驾驶安全验证提供了更鲁棒的场景检索解决方案。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [50] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion混合深度学习模型，用于SAR图像中的溢油分割，结合SegNet和DeepLabV3+并加入注意力特征融合机制，显著提高边界精度和上下文理解，减少误报率。


<details>
  <summary>Details</summary>
Motivation: 传统阈值方法在卫星图像溢油检测中因风滑、船迹等类似现象导致误报率过高，性能下降，需要更准确、稳定的检测方法。

Method: 提出DeepSegFusion混合深度学习模型，集成SegNet和DeepLabV3+架构，并加入基于注意力的特征融合机制，以提升边界精度和上下文理解能力。

Result: 在SAR溢油数据集（包括ALOS PALSAR）上达到94.85%准确率、IoU 0.5685、ROC-AUC 0.9330，相比基线模型和传统方法减少64.4%误报，误检减少超三倍。

Conclusion: DeepSegFusion在不同海洋条件下表现稳定，适用于近实时溢油监测场景，显著提升检测性能并大幅降低误报。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [51] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS：一个数据高效框架，仅需极少监督（少至10张图像）即可实现高保真半透明物体重建，通过扩散模型生成高质量数据增强，结合几何先验提升重建稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前神经渲染中建模次表面散射（SSS）效果面临两大挑战：复杂的光传输需要密集的多视角多光照数据集（通常需要100+视角和112个OLAT），数据采集成本极高。需要开发能够在极稀疏监督下实现高质量半透明重建的方法。

Method: 1）微调扩散模型用于新视角合成和重光照，仅需不到7%的数据集进行训练，生成可替代95%缺失采集的光照真实增强数据；2）引入光照无关的几何先验：多视角轮廓一致性损失和多视角深度一致性损失，以稳定稀疏或合成监督下的重建。

Result: 在所有稀疏度情况下，DIAMOND-SSS在可重光照的高斯渲染中实现了最先进的质，相比SSS-3DGS将实际采集需求减少了高达90%。

Conclusion: DIAMOND-SSS通过结合扩散模型生成的数据增强和光照无关的几何先验，显著降低了高质量半透明物体重建的数据采集需求，实现了在极稀疏监督下的高保真重建。

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [52] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic是一个新颖的模型无关框架，通过逻辑表示解释和量化视觉模型决策，识别最小可解释视觉区域子集（视觉焦点），并将其转化为精确紧凑的逻辑表达式。


<details>
  <summary>Details</summary>
Motivation: 现代视觉模型的可解释性在关键应用中至关重要，但现有方法要么依赖白盒模型访问，要么缺乏定量严谨性。

Method: 开发模型无关框架，识别对模型预测有决定性影响的最小可解释视觉区域子集（视觉焦点），将其转化为精确的逻辑表达式，并提出焦点精度、召回率和散度等定量评估指标。

Result: 经验分析表明FocaLogic能够揭示训练导致的集中、通过泛化提高焦点准确性，以及在偏见和对抗攻击下的异常焦点等关键见解。

Conclusion: FocaLogic为解释视觉模型提供了一个系统化、可扩展且定量的解决方案。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [53] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: 提出了Masked Jigsaw Puzzle (MJP)框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩盖打乱token的位置信息，从而增强Transformer在联邦学习中对梯度攻击的防御能力，同时提升模型在CV和NLP任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，Transformer面临梯度攻击的威胁，研究发现位置嵌入的梯度包含足够信息可用于重建输入数据。需要一种既能防御梯度攻击又能提升模型性能的解决方案。

Method: 提出Masked Jigsaw Puzzle (MJP)框架：1) 随机打乱token顺序破坏原始顺序；2) 使用可学习的未知位置嵌入掩盖打乱token的位置信息；3) 迫使模型学习不依赖局部空间信息的特征表示。

Result: 实验结果表明，MJP不仅能提高模型对梯度攻击的鲁棒性，还能提升模型在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）等任务中的性能，是一个适用于不同Transformer模型的统一框架。

Conclusion: MJP框架通过破坏位置嵌入中的局部空间信息，有效防御梯度攻击并提升模型性能，为联邦学习中的Transformer模型提供了一个统一的解决方案。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [54] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一个任务驱动的多模态云去除框架，通过可学习退化提示融合SAR信息，同时进行云去除和土地覆盖分割，以生成分析就绪数据。


<details>
  <summary>Details</summary>
Motivation: 传统云去除方法过度关注低层保真度，会过度平滑对分析就绪数据至关重要的纹理和边界，导致视觉合理恢复与语义实用性之间的不匹配。

Method: 提出TDP-CR框架，包含提示引导融合机制（PGF），使用可学习退化提示编码云厚度和空间不确定性，结合全局通道上下文和局部提示条件空间偏置，仅在光学数据损坏区域自适应集成SAR信息。采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR以仅15%的参数超越最先进基线0.18 dB PSNR，在多任务竞争者中实现1.4%的mIoU提升，有效提供分析就绪数据。

Conclusion: TDP-CR通过任务驱动的多模态框架成功解决了云去除中视觉质量与语义实用性之间的差距，提供了一种高效生成分析就绪数据的方法。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [55] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

TL;DR: AUTO-DIP：基于图像元数据相似性的无监督深度图像先验参数自动迁移方法，用于荧光显微镜图像去噪


<details>
  <summary>Details</summary>
Motivation: 传统DIP方法需要针对每张新图像优化网络架构和停止点，耗时且不适用于需要处理大量图像的场景。作者假设相似图像在DIP去噪中具有可比的最优参数配置，希望实现荧光显微镜图像的免优化DIP去噪。

Method: 1. 从开源数据集生成校准集（110张）和验证集（55张）语义不同的图像；2. 针对U-net架构和停止点进行网络架构搜索；3. 开发AUTO-DIP管道，基于图像元数据相似性（显微镜类型、成像样本等）自动迁移参数；4. 与原始DIP配置和变分去噪方法进行比较。

Result: 1. 基于图像元数据相似性的参数迁移比基于定量图像相似性度量的迁移表现更好；2. AUTO-DIP在多个复杂度不同的开源测试数据集上优于基线DIP和变分去噪方法，特别是在噪声较大的输入上；3. 在本地采集的荧光显微镜图像上进一步证明了AUTO-DIP的优越性。

Conclusion: AUTO-DIP通过基于图像元数据相似性的参数自动迁移，成功实现了荧光显微镜图像的免优化DIP去噪，显著提高了处理效率并保持了去噪性能，为大规模荧光显微镜图像处理提供了实用解决方案。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [56] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

TL;DR: LSMRL是一种语言驱动的序列级模态不变表示学习方法，用于视频可见光-红外行人重识别，通过改进空间-时间建模、增强跨模态交互和引入模态级损失来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP语言提示的VVI-ReID方法在空间-时间建模效率、跨模态交互充分性和显式模态级损失指导方面存在局限性，需要更有效的模态不变表示学习方法。

Method: 提出LSMRL方法，包含三个模块：1) STFL模块基于CLIP进行参数和计算高效的空间-时间建模；2) SD模块将模态共享语言提示扩散到可见光和红外特征中建立初步模态一致性；3) CMI模块利用双向跨模态自注意力消除残留模态差异并细化模态不变表示。引入两种模态级损失增强特征判别能力和泛化能力。

Result: 在大规模VVI-ReID数据集上的广泛实验表明，LSMRL方法优于现有最佳方法(AOTA)。

Conclusion: LSMRL通过高效的空间-时间建模、充分的跨模态交互和显式的模态级损失指导，成功解决了VVI-ReID中的模态不变表示学习问题，取得了优异的性能。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [57] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于随机桥模型的视频到视频翻译方法，用于视频目标移除任务，通过利用输入视频作为结构先验，实现更精确的移除和逻辑一致的填充。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频目标移除方法从高斯噪声开始生成，丢弃了原始视频丰富的结构和上下文先验，导致目标移除不完整或生成内容与场景物理逻辑冲突。

Method: 将视频目标移除重新定义为通过随机桥模型的视频到视频翻译任务，建立从源视频（有目标）到目标视频（目标移除）的直接随机路径。提出自适应掩码调制策略，根据掩码特性动态调整输入嵌入，平衡背景保真度和生成灵活性。

Result: 大量实验表明，该方法在视觉质量和时间一致性方面显著优于现有方法。

Conclusion: 通过桥模型利用输入视频作为强结构先验，能够实现更精确的视频目标移除，同时确保填充区域与周围环境逻辑一致，解决了传统噪声初始化方法的局限性。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [58] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

TL;DR: ARMARecon：一种结合自回归移动平均图滤波和重构驱动目标的统一图学习框架，用于阿尔茨海默病和额颞叶痴呆的早期检测


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和额颞叶痴呆（FTD）等神经退行性疾病的早期检测对降低疾病进展风险至关重要。由于AD和FTD沿着白质区域以全局、图依赖的方式传播，基于图的神经网络适合捕捉这些模式。

Method: 提出ARMARecon统一图学习框架，集成自回归移动平均（ARMA）图滤波与重构驱动目标，增强特征表示并提高分类准确性。该方法利用从白质区域提取的20-bin分数各向异性（FA）直方图特征，有效建模局部和全局连接性，同时缓解过平滑问题。

Result: ARMARecon在ADNI和NIFD等多站点dMRI数据集上相比最先进方法实现了更优性能。

Conclusion: ARMARecon框架通过结合ARMA图滤波和重构目标，能够有效捕捉神经退行性疾病的传播模式，在早期检测任务中表现出优越性能。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [59] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 论文提出RS-RVOS Bench首个大规模遥感视频指代分割基准数据集，并设计MQC-SAM框架解决现有方法在复杂动态场景中的记忆偏差和错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 遥感视频指代分割面临目标显著性弱、视觉信息截断严重的问题，现有方法存在初始记忆构建偏差和记忆累积无差别的问题，导致复杂场景中实例定位不准确和错误传播。同时该领域缺乏大规模专用基准数据集。

Method: 提出MQC-SAM框架：1) 时间运动一致性模块进行初始记忆校准，利用短期运动轨迹先验修正结构偏差；2) 解耦注意力记忆整合机制，通过动态质量评估选择性更新高置信度语义特征，过滤不可靠信息。

Result: 构建了包含111个视频序列、约25,000帧图像和213,000个时间指代标注的RS-RVOS Bench数据集。在RS-RVOS Bench上的实验表明MQC-SAM达到了最先进的性能。

Conclusion: 通过构建首个大规模遥感视频指代分割基准数据集并提出基于记忆质量控制的在线指代分割框架，有效解决了复杂动态场景中的目标表示保持和错误传播问题，推动了该领域的研究进展。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [60] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: EmoLat是一种新颖的情感潜在空间，通过建模文本语义与视觉情感特征之间的跨模态关联，实现细粒度、文本驱动的图像情感迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法缺乏细粒度控制和文本引导能力，需要建立文本语义与视觉情感之间的有效关联机制，以实现更精确可控的情感迁移。

Method: 构建情感语义图捕捉情感、物体和视觉属性的关系结构；采用对抗正则化增强情感表示的判别性和可迁移性；提出跨模态情感迁移框架，通过文本和EmoLat特征的联合嵌入来操作图像情感；使用包含语义一致性、情感对齐和对抗正则化的多目标损失优化网络。

Result: 在构建的大规模基准数据集EmoSpace Set上的实验表明，该方法在定量指标和定性迁移保真度上均显著优于现有最先进方法，为文本引导的可控图像情感编辑建立了新范式。

Conclusion: EmoLat成功实现了细粒度、文本驱动的图像情感迁移，通过建模跨模态情感关联和构建大规模标注数据集，为可控图像情感编辑提供了有效解决方案。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [61] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: 提出FCLM模型，通过深度感知蒸馏、域不变学习和面向对象解码器，解决高精度场景解析中的类别泛化、数据稀缺和交互预测问题。


<details>
  <summary>Details</summary>
Motivation: 现有高精度场景解析方法主要针对单个显著前景对象，交互方法类别无关设计限制跨类别泛化，且高质量标注稀缺导致依赖不和谐的合成数据，对真实场景泛化能力差。

Method: 提出前景一致学习模型FCLM：1) 深度感知蒸馏策略，传递深度相关知识改善前景表示；2) 将合成数据处理视为域适应问题，提出域不变学习策略聚焦前景学习；3) 面向对象解码器，可接收视觉和语言提示预测参考目标。

Result: 实验结果表明，该方法在定量和定性评估上均优于现有最先进方法。

Conclusion: FCLM模型通过整合深度感知知识、域不变学习和多模态交互能力，有效解决了高精度场景解析中的关键挑战，提升了模型的泛化性能和实用性。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [62] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 提出HistoCRF框架，通过条件随机场（CRF）优化组织病理学图像中视觉语言模型（VLM）的零样本预测，无需额外训练，利用标注信息提升分类准确率。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像分析对癌症检测和分期具有重要临床价值。虽然视觉语言模型（VLM）在组织病理学领域展现出强大的零样本预测能力，但其预测结果仍不完美，需要进一步优化。

Method: 提出HistoCRF框架，将条件随机场（CRF）适配到组织病理学应用中。引入新的成对势能定义，促进标签多样性并利用专家标注。设计了三种实验设置：无标注、有专家标注、以及迭代式人机交互标注。

Result: 在五个涵盖不同器官和疾病的补丁级分类数据集上，相比零样本预测：无标注时平均准确率提升16.0%；仅用100个标注时提升27.5%；人机交互迭代标注进一步将提升幅度提高到32.6%。

Conclusion: HistoCRF能有效优化组织病理学基础模型的零样本预测，显著提升分类准确率，且支持人机交互迭代优化，具有重要临床应用价值。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [63] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

TL;DR: 本文提出了一种基于大语言模型和多模态视觉模型的智能体框架，用于在自动驾驶车辆中动态生成和调整行为树，以应对不可预测的真实环境。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要自适应行为规划器来安全导航不可预测的真实环境。传统行为树虽然提供结构化决策逻辑，但本质上是静态的，需要大量人工调整，限制了其在SAE Level 5自动驾驶中的应用。

Method: 采用基于大语言模型和多模态视觉模型的智能体框架：1) 描述器智能体使用符号链提示评估场景关键性；2) 规划器智能体通过上下文学习构建高级子目标；3) 生成器智能体以XML格式合成可执行的行为树子树。系统集成到CARLA+Nav2仿真中，仅在基线行为树失败时触发。

Result: 系统成功实现了在遇到意外障碍物（如街道堵塞）时的自主导航，无需人工干预。与静态行为树基线相比，该方法作为概念验证可扩展到多样化的驾驶场景。

Conclusion: 该智能体框架通过动态生成和调整行为树，为自动驾驶车辆在不可预测环境中的自适应导航提供了可行的解决方案，克服了传统静态行为树的局限性。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [64] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

TL;DR: 提出一种针对工业料箱的6DoF位姿估计方法，利用料箱的立方体几何特性，通过检测3D线段并几何处理来估计位姿，无需实例特定的CAD模型。


<details>
  <summary>Details</summary>
Motivation: 传统6DoF物体位姿估计方法需要大量训练数据或CAD模型，限制了在数据稀缺、物体实例多变的工业场景中的应用。工业料箱具有标准化的立方体几何特征，为简化位姿估计提供了机会。

Method: 利用料箱的立方体几何特性，首先检测对应料箱顶边的3D线段。将2D线段检测网络LeTR扩展到结构化点云数据，然后通过简单的几何处理流程从检测到的3D线段中鲁棒地确定料箱的6DoF位姿。

Result: 通过扩展现有数据集并收集新数据集进行评估。实验表明，加入合成训练数据显著提高了真实扫描的位姿估计精度。方法在精度上显著优于当前最先进的6DoF位姿估计方法（3 cm平移误差，8.2°旋转误差），且推理时不需要实例特定的CAD模型。

Conclusion: 该方法针对工业料箱的几何特性，提出了一种有效且实用的6DoF位姿估计方案，克服了传统方法对大量数据和CAD模型的依赖，在工业自动化场景中具有良好应用前景。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [65] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

TL;DR: CD-TWINSAFE是一个基于V2I的数字孪生系统，用于自动驾驶车辆，通过实时同步车载感知数据与虚拟仿真环境，实现安全预警


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶车辆开发一个数字孪生安全系统，通过V2I通信将真实驾驶环境与虚拟仿真同步，实现实时安全监控和预警

Method: 采用双栈架构：车载驾驶栈（包含立体相机进行场景理解）和数字孪生栈（运行Unreal Engine 5场景副本）。车载栈实现定位和感知模块，通过ROS2消息和4G V2I通信将数据传输到基础设施侧的数字孪生系统

Result: 通过多种驾驶场景测试验证了该架构的有效性和实时响应能力

Conclusion: CD-TWINSAFE架构成功实现了自动驾驶车辆与数字孪生环境的实时同步，为V2I安全应用提供了有效解决方案

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [66] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

TL;DR: 使用知识蒸馏和集成学习将大型CNN模型压缩为轻量级模型，在咖啡叶病诊断中实现高精度低能耗


<details>
  <summary>Details</summary>
Motivation: 咖啡叶病诊断在田间面临挑战，AI视觉模型虽然准确率高，但受限于设备计算能力和网络连接问题，难以在实际场景中部署

Method: 采用知识蒸馏方法，通过集成学习将训练在数据中心的高容量CNN模型知识转移到紧凑CNN模型中，使用简单优化的集成策略增强准确性

Result: 在咖啡叶数据集上，蒸馏后的轻量级集成模型取得了与先前工作相当的准确率，同时显著降低了能耗和碳足迹

Conclusion: 经过适当蒸馏和集成的轻量级模型可以为物联网应用提供实用的诊断解决方案，平衡了准确性和资源约束

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [67] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ：一种视觉地点识别框架，通过残差引导的互补融合和基于查询的全局聚合，有效整合不同视觉基础模型的互补信息，在视角变化、光照变化和域偏移等挑战下实现鲁棒的全局表示。


<details>
  <summary>Details</summary>
Motivation: 现有视觉地点识别方法通常依赖单一视觉基础模型，忽略了不同模型提供的互补信息。然而，利用这些互补信息会改变token分布，挑战现有基于查询的全局聚合方案的稳定性。

Method: 提出DC-VLAQ框架：1）轻量级残差引导互补融合：以DINOv2特征空间为锚点，通过学习的残差校正注入CLIP的互补语义；2）局部聚合查询向量：基于查询-残差的全局聚合方案，通过token对可学习查询的残差响应来编码局部token，提高稳定性并保留细粒度判别线索。

Result: 在Pitts30k、Tokyo24/7、MSLS、Nordland、SPED和AmsterTime等标准VPR基准测试中，DC-VLAQ持续优于强基线，特别是在具有挑战性的域偏移和长期外观变化下达到最先进性能。

Conclusion: DC-VLAQ通过有效融合互补的视觉基础模型特征和设计稳定的全局聚合方案，解决了视觉地点识别中的表示鲁棒性问题，在多种挑战性场景下表现出优越性能。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [68] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

TL;DR: 提出RCDN网络，通过以真实图像为中心的表征空间来提升跨域伪造检测的泛化能力，在DiFF数据集上实现了最优的域内准确率和跨域泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有伪造检测方法在训练和测试域相同时表现优异，但在跨域场景下性能显著下降。随着新伪造技术不断涌现，检测器必须对未见过的篡改保持可靠性，这成为一个关键挑战。

Method: 提出Real-Centered Detection Network (RCDN)，采用Xception骨干网络的频域空间CNN框架。该方法不建模多样且不断演化的伪造模式，而是强调真实图像的一致性，通过双分支架构和以真实图像为中心的损失设计来增强分布偏移下的鲁棒性。

Result: 在DiFF数据集上对三种代表性伪造类型(FE, I2I, T2I)进行广泛实验，RCDN实现了最先进的域内准确率和显著更强的跨域泛化能力。相比领先基线，RCDN减少了泛化差距，并实现了最高的跨域/域内稳定性比率。

Conclusion: RCDN通过以真实图像为中心的表征空间，为防御不断演化和未见过的图像伪造技术提供了一个实用的解决方案，具有强大的跨域泛化能力。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [69] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP框架通过从全局匹配转向空间约束的patch级对应，解决了开放词汇6D姿态估计中的模糊性问题，使用patch相关性矩阵作为结构先验来过滤背景干扰。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中容易将目标特征与背景干扰混淆，导致匹配模糊和姿态估计性能下降。

Method: 提出FiCoP框架：1) 对象中心解耦预处理隔离语义目标与环境噪声；2) 跨视角全局感知模块融合双视角特征，通过显式上下文推理建立结构共识；3) Patch相关性预测器生成精确的块级关联图，作为空间过滤器实现细粒度、抗噪声匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP相比现有最优方法分别提高了8.0%和6.1%的平均召回率，展现了在复杂开放世界环境中的鲁棒泛化能力。

Conclusion: FiCoP通过引入patch级对应和空间约束匹配策略，有效解决了开放词汇6D姿态估计中的模糊性问题，为机器人在复杂开放世界环境中的感知提供了更鲁棒的解决方案。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [70] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: 提出了CARLA-Round数据集，这是一个专门用于环岛轨迹预测的系统化仿真数据集，包含25个控制场景，涵盖不同天气条件和交通密度水平，解决了现有环岛数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对于减少交通事故至关重要，但由于其环形几何结构、连续的交织让行交互以及缺乏交通信号而极具挑战性。现有数据集稀缺，真实世界数据收集存在观测不完整和混杂因素难以分离的问题。

Method: 开发了CARLA-Round数据集，采用系统化设计，在仿真环境中控制天气条件（5种类型）和交通密度水平（服务水平A-E），生成25个结构化场景。数据集包含真实的驾驶行为混合，并提供现有数据集缺乏的显式标注。

Result: 验证实验使用标准基线模型（LSTM、GCN、GRU+GCN）显示，交通密度对预测难度具有主导性的单调效应，而天气条件呈现非线性影响。最佳模型在真实世界rounD数据集上达到0.312m ADE，证明了有效的仿真到真实迁移。

Conclusion: CARLA-Round数据集通过系统化设计量化了在真实世界混杂数据集中无法分离的因素影响，为环岛轨迹预测研究提供了可靠、多模态、现实的仿真数据资源。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [71] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN：一个统一的隐式推理框架，通过预训练的视觉自回归器将想象的视觉token编码到紧凑的潜在空间，实现推理感知的实时视觉语言导航，相比显式CoT方法大幅降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航中的CoT推理方法存在两大问题：纯文本CoT缺乏空间基础且容易过拟合稀疏标注的推理步骤；多模态CoT通过生成想象的视觉观察导致严重的token膨胀，使得实时导航不切实际。

Method: 提出FantasyVLN框架，使用预训练的视觉自回归器将想象的视觉token编码到紧凑的潜在空间，在CoT推理训练中联合学习文本、视觉和多模态CoT模式，采用统一的多CoT策略。推理时直接进行指令到动作的映射，同时保持推理感知的表征。

Result: 在LH-VLN上的大量实验表明，该方法实现了推理感知的实时导航，提高了成功率和效率，相比显式CoT方法将推理延迟降低了一个数量级。

Conclusion: FantasyVLN框架通过隐式推理保留了CoT推理的优势，避免了显式token开销，为实时视觉语言导航提供了一种高效且有效的解决方案。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [72] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是一个轻量级的SAM扩展模型，能够同时进行高质量的交互式图像分割和抠图，通过MVLE和Local-Adapter模块提升细节精度。


<details>
  <summary>Details</summary>
Motivation: SAM在零样本泛化和灵活提示方面表现出色，但其掩码预测精度在实际应用中仍显不足。现有的细化模块难以在统一框架内实现高精度对象分割，且交互式图像抠图在SAM背景下尚未被探索。研究发现分割与抠图之间存在强相关性，因此需要开发一个能同时处理这两项任务的统一模型。

Method: 提出了SAMA，这是SAM的轻量级扩展。采用多视图定位编码器（MVLE）从局部视角捕捉细节特征，使用定位适配器（Local-Adapter）通过恢复细微边界细节来细化掩码输出。在架构中为每个任务集成了两个预测头，同时生成分割和抠图掩码。

Result: 在从公开来源聚合的多样化数据集上进行训练，SAMA在多个分割和抠图基准测试中取得了最先进的性能，展示了其在广泛下游任务中的适应性和有效性。

Conclusion: SAMA成功地将高质量的分割和抠图功能集成到一个轻量级统一框架中，通过MVLE和Local-Adapter模块显著提升了边界细节的恢复能力，为实际应用提供了更精确的图像处理解决方案。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [73] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

TL;DR: 提出THz-SSDD网络，基于PCA和自监督学习，无需标签图像即可同时处理太赫兹图像的低频模糊和高频噪声问题。


<details>
  <summary>Details</summary>
Motivation: 太赫兹系统固有的频率依赖性退化效应导致振幅图像出现低频模糊和高频噪声。传统图像处理方法无法同时解决这两个问题，且需要人工干预来确定去噪和去模糊的边界。

Method: 提出基于主成分分析（PCA）的太赫兹自监督去噪去模糊网络（THz-SSDD）。采用Recorrupted-to-Recorrupted自监督学习策略，通过利用重复损坏下的不变性来捕捉噪声的内在特征。然后应用PCA分解和重建来恢复低频和高频图像。

Result: 在四种样品上评估网络性能。训练仅需少量无标签噪声图像，在不同材料特性和测量模式的样品测试中显示出有效的去噪和去模糊效果。定量分析进一步验证了网络的可行性，在改善图像质量的同时保留了原始信号的物理特性。

Conclusion: THz-SSDD网络能够有效解决太赫兹图像的低频模糊和高频噪声问题，采用自监督学习减少了数据标注需求，在保持信号物理特性的同时显著提升图像质量。

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [74] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种空间和时间高效的推理策略，通过空间感知的邻近块稀疏化注意力，并通过全局注意力分数过滤非信息性标记，从而在高分辨率全玻片图像推理中大幅减少GPU内存和运行时间，同时保持甚至提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前病理学基础模型受限于特定输入尺寸（如224×224），应用于数千分辨率级别的全玻片图像时效率低下。简单的放大输入会导致GPU内存消耗过高，而下采样会改变像素分辨率并掩盖关键形态细节。

Method: 提出一种空间和时间高效的推理策略：1）使用空间感知的邻近块稀疏化注意力机制；2）通过全局注意力分数过滤非信息性标记。这种设计能在保持高分辨率推理的同时显著降低GPU内存和运行时间。

Result: 实验结果表明，该方法在ROI分类任务中实现了高达7.67%的性能提升，在分割任务中获得了兼容的结果，能够在相同GPU预算下实现更高分辨率的推理。

Conclusion: 该方法有效解决了病理学基础模型在全玻片图像推理中的效率问题，通过创新的注意力稀疏化和标记过滤策略，在减少计算资源消耗的同时保持甚至提升了模型性能，为高分辨率医学图像分析提供了实用解决方案。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [75] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

TL;DR: 提出一种利用持续同调先验的协作式逆渲染方法，通过拓扑约束解决3D重建中的几何、外观和拓扑歧义问题，特别针对高亏格曲面重建。


<details>
  <summary>Details</summary>
Motivation: 从图像重建3D物体本质上是病态问题，存在几何、外观和拓扑的多重歧义。现有方法在处理高亏格曲面时容易发生隧道塌陷或拓扑结构丢失等灾难性失败，需要更强的拓扑约束来指导重建过程。

Method: 提出协作式逆渲染框架，结合多视角图像的光度一致性和持续同调先验。利用持续同调捕捉关键拓扑特征（如隧道环、手柄环），在基于网格的逆渲染框架中通过梯度优化实现拓扑约束，而非依赖神经网络。

Result: 实验表明，加入持续同调先验的方法在Chamfer距离（CD）和体积IoU指标上优于最先进的基于网格的方法，展现出更高的几何精度和拓扑鲁棒性，能有效避免隧道塌陷和高亏格结构丢失。

Conclusion: 持续同调先验能有效解决3D重建中的拓扑歧义问题，特别是对于高亏格曲面。该方法通过拓扑约束与光度一致性协作，在基于网格的逆渲染框架中实现了更准确、更鲁棒的几何重建。

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [76] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: VIRTUE是一个基于多模态大语言模型的通用视频检索框架，整合了语料库级检索、时刻级检索和组合多模态查询能力，通过对比对齐和LoRA高效训练，在零样本视频检索任务上超越其他MLLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统存在局限性：专用架构虽然检索性能强，但无法处理组合多模态查询；而MLLM方法支持丰富多模态搜索，但检索性能远低于专用系统。需要开发一个既能处理多样化检索任务，又能保持高性能的单一架构。

Method: 使用共享MLLM主干生成视觉和文本嵌入，通过对比对齐促进高效的基于嵌入的候选搜索。采用低秩适应(LoRA)在70万对视觉-文本数据样本上进行高效训练。通过重新排序嵌入搜索中识别的候选来进一步提升性能。

Result: 在零样本视频检索任务上超越其他MLLM方法；同一模型无需额外训练即可在零样本时刻检索上取得竞争性结果；在零样本组合视频检索上达到最先进水平；通过重新排序训练后，性能远超现有MLLM系统，接近在更大规模数据上训练的专用模型。

Conclusion: VIRTUE证明了单一MLLM架构能够同时实现高性能的语料库级检索、时刻级检索和组合多模态查询，在多种视频检索任务上达到或接近专用模型的性能，同时保持了MLLM的灵活性和通用性。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [77] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出SurgRef框架，通过运动引导实现自然语言对手术器械的指代分割，克服静态视觉特征和预定义器械名称的限制。


<details>
  <summary>Details</summary>
Motivation: 当前手术场景中的指代分割方法依赖静态视觉特征和预定义器械名称，难以泛化到遮挡、模糊或陌生术语的情况，限制了语言驱动的手术交互发展。

Method: 提出SurgRef运动引导框架，基于器械运动轨迹而非外观特征进行语言指代分割；创建Ref-IMotion数据集，包含密集时空掩码和以运动为中心的语言描述。

Result: SurgRef在多种手术程序中实现了最先进的准确率和泛化能力，为鲁棒的语言驱动手术视频分割设立了新基准。

Conclusion: 通过关注器械运动而非静态外观，SurgRef能够更好地处理遮挡、模糊和陌生术语，推动了智能手术室和自主手术机器人辅助的发展。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [78] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: 提出DiffusionQC方法，利用扩散模型将病理图像中的伪影检测为异常值，仅需干净图像训练，无需像素级标注和预定义伪影类型


<details>
  <summary>Details</summary>
Motivation: 数字病理学在疾病诊断、预后和治疗中至关重要，但组织病理学图像常包含制备和数字化过程中引入的伪影。传统监督模型需要大量标注数据，资源密集且难以泛化到新伪影类型

Method: 提出DiffusionQC方法：1）使用扩散模型，将伪影检测为干净图像中的异常值；2）仅需干净图像训练，无需像素级伪影标注和预定义伪影类型；3）引入对比学习模块，显式扩大伪影与干净图像的分布分离，形成增强版本

Result: 实证结果优于最先进方法，具有跨染色泛化能力，且所需数据和标注显著减少

Conclusion: DiffusionQC为数字病理学中的伪影检测提供了一种高效、泛化性强的无监督方法，减少了标注需求，提高了检测性能

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [79] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

TL;DR: PRISM是一个三阶段视频摘要框架，通过集成语义和多模态分析，用少于5%的原始帧保留84%的语义内容，在手术培训等高风险领域特别有效。


<details>
  <summary>Details</summary>
Motivation: 视频摘要对长视频处理至关重要，特别是在手术培训等高风险领域。现有方法从基本视觉特征发展到预训练视觉语言模型，但需要更准确理解视频语义和时序流程，生成上下文感知的摘要。

Method: 提出PRISM三阶段框架：1）自适应视觉采样；2）标签驱动的关键帧锚定；3）使用大语言模型进行上下文验证。该方法结合语义和多模态分析，确保所选帧反映有意义的程序性过渡，过滤通用或幻觉内容。

Result: 在指导和活动数据集上评估，仅采样少于5%的原始帧，摘要保留84%的语义内容，比基线方法提升高达33%。该方法在程序和领域特定视频任务中均表现良好，具有强大的语义对齐和精确性。

Conclusion: PRISM框架通过集成语义和多模态分析，能够生成语义基础牢固的视频摘要，在保留关键内容的同时显著减少帧数，适用于手术培训等高风险领域的视频分析任务。

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [80] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

TL;DR: 该论文提出了一种结合PAAC和Transformer架构的创新框架，用于乳腺X线图像中恶性肿块的检测，通过多尺度特征融合和混合损失函数，在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性最常见的癌症之一，准确及时的诊断对改善治疗效果至关重要。现有方法在复杂场景和大数据集上的检测性能仍有提升空间。

Method: 提出了一种集成金字塔自适应空洞卷积（PAAC）和Transformer架构的创新框架，采用多尺度特征融合技术增强良恶性组织的特征提取，结合Dice Loss和Focal Loss函数优化模型学习过程。使用INbreast、MIAS和DDSM数据集，经过数据增强和对比度增强预处理后，将图像调整为227×227像素进行训练。

Result: 模型在检测癌性肿块方面表现出色，准确率达到98.5%，灵敏度97.8%，特异性96.3%，F1分数98.2%，总体精度97.9%。性能优于BreastNet、DeepMammo、Multi-Scale CNN、Swin-Unet和SegFormer等基准模型。

Conclusion: 该模型在复杂场景和大数据集上识别癌性肿块效果显著，证明了其作为乳腺癌诊断可靠高效工具的潜力，可有效集成到医疗诊断系统中。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [81] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: FedDCG是一种联邦学习框架，同时解决领域泛化和类别泛化问题，通过领域分组策略和可学习网络提升在未见领域和类别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型微调方法通常单独处理未见类别或未见领域问题，缺乏一个统一的框架同时解决这两类泛化挑战。特别是在联邦学习场景下，需要一种能够同时处理领域和类别泛化的方法。

Method: 提出FedDCG框架：1）采用领域分组策略，在每个组内训练类别泛化网络以避免决策边界混淆；2）推理时基于领域相似性聚合类别泛化结果；3）使用可学习网络增强类别泛化能力；4）通过解耦机制分离通用知识和领域特定知识。

Result: 在多个数据集上的广泛实验表明，FedDCG在准确性和鲁棒性方面均优于现有最先进的基线方法。

Conclusion: FedDCG成功解决了联邦学习中的领域和类别泛化问题，通过创新的分组策略和解耦机制实现了更好的泛化性能，为视觉语言模型在联邦学习环境下的高效微调提供了有效解决方案。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [82] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

TL;DR: 该论文提出了一种从普通非视距(NLOS)照片进行3D场景重建的新方法，通过将隐藏场景分解为光遮挡和非光遮挡组件，并开发了梯度优化和神经网络两种解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统成像需要视线才能创建场景的准确视觉表示，但在某些情况下获得合适的视线可能不切实际、危险甚至不可能。现有的被动NLOS方法仅限于1D或低分辨率2D彩色成像，或只能定位形状大致已知的隐藏物体。

Method: 提出了一种新的光传输模型重构方法，将隐藏场景分解为光遮挡和非光遮挡组件，形成可分离非线性最小二乘逆问题。开发了两种解决方案：基于梯度的优化方法和物理启发的神经网络方法（称为Soft Shadow diffusion，SSD）。

Result: 该方法在真实实验场景中对多个3D场景有效。SSD虽然在模拟中训练，但能很好地泛化到模拟和真实世界NLOS场景中的未见类别，并且对噪声和环境光照表现出惊人的鲁棒性。

Conclusion: 该研究扩展了被动NLOS成像的能力，实现了从普通NLOS照片进行3D场景重建，为解决这一具有挑战性的逆问题提供了有效方法，并展示了神经网络的泛化能力和鲁棒性。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [83] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

TL;DR: AgenticPruner：利用大语言模型进行MAC约束优化的神经网络剪枝框架，通过三个智能体协同工作，在满足MAC预算的同时保持或提升模型精度


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法主要关注参数减少，但无法直接控制计算成本，导致在需要严格MAC预算的部署场景中推理延迟不可预测。需要一种能够直接控制MAC操作预算的剪枝方法。

Method: 提出AgenticPruner框架，利用大语言模型实现MAC约束优化：1) Profiling Agent分析模型架构和MAC分布；2) Master Agent协调工作流程并进行发散监控；3) Analysis Agent（基于Claude 3.5 Sonnet）从历史尝试中学习最优策略。结合基于同构剪枝的图结构分组，通过分析剪枝迭代中的模式实现上下文感知适应。

Result: 在ImageNet-1K上验证：ResNet-50达到1.77G MACs，精度77.04%（比基线+0.91%）；ResNet-101达到4.22G MACs，精度78.94%（+1.56%）。ConvNeXt-Small剪枝到8.17G MACs，GPU加速1.41倍，CPU加速1.07倍，参数减少45%。Vision Transformers能在用户定义的容差带内（通常超调+1%到+5%，欠调-5%到-15%）满足MAC预算。

Conclusion: AgenticPruner能够自动收敛到目标MAC预算，同时保持或提升模型精度，为需要严格计算保证的部署场景提供了可行的解决方案。通过情境学习，Analysis Agent将收敛成功率从48%提升到71%。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [84] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: 提出了CytoCLIP视觉语言模型套件，用于自动识别大脑细胞构筑区域，通过CLIP框架学习脑组织切片的视觉-文本联合表示，包含低分辨率全区域和高分辨率图像块两个变体。


<details>
  <summary>Details</summary>
Motivation: 大脑不同区域的功能与其独特的细胞构筑密切相关，但手动在脑组织切片中划分这些区域耗时且需要专业知识，需要自动化方法来减少专家工作量。

Method: 基于预训练的CLIP框架开发CytoCLIP模型套件，包含两个变体：一个用低分辨率全区域图像训练以理解区域整体细胞构筑模式，另一个用高分辨率图像块训练以获得细胞级细节表示。使用NISSL染色的胎儿脑组织切片构建训练数据集。

Result: CytoCLIP在区域分类和跨模态检索任务中表现优异，在多种数据设置下（包括不同年龄和切片平面）均优于现有方法。低分辨率全区域分类F1分数0.87，高分辨率图像块分类F1分数0.91。

Conclusion: CytoCLIP成功实现了对大脑细胞构筑的自动化识别和理解，为脑科学研究提供了有效的工具，显著减少了专家工作量并提高了分析效率。

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [85] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT是一种无需训练的区域自适应扩散变换器，通过语义感知聚类、复杂度驱动的区域调度和边界感知细化，在保持感知和语义质量的同时实现高达3.0倍的加速。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在文本到图像合成中表现出色，但由于去噪过程的迭代性和全局注意力的二次计算成本，计算开销很大。研究发现去噪动态在空间上不均匀，背景区域快速收敛，而边缘和纹理区域变化更活跃。

Method: 提出SDiT框架：1）基于快速Quickshift的语义感知聚类进行区域分割；2）复杂度驱动的区域调度，选择性地更新信息丰富的区域；3）边界感知细化以保持空间连贯性。无需模型重新训练或架构修改。

Result: SDiT在保持与全注意力推理几乎相同的感知和语义质量的同时，实现了高达3.0倍的加速。

Conclusion: SDiT通过利用去噪动态的空间不均匀性，提供了一种训练免费的加速框架，为扩散变换器的高效推理提供了实用解决方案。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [86] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出基于参数化人脸模型的辐射场表示，实现高效、可控的3D人脸虚拟形象经典渲染


<details>
  <summary>Details</summary>
Motivation: 传统神经渲染方法需要定制化工程且难以在线部署，希望开发一种既能保持照片级真实感，又能在传统图形平台上高效渲染的3D人脸虚拟形象表示方法

Method: 利用参数化人脸模型锚定的辐射场，学习3D空间中的辐射流形，提取显式的分层网格以及外观和变形纹理，通过线性混合和alpha合成实现控制与动画

Result: 实现了复杂面部特征（头发、皮肤、眼睛）的可控体积渲染，生成的可流式传输虚拟形象能在传统图形平台上使用经典网格和着色器渲染，无需定制工程

Conclusion: 该方法结合了神经渲染的逼真性和传统图形管线的效率，为在线部署和实时交互的3D人脸虚拟形象提供了实用解决方案

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [87] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD是一种新颖的后处理概念瓶颈模型，通过表示分解为预训练黑盒模型添加可解释性，利用MLLM自动提取和筛选视觉概念，在保持高性能的同时提升模型透明度。


<details>
  <summary>Details</summary>
Motivation: 现有概念解释方法存在概念相关性不可靠、概念定义非可视化或劳动密集、模型或数据无关假设等局限性，限制了深度学习模型在关键领域的部署。

Method: PCBM-ReD从预训练编码器自动提取视觉概念，使用多模态大语言模型标记和筛选概念，通过重建引导优化选择独立概念子集，利用CLIP的视觉-文本对齐将图像表示分解为概念嵌入的线性组合。

Result: 在11个图像分类任务上的广泛实验表明，PCBM-ReD达到最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD通过表示分解有效为预训练黑盒模型添加可解释性，实现了高性能与透明度的平衡，为深度学习在关键领域的可信部署提供了解决方案。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [88] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 提出2S-GDA框架，通过全局多样化策略提升视觉语言预训练模型在对抗攻击中的效果


<details>
  <summary>Details</summary>
Motivation: 视觉语言预训练模型对对抗样本存在脆弱性，尤其在黑盒场景下。现有多模态攻击方法存在扰动多样性有限和多阶段流程不稳定等问题。

Method: 提出两阶段全局多样化攻击框架：第一阶段通过候选文本扩展和全局感知替换引入文本扰动；第二阶段通过多尺度调整和块混洗旋转增强视觉多样性。

Result: 实验表明2S-GDA在VLP模型上攻击成功率持续提升，在黑盒设置下相比现有方法提升高达11.17%。

Conclusion: 2S-GDA框架具有模块化特性，可轻松与现有方法结合进一步提升对抗可迁移性。

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [89] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: AMC-MetaNet是一个轻量级少样本遥感图像分类框架，通过相关性引导的特征金字塔、自适应通道相关性模块和相关性引导元学习，解决了遥感领域数据稀缺、域偏移和多尺度对象问题。


<details>
  <summary>Details</summary>
Motivation: 遥感领域少样本学习面临三大挑战：标注数据稀缺、显著的域偏移以及地理空间对象的多尺度特性。现有方法通常依赖大型预训练模型或Transformer，计算成本高且难以适应多尺度变化。

Method: 提出自适应多尺度相关性元网络（AMC-MetaNet），包含三个核心创新：1）相关性引导的特征金字塔捕捉尺度不变模式；2）自适应通道相关性模块学习动态跨尺度关系；3）相关性引导元学习利用相关性模式而非传统原型平均。

Result: AMC-MetaNet仅需约60万参数（比ResNet-18少20倍），推理速度<50ms/图像，在EuroSAT、NWPU-RESISC45、UC Merced Land Use和AID等数据集上实现5-way 5-shot分类最高86.65%准确率。

Conclusion: AMC-MetaNet为真实世界遥感少样本学习提供了一个计算高效、尺度感知的框架，在保持高性能的同时显著降低了模型复杂度和计算成本。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [90] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 该论文提出了CurConMix+框架，通过课程引导的对比学习和多分辨率时间Transformer解决手术动作三元组识别中的类别不平衡、视觉变化细微和语义依赖等挑战，并在新的LLS48数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别对工作流程分析和技能评估至关重要，但面临严重类别不平衡、细微视觉变化和三元组组件间语义依赖等挑战。现有方法通常只解决部分问题，缺乏整体解决方案。

Method: 1. CurConMix：基于空间表示的课程引导对比学习框架，包含结构化困难对采样和特征级混合
2. CurConMix+：引入多分辨率时间Transformer（MRTT），自适应融合多尺度时间特征，动态平衡时空线索
3. 提出LLS48数据集：针对复杂腹腔镜左外侧切除术的新基准，包含步骤、任务和动作三个层次的标注

Result: 在CholecT45和LLS48数据集上的实验表明，CurConMix+在三元组识别任务上优于现有最先进方法，同时展现出强大的跨层次泛化能力，其细粒度特征能有效迁移到更高层次的阶段和步骤识别任务。

Conclusion: 该框架和数据集为层次感知、可重复且可解释的手术工作流程理解提供了统一基础。代码和数据集将在GitHub公开，以促进可重复性和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [91] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S²F-Net：一种基于频谱分析的跨模型合成图像检测框架，通过探索真实与合成纹理间的频谱差异来提升检测泛化能力


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求。现有检测方法通常过度拟合特定源模型，在面对未见过的生成架构时性能显著下降。

Method: 提出S²F-Net跨模型检测框架，核心在于探索和利用真实与合成纹理间的固有频谱差异。聚焦于频率域伪影检测，引入可学习的频率注意力模块，通过协同空间纹理分析和频谱依赖关系自适应加权和增强判别性频带。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S²F-Net实现了90.49%的检测准确率，在跨域检测场景中显著优于各种现有基线方法。

Conclusion: 通过探索频谱差异作为检测合成图像的根本特征，S²F-Net有效解决了现有方法对特定源模型过度拟合的问题，显著提升了检测方法的泛化能力和跨模型性能。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [92] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 提出了一种语义调制、多尺度Transformer用于3D视线估计，通过原型银行条件化CLIP全局特征，融合多尺度特征，使用Mixture of Experts增加条件容量，在多个数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有视线估计方法在复杂场景下性能有限，需要更好地建模光照、头部姿态、背景和视线方向等语义因素，并有效融合多尺度特征

Method: 使用可学习的原型银行（光照、头部姿态、背景、方向）条件化CLIP全局特征，在统一注意力空间中融合原型增强的全局向量、CLIP补丁标记和高分辨率CNN标记，用路由/共享的Mixture of Experts替换多个FFN块以增加条件容量

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上分别达到2.49°、3.22°、10.16°和1.44°的角误差，相比先前结果相对提升高达64%

Conclusion: 通过语义调制和多尺度特征融合，结合Mixture of Experts架构，显著提升了3D视线估计的准确性和鲁棒性，消融实验验证了原型条件化、跨尺度融合和MoE的有效性

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [93] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

TL;DR: 提出一种基于超网络的轻量级描述符学习架构，用于提升多模态图像块匹配性能，在VIS-IR等基准测试中达到SOTA，并发布了新的跨平台VIS-IR数据集GAP-VIR。


<details>
  <summary>Details</summary>
Motivation: 多模态图像匹配（如可见光与红外图像）面临显著的外观差异挑战。传统描述符方法在处理这种域偏移时性能受限，而现有方法要么计算成本高，要么无法有效适应不同模态的特征分布。

Method: 采用超网络增强的Siamese CNN架构：1）超网络模块计算自适应、逐通道的缩放和偏移；2）条件实例归一化在浅层提供模态特定的适应（如VIS-IR）。结合三元组损失和难负样本挖掘进行训练。

Result: 在VIS-NIR和其他VIS-IR基准测试中达到最先进性能，在多个数据集上匹配或超越先前方法（尽管先前方法推理成本更高）。同时发布了包含50万对图像的跨平台VIS-IR数据集GAP-VIR。

Conclusion: 通过超网络和条件实例归一化的轻量级架构，在保持推理效率的同时显著提升了多模态图像匹配的鲁棒性，为解决域偏移问题提供了有效方案，并贡献了新的评估数据集。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [94] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit是一个无需训练的框架，通过构建多模态情感关联知识图谱（MSA-KG）来实现精确且保持结构的图像情感编辑，有效解耦情感线索和内容表示。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以从潜在内容表示中解耦情感线索，导致情感表达弱且视觉结构扭曲，需要更精确的结构保持编辑方法。

Method: 1. 构建MSA-KG知识图谱，明确编码对象-属性-情感之间的因果关系链；2. 利用MSA-KG指导多模态大模型推理情感相关视觉线索；3. 设计解耦的结构-情感编辑模块，在潜在空间中分离情感属性和布局特征。

Result: 大量实验表明EmoKGEdit在情感保真度和内容保持方面表现优异，超越了现有最先进方法。

Conclusion: EmoKGEdit通过知识图谱引导的推理和解耦编辑，实现了精确且结构保持的图像情感编辑，解决了现有方法情感表达弱和结构扭曲的问题。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [95] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出FlowIID，一种基于流匹配的轻量级内在图像分解方法，能在单次推理中高效分离图像的反射率和光照分量


<details>
  <summary>Details</summary>
Motivation: 现有IID模型虽然效果好，但参数量大，难以与其他模型集成，不适合资源受限和实时应用场景

Method: 基于潜在流匹配设计FlowIID架构，结合VAE引导的潜在空间和流匹配模块，实现稳定分解

Result: FlowIID不仅参数量少、推理高效，还在多个基准测试中取得了优于现有模型的竞争性结果

Conclusion: FlowIID是参数高效、单步推理的IID解决方案，适合部署在资源受限和实时视觉应用中

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [96] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 本文提出Turbo-GoDec方法，通过引入异常像素的"簇稀疏性"先验假设，改进了经典GoDec算法在高光谱异常检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱异常检测方法主要依赖低秩背景和稀疏异常的假设，但很少对异常的空间分布特性进行深入探索。作者观察到异常像素在空间中通常以小型聚集簇的形式出现，这种"簇稀疏性"特征未被充分利用。

Method: 结合异常簇稀疏性先验与GoDec算法，在GoDec的S步骤中融入簇稀疏性约束。使用马尔可夫随机场建模异常簇稀疏性，通过因子图上的消息传递计算异常边缘概率，将高异常概率位置作为Turbo-GoDec中的稀疏分量。

Result: 在三个真实高光谱图像数据集上的实验表明，与原始GoDec（LSMAD）和最先进的异常检测方法相比，Turbo-GoDec在小尺寸异常检测方面表现出优越性能。

Conclusion: 通过引入异常像素的簇稀疏性先验假设，Turbo-GoDec方法能够更有效地检测小尺寸异常，提升了高光谱异常检测的性能。

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [97] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

TL;DR: 提出了MMDeepResearch-Bench (MMDR-Bench)，这是一个包含140个专家设计任务的多模态深度研究基准，用于评估模型的多模态理解和引用报告生成能力，同时提出了三个统一的评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对纯文本设置或短格式多模态问答，缺乏端到端多模态证据使用的评估，无法全面评估深度研究代理的多模态理解和引用报告生成能力。

Method: 1. 构建MMDR-Bench基准：包含140个专家设计的任务，覆盖21个领域，每个任务提供图像-文本捆绑，评估多模态理解和引用报告生成；2. 提出三个评估方法：FLAE用于报告质量评估，TRACE用于引用证据对齐评估，MOSAIC用于文本-视觉完整性评估。

Result: 在25个最先进的模型上进行实验，揭示了生成质量、引用规范和多模态基础之间的系统性权衡，表明强文本生成能力不能保证忠实证据使用，多模态完整性仍是深度研究代理的关键瓶颈。

Conclusion: MMDR-Bench填补了多模态深度研究评估的空白，提出的评估方法支持细粒度错误诊断，揭示了当前模型在多模态证据使用方面的局限性，为深度研究代理的发展提供了重要基准。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [98] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch提出了一种简单有效的语义匹配框架，通过在低分辨率下工作来解决现有方法依赖高分辨率输入的问题，通过轻量级上采样解码器和多尺度监督损失恢复空间细节，同时减少51%训练内存。


<details>
  <summary>Details</summary>
Motivation: 现有语义匹配方法严重依赖预训练大规模模型，需要高分辨率输入才能获得最佳性能，这导致了巨大的计算开销。主要问题是深层下采样操作会导致相邻关键点特征的不可逆融合，当语义不同的关键点落在同一个下采样感受野内时（如16×16的patch），这个问题尤为严重。

Method: 1. 轻量级上采样解码器：逐步将深层特征上采样到1/4分辨率，恢复空间细节；2. 多尺度监督损失：确保上采样特征在不同空间尺度上保持判别性特征；3. 稀疏匹配和基于窗口的定位：优化训练内存使用，减少51%内存消耗。

Result: 在252×252分辨率下（比当前SOTA方法小3.3倍），SimpleMatch在SPair-71k基准测试上达到84.1%的PCK@0.1，表现出优越性能。

Conclusion: SimpleMatch提供了一个实用高效的语义匹配基准框架，能够在低分辨率下实现强大性能，同时显著降低计算开销和内存需求，为未来语义匹配研究提供了新的方向。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [99] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++是一个用于作物分割的基础模型，能够在开放田间环境中分割不同作物品种，在综合测试集上达到93.11% mIoU，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型通常因像素级标注成本高昂而只能从有限数据中学习，导致只能在特定作物类型或受控环境下表现良好。本文旨在开发一个能够在开放田间环境中泛化的跨物种、跨场景作物分割基础模型。

Method: 1）扩展了包含28,406张图像、30+物种和15种环境条件的跨物种跨场景数据集；2）基于ViT-Adapter架构，通过动态上采样增强细节感知；3）采用两阶段自训练管道进行训练。

Result: 在综合测试集上达到93.11% mIoU，比有监督基线方法高0.36%，比通用视觉基础模型SAM高48.57%。在夜间环境（86.90% mIoU）、高密度冠层（90.09% mIoU）和未见作物品种（90.09% mIoU）等挑战性场景中表现优异。

Conclusion: DepthCropSeg++通过大规模数据集、改进的架构和自训练策略，实现了作物分割的新SOTA，为植物表型分析、密度估计和杂草控制等下游农业任务提供了强大的基础模型。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [100] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出基于分数生成模型的异常检测方法ScoreAD，利用高光谱图像的低维流形特性，通过分数场区分背景和异常光谱


<details>
  <summary>Details</summary>
Motivation: 高光谱图像光谱维度高但由少数因素决定，满足流形假设。背景光谱位于低维流形上，而异常光谱偏离该流形，基于此差异可进行异常检测

Method: 使用分数生成模型学习数据分布的梯度场（分数），训练时使用全部光谱，测试时对光谱添加扰动后通过SGM获取估计分数，基于分数差异检测异常

Result: 在四个高光谱数据集上的实验证明了该方法的有效性

Conclusion: ScoreAD方法成功利用高光谱流形假设和分数生成模型进行异常检测，为高光谱异常检测提供了新思路

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [101] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 该研究评估了10个基础模型在皮肤病变分层分类中的表现，发现通用医学基础模型在高级别筛查中表现优异，但精细粒度分类需要专科模型策略。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准测试通常将复杂的诊断分类简化为二元分类任务（如区分黑色素瘤与良性痣），这种过度简化掩盖了模型执行细粒度鉴别诊断的能力，而这对临床工作流程整合至关重要。

Method: 使用DERM12345数据集（包含40个病变亚类），计算10个基础模型的冻结嵌入，并训练轻量级适配器模型，采用五折交叉验证。引入分层评估框架，在四个临床粒度级别评估性能：40个亚类、15个主类、2和4个超类以及二元恶性检测。

Result: 发现模型能力存在"粒度差距"：MedImageInsights在二元恶性检测中表现最佳（加权F1分数97.52%），但在40类亚型分类中下降至65.50%。相反，MedSigLip（69.79%）和皮肤病专科模型（Derm Foundation和MONET）在细粒度40类亚型区分中表现优异，但在更广泛的分类任务中整体性能低于MedImageInsights。

Conclusion: 通用医学基础模型在高级别筛查中非常有效，但诊断支持系统所需的精细区分需要专门的建模策略。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [102] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE和LFMM方法，实现无需外部数据库的纯点云场景生成，通过类别分区码本解决复杂场景中类别特定点云生成问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法主要生成物体边界框参数，扩散方法生成类别标签和潜在特征后需要从预定义数据库中检索物体。对于复杂多变的多类别场景，当前自动编码器无法有效解码扩散生成的潜在特征为与目标类别一致的点云物体。

Method: 1. 提出类别分区向量量化变分自编码器(CPVQ-VAE)，采用类别分区码本，码向量按类别标记；2. 为解决码本坍缩问题，提出类别感知运行平均更新策略，重新初始化每个分区内的死亡码向量；3. 设计专门用于场景生成的潜在空间流匹配模型(LFMM)，生成物体特征和类别标签；4. CPVQ-VAE通过类别感知逆查找将生成潜在特征映射到码本条目，解码为类别特定的点云形状。

Result: 实验表明该方法可靠地恢复合理的点云场景，在复杂客厅场景上，Chamfer距离和Point2Mesh误差分别降低70.4%和72.3%。

Conclusion: 该方法实现了无需依赖外部物体数据库检索的纯点云生成，通过类别分区码本和类别感知更新策略有效解决了复杂多类别场景中点云生成的质量问题。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [103] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

TL;DR: 论文综述了人脸情绪检测方法，选取三种最佳方案在多样化数据集上训练测试，揭示了现有解决方案的弱点


<details>
  <summary>Details</summary>
Motivation: 人脸情绪检测是人机交互的重要机器学习问题，现有方法众多但缺乏系统性比较，需要深入分析不同方法的性能表现

Method: 1) 深入综述相关文献和科学研究；2) 选取三种最有趣和最佳解决方案；3) 选择三个具有图像多样性和数量优势的数据集；4) 训练选定神经网络；5) 进行一系列性能比较实验，包括在不同数据集上的交叉测试

Result: 实验揭示了现有解决方案的弱点：不同数据集之间存在差异、识别某些情绪的难度不均等、区分相近情绪存在挑战

Conclusion: 人脸情绪检测系统面临数据集不一致、情绪识别难度差异和相近情绪区分困难等挑战，需要进一步改进现有方法

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [104] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 本文提出一种基于最优运输理论的非监督稀疏特征匹配方法，通过相机几何的线约束解决立体视觉中的匹配问题，特别适用于面部地标点匹配等应用。


<details>
  <summary>Details</summary>
Motivation: 立体视觉在自动驾驶、机器人、人脸分析等应用中面临遮挡、运动、相机畸变等挑战，而稀疏特征（如面部地标点）的立体匹配由于参数敏感性更加复杂。为了解决这一不适定问题并实现非监督稀疏匹配。

Method: 从最优运输视角考虑相机几何的线约束，将相机投影点建模为（半）直线，提出使用经典极线距离和3D射线距离来量化匹配质量。将这些距离作为（部分）最优运输问题的成本函数，形成高效可解的分配问题。此外，通过将其表述为分层最优运输问题，扩展到非监督物体匹配。

Result: 所得算法实现了高效的特征和物体匹配，数值实验验证了其有效性。研究特别关注面部分析应用，旨在匹配不同的地标点标注约定。

Conclusion: 该方法通过最优运输理论框架，利用相机几何约束解决了稀疏特征匹配的不适定问题，为立体视觉中的非监督匹配提供了一种有效的解决方案，特别适用于面部地标点匹配等实际应用场景。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [105] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi提出了一种基于无线传感器（LiDAR和毫米波）的骨架动作识别框架，通过跨模态知识转移和增强的时序图卷积来解决无线传感器数据噪声大、训练数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB摄像头的骨架动作识别在暗光环境下性能下降且存在隐私问题，限制了在智能家居和医院等场景的应用。无线传感器（LiDAR和毫米波）提供了非侵入式替代方案，但面临训练数据不足和骨架关键点噪声大的挑战。

Method: 提出SkeFi框架：1）使用跨模态知识转移方法，从数据丰富的RGB模态学习；2）提出增强的时序相关自适应图卷积（TC-AGC）配合帧交互增强来处理缺失或不连续帧的噪声；3）通过双重时序卷积增强多尺度时序建模。

Result: 实验表明SkeFi在毫米波和LiDAR传感器上实现了最先进的性能，能够从噪声的无线传感器数据中提取准确的姿态和动作信息。

Conclusion: SkeFi成功解决了无线传感器骨架动作识别的两大挑战，通过跨模态学习和先进的图卷积设计，为暗光环境和隐私敏感场景提供了可行的替代方案。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [106] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 本文综述了视觉语言模型（VLMs）对抗防御策略的最新进展，重点分析了三种主要防御范式：训练时防御、测试时自适应防御和免训练防御，并讨论了各自的优缺点及当前挑战。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（如CLIP）的广泛应用，其对抗脆弱性引发了安全担忧。对抗攻击可能影响模型性能并威胁跨模态任务系统安全，因此需要系统研究有效的防御策略。

Method: 论文采用文献综述方法，系统梳理了三种主要防御范式：1）训练时防御（通过对抗微调增强鲁棒性）；2）测试时自适应防御（在推理时更新模型参数）；3）免训练防御（通过修改对抗输入或特征嵌入来缓解攻击）。

Result: 综述总结了各种防御方法的优缺点：训练时防御有效但计算成本高且泛化性有限；测试时自适应防御灵活但增加复杂性和计算开销；免训练防御无需额外训练但可能防御能力有限。指出了当前防御策略面临的挑战和未来研究方向。

Conclusion: 本文系统梳理了视觉语言模型对抗防御的最新研究进展，强调需要平衡防御效果、计算效率和泛化能力。未来研究应关注更高效、通用的防御机制，以增强VLMs在实际应用中的安全性和鲁棒性。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [107] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 论文提出了一个大规模、多来源的电子显微镜多细胞器实例分割基准数据集，包含超过10万张2D EM图像，覆盖多种细胞类型和5种细胞器类别，以解决现有小规模数据集无法捕捉真实世界EM数据异质性和大空间上下文的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型、精选数据集的基准无法捕捉真实世界EM数据的固有异质性和大空间上下文，这对当前基于局部补丁的方法构成了根本性限制。需要建立一个能反映真实世界变异性的基准来推动细胞器实例分割技术的发展。

Method: 开发了大规模、多来源的多细胞器实例分割基准数据集，包含超过10万张2D EM图像，涵盖多种细胞类型和5种细胞器类别。使用设计的连通性感知标签传播算法（3D LPA）生成数据集标注，并进行专家精修。对U-Net、SAM变体和Mask2Former等最先进模型进行了基准测试。

Result: 当前模型在异质EM数据上的泛化能力有限，对于具有全局、分布形态的细胞器（如内质网）表现较差。研究结果揭示了局部上下文模型与建模真实世界变异性中长程结构连续性挑战之间的根本性不匹配。

Conclusion: 需要开发能够处理EM数据中长程结构连续性和真实世界变异性的新方法。该基准数据集和标注工具将公开发布，为电子显微镜细胞器实例分割研究提供重要资源。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [108] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出DCAC方法，通过为每个类别维护缓存收集高熵样本，在测试时校准预测，有效降低OOD样本的过自信预测


<details>
  <summary>Details</summary>
Motivation: 针对深度神经网络在OOD检测中的过自信预测问题，发现OOD样本在预测为同一类别时，彼此之间视觉相似度高于真实ID样本，这一类别特异性观察启发了新方法

Method: 提出DCAC（动态类别感知缓存），训练免费、测试时校准模块，为每个ID类别维护独立缓存收集高熵样本，通过轻量级两层模块利用缓存视觉特征和预测概率来校准原始预测

Result: 在多个OOD基准测试上，DCAC显著提升现有方法性能，如与ASH-S集成时在ImageNet OOD基准上将FPR95降低6.55%

Conclusion: DCAC是一种有效且高效的OOD检测增强方法，可无缝集成到各种现有方法中，包括单模态和视觉语言模型，计算开销最小

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [109] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 提出首个基于多视角图像的高保真3D动物毛发建模方法，利用视觉语言模型指导毛发重建，解决了动物毛发数据集缺乏和细节重建困难的问题。


<details>
  <summary>Details</summary>
Motivation: 从图像重建逼真的动物毛发几何结构极具挑战，因为毛发具有精细细节、自遮挡和视角依赖性。与人发重建不同，动物毛发缺乏可用于学习先验的数据集。

Method: 1) 使用传统多视角立体技术重建粗糙表面几何；2) 利用视觉语言模型获取身体各部位毛发的真实长度结构信息；3) 基于此构建无毛几何体并在其上生长毛发束；4) 使用几何和光度损失进行监督；5) 利用VLM指导毛发生长方向，结合重力向量作为损失。

Result: 该方法能够在不同毛皮类型的多种动物上实现泛化，展示了使用VLM指导多视角3D重建的新范式。

Conclusion: 通过结合视觉语言模型的通用知识，首次实现了基于多视角的高保真3D动物毛发建模，为缺乏数据集的领域提供了新的解决方案。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [110] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了Histopath-C基准测试，用于评估数字病理学中视觉语言模型对真实世界分布偏移的鲁棒性，并提出了LATTE方法来提升模型适应性。


<details>
  <summary>Details</summary>
Motivation: 数字病理学图像存在染色、污染、模糊和噪声等严重的领域偏移问题，这些偏移会严重降低视觉语言模型的下游性能，需要专门的测试和适应方法。

Method: 1) 创建Histopath-C基准测试，使用真实合成损坏来模拟数字病理学中的分布偏移；2) 提出LATTE方法，一种利用多文本模板的低秩适应策略，减少病理学视觉语言模型对文本输入的敏感性。

Result: LATTE方法在多个病理学数据集上超越了为自然图像设计的最先进的测试时适应方法，证明了该方法在病理学图像中鲁棒适应的有效性。

Conclusion: 该研究为数字病理学中的视觉语言模型鲁棒性评估提供了新基准，提出的LATTE方法能有效应对真实世界分布偏移，提升模型在病理学图像中的适应性。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [111] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出基于移动无人机的大规模密集人群计数与跟踪方案，通过新数据集MovingDroneCrowd++和GD3A、DVTrack方法显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有固定摄像头方法空间覆盖有限，无法满足大规模密集人群分析需求。移动无人机能提供更灵活的视角和更全面的场景覆盖，但缺乏相应数据集和方法

Method: 1) 提出MovingDroneCrowd++数据集，覆盖多种飞行高度、相机角度和光照条件；2) 提出GD3A方法，通过最优传输建立像素级描述符对应关系，将全局密度图分解为共享、流入、流出分量；3) 提出DVTrack方法，通过描述符投票机制将描述符级匹配转换为实例级关联

Result: GD3A和DVTrack方法在密集人群和复杂运动条件下显著优于现有方法，计数误差降低47.4%，跟踪性能提升39.2%

Conclusion: 移动无人机为大规模密集人群分析提供了灵活解决方案，提出的数据集和方法有效解决了现有方法的局限性，为无人机视角下的人群分析建立了新基准

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [112] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

TL;DR: SDCoNet提出一种显著性驱动的多任务协作网络，通过隐式特征共享将超分辨率与检测任务耦合，解决遥感图像中小目标检测的挑战。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中复杂的背景、微弱的目标信号和小目标尺度使得准确检测特别困难，尤其是在低质量成像条件下。现有的串行流水线（先超分辨率后检测）存在优化目标不对齐、特征冗余以及超分辨率与检测之间缺乏有效交互的问题。

Method: 提出SDCoNet网络：1）使用基于Swin Transformer的共享编码器，通过分层窗口移位自注意力支持跨任务特征协作；2）多尺度显著性预测模块生成重要性分数来选择关键token，聚焦弱目标区域并抑制背景杂波；3）引入梯度路由策略缓解优化冲突，先稳定检测语义，然后沿检测导向方向路由超分辨率梯度。

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split等公开数据集上的实验表明，该方法在保持计算效率竞争力的同时，在低质量遥感图像的小目标检测方面显著优于现有主流算法。

Conclusion: SDCoNet通过多任务协作框架有效解决了遥感图像中小目标检测的挑战，通过隐式特征共享、显著性驱动和梯度路由实现了超分辨率与检测的协同优化。

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [113] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出基于CycleGAN的无监督医学图像域适应方法，解决不同MRI扫描仪间域偏移问题，无需配对数据即可实现双向域映射。


<details>
  <summary>Details</summary>
Motivation: 不同MRI扫描仪或机构获取的图像存在域偏移（硬件、协议、采集参数差异），导致在源域训练的深度学习模型在目标域性能下降。

Method: 使用CycleGAN模型进行无监督医学图像域适应，通过双向映射学习源域和目标域间关系，结合内容损失和差异损失保持图像解剖结构完整性。

Result: 在多个MRI数据集上的实验表明，该方法能有效实现无标签数据的双向域适应，提高模型性能并减少域相关变异性。

Conclusion: 该方法为提升医疗诊断准确性提供了有前景的途径，有助于实现更精确、一致的医学图像分析。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [114] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 提出一种结合数据驱动语义先验与传统方法精确控制的网格变形技术，通过深度特征邻近性计算平滑语义权重，实现实时高性能变形


<details>
  <summary>Details</summary>
Motivation: 传统基于手柄的网格变形方法需要用户预先知道手柄的理想分布，变形行为与手柄集之间的映射关系不直观且非语义。现代数据驱动方法虽然能获得语义编辑，但速度慢且不精确。需要融合两者的优势

Method: 提出深度特征邻近性方法计算平滑语义变形权重，无需额外正则化。引入重心特征蒸馏管道，利用形状渲染的视觉信号最小化蒸馏成本。通过特征空间约束和局部性加权保留传统方法特性，支持语义对称检测和对称保持变形

Result: 能够为高分辨率网格（最高100万面）在消费级机器上实时计算变形权重，计算时间从传统方法的数小时缩短到一分钟以内，同时保持语义编辑能力

Conclusion: 该方法成功融合了数据驱动的语义先验与传统方法的精确控制和速度优势，实现了简单有效、实时高性能的语义网格变形

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [115] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine：一种与检测器无关的亚像素关键点精炼方法，通过跨注意力架构仅使用关键点周围的图像块来提升匹配精度，可泛化到不同检测器并支持多视图特征跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器产生的匹配在空间上不准确，现有的精炼方法通常是检测器特定的，需要为每个检测器重新训练，缺乏通用性。

Method: 提出XRefine方法，基于跨注意力架构，仅使用以匹配关键点为中心的图像块来预测精炼后的坐标，不依赖检测器内部表示，实现检测器无关性。

Result: 在MegaDepth、KITTI和ScanNet数据集上的实验表明，该方法能持续提升几何估计精度，性能优于现有精炼方法，同时保持运行效率。

Conclusion: XRefine是一种有效的检测器无关亚像素关键点精炼方法，能够泛化到不同检测器并支持多视图跟踪，显著提升了3D视觉任务的几何估计准确性。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [116] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 作者创建了BirdsEye-RU数据集，包含2,978张图像和8,000多个标注的人脸，专门用于检测高空俯拍图像中的小尺寸和远距离人脸。


<details>
  <summary>Details</summary>
Motivation: 解决高空俯拍图像中人脸检测的挑战，包括极端尺度变化和环境干扰，现有数据集难以应对这些困难。

Method: 创建了BirdsEye-RU数据集，收集了2,978张包含8,000多个标注人脸的图像，涵盖无人机和高空智能手机拍摄的多样化环境。

Result: 建立了专门针对高空俯拍人脸检测的数据集，包含丰富的小尺寸和远距离人脸样本，已在Kaggle上公开免费提供。

Conclusion: BirdsEye-RU数据集填补了高空俯拍人脸检测领域的空白，为相关研究提供了重要资源，有助于推动该领域的发展。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [117] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 该研究开发了一种基于自监督眼动重建的新模型，用于从低分辨率视频中预测情感表达，并在大屠杀幸存者访谈数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然眼动模式已被证明是情感表达的可靠指标，但现有研究大多依赖高精度眼动仪设备，限制了应用范围。本研究旨在探索如何从自然、低分辨率视频中利用眼动来预测多模态情感表达标记。

Method: 受语言模型预训练方法启发，开发了一种新颖的自监督眼动重建模型，利用未标记视频进行训练。使用该模型的编码器嵌入来微调两个下游任务：1) 将眼动与语音中的方向性情感估计对齐；2) 使用眼动预测三种瞬时情感行为表现：笑、哭/抽泣、叹气。

Result: 新模型能有效预测情感结果，且观察到预训练性能与情感处理性能之间存在正相关关系。两个实验都验证了自监督眼动重建方法在编码情感信号方面的有效性。

Conclusion: 自监督眼动重建是从低分辨率视频中编码眼动所携带情感信号的有效方法，为情感计算领域提供了更广泛应用的可行方案。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [118] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE：基于物理信息深度鬼成像的低带宽边缘感知框架，通过伴随算子初始化与语义引导，在5%采样率下分类准确率提升2.57%，方差降低9倍。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备在低带宽条件下的感知问题，传统鬼成像方法在低采样率下性能受限，需要提升分类准确率并降低结果方差。

Method: 结合物理信息深度学习与鬼成像，采用伴随算子初始化网络参数，引入语义引导优化重建过程，实现低采样率下的高效边缘感知。

Result: 在5%采样率下，分类准确率相比基线提升2.57%，结果方差降低9倍，显著改善了低带宽边缘感知的稳定性和精度。

Conclusion: PISE框架有效融合物理先验与深度学习，为低带宽边缘感知提供了高效解决方案，在保持低采样率的同时显著提升感知性能。

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [119] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: 提出PnP-ProCay78算法，通过结合经典二次重构误差公式、Cayley旋转参数化和最小二乘优化，解决平面透视n点问题，特别针对标定物体的初始位姿估计。


<details>
  <summary>Details</summary>
Motivation: 相机相对于观测场景的位置和方向估计是计算机视觉中的核心问题，特别是在相机标定和多传感器系统背景下。现有方法在计算效率和算法复杂度方面存在改进空间。

Method: 结合经典二次重构误差公式与Cayley旋转参数化，通过最小二乘优化。关键创新是使用基于两个规范向量重构误差分析的确定性起始点选择方法，避免昂贵的解空间搜索过程。

Result: 实验验证表明，该算法在投影精度上与最优SQPnP几乎相同，略高于IPPE（两者都是PnP-OpenCV中的主要方法），同时保持了更简单的算法结构。Cayley空间中的优化轨迹分析提供了对收敛过程的直观理解。

Conclusion: PnP-ProCay78算法将投影误差最小化与解析消除的平移重构误差替代项相结合，形成了几何透明且计算高效的混合成本公式，在保持高精度的同时简化了算法结构，具有教学吸引力。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [120] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

TL;DR: 论文发现视觉语言模型通过线性绑定空间ID到文本激活来编码物体位置，并通过语言token进行推理，同时识别了类似的时间ID机制用于视频VLMs


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型中时空推理能力的底层机制，理解视觉/几何和文本表示如何在模型计算中结合，以提升模型的可解释性和能力设计

Method: 通过严格的因果干预实验，识别VLMs中线性绑定空间ID到文本激活的机制，并扩展到视频VLMs中的时间ID分析

Result: 发现VLMs通过空间ID编码物体位置，这些ID在模型各层普遍存在并能系统性地调节模型信念；同时识别了视频VLMs中的线性时间ID机制

Conclusion: 阐明了VLMs中先前未被充分探索的内部推理过程，为改进模型可解释性、对齐性和能力设计提供了理论基础和实用工具

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [121] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: 论文分析了基于Swin-Transformer的U-Net模型（Swin-BathyUNet）如何推断水深，评估其预测可靠性，并提供实用部署指南。


<details>
  <summary>Details</summary>
Motivation: Sentinel-2卫星衍生水深（SDB）在不同站点部署仍面临挑战，需要理解模型如何推断水深以及何时预测可信。

Method: 1) 采用留一频带研究评估光谱重要性；2) 将基于消融的CAM适应到回归任务（A-CAM-R），并通过性能保留测试验证可靠性；3) 进行注意力消融分析；4) 进行跨区域推理实验（在一个站点训练，在另一个站点测试）。

Result: 1) 光谱重要性排名与浅水光学一致；2) A-CAM-R能有效定位模型依赖的证据；3) 解码器条件化的跳跃连接交叉注意力能提高对耀斑/泡沫的鲁棒性；4) 跨区域推理显示误差随水深线性增加，双峰水深分布会加剧中/深水误差。

Conclusion: 为稳健部署SDB提供实用指南：保持宽感受野，保护绿/蓝通道的辐射测量保真度，预处理近岸高亮度高方差区域，采用轻量目标站点微调与深度感知校准以实现跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [122] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: 提出混合精度量化框架优化LiDAR 3D目标检测，通过敏感层搜索和异常值处理，在保持精度的同时实现2.35倍加速和2.26倍模型压缩


<details>
  <summary>Details</summary>
Motivation: LiDAR 3D目标检测需要实时运行，但直接量化会导致性能下降，因为LiDAR数据具有宽数值分布和极端异常值。需要设计专门的量化方法来解决这些问题。

Method: 1) 混合精度框架：通过PTQ逐层量化搜索敏感层，将top-k敏感层保持为浮点数；2) 贪婪搜索敏感层组合生成候选模型；3) 使用少量校准数据减少异常值影响；4) 提供PTQ和QAT两种流水线

Result: 1) PTQ流水线无需训练即可获得混合精度模型；2) QAT流水线性能可与浮点模型竞争；3) TensorRT部署下延迟降低2.35倍，模型大小减少2.26倍

Conclusion: 提出的混合精度量化框架有效解决了LiDAR数据量化难题，在保持检测精度的同时显著提升了推理速度和模型压缩率，适用于自动驾驶实时3D目标检测任务。

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [123] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 本文研究了在非独立同分布联邦学习场景中，针对癌症组织病理学任务的超参数优化跨数据集泛化问题，提出了一种简单的跨数据集聚合启发式方法。


<details>
  <summary>Details</summary>
Motivation: 深度学习在癌症组织病理学训练中存在隐私约束问题，联邦学习虽然能保持数据本地化，但其性能在非独立同分布客户端数据集下高度依赖超参数选择。需要研究超参数优化策略是否能跨不同癌症数据集和非IID联邦场景泛化。

Method: 针对卵巢癌和结直肠癌的二元组织病理学任务，进行集中式贝叶斯超参数优化，然后将数据集特定最优参数转移到非IID联邦学习设置中。主要贡献是引入简单的跨数据集聚合启发式方法：通过平均学习率、考虑模态优化器和批量大小来组合配置。

Result: 提出的组合配置实现了具有竞争力的分类性能，表明这种跨数据集聚合方法在非IID联邦学习场景中是有效的。

Conclusion: 在癌症组织病理学的联邦学习中，通过跨数据集聚合超参数配置的简单启发式方法，可以在非IID场景下获得良好的分类性能，为解决隐私约束下的模型训练提供了实用方案。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [124] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出了一种基于神经隐式表示的单次彩色光度立体视觉框架，能够从单张图像恢复表面细节，适用于近光和非朗伯表面，并通过光学触觉传感器验证方法有效性。


<details>
  <summary>Details</summary>
Motivation: 传统彩色光度立体视觉需要多张图像且假设理想远距离照明和朗伯反射，限制了在近光条件和非朗伯表面的实际应用。现有方法对这些更实际的场景探索不足。

Method: 提出基于神经隐式表示的框架，在单色性假设（均匀色度和同质材料）下进行深度和BRDF建模，缓解彩色光度立体视觉的病态问题，仅需单张图像即可实现详细表面恢复。还设计了紧凑型光学触觉传感器进行验证。

Result: 在合成和真实数据集上的实验表明，该方法能够实现准确且鲁棒的表面重建。

Conclusion: 该方法成功扩展了彩色光度立体视觉的应用范围，使其能够处理更实际的近光条件和非朗伯表面，仅需单次拍摄即可获得详细表面重建，具有实用价值。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [125] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 在联邦学习环境下，结合预处理和测试时增强能显著提升脑肿瘤MRI分类性能，而单独预处理效果有限。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤的早期诊断至关重要，但由于病变变异性和图像复杂性，实现高效诊断具有挑战性。研究旨在探索在联邦学习框架下，如何通过图像预处理和测试时增强来提升卷积神经网络对MRI图像的分类性能。

Method: 在联邦学习设置中评估卷积神经网络，比较在原始MRI图像与预处理图像（包括调整大小、灰度转换、归一化、滤波和直方图均衡化）上训练的模型。进一步研究预处理与测试时增强（TTA）的结合效果。

Result: 单独预处理带来的性能提升微乎其微；但当预处理与测试时增强结合时，在联邦MRI分类中产生了持续且统计显著的改进（p<0.001）。

Conclusion: 在基于联邦学习的医学影像应用中，测试时增强应作为默认的推理策略；当计算预算允许时，将测试时增强与轻量级预处理结合，可提供额外的可靠性能提升。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [126] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: 提出VILTA框架，将视觉语言模型整合到自动驾驶闭环训练中，直接编辑周围车辆轨迹生成多样化危险场景，提升自动驾驶策略的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统面临长尾问题，罕见但关键的驾驶场景在真实数据中严重不足。现有方法依赖规则启发式、重采样和基于离线数据的生成模型，无法产生多样新颖的挑战场景。两阶段方法限制了视觉语言模型的生成潜力。

Method: 提出VILTA框架，将视觉语言模型整合到自动驾驶闭环训练中。VILTA理解动态驾驶环境，通过直接精细编辑周围车辆的未来轨迹来战略性生成挑战场景。这种直接编辑方法充分利用VLM的强大泛化能力。

Result: 该方法显著提升了自动驾驶策略的安全性和鲁棒性，特别是在处理关键长尾事件方面表现突出。

Conclusion: VILTA框架通过将视觉语言模型整合到闭环训练中，直接编辑周围车辆轨迹，能够生成超出传统方法范围的多样化、合理且具有挑战性的场景，有效解决了自动驾驶的长尾问题。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [127] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 针对高温结构变形测量中热辐射和热雾霾导致的图像退化问题，提出基于图像分层表示和多曝光融合的图像处理方法，有效提升DIC测量精度。


<details>
  <summary>Details</summary>
Motivation: 高温结构变形测量中，热辐射导致图像退化，热雾霾引入随机误差，严重限制了数字图像相关法（DIC）的测量精度和有效性。

Method: 1. 针对热辐射：基于图像分层表示，将图像分解为正负通道并行处理，通过多曝光图像融合优化图像质量；2. 针对热雾霾：采用FSIM作为目标函数指导模型参数迭代优化，结合灰度平均算法均衡异常灰度值。

Result: 1. 多曝光融合算法将欠曝光图像有效计算区域从26%提升至50%，过曝光图像从32%提升至40%；2. 图像恢复结合灰度平均算法显著降低静态热变形测量误差：ε_xx误差减少85.3%，ε_yy和γ_xy误差分别减少36.0%和36.4%。

Conclusion: 提出的图像处理方法能有效抑制热辐射和热雾霾干扰，提高图像质量，降低变形测量误差，在热变形测量中具有潜在应用价值。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [128] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: 提出GaussianTrimmer方法，针对现有3D高斯分割方法中由于高斯基元尺度变化大导致分割边界锯齿状的问题，通过在线边界修剪改善分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯的场景分割方法存在边界锯齿问题，主要原因是高斯基元尺度变化范围大，大尺寸高斯常跨越前景和背景，导致分割物体边界不平滑。

Method: 提出一种高效的即插即用后处理方法，包含两个核心步骤：1）生成均匀且覆盖良好的虚拟相机；2）基于虚拟相机上的2D分割结果在基元级别修剪高斯。

Result: 广泛的定量和定性实验表明，该方法能有效提高现有3D高斯分割方法的分割质量，作为即插即用方法效果显著。

Conclusion: GaussianTrimmer是一种有效的在线边界修剪方法，能够改善现有3D高斯分割方法的边界质量，解决了高斯基元尺度变化导致的边界锯齿问题。

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [129] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: 提出基于3D高斯溅射的红外-可见光图像融合框架IVGF，通过重建场景几何实现多视角融合渲染，解决传统2D方法视角固定和信息损失问题


<details>
  <summary>Details</summary>
Motivation: 现有2D红外-可见光图像融合方法局限于固定相机视角，缺乏对复杂场景的全面理解，导致关键场景信息丢失。需要一种能够从多模态2D输入重建场景几何并实现直接融合渲染的方法。

Method: 提出红外-可见光高斯融合(IVGF)框架：1) 从多模态2D输入重建场景几何；2) 设计跨模态调整(CMA)模块，通过调制高斯不透明度解决跨模态冲突；3) 引入融合损失函数指导CMA优化，确保融合图像保留各模态关键特征

Result: 通过全面的定性和定量实验验证了所提方法的有效性，能够生成保留红外和可见光关键特征的融合图像，优于传统2D融合方法

Conclusion: IVGF框架通过3D高斯溅射技术实现红外-可见光图像融合，克服了传统2D方法的局限性，能够从多视角重建场景几何并生成高质量的融合图像，为多模态图像融合提供了新思路

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [130] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA是一个参数高效的多标签类增量学习框架，通过提示-标签模块和连续适配器模块，解决了特征混淆和领域差异问题，无需内存缓冲区且参数量少。


<details>
  <summary>Details</summary>
Motivation: 现有多标签类增量学习方法存在计算成本高（全参数微调）、存储开销大（内存缓冲区）、特征混淆和领域差异处理不足等问题，需要更高效的解决方案。

Method: 提出P2L-CA框架：1) P2L模块使用类别特定提示解耦多标签表示，融入语言先验保持语义-视觉对齐稳定；2) CA模块使用轻量适配器缓解预训练模型与下游任务间的领域差异，增强模型可塑性。

Result: 在MS-COCO和PASCAL VOC的标准和挑战性MLCIL设置上，P2L-CA相比SOTA方法有显著提升，在CIL场景中表现出强泛化能力，同时只需极少可训练参数且无需内存缓冲区。

Conclusion: P2L-CA通过参数高效的提示-标签和连续适配器设计，有效解决了多标签类增量学习中的计算、存储和性能挑战，为实际应用提供了实用解决方案。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [131] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: 提出RSOD师生框架，通过可靠性评分和物体混合伪标签策略，解决声纳图像标注数据有限下的目标检测问题，在仅5%标注数据下达到与100%标注基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 声纳图像相比自然图像纹理细节少、噪声多，非专家难以区分类别间的细微差异，导致无法提供精确标注数据。因此需要设计在标注极其有限情况下有效的声纳图像目标检测方法。

Method: 提出RSOD师生框架：1）通过评估教师模型在不同视图下预测的一致性计算可靠性评分；2）引入物体混合伪标签方法解决声纳图像标注数据短缺问题；3）实施可靠性引导的自适应约束优化学生模型性能。

Result: 在UATD数据集上，仅使用5%标注数据的方法结果可与基线算法在100%标注数据上训练的结果竞争。同时收集了新数据集为声纳领域研究提供更多有价值数据。

Conclusion: RSOD框架能充分利用未标注数据，通过可靠性评分和伪标签策略有效缓解标注数据有限的影响，在极有限标注情况下仍能获得良好性能，为声纳图像目标检测提供了有效解决方案。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [132] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一个用于移动设备的高效流式视频生成模型，通过新颖的注意力机制和动态规划搜索实现高质量实时生成。


<details>
  <summary>Details</summary>
Motivation: 现有Diffusion Transformers在视频生成质量上有所提升，但计算成本过高，无法在移动设备上实现实时或本地生成。

Method: 1) 提出LinConv混合注意力(LCHA)和跨步自注意力(SSA)实现高效注意力；2) 通过预算感知动态规划搜索发现三明治结构设计；3) 提出2合1蒸馏框架将大模型能力转移到紧凑模型中。

Result: S2DiT在iPhone上实现了超过10 FPS的流式生成，质量与最先进的服务器视频模型相当。

Conclusion: S2DiT通过高效注意力机制、三明治结构设计和知识蒸馏，成功实现了在移动设备上的高质量实时视频生成。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [133] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM 是一个利用大型重建模型（LRM）的先验知识，通过单视图图像进行参数化3D人脸重建的方法。它通过将LRM的triplane特征投影到FLAME参数空间来恢复几何形状，并使用与FLAME网格紧密耦合的2D高斯图元来建模外观，从而在自遮挡和不同视角下实现准确且一致的3D人脸重建。


<details>
  <summary>Details</summary>
Motivation: 现有的3D形变模型（3DMM）回归器在不同视角下往往表现出较差的一致性。虽然参数化3D形变模型因其紧凑且可解释的参数化而广泛用于人脸重建，但它们在多视角一致性方面存在不足，特别是在自遮挡和视角变化较大的情况下。

Method: KaoLRM利用预训练的LRM的3D先验知识，将LRM的triplane特征投影到FLAME参数空间来恢复几何形状。同时，它通过紧密耦合到FLAME网格的2D高斯图元来建模外观，将这些组件集成到LRM的渲染流程中，使FLAME回归器能够感知3D结构。

Result: 在受控和真实场景的基准测试中，KaoLRM在重建精度和跨视角一致性方面均优于现有方法。现有方法对视角变化仍然敏感，而KaoLRM在自遮挡和多样化视角下实现了准确且鲁棒的重建。

Conclusion: KaoLRM通过利用大型重建模型的预训练先验知识，显著提升了参数化3D人脸重建的准确性和跨视角一致性，解决了现有方法在视角变化下的敏感性问题，为单视图3D人脸重建提供了更可靠的解决方案。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [134] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: 本文提出SSPFormer，一种用于MRI图像的自监督预训练Transformer，通过逆频率投影掩码和频率加权FFT噪声增强策略，解决了医学图像特异性、数据隐私和稀缺性问题。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现出色，但直接应用于MRI图像面临两大挑战：1）无法适应医学解剖结构的特异性；2）医学数据的隐私性和稀缺性带来的限制。

Method: 提出SSPFormer，采用两种核心策略：1）逆频率投影掩码，优先重建高频解剖区域以增强结构感知表示学习；2）频率加权FFT噪声增强，在傅里叶域注入生理真实噪声以增强对MRI伪影的鲁棒性。

Result: 在分割、超分辨率和去噪任务上的广泛实验表明，SSPFormer实现了最先进的性能，充分验证了其捕捉细粒度MRI图像保真度和适应临床应用需求的能力。

Conclusion: SSPFormer通过自监督学习直接从原始扫描中学习领域不变和伪影鲁棒的特征，有效解决了医学图像的特异性问题和数据稀缺挑战，为临床MRI图像分析提供了有力工具。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [135] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Moaw是一个将视频扩散模型从图像到视频生成转换为视频到密集跟踪的框架，通过训练运动感知模型实现零样本运动迁移


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在大型数据集上训练时自然捕捉了帧间共享特征的对应关系，最近的研究利用这一特性进行零样本光流预测和跟踪。本研究旨在探索有监督训练是否能更充分利用视频扩散模型的跟踪能力

Method: 提出Moaw框架，训练扩散模型进行运动感知，将其模态从图像到视频生成转换为视频到密集跟踪。构建运动标注数据集识别最强运动信息的特征，将这些特征注入结构相同的视频生成模型中。由于两个网络同质性，这些特征可以零样本适应，无需额外适配器

Result: 通过训练运动感知模型和特征注入，实现了零样本运动迁移，为生成建模和运动理解提供了新范式

Conclusion: Moaw框架释放了视频扩散模型的运动感知能力，为更统一和可控的视频学习框架铺平了道路，展示了生成建模与运动理解结合的新范式

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [136] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: DSOD是一种新颖的源自由目标检测框架，通过VFM辅助来缓解源域偏差问题，在多种跨域适应任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有源自由目标检测方法存在源域偏差问题，即适应后的模型仍然偏向源域特征，导致泛化能力差和自训练过程中的错误累积。

Method: 提出了DSOD框架，包含三个核心组件：1）统一特征注入模块，通过简单尺度扩展和域感知自适应加权将VFM特征集成到CNN骨干网络；2）语义感知特征正则化，约束特征学习防止过拟合到源域特征；3）针对计算受限场景的VFM-free变体DSOD-distill，采用新颖的双教师蒸馏方案。

Result: 在多个基准测试中表现出色：Normal-to-Foggy天气适应达到48.1% AP，跨场景适应达到39.3% AP，合成到真实适应达到61.4% AP，均优于现有最先进的SFOD方法。

Conclusion: DSOD通过VFM辅助有效缓解了源自由目标检测中的源域偏差问题，在多种跨域适应场景中实现了卓越的性能，同时提供了适用于计算受限环境的蒸馏变体。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [137] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

TL;DR: Spatial-VLN提出一个感知引导的探索框架，通过增强空间感知和专家推理机制，解决零样本视觉语言导航中的三个关键空间挑战：门交互、多房间导航和模糊指令执行。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的零样本视觉语言导航代理在泛化能力上表现优异，但在复杂连续环境中存在空间感知不足的问题。特别是面临三个关键空间挑战时失败率较高：门交互、多房间导航和模糊指令执行。

Method: 提出Spatial-VLN框架，包含两个核心模块：1) 空间感知增强模块，整合全景过滤与专门的门和区域专家，生成空间连贯、跨视图一致的感知表示；2) 探索多专家推理模块，使用并行LLM专家处理路径点级语义和区域级空间转换，当专家预测不一致时激活查询探索机制主动探测关键区域。

Result: 在VLN-CE数据集上实现了最先进的性能，仅使用低成本LLM。通过基于价值的路径点采样策略有效缩小Sim2Real差距，真实世界评估表明框架在复杂环境中具有优越的泛化能力和鲁棒性。

Conclusion: Spatial-VLN通过感知引导的探索框架成功解决了零样本视觉语言导航中的关键空间挑战，在仿真和真实环境中都表现出色，为实际应用提供了有效解决方案。

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [138] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

TL;DR: HVP-Net是一个用于视频文本检索的层次化视觉感知网络，通过提取和精炼视觉编码器的多层中间特征来挖掘更丰富的视频语义，减少冗余并提升匹配精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP等预训练模型的视频文本检索方法存在两个主要问题：1）视频本身固有的冗余性；2）依赖粗粒度的最终层特征。这些问题限制了匹配准确性。

Method: 提出HVP-Net框架，从视觉编码器的多个中间层提取特征，通过渐进式蒸馏从原始补丁标记中提炼不同语义层次的关键视觉概念，减少冗余同时保留对齐所需的关键细节。

Result: 在MSRVTT、DiDeMo和ActivityNet等具有挑战性的基准测试中取得了新的最先进性能。

Conclusion: 这项工作验证了利用层次化特征推进视频文本检索的有效性，通过挖掘更丰富的视频语义表示来提升检索性能。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [139] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于单张图像实时重建可动画3D头部头像的新框架，利用参数化模型、3D GAN先验和UV空间特征融合，实现高质量360度渲染和实时动画控制。


<details>
  <summary>Details</summary>
Motivation: 从单张图像构建可动画的3D头部头像是一个重要但具有挑战性的问题。现有方法在大角度相机姿态变化下容易失效，影响了3D头像的真实感。

Method: 1. 在参数化人脸模型的UV空间中嵌入高斯基元建模3D头部头像；2. 利用预训练3D GAN提取全局全头特征并提供多视角监督；3. 利用UV空间和人脸对称性，融合局部细粒度输入图像特征与全局全头纹理。

Result: 实验表明该方法能实现高质量3D全头建模和实时动画，提升了3D说话头像的真实感。

Conclusion: 该方法通过创新的UV空间嵌入、3D GAN先验利用和特征融合策略，成功解决了单张图像实时重建可动画3D头部头像的挑战，实现了高质量360度渲染和实时动画控制。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [140] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP提出了一种基于检索增强的开词汇全景分割方法，通过构建掩码片段特征数据库来提升未见类别的分割性能


<details>
  <summary>Details</summary>
Motivation: 现有的全景分割系统通常在特定数据集上训练，难以泛化到训练数据之外的未见类别。开词汇全景分割需要能够根据用户输入分割任意类别，这需要解决未见类别的泛化问题。

Method: 1. 使用图文对数据构建掩码片段特征数据库；2. 推理时，将输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和相关类别标签；3. 基于查询特征与检索特征的相似度分配分类分数；4. 将检索分类分数与CLIP基础分数结合得到最终输出。

Result: 在COCO上训练后，在ADE20k数据集上达到30.9 PQ、19.3 mAP、44.0 mIoU，相比基线分别提升+4.5 PQ、+2.5 mAP、+10.0 mIoU。

Conclusion: RetCLIP通过检索增强机制有效提升了开词汇全景分割中未见类别的性能，为处理开放世界视觉理解任务提供了有效解决方案。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [141] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: 提出SKANet深度學習框架，整合時頻圖像和功率譜密度，使用多分支選擇性核與非對稱卷積模塊動態調整感受野，有效分類複雜的複合干擾信號。


<details>
  <summary>Details</summary>
Motivation: 隨著電磁環境日益複雜，全球導航衛星系統面臨來自複雜干擾的威脅。雖然深度學習能有效識別基本干擾，但由於多種干擾源的疊加，分類複合干擾仍然困難。現有的單域方法常因瞬態突發信號和連續全局信號需要衝突的特徵提取尺度而性能下降。

Method: 提出SKANet認知深度學習框架，基於雙流架構整合時頻圖像和功率譜密度。採用多分支選擇性核模塊結合非對稱卷積塊，使網絡能動態調整感受野，同時捕獲微尺度瞬態特徵和宏尺度頻譜趨勢。在融合階段集成Squeeze-and-Excitation機制，自適應重新校準各模態異構特徵的貢獻。

Result: 在405,000個樣本的數據集上評估，SKANet達到96.99%的總體準確率，在複合干擾分類方面表現出優越的魯棒性，特別是在低干噪比條件下。

Conclusion: SKANet通過動態調整感受野的自適應機制，有效解決了複合干擾分類中微觀瞬態特徵與宏觀頻譜趨勢的提取衝突問題，為複雜電磁環境下的GNSS干擾識別提供了有效解決方案。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [142] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

TL;DR: Jo-SNC提出了一种基于自一致性和邻居一致性的联合样本选择与模型正则化方法，用于处理标签噪声问题，特别关注不同mini-batch中标签噪声的不平衡和分布外噪声数据。


<details>
  <summary>Details</summary>
Motivation: 现实场景中普遍存在标签噪声，深度网络容易记忆这些噪声样本。现有方法主要专注于识别干净数据进行训练，但往往忽略不同mini-batch中标签噪声的不平衡性，并且对分布外噪声数据关注不足。

Method: 提出Jo-SNC方法：1) 使用Jensen-Shannon散度结合样本最近邻来衡量样本是干净或分布外的"可能性"；2) 设计自适应数据驱动的阈值方案调整每类选择阈值；3) 干净样本采用常规训练，检测到的分布内和分布外噪声样本分别采用部分标签学习和负学习；4) 提出三元一致性正则化，促进自预测一致性、邻居预测一致性和特征一致性。

Result: 在多个基准数据集上的广泛实验和全面的消融研究表明，该方法在有效性上优于现有最先进方法。

Conclusion: Jo-SNC通过联合样本选择和模型正则化，有效解决了标签噪声问题，特别在处理不同mini-batch噪声不平衡和分布外噪声方面表现出色。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [143] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: 该论文提出PhyG-MoE框架，通过物理引导的专家混合模型动态调整计算资源以适应信号复杂度，解决GNSS干扰识别中静态模型计算资源不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在GNSS干扰识别中存在根本性限制：采用固定的计算拓扑结构，无法根据输入信号的物理熵动态调整计算资源，导致简单信号和复杂饱和信号消耗相同处理成本，造成严重的资源不匹配问题。

Method: 提出PhyG-MoE（物理引导的专家混合）框架，采用基于频谱的门控机制，根据信号的频谱特征纠缠度进行路由。对于复杂饱和场景，按需激活高容量TransNeXt专家进行特征解耦；对于基本信号，使用轻量级专家处理以最小化延迟。

Result: 在21种干扰类别上的评估显示，PhyG-MoE达到97.58%的整体准确率，在显著降低计算开销的同时保持性能不下降，解决了静态计算与动态电磁环境之间的内在冲突。

Conclusion: PhyG-MoE框架通过动态调整模型容量以适应信号复杂度，为资源受限的认知接收器提供了可行的解决方案，解决了GNSS干扰识别中计算资源不匹配的根本问题。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [144] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 该研究使用可控的1D图像-文本测试平台，探索了基于Transformer的视觉和文本编码器如何通过CLIP风格对比训练学习左右关系理解，发现标签多样性是泛化的主要驱动力，并通过注意力分解揭示了位置嵌入和标记嵌入的交互如何打破左右对称性。


<details>
  <summary>Details</summary>
Motivation: 空间理解是视觉语言模型的关键挑战，但目前尚不清楚这种理解是否真正被习得，以及通过何种机制习得。研究旨在探究基于Transformer的编码器在CLIP风格对比目标下如何出现左右关系理解。

Method: 创建可控的1D图像-文本测试平台，训练轻量级Transformer视觉和文本编码器，使用成对的单对象和双对象场景描述进行端到端训练。通过注意力分解分析位置嵌入和标记嵌入的交互作用如何产生水平注意力梯度。

Result: 对比训练确实学习了左右关系，标签多样性（而非布局多样性）是泛化的主要驱动力。注意力分解显示位置嵌入和标记嵌入的交互诱导了水平注意力梯度，打破了编码器的左右对称性；消除这一贡献会显著降低左右区分能力。

Conclusion: 研究提供了关于CLIP风格模型何时以及如何获得关系能力的机制性见解，揭示了位置和标记嵌入的交互在空间关系学习中的关键作用。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [145] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架，同时优化3D高斯溅射的率失真压缩与语义分割，支持解码端场景编辑应用


<details>
  <summary>Details</summary>
Motivation: 现有研究将3DGS的实时渲染和语义理解作为独立任务处理，缺乏联合优化框架。需要支持解码端场景编辑等应用，而不仅仅是传统场景重建和视图合成

Method: 1) 轻量级隐式神经表示超先验，高效熵编码颜色和语义属性；2) 压缩引导的分割学习，包括量化感知训练增强特征可分性和质量感知权重机制抑制不可靠高斯基元

Result: 在LERF和3D-OVS数据集上的实验表明，该方法显著降低传输成本，同时保持高渲染质量和强分割性能

Conclusion: 提出了首个统一框架，将语义学习集成到3DGS压缩流程中，支持解码端应用，为3D场景的压缩和语义理解提供了高效解决方案

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [146] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

TL;DR: SDF-HOLO是一个针对全身PET/CT的多模态基础模型，通过双流编码器分离CT和PET表征学习，结合跨模态交互模块，解决了全身成像中异质性信号、大轴向覆盖和结构化语义的挑战。


<details>
  <summary>Details</summary>
Motivation: 全身PET/CT成像面临三大挑战：1）解剖和代谢信号的异质性；2）约2米轴向覆盖范围；3）结构化放射学语义。现有医学AI模型假设单模态输入、局部视野和粗粒度图文对齐，无法有效处理全身PET/CT的复杂特性。

Method: 1. 双流编码器分别学习CT和PET表征，通过跨模态交互模块耦合，使解剖上下文优化PET聚合，代谢显著性指导细微形态推理；2. 分层上下文建模结合高效局部窗口和全局注意力，建模全身长程依赖；3. 使用解剖分割掩码作为显式语义锚点，在预训练中执行体素-掩码-文本对齐；4. 在超过10,000名患者数据上预训练。

Result: 在肿瘤分割、低剂量病灶检测和多语言诊断报告生成任务中，SDF-HOLO优于强任务特定和临床参考基线，减少了定位错误和幻觉发现。此外，模型支持全身代谢分析和揭示肿瘤相关的器官间代谢网络相互作用指纹。

Conclusion: SDF-HOLO为全身PET/CT诊断和系统级精准肿瘤学提供了可扩展的计算基础，超越了局部解释，实现了全身代谢分析和系统级生物学洞察。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [147] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS使用3D高斯溅射从航拍图像重建森林场景，通过优化高斯场提取密集点云，利用不透明度加权圆拟合方法测量胸径（DBH），在10个样地的评估中达到4.79厘米RMSE，优于激光雷达基线。


<details>
  <summary>Details</summary>
Motivation: 尽管航拍遥感能高效进行大范围勘测，但在复杂自然场景中进行精确的对象级测量仍很困难。特别是树木胸径（DBH）的测量，由于树干在航拍图像中距离远、观测稀疏（在典型飞行高度下可能只占几个像素），传统重建方法难以准确约束树干几何形状。

Method: 1. 使用SfM-MVS进行初始化；2. 采用3D高斯溅射作为连续、可密集化的场景表示进行高斯优化；3. 使用RaDe-GS的深度感知累积不透明度积分从高斯场提取密集点集；4. 为每个样本分配多视角不透明度可靠性评分；5. 从树干隔离点使用不透明度加权实心圆拟合方法估计DBH。

Result: 在10个具有实地测量DBH的样地上进行评估，TreeDGS达到4.79厘米RMSE（约2.6像素），优于最先进的激光雷达基线（7.91厘米RMSE）。

Conclusion: 基于溅射的密集化几何表示能够实现准确、低成本的航拍DBH测量，证明了从稀疏航拍图像中重建详细树干几何形状的可行性。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [148] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 研究通过多模型对比分析，发现Grad-CAM在医学影像解释中存在局限性，尤其在Vision Transformer模型上解释保真度显著下降，需要更谨慎地使用可视化解释工具。


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学影像分析中广泛应用，但其忠实性和可靠性仍受质疑。本研究旨在批判性评估Grad-CAM是否真实反映深度学习模型在肺癌图像分类中的内部决策过程。

Method: 使用公开的IQ-OTH/NCCD数据集，评估ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0和ViT-Base-Patch16-224五种代表性架构。引入结合定位准确性、基于扰动的忠实性和解释一致性的定量评估框架。

Result: Grad-CAM在大多数卷积网络中能有效突出肿瘤区域，但在Vision Transformer模型上解释保真度显著下降（由于非局部注意力行为）。跨模型比较显示显著性定位存在显著变异性，表明Grad-CAM解释不一定对应网络实际使用的诊断证据。

Conclusion: 暴露了当前基于显著性的XAI方法在医学影像中的关键局限性，强调需要开发兼具计算合理性和临床意义的模型感知可解释性方法。敦促社区重新思考"信任"模型解释的真正含义。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [149] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

TL;DR: 本文提出频率引导任务平衡Transformer(FGTBT)，通过频率域建模和多数据集统一训练来提升面部关键点检测在挑战性场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在面部姿态变化、光照变化和表情变化等挑战性场景下难以准确捕捉面部几何结构，且现有数据集规模有限、多样性不足，限制了模型的鲁棒性训练。

Method: 提出了频率引导任务平衡Transformer(FGTBT)，包含两个核心组件：1)细粒度多任务平衡损失(FMB-loss)，基于各数据集中的关键点出现频率为单个关键点分配权重；2)频率引导结构感知模型(FGSA)，通过频率引导的结构注入和正则化来学习面部结构约束。

Result: 在多个流行基准数据集上的实验结果表明，FGTBT框架结合FMB-loss和FGSA模型，达到了与当前最先进方法相当的性能。

Conclusion: 通过频率域建模和细粒度的多数据集统一训练策略，有效提升了面部关键点检测在挑战性场景下的准确性和鲁棒性。

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [150] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出HPT-GPD方法，通过跨架构的代理对抗鲁棒性传输来解决视觉语言模型对抗鲁棒性蒸馏中的计算资源挑战，同时平衡零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 对抗鲁棒性蒸馏在传统图像分类任务中效果显著，但应用于视觉语言模型（如CLIP）时面临挑战：为大规模多模态模型构建对抗鲁棒性教师模型需要极高的计算资源。

Method: 发现普通CLIP对由不同架构CLIP生成的对抗样本具有内在防御能力（代理对抗鲁棒性），提出异构代理传输（HPT）框架建立跨架构鲁棒性蒸馏通道。为解决代理传输导致的过拟合问题，设计泛化枢轴解耦（GPD），利用学习率调度差异将传输过程分解为保持泛化的预热阶段和提升对抗鲁棒性的传输阶段。

Result: 在15个零样本数据集上的广泛实验证明了HPT-GPD方法的有效性，成功实现了自然泛化与对抗鲁棒性之间的平衡。

Conclusion: HPT-GPD方法通过代理对抗鲁棒性传输和泛化枢轴解耦，有效解决了视觉语言模型对抗鲁棒性蒸馏中的计算资源挑战，同时保持了模型的零样本泛化能力。

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [151] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: 提出THFEM框架，将音频驱动说话头生成模型与面部表情操纵技术结合，通过相邻帧学习策略优化生成质量，实现表情改变时口型同步保持


<details>
  <summary>Details</summary>
Motivation: 现有的语音保持面部表情操纵技术仍存在口型同步困难的问题，而音频驱动说话头生成模型擅长生成精确的口型运动，因此探索两者的结合以改进表情操纵时的口型保持

Method: 提出THFEM框架：1）使用音频驱动说话头生成模型从音频输入和SPFEM处理图像生成口型同步的帧；2）开发相邻帧学习策略，微调模型预测连续帧序列，利用相邻帧信息提高图像质量

Result: 实验评估表明该框架能有效保持表情操纵时的口型形状，验证了音频驱动说话头生成模型与SPFEM结合的优势

Conclusion: 通过集成音频驱动说话头生成模型和相邻帧学习策略，THFEM框架成功解决了表情操纵中的口型同步问题，为面部表情操纵技术提供了新方向

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [152] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

TL;DR: YOLO26通过消除NMS后处理，采用端到端学习策略，在推理速度和检测精度上超越现有SOTA方法，解决了延迟与精度之间的历史权衡。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO系列（v1-v11）受到NMS后处理的延迟和超参数敏感性限制，需要一种能消除这种约束的新范式。

Method: 引入MuSGD优化器稳定轻量级骨干网络，采用STAL进行小目标感知分配，使用ProgLoss进行动态监督，完全消除NMS后处理。

Result: YOLO26在官方性能基准测试中建立了新的帕累托前沿，在推理速度和检测精度上均超越RTMDet、DAMO-YOLO等先进竞争对手。

Conclusion: 通过将表示学习与启发式后处理解耦，YOLO26成功解决了延迟与精度之间的历史权衡，标志着边缘计算机视觉的下一进化步骤。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [153] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 该研究开发了一个集成深度学习框架，通过优化加权平均集成VGG16、ResNet50和InceptionV3模型，实现了对牛结节性皮肤病（LSD）和口蹄疫（FMD）的同时检测，准确率达到98.2%，解决了两种疾病症状重叠的诊断难题。


<details>
  <summary>Details</summary>
Motivation: LSD和FMD是影响牛的高度传染性病毒疾病，造成重大经济损失。由于症状相互重叠且与良性病症（如昆虫叮咬或化学灼伤）相似，视觉诊断困难，延误了及时控制措施的实施。

Method: 使用来自印度、巴西和美国18个农场的10,516张专家标注图像数据集，提出新颖的集成深度学习框架，将VGG16、ResNet50和InceptionV3模型通过优化加权平均方法进行集成，实现LSD和FMD的同时检测。

Result: 模型达到最先进的98.2%准确率，宏观平均精确度为98.2%，召回率为98.1%，F1分数为98.1%，AUC-ROC为99.5%。该框架独特解决了多疾病检测中症状重叠的关键挑战。

Conclusion: 该方法实现了早期、精确和自动化的疾病诊断，有潜力改善疾病管理，支持全球农业可持续性，并设计用于未来在资源有限环境中的部署。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [154] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

TL;DR: TwoHead-SwinFPN：用于身份证件防伪检测的统一深度学习架构，同时实现二进制分类和篡改区域精确定位，在FantasyIDiap数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI模型的普及，身份证件面临越来越严重的合成篡改威胁（如换脸和文本修复攻击），需要有效的检测和定位方法。

Method: 提出TwoHead-SwinFPN统一架构，集成Swin Transformer主干网络、特征金字塔网络（FPN）和UNet风格解码器，增强CBAM注意力模块，采用双头架构进行检测和分割任务的联合优化，使用不确定性加权多任务学习。

Result: 在FantasyIDiap数据集上取得84.31%准确率、90.78% AUC（分类）和57.24%平均Dice分数（定位），二元分类F1分数达88.61%，同时保持计算效率，适合通过FastAPI实现实际部署。

Conclusion: 该方法在身份证件防伪检测中表现出色，能够同时实现高精度分类和篡改区域定位，具有良好的实际部署潜力，并通过多语言和多设备测试验证了其泛化能力。

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [155] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

TL;DR: 提出SHT弱监督框架，通过面部幻觉和姿态迁移任务增强面部关键点检测，解决低分辨率图像、数据不足和标注不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 传统高精度面部关键点检测依赖高分辨率深度特征，但低分辨率图像、图像压缩、训练数据不足以及标注不精确都会降低检测准确性。

Method: 提出SHT框架，包含两个相互增强的模块：DHLN（双幻觉学习网络）通过面部关键点检测和面部幻觉任务学习高分辨率表示；FPTN（面部姿态迁移网络）通过变换面部姿态进一步改善关键点热图和幻觉面部。

Result: 实验结果表明，该方法在面部幻觉和面部关键点检测任务上都超越了当前最先进的技术。

Conclusion: 这是首个通过整合面部幻觉和面部姿态迁移任务来探索弱监督面部关键点检测的研究，能有效提升低分辨率输入下的检测精度。

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [156] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

TL;DR: DSCT通过融合区域特征和分割特征，采用动态方式解决语义不一致和空间错位问题，在图像描述生成任务中超越现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于区域特征的图像描述方法虽然进展迅速，但由于缺乏上下文信息且过度依赖已生成的部分描述来预测剩余词汇，容易产生不相关的描述。

Method: 提出双流协作Transformer(DSCT)，包含多个模式特定互注意力编码器(PSMAE)和动态提名解码器(DND)。PSMAE通过互相查询来突出和整合两种表示的特征；DND动态搜索与输入文本表示最相关的学习块，并利用整合后的区域和分割特征之间的同质特征来生成描述。

Result: 在流行基准数据集上的实验结果表明，DSCT在图像描述生成任务中优于现有最先进模型。

Conclusion: 这是首个探索如何以动态方式融合不同模式特定特征来解决语义不一致和空间错位问题的研究，为图像描述生成提供了更准确和描述性的解决方案。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [157] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究针对目标识别领域的成员推断测试(MINT)进行分析，提出专门优化的MINT模型架构，在三个公开数据库上通过实验验证，能够以70-80%的准确率识别数据是否用于训练。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决目标识别领域中成员推断测试的性能问题，特别是在确定给定数据是否被用于训练阶段这一挑战。当前MINT方法在目标识别这一复杂领域缺乏专门优化的架构，需要针对该领域特点设计更有效的解决方案。

Method: 提出专门针对目标识别领域优化的MINT模型架构，采用卷积层捕获和建模训练过程中的激活模式。实验包含目标检测模型、嵌入提取器和MINT模块三部分，在三个公开数据库(总计超过174K图像)上进行测试，分析不同检测模块层深度对MINT性能的影响。

Result: 提出的架构能够有效识别测试和训练数据，准确率在70%到80%之间，具体取决于输入MINT模块的检测模块层深度。研究还分析了影响MINT模块性能的因素，为训练过程提供了更透明的洞察。

Conclusion: 研究成功开发了针对目标识别领域优化的MINT架构，能够有效进行成员推断测试，为理解训练过程和数据使用提供了有价值的工具。准确率结果显示了该方法的有效性，同时为训练过程的透明度分析提供了基础。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [158] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA是一种质量引导的K自适应槽注意力方法，通过解耦槽选择与重建、提出无监督槽质量度量，显著提升了动态对象数量场景下的对象中心学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应方法存在两个主要问题：1) 未显式约束槽绑定质量，导致低质量槽的特征归属模糊；2) 在重建目标中加入槽数量惩罚会造成减少活跃槽数量与保持重建保真度之间的优化冲突，导致性能显著落后于固定K的方法。

Method: 1) 解耦槽选择与重建，消除两个目标间的相互约束；2) 提出无监督Slot-Quality度量来评估每个槽的质量；3) 设计质量引导的槽选择方案，动态选择高质量槽子集；4) 使用新设计的门控解码器进行重建训练；5) 推理时通过槽注意力上的token-wise竞争实现K自适应。

Result: QASA在真实和合成数据集上都大幅超越现有K自适应方法，在真实世界数据集上甚至超过了固定K的方法。

Conclusion: 通过解耦槽选择与重建、引入槽质量度量和质量引导的选择机制，QASA有效解决了现有K自适应方法的局限性，实现了在动态对象数量场景下高质量的对象中心学习。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [159] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD是一种从单张RGB图像联合估计3D注视方向和人体姿态的新方法，利用扩散模型处理不确定性，生成多个合理的3D注视和姿态假设。


<details>
  <summary>Details</summary>
Motivation: 现有的3D注视估计方法通常需要时间信息或无法处理不确定性，而注视与人体姿态密切相关，需要一种能够从单张图像联合估计注视和姿态的方法。

Method: 1) 使用扩散模型处理不确定性，基于输入图像提取的2D上下文信息生成多个合理的3D注视和姿态假设；2) 将2D姿态、主体周围环境和场景上下文作为去噪过程的约束条件；3) 提出新颖的3D注视表示方法，将其作为距离眼睛固定距离的额外身体关节；4) 通过联合去噪过程同时估计注视和姿态。

Result: 在三个基准数据集上的评估表明，GazeD在3D注视估计方面达到了最先进的性能，甚至超过了依赖时间信息的方法。

Conclusion: GazeD通过扩散模型成功实现了从单张RGB图像联合估计3D注视和人体姿态，提出的新颖注视表示方法和联合去噪框架有效利用了注视与姿态的紧密关系，取得了优异的性能。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [160] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 本文提出StyMam，一种基于Mamba架构的图像风格迁移方法，通过残差双路径条带扫描机制和通道重加权空间注意力模块，解决了现有方法在局部纹理和全局依赖建模上的不足，实现了高质量、无伪影的风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有图像风格迁移方法存在显著缺陷：基于GAN的方法（使用CNN或Transformer）难以同时捕捉局部和全局依赖关系，导致伪影和不协调模式；基于稳定扩散的方法虽然减少了这些问题，但往往无法保留内容结构且推理速度慢。需要一种既能生成高质量风格化图像，又能保持内容结构并实现快速推理的新方法。

Method: 提出基于Mamba的生成器StyMam，包含两个核心组件：1）残差双路径条带扫描机制，用于高效捕捉局部纹理特征；2）通道重加权空间注意力模块，用于建模全局依赖关系。这种架构设计旨在克服传统方法的局限性。

Result: 通过广泛的定性和定量实验证明，所提出的方法在质量和速度方面均优于最先进的算法，能够生成高质量的风格化图像，同时避免伪影和不协调模式的出现。

Conclusion: StyMam方法通过重新审视GAN架构并引入Mamba-based生成器，成功解决了现有图像风格迁移方法的关键问题，实现了在保持内容结构的同时生成高质量风格化图像，且具有快速推理的优势。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [161] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 本文提出了一种空间亲和力组件，可将高分辨率遥感图像融入自监督预训练，提升中分辨率图像的表示学习和下游分割性能。


<details>
  <summary>Details</summary>
Motivation: 遥感领域自监督预训练主要使用中分辨率图像数据集，但随着高分辨率数据集的发布，需要探索如何利用高分辨率数据来增强中分辨率图像的表示学习，提升下游分割任务的性能。

Method: 设计了一个空间亲和力组件，可以集成到现有的自监督学习框架中，利用高分辨率图像来学习更好的中分辨率图像表示。

Result: 在两个自监督学习框架上测试表明，该空间亲和力组件优于仅使用高分辨率或中分辨率图像单独预训练的模型。

Conclusion: 通过引入高分辨率数据并设计空间亲和力组件，能够有效提升中分辨率遥感图像的自监督表示学习效果，从而改善下游分割任务的性能。

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [162] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

TL;DR: 该研究提出了一种基于表格Transformer（TabTrans）架构的新型方法，用于分析纵向患者数据进行早期2型糖尿病风险预测，在卡塔尔生物银行队列中表现出优于传统机器学习方法和生成式AI模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理纵向患者数据时往往忽略疾病进展中的复杂长期依赖关系，需要开发能够更有效分析多模态医疗数据（包括电子健康记录和DXA数据）的先进模型来改善2型糖尿病的早期预测和个性化管理。

Method: 采用表格Transformer（TabTrans）架构处理纵向患者健康记录和骨骼相关表格数据，使用SMOTE和SMOTE-ENN技术解决类别不平衡问题，在包含1,382名受试者的卡塔尔生物银行队列中验证模型，并与传统ML模型及生成式AI模型（Claude 3.5 Sonnet、GPT-4、Gemini Pro）进行比较。

Result: TabTrans模型在2型糖尿病预测中表现出优越性能，ROC AUC达到79.7%以上，优于生成式AI模型和传统机器学习方法。特征解释分析确定了关键风险指标，包括内脏脂肪组织质量和体积、ward骨密度和骨矿物含量、T和Z分数、L1-L4分数。

Conclusion: TabTrans在分析复杂表格医疗数据方面具有显著潜力，为卡塔尔人群的主动2型糖尿病管理和个性化临床干预提供了强大工具，证明了表格Transformer架构在医疗预测任务中的有效性。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [163] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: AsyncBEV是一个可训练的轻量级模块，用于提高3D BEV目标检测模型对传感器异步的鲁棒性，通过估计BEV特征流来对齐特征图。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的多模态感知任务通常依赖传感器同步，但现实中网络延迟、硬件故障等因素导致传感器存在时间偏移，这种异步会降低感知性能，特别是对动态物体。

Method: 受场景流估计启发，AsyncBEV首先估计两个不同传感器模态BEV特征的2D流，考虑已知的时间偏移，然后使用预测的特征流对特征图进行扭曲和对齐，可集成到不同的BEV检测器架构中。

Result: 实验表明AsyncBEV显著提高了对LiDAR或相机传感器小和大异步的鲁棒性，在0.5秒时间偏移的最坏情况下，动态物体的NDS分别比基线提高了16.6%和11.9%。

Conclusion: AsyncBEV是一个有效且通用的模块，能够显著提升BEV检测器对传感器异步的鲁棒性，特别是在处理动态物体方面表现突出。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [164] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D是一个无需额外训练的框架，通过3D重建模型和交互式相机操作，让视觉大模型能够进行3D空间推理，显著提升了多个模型的3D推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型虽然在2D视觉理解方面表现出色，但本质上仍是2D感知器，缺乏真正的3D空间推理能力。而理解物理世界需要空间智能，包括几何、透视和空间关系的理解。

Method: 利用3D重建模型从图像或视频中恢复点云和相机位姿，通过相机操作和视角切换（自我视角/全局视角）让智能体主动操纵空间，将空间推理转化为交互式的3D思维链过程。

Result: 在无需额外训练的情况下，Think3D显著提升了GPT-4.1和Gemini 2.5 Pro等先进模型的性能，在BLINK Multi-view和MindCube上平均提升7.8%，在VSI-Bench上提升4.7%。对于较小模型，通过强化学习策略选择信息丰富的视角和操作，工具使用的收益从0.7%提升到6.8%。

Conclusion: 免训练的工具增强空间探索是实现多模态智能体更灵活、更类人3D推理的有效途径，为多模态智能建立了新的维度。代码和权重已开源。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [165] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个用于电力基础设施3D语义分割的多模态数据集，结合了高密度LiDAR和高分辨率倾斜影像，包含7,694张图像和25亿个点，标注为11个类别。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR和高分辨率倾斜影像，并带有电力线路资产3D语义标签的公开数据集，这对电力基础设施的精确分割和分析造成了限制。

Method: 创建了GridNet-HD数据集，包含预定义的数据分割和mIoU评估指标，提供了单模态（仅LiDAR、仅图像）和多模态融合的基线模型。

Result: 在多模态融合模型中，融合方法比最佳单模态基线提升了+5.55 mIoU，证明了几何信息和外观信息的互补性。

Conclusion: GridNet-HD填补了电力基础设施多模态3D语义分割数据集的空白，为相关研究提供了基准数据和代码资源，推动了电力线路资产的精确分析。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [166] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

TL;DR: 提出一种双分支原型学习网络，结合Retinex理论与少样本学习，用于低光照环境下的裂缝分割，无需大量标注数据。


<details>
  <summary>Details</summary>
Motivation: 真实世界裂缝常出现在隧道、桥底等低光照环境中，导致计算机视觉分割精度下降；像素级标注耗时且大多数深度学习方法需要大量良好光照数据集。

Method: 1. 双分支原型学习网络整合Retinex理论与少样本学习；2. Retinex反射分量指导光照不变的全局表示学习；3. 度量学习减少对大型标注数据集的依赖；4. 交叉相似性先验掩码生成模块计算查询与支持特征间的高维相似性；5. 多尺度特征增强模块融合多尺度特征与先验掩码缓解空间不一致性。

Result: 在多个基准测试上进行广泛实验，在低光照条件下展现出一致的state-of-the-art性能。

Conclusion: 该方法通过整合Retinex理论与少样本学习，有效解决了低光照环境下裂缝分割的挑战，减少了对大规模标注数据的依赖，在多个基准测试中取得了最佳性能。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [167] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: HyperAdapt框架通过患者条件化适配改进医疗AI模型的亚组可靠性，使用超网络生成残差调制参数，在保持共享骨干网络的同时针对不同患者亚组进行适配。


<details>
  <summary>Details</summary>
Motivation: 医疗AI模型在不同患者亚组中表现不均，现有公平性方法通过抑制敏感属性会损失重要诊断信息。临床决策需要结合患者上下文，因此需要设计亚组感知模型。

Method: 提出HyperAdapt患者条件化适配框架：将年龄、性别等临床相关属性编码为紧凑嵌入，通过超网络模块生成残差调制参数，调整共享骨干网络的选定层。采用低秩和瓶颈参数化约束适配复杂度。

Result: 在多个医疗影像基准测试中，该方法一致提高亚组性能而不牺牲整体准确率。在PAD-UFES-20数据集上，比最强基线在召回率上提升4.1%，F1分数提升4.4%，对代表性不足的患者群体提升更大。

Conclusion: HyperAdapt框架有效解决了医疗AI模型的亚组性能不均问题，通过患者条件化适配在保持共享诊断模型的同时提高亚组可靠性，为医疗公平性提供了新方向。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [168] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: SANDesc是一个基于注意力机制的轻量级描述符提取网络，可在不修改底层关键点检测器的情况下提升匹配性能，仅需240万参数。


<details>
  <summary>Details</summary>
Motivation: 现有关键点描述符在匹配任务中存在改进空间，需要一种能有效提升匹配性能而不改变底层检测器的轻量级描述符提取网络。

Method: 采用改进的U-Net架构，结合卷积块注意力模块和残差路径，构建残差U-Net注意力块。使用改进的三元组损失和课程学习启发的困难负样本挖掘策略进行训练。

Result: 在HPatches、MegaDepth-1500和Image Matching Challenge 2021上，SANDesc相比原始描述符在多个匹配任务中表现更优。在作者提出的4K城市数据集上，SANDesc在有限计算资源下取得显著性能提升。

Conclusion: SANDesc是一个高效轻量的描述符提取网络，能显著提升关键点匹配性能，同时作者贡献了一个新的4K城市数据集用于特征提取器评估。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [169] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark是一种单次、无优化的水印框架，通过在VAE潜在频域直接调制相位，比优化方法快数千倍，同时保持卓越的抗攻击能力和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有潜在扩散模型（LDMs）生成的水印方法速度太慢，因为它们依赖迭代优化或反演过程。需要一种快速、有效且能抵抗严重攻击的水印方案。

Method: PhaseMark采用单次、无优化的框架，直接在VAE潜在频域中调制相位。分析了四种调制变体，探索性能与质量之间的权衡。

Result: PhaseMark比基于优化的技术快数千倍，同时实现了最先进的抗攻击能力（包括再生攻击），且不降低图像质量。

Conclusion: PhaseMark展示了一种新范式，通过利用潜在内在特性实现高效、弹性的水印，为快速稳健的水印提供了新的方向。

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [170] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer是一个基于3D高斯泼溅的具身探索与推理框架，通过视觉语言模型实现3D场景中的问题驱动探索，在复杂组合语言查询上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：1）基于语言嵌入3DGS的方法只能处理简单查询，难以应对复杂的组合语言查询；2）基于物体中心RGB-D结构化记忆的方法虽然有空间基础，但受限于预定义视角。需要一种既能处理复杂语言查询，又能灵活探索3D场景的方法。

Method: 在3DGS基础上引入视觉语言模型，实现问题驱动的3D场景探索与推理。首先识别与查询问题最相关的预捕获图像，然后将其调整到新的视角以更准确地捕捉视觉信息，供VLM进行更好的推理。

Result: 实验表明，GaussExplorer在多个基准测试中优于现有方法，证明了将VLM推理与3DGS集成在具身任务中的有效性。

Conclusion: GaussExplorer成功解决了现有方法的局限性，通过结合3DGS和VLM，实现了对复杂组合语言查询的有效处理，并在具身探索任务中表现出色。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [171] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一个用于人体中心视觉任务的无监督预训练框架，利用CLIP生成多级语义伪标签，通过Prompt-Controlled MoE模块动态适应不同下游任务的语义粒度需求。


<details>
  <summary>Details</summary>
Motivation: 随着大规模无标签人体图像数据集的涌现，需要一种通用的无监督预训练模型来支持多样化的人体中心下游任务，如监控、医疗和人机交互。

Method: 1. 利用CLIP生成低层（身体部位）和高层（属性）语义伪标签；2. 引入Prompt-Controlled Mixture-of-Experts模块动态适应任务特定提示；3. 采用多任务预训练策略，整合部位和属性级伪标签指导表示学习。

Result: 在多个基准测试上的广泛实验表明，CLASP持续优于现有的无监督预训练方法，推动了人体中心视觉分析领域的发展。

Conclusion: CLASP通过结合CLIP的多级语义伪标签和自适应MoE模块，为人体中心视觉任务提供了一个强大且通用的无监督预训练框架，显著提升了表示学习的效果和迁移能力。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [172] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: 本文介绍了TVWorld，一个基于图的离线电视导航抽象系统，用于评估大视觉语言模型在电视遥控交互中的能力，并提出了拓扑感知训练框架和TVTheseus模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型研究主要关注点选交互，而日常生活中常见的电视遥控交互尚未得到充分探索。需要填补这一空白，评估模型在真实电视导航中的能力。

Method: 1. 构建TVWorld：基于图的离线电视导航抽象系统，支持可复现、免部署的评估
2. 创建两个互补基准：TVWorld-N用于拓扑感知导航，TVWorld-G用于焦点感知接地
3. 提出拓扑感知训练框架：向大视觉语言模型注入拓扑意识
4. 开发TVTheseus：专门用于电视导航的基础模型

Result: TVTheseus在TVWorld-N上达到68.3%的成功率，超过了Gemini 3 Flash等强闭源基线模型，建立了最先进的性能表现。

Conclusion: 现有代理在基于焦点的长视野电视导航中存在拓扑意识不足的问题。通过拓扑感知训练可以显著提升模型性能，TVTheseus的成功为开发有效的电视使用代理提供了有价值的见解。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [173] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一种生成交互式、可对话、逼真3D虚拟人像的方法，通过多视角采集构建可动画的3D面部和动态身体模型，使用高斯图元渲染，结合LLM实现对话能力，语音驱动面部动画同步，应用于游戏、虚拟助手、教育等领域。


<details>
  <summary>Details</summary>
Motivation: 创建能够实时交互、对话且具有照片级真实感的3D虚拟人像，以支持沉浸式环境中的多种应用场景，如游戏、虚拟助手和个性化教育。

Method: 基于多视角采集构建可动画的3D面部模型和动态3D身体模型，使用高斯图元渲染；结合LLM实现对话能力；通过语音信号驱动面部动画实现精确同步；采用改进的SWinGS++进行身体重建和HeadGaS++进行面部重建，并提供无伪影的面部与身体模型融合方案。

Result: 开发了完整的ICo3D系统，展示了实时与3D虚拟人像对话的多个用例，实现了支持口头和书面形式交互的完全集成虚拟人像体验。

Conclusion: ICo3D提供了一种完全集成的虚拟人像体验，适用于游戏、虚拟助手、个性化教育等多个领域，展示了交互式对话3D虚拟人像的广泛适用性。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [174] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 团队在MICCAI 2025的SSL3D和FOMO25两个3D脑MRI挑战赛中均获第一名，提出基于U-Net CNN的解决方案，结合解剖学先验和神经影像领域知识，相比Transformer方法训练快10-100倍且模型小10倍。


<details>
  <summary>Details</summary>
Motivation: 开发适用于医学影像分析的Foundation Models以克服放射学任务中的独特挑战，特别是在3D脑MRI领域。

Method: 采用U-Net CNN架构，结合解剖学先验知识和神经影像领域知识策略，不使用Transformer架构。

Result: 在MICCAI 2025的SSL3D和FOMO25两个3D脑MRI挑战赛中均排名第一，模型训练速度比Transformer方法快1-2个数量级，模型尺寸小10倍。

Conclusion: U-Net CNN结合领域知识的方法在3D脑MRI分析中相比Transformer方法具有显著效率优势，为医学影像Foundation Models开发提供了实用方案。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [175] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: 该论文提出了GTPred基准测试，用于评估多模态大语言模型在结合时间和空间信息的地理定位任务上的表现，发现现有模型在时空推理方面仍有局限。


<details>
  <summary>Details</summary>
Motivation: 现有地理定位研究主要关注视觉空间信息，忽视了图像中的时间信息对定位的约束作用，需要建立同时考虑时空信息的基准测试来评估模型能力。

Method: 创建了GTPred基准测试，包含370张全球分布、时间跨度120年的图像；评估方法同时考虑年份和分层位置序列匹配，并对中间推理链进行细致评估。

Result: 在8个专有和7个开源MLLM上的实验表明，尽管模型具有强大的视觉感知能力，但在世界知识和地理时空推理方面仍有限制；同时发现结合时间信息能显著提升位置推断性能。

Conclusion: GTPred基准填补了现有地理定位评估中时间信息缺失的空白，揭示了当前MLLM在时空联合推理方面的不足，为未来研究提供了重要参考。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [176] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

TL;DR: 论文提出Additive U-Net，用门控加法连接替代传统U-Net中的拼接连接，通过可学习的非负标量控制编码器贡献，避免通道维度膨胀，在图像去噪任务中实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 传统U-Net中的跳跃连接通过拼接实现，但会加倍通道维度并模糊信息流，导致不受控制的噪声传递。需要一种更轻量、更可解释的替代方案。

Method: 提出Additive U-Net，将拼接式跳跃连接替换为门控加法连接。每个跳跃路径通过可学习的非负标量进行缩放，提供对编码器贡献的显式和可解释控制，同时避免通道膨胀。

Result: 在Kodak-17去噪基准测试中，Additive U-Net在噪声水平σ=15、25、50下实现了竞争性的PSNR/SSIM性能，对内核调度和网络深度具有鲁棒性。即使没有显式的下采样/上采样或强制层次结构，模型也能自然学习从高频到带通再到低频特征的渐进过程。

Conclusion: 加法跳跃连接作为拼接的轻量级和可解释替代方案，既能实现高效设计，又能更清晰地理解重建网络中的多尺度信息传递。

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [177] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 本文提出了一个用于评估基于对象的视觉注意力的VR街景导航数据集，并引入了对象相似度（oSIM）评估指标和基于Mamba U-Net的SUMGraph模型。


<details>
  <summary>Details</summary>
Motivation: 人类视觉注意力本质上是基于对象的，但现有计算模型对此关注不足，主要缺乏合适的评估数据集和指标。特别是在街景导航等安全关键场景中，难以在真实环境中收集可比数据。

Method: 1) 创建包含120名参与者的VR街景导航数据集，包含精确注视数据、完整环境状态表示、丰富标注（全景分割、深度信息、车辆关键点）和可变场景复杂度；2) 提出对象相似度（oSIM）作为基于对象注意力的评估指标；3) 提出SUMGraph模型，使用Mamba U-Net架构并通过图表示显式编码关键场景对象（车辆）。

Result: 1) 数据集填补了基于对象注意力评估的空白；2) 显式优化基于对象注意力不仅提高了oSIM性能，也改善了模型在常见指标上的表现；3) SUMGraph模型在多个最先进的视觉注意力预测方法上取得了进一步的性能提升。

Conclusion: 该研究通过提供专门的数据集、评估指标和模型，推动了基于对象的视觉注意力计算建模，在安全关键应用（如街景导航）中具有重要价值，所有资源将公开释放。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [178] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: 本文介绍了BLEMORE数据集，这是一个用于多模态混合情感识别的新数据集，包含情感相对显著性的标注，并评估了多种模型在混合情感识别任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 人类通常同时体验多种情感混合而非单一情感，但现有视频情感识别方法大多只能识别单一情感。少数尝试识别混合情感的方法无法评估混合中各种情感的相对显著性，主要原因是缺乏标注相对显著性的混合情感数据集。

Method: 引入BLEMORE数据集，包含58位演员的3000多个视频片段，涵盖6种基本情感和10种不同混合，每种混合有3种显著性配置（50/50、70/30、30/70）。使用该数据集评估了最先进的视频分类方法在两个混合情感预测任务上的表现：情感存在预测和情感相对显著性预测。

Result: 单模态分类器在验证集上情感存在准确率最高达29%，显著性准确率13%；多模态方法有明显提升，ImageBind + WavLM达到35%存在准确率，HiCMAE达到18%显著性准确率。在测试集上，最佳模型达到33%存在准确率（VideoMAEv2 + HuBERT）和18%显著性准确率（HiCMAE）。

Conclusion: BLEMORE数据集为推进考虑混合情感表达复杂性和重要性的情感识别系统研究提供了宝贵资源，展示了多模态方法在混合情感识别任务上的优势。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [179] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

TL;DR: 提出ConvMambaNet混合深度学习模型，结合CNN和Mamba结构化状态空间模型，用于癫痫脑电信号中的发作检测，在CHB-MIT头皮脑电数据集上达到99%准确率。


<details>
  <summary>Details</summary>
Motivation: 癫痫严重影响生活质量，脑电图是监测神经活动和检测发作的主要工具，但由于脑电信号的时间复杂性，自动分析仍然具有挑战性。

Method: 提出ConvMambaNet混合深度学习模型，将Mamba结构化状态空间模型块嵌入到卷积神经网络框架中，有效捕捉空间特征和长程时间动态。

Result: 在CHB-MIT头皮脑电数据集上评估，ConvMambaNet达到99%的准确率，在严重类别不平衡情况下表现出鲁棒性能。

Conclusion: 模型在癫痫发作检测方面具有精确高效的潜力，为临床环境中实时自动化癫痫监测提供了可行路径。

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [180] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出了首个利用真实天气条件攻击视觉语言模型的对抗框架，专注于雨天场景，通过两阶段参数化扰动模型分析雨致决策偏移，揭示了主流VLM在真实天气条件下的语义对齐脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型通常在规范视觉条件下训练，对真实天气条件（尤其是雨天）的鲁棒性以及在此类结构化扰动下跨模态语义对齐的稳定性研究不足。作者旨在探索天气条件对VLM安全性和可靠性的潜在风险。

Method: 采用两阶段参数化扰动模型：第一阶段通过低维全局调制建模降雨全局效应，逐渐削弱原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引发的光照变化，优化不可微的天气空间以诱导稳定的语义偏移。

Result: 实验表明，即使物理上合理且高度受限的天气扰动也能在主流VLM中引发显著的语义错位，证实了光照建模和多尺度雨滴结构是驱动这些语义偏移的关键因素。

Conclusion: 该研究揭示了视觉语言模型在真实天气条件下的脆弱性，强调需要开发更鲁棒的模型以应对现实世界部署中的安全风险，为理解天气扰动对多模态系统的影响提供了新视角。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [181] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 提出基于3D超声波传感器Calyo Pulse的学习型3D语义分割框架，用于恶劣环境下的自动驾驶感知


<details>
  <summary>Details</summary>
Motivation: 激光雷达和摄像头系统存在成本、鲁棒性和恶劣天气性能的权衡，需要开发成本效益高且可靠的感知系统

Method: 引入基于Calyo Pulse固态3D超声波传感器的学习框架，采用3D U-Net架构对空间超声波数据进行体素分割训练

Result: Calyo Pulse传感器展现出稳健的分割性能，通过更大数据集、精细化真值标注和加权损失函数有进一步提升潜力

Conclusion: 3D超声波传感是自动驾驶可靠感知的有前景的补充模态，特别是在恶劣和杂乱环境中

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [182] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity是一个首个开放、大规模、多领域的工程图数据集，包含全面的结构化标注，用于自动化图表解析。


<details>
  <summary>Details</summary>
Motivation: 目前AI在科学发现中面临的根本障碍是缺乏对工程图中视觉结构知识的理解和操作能力，这阻碍了AI在需要图表解释、技术图纸分析和视觉推理的科学工作流程中充分发挥作用。

Method: 创建了一个开放、大规模、多领域的工程图数据集，包含层次化组件关系、连接关系和语义元素的全面结构化标注，专门设计用于自动化图表解析。

Result: 提出的Enginuity数据集将能够支持多模态大语言模型处理关键下游任务，包括结构化图表解析、跨模态信息检索和AI辅助工程仿真。

Conclusion: Enginuity数据集将对科学发现的AI研究产生变革性影响，使AI系统能够理解和操作工程图中嵌入的视觉结构知识，打破当前阻碍AI全面参与科学工作流程的根本障碍。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [183] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 提出了CausalSpatial基准测试，揭示多模态大语言模型在因果空间推理能力上的严重缺陷，并提出了Causal Object World model（COW）框架来通过生成假设动态视频提升模型的物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过观察静态场景预测后续动态变化（如碰撞、遮挡等），但当前的多模态大语言模型主要局限于静态空间感知，无法回答"如果...会怎样"的因果推理问题。需要评估和提升模型在这方面的能力。

Method: 1) 创建CausalSpatial诊断基准，包含碰撞、兼容性、遮挡和轨迹四个任务；2) 分析模型失败原因，发现模型过度依赖文本思维链而脱离视觉证据；3) 提出Causal Object World model（COW）框架，通过生成假设动态视频来外化模拟过程。

Result: 人类在基准测试中得分84%，而GPT-5仅得54%，显示模型与人类在因果空间推理能力上的巨大差距。COW框架通过提供明确的视觉因果线索，使模型能够将推理建立在物理现实而非语言先验之上。

Conclusion: 当前MLLMs在因果空间推理方面存在根本性缺陷，主要问题是过度依赖文本推理而脱离视觉证据。COW框架通过外化模拟过程、生成视觉动态，为解决这一问题提供了有效途径，为提升模型的物理推理能力指明了方向。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [184] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一个多模态空间转录组学分析框架，通过跨注意力融合联合建模空间拓扑、基因表达和组织形态，实现更清晰的时空域划分。


<details>
  <summary>Details</summary>
Motivation: 现有空间转录组学方法在整合组织形态学和分子谱方面存在不足，往往采用浅层融合策略或完全忽略组织图像，导致难以解析模糊的空间域边界。

Method: MultiST采用基于跨注意力的融合机制，结合基于图的基因编码器与对抗对齐学习鲁棒空间表征，同时整合颜色归一化的组织形态特征来捕获分子-形态依赖关系并细化域边界。

Result: 在13个跨两个器官（人脑皮层和乳腺癌组织）的多样化ST数据集上，MultiST相比现有方法产生了边界更清晰、更一致的空间域，获得了更稳定的伪时间轨迹和更具生物学可解释性的细胞间相互作用模式。

Conclusion: MultiST通过有效整合多模态信息，显著提升了空间转录组学数据的分析能力，为研究组织结构和细胞间相互作用提供了更强大的工具。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [185] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出一种在灰尘弥漫的封闭环境中生成可控多级灰尘浓度的方法，用于毫米波传播研究，并开发基于阈值滤波和规则分类的实时行人检测系统。


<details>
  <summary>Details</summary>
Motivation: 地下矿井、公路隧道、倒塌建筑等恶劣封闭环境中存在大量灰尘和反射表面，严重影响毫米波雷达的感知功能，需要研究这些条件下的可靠检测方法。

Method: 1) 设计可控多级灰尘浓度生成方法；2) 创建包含毫米波雷达、相机和LiDAR的4D数据集；3) 开发基于RCS、速度、方位角、仰角等参数的阈值滤波框架；4) 构建基于聚类级规则分类的行人检测管道。

Result: 该方法显著增强了灰尘弥漫矿井环境中的杂波抑制、检测鲁棒性和系统整体韧性，实现了可靠的实时行人检测。

Conclusion: 集成的灰尘生成、数据采集和处理框架为恶劣电磁约束条件下的毫米波传播研究提供了可重复的实验平台，并能有效应对灰尘颗粒和反射表面的联合影响。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [186] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 提出一种基于球形几何表示和条件扩散的文本到3D人脸生成方法，通过将复杂几何约束到规则球面流形上，实现高质量几何和纹理合成。


<details>
  <summary>Details</summary>
Motivation: 文本到3D人脸生成面临几何质量低下的核心挑战，现有方法难以处理顶点在3D空间中的任意复杂分布，导致网格连接性差和几何效果不理想。

Method: 提出球形几何表示，将几何信号锚定到均匀球坐标，确保规则点分布；引入球形几何扩散框架，基于2D映射的条件扩散模型，联合建模几何和纹理，几何显式条件纹理合成。

Result: 在文本到3D生成、人脸重建和基于文本的3D编辑等任务中表现出色，在几何质量、文本保真度和推理效率方面显著优于现有方法。

Conclusion: 通过将复杂几何约束到简单规则流形（拓扑球面），并结合2D生成模型，实现了高质量、可控的3D人脸生成，为文本到3D生成提供了有效解决方案。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [187] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 提出基于4D毫米波雷达的模型驱动感知框架，用于恶劣工业环境下实时人员检测


<details>
  <summary>Details</summary>
Motivation: 工业及地下环境中的粉尘、烟雾、狭窄空间和金属结构严重制约光学和LiDAR感知，需要能在恶劣条件下稳定工作的人员检测方案

Method: 完全模型驱动的4D雷达感知框架，包括领域感知多阈值滤波、自运动补偿时间累积、KD树欧几里得聚类与多普勒感知优化、基于规则的3D分类器

Result: 在粉尘填充的封闭拖车和真实地下矿井隧道中评估，在摄像头和LiDAR因严重能见度下降而失效时，雷达检测器仍能稳定识别行人

Conclusion: 所提模型驱动方法为恶劣工业及地下环境中的安全关键应用提供了鲁棒、可解释且计算高效的感知解决方案

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [188] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 该论文对三种半监督目标检测方法（MixPL、Semi-DETR、Consistent-Teacher）在MS-COCO、Pascal VOC和自定义甲虫数据集上进行了全面比较，分析了标签图像数量对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺场景下，如何利用大量未标记图像提升目标检测性能是一个重要研究课题。半监督目标检测旨在通过少量标记图像和大量未标记图像来提升检测性能，本文旨在比较不同SSOD方法在标签数量变化时的性能表现。

Method: 使用三种先进的SSOD方法（MixPL、Semi-DETR、Consistent-Teacher），在MS-COCO和Pascal VOC两个标准目标检测基准数据集上进行实验，同时在自定义的甲虫数据集上评估，分析不同标签数量下的性能变化。

Result: 研究发现不同方法在准确率、模型大小和延迟之间存在权衡，为低数据场景下的方法选择提供了见解，揭示了标签图像数量对性能的具体影响模式。

Conclusion: 通过系统性比较三种SSOD方法，论文为数据稀缺场景下的目标检测方法选择提供了实用指导，揭示了不同方法在不同标签数量下的性能特性，有助于实际应用中的方法选型。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [189] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT提出了一种器官感知的CT图像分类方法，在胸部和腹部CT上实现了最先进的监督分类性能


<details>
  <summary>Details</summary>
Motivation: 医疗影像如CT扫描数量庞大，急需有效的分类和分诊方法来改善患者护理并减轻放射科医生负担。现有的视觉语言模型在处理3D解剖结构、协议变化和噪声报告监督方面存在困难

Method: 开发了ORACLE-CT方法，包含器官掩码注意力（器官特定池化提供空间证据）和器官标量融合（轻量级融合归一化体积和平均HU值特征），在简单全局平均池化基线基础上进行改进

Result: 在CT-RATE胸部数据集上AUROC达到0.86；在MERLIN腹部数据集（30种发现）上，基线模型已超过零样本VLM，加入掩码注意力和标量融合后AUROC提升至0.85，在两个数据集上都实现了最先进的监督分类性能

Conclusion: ORACLE-CT为胸部和腹部CT提供了一种统一的监督分类解决方案，在公开最大CT数据集上验证了其有效性，代码已开源

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [190] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 基于Transformer的3D雷达目标检测架构，使用新颖的Transformer Decoder作为预测头，直接从雷达特征表示回归3D边界框和类别分数


<details>
  <summary>Details</summary>
Motivation: 现有雷达目标检测方法通常需要密集的候选框生成和启发式后处理（如NMS调优），缺乏对长程时空相关性和跨特征交互的建模

Method: 1）使用Transformer Decoder作为预测头直接回归3D边界框和类别分数；2）提出Pyramid Token Fusion（PTF）轻量模块，将特征金字塔转换为统一的尺度感知token序列；3）将检测建模为集合预测问题，使用可学习对象查询和位置编码

Result: 在RADDet数据集上评估，相比最先进的雷达基线方法取得了显著改进

Conclusion: 该Transformer-based架构能够建模长程时空相关性和跨特征交互，消除了密集候选框生成和启发式后处理的需求，在雷达目标检测任务上表现优异

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [191] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: 提出DIP-ℓ₀框架，结合深度图像先验和ℓ₀梯度正则化，无需训练数据即可实现高质量图像平滑。


<details>
  <summary>Details</summary>
Motivation: 现有图像平滑方法依赖局部窗口统计或优化问题求解，最新深度学习方法需要精心策划的训练数据集。由于构建合适的图像平滑训练数据集具有挑战性，作者提出无需训练数据的解决方案。

Method: 提出DIP-ℓ₀框架，将深度图像先验与ℓ₀梯度正则化相结合。为最小化包含非凸、非光滑ℓ₀"范数"的损失函数，开发了交替方向乘子法，利用现成的ℓ₀梯度最小化求解器。

Result: 数值实验表明，DIP-ℓ₀在边缘保持图像平滑和JPEG伪影去除方面优于许多现有图像平滑算法。

Conclusion: DIP-ℓ₀框架能够实现无需训练数据的高质量图像平滑，在边缘保持和伪影去除方面表现出色，为解决训练数据获取困难的问题提供了有效方案。

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [192] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 本文针对当前视觉语言模型在定量空间推理上的缺陷，提出了SQuID基准数据集和QVLM模型架构，通过代码生成方式保持像素级精度，显著提升了卫星图像定量推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定量空间推理任务上表现不佳，主要原因是其架构通过图像块嵌入压缩图像，破坏了像素级信息，导致计数和测量所需的空间索引能力丧失。

Method: 1. 提出SQuID数据集：包含2000个卫星图像问答对，涵盖数值范围和分类答案，分为三个难度层级，基于人工标注自动生成。2. 提出QVLM模型：采用代码生成架构，将语言理解与视觉分析解耦，生成可执行代码调用分割模型获取像素级掩码，直接在掩码上进行操作，保持空间索引。

Result: QVLM使用GPT-5作为代码生成器，在SQuID基准上达到42.0%的准确率，相比直接将图像-问题对输入VLM的28.1%准确率有显著提升。

Conclusion: 对于定量空间推理任务，架构解耦能够实现更好的准确性。QVLM通过保持像素级精度的方法，有效解决了传统VLM在计数和测量任务上的局限性。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [193] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出用于黑盒模型的局部和全局解释方法，通过人类可识别的原始概念生成解释，以单调析取范式表示，在保持高保真度和覆盖度的同时保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然图像分类效果极佳，但缺乏透明度和可解释性，需要为黑盒模型提供人类可理解的解释方法。

Method: 引入局部和全局解释方法，将单张图像的局部解释和图像集的全局解释都表示为单调析取范式逻辑公式，还提出用单调解释列表来解释多类别分类。

Result: 尽管方法简单且可解释性强，但在具有挑战性的视觉数据集上，这些解释对目标黑盒模型保持了高保真度和高覆盖度。

Conclusion: 提出的基于原始概念的解释方法能够有效解释黑盒模型，在保持可解释性的同时不牺牲对原始模型的忠实度。

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [194] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 该研究探索了深度学习在结肠胶囊内窥镜图像清洁度预测中的应用，通过ResNet-18模型和结构化剪枝技术，在保持高准确率的同时实现了79%的稀疏度，并使用多种CAM方法进行可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 结肠胶囊内窥镜图像清洁度评估对临床诊断至关重要，但传统评估方法存在主观性和不一致性。研究旨在开发自动、可靠的深度学习模型来预测清洁质量，并解决模型效率和可解释性问题。

Method: 使用500张Leighton-Rex量表标注的图像训练ResNet-18模型，采用分层K折交叉验证。应用结构化剪枝技术优化模型，使用Grad-CAM、Grad-CAM++、Eigen-CAM、Ablation-CAM和Random-CAM进行可解释性分析，并用ROAD方法评估一致性。最后采用自适应温度缩放校准模型。

Result: 剪枝后的模型达到88%的交叉验证准确率和79%的稀疏度，相比未剪枝模型的84%准确率有所提升。研究还揭示了评估CCE图像清洁度的挑战，以及ROAD方法在该任务中的局限性。

Conclusion: 结构化剪枝能有效提高模型效率而不牺牲性能，可解释性分析对临床应用至关重要。研究为结肠胶囊内窥镜图像清洁度评估提供了自动化解决方案，并指出了未来改进方向。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [195] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 研究表明，冻结的扩散模型特征可以作为通用特征编码器，在细粒度识别任务中表现出色，特别是在现实世界浮游生物监测中，能有效应对数据分布偏移。


<details>
  <summary>Details</summary>
Motivation: 扩散模型作为最先进的图像生成方法，其作为通用特征编码器的潜力尚未充分探索。尽管它们通过去噪和生成训练，无需标签，可以视为捕捉低层和高层结构的自监督学习器。

Method: 作者使用冻结的扩散模型主干作为特征编码器，通过探测不同层和去噪时间步的中间特征，为每一对层-时间步组合训练一个线性分类器，从而进行细粒度识别。

Result: 冻结扩散特征在平衡和自然长尾设置中与监督基线竞争，并优于其他自监督方法。在时间和地理分布偏移的浮游生物数据集上，扩散特征保持了高准确率和Macro F1分数。

Conclusion: 扩散模型不仅是强大的生成模型，还可以作为有效的通用特征编码器，在现实世界细粒度识别任务中表现出色，特别是在应对数据分布偏移方面具有优势。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [196] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: SGWA-GAN是首个将切片Gromov Wasserstein距离融入视网膜图像增强的框架，通过保持类内几何结构提升临床任务性能


<details>
  <summary>Details</summary>
Motivation: 现有GAN和扩散模型在增强视网膜图像时虽然提升了感知质量，但会扭曲类内几何结构，导致临床相关样本分散、疾病边界模糊，损害下游诊断任务性能

Method: 提出SGWA-GAN框架，将切片Gromov Wasserstein距离融入视网膜图像增强，通过随机投影近似GW距离，在保持类内关系保真度的同时大幅降低计算成本

Result: 在公开数据集上，SGWA-GAN产生视觉上吸引人的增强效果，在糖尿病视网膜病变分级任务上表现优异，并在疾病标签上报告最低的GW差异

Conclusion: SGWA-GAN通过保持类内几何结构，在无配对医学图像增强中实现了效率与临床保真度的平衡，为视网膜图像增强提供了新方向

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [197] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: 该论文全面分析了基于视觉语言模型（VLMs）的异常检测方法，重点关注CLIP模型在零样本和少样本异常分类与分割中的应用，系统比较了不同架构范式并评估了关键性能指标。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（特别是CLIP）通过图像和文本的对齐表示学习，无需大量标注数据即可实现异常检测，消除了传统方法对任务特定训练或缺陷样本的需求，为工业质量控制提供了新途径。

Method: 系统分析了三种关键架构范式：基于滑动窗口的密集特征提取（WinCLIP）、具有可学习投影的多阶段特征对齐（AprilLab框架）以及组合提示集成策略。从特征提取机制、文本-视觉对齐策略、提示工程技术、零样本与少样本权衡、计算效率和跨域泛化等维度进行评估。

Result: 通过在MVTec AD和VisA等基准数据集上的严格实验，比较了分类准确率、分割精度和推理效率，提供了VLM在异常检测中成功原因的基础理解，并合成了方法选择的实践见解。

Conclusion: 该研究为工业质量控制中基于VLM方法的知情采用提供了指导，识别了当前局限性并指明了未来研究方向，推动了零样本和少样本异常检测技术的发展。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [198] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 提出了一种基于物理的框架，将事件相机数据映射到对数强度和强度导数估计，并嵌入动态线性系统模型，实现从事件数据直接进行逆滤波和频域维纳反卷积。


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器（神经形态相机）输出稀疏、异步的ON/OFF事件，具有微秒级传感、高动态范围和低数据带宽优势。但由于其非线性特性，难以与基于线性前向模型的计算成像和光学系统设计方法集成。

Method: 1. 提出物理基础的流水线，将事件流映射到每个像素的对数强度和强度导数估计；2. 将这些测量嵌入具有时变点扩散函数的动态线性系统模型；3. 使用已知（或参数化）的动态传递函数，通过频域维纳反卷积直接从事件数据进行逆滤波。

Result: 在模拟中验证了调制散焦下单点和重叠点源的情况，并在真实事件数据（可调焦望远镜拍摄星场）上进行了验证，展示了源定位和可分离性。

Conclusion: 该框架为事件传感和基于模型的计算成像之间提供了实用的桥梁，特别适用于动态光学系统。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [199] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2：一种针对遥感多模态学习中缺失模态问题的新范式，通过DLKD协同解耦学习和知识蒸馏，结合类别特征学习和多分辨率融合，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 遥感多模态学习面临严重的数据异质性和尺度变化问题，导致传统方法失效。传统解耦学习依赖模态间特征重叠，而知识蒸馏则成为无目标的模仿任务，无法解决语义鸿沟问题。

Method: 提出DIS2方法，核心是DLKD协同机制，明确捕获补偿特征来弥补缺失模态；CFLM模块自适应学习类别特异性特征；采用分层混合融合结构利用多分辨率特征。

Result: 大量实验验证该方法在多个基准测试中显著优于现有最先进方法。

Conclusion: DIS2从依赖模态共享特征和无目标模仿转向主动、指导性的缺失特征补偿，为遥感多模态学习中的缺失模态问题提供了有效解决方案。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [200] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个针对多层虚拟试衣（ML-VTON）的方法，通过服装遮挡学习和基于StableDiffusion的服装变形拟合模块，解决多层服装的遮挡关系和变形问题，并在新数据集MLG上验证了其SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的虚拟试衣方法主要关注单层或多件服装试衣，忽略了多层虚拟试衣（ML-VTON）任务，即需要将多层服装穿着到人体上并产生真实变形和层次感。主要挑战在于准确建模内外层服装之间的遮挡关系，以减少冗余内层服装特征的干扰。

Method: 提出GO-MLVTON方法，包含两个核心模块：1）Garment Occlusion Learning模块，用于学习服装间的遮挡关系；2）StableDiffusion-based Garment Morphing & Fitting模块，用于将服装变形并拟合到人体上。此外，还构建了MLG数据集用于该任务，并提出新的评估指标LACD（Layered Appearance Coherence Difference）。

Result: 大量实验表明GO-MLVTON达到了最先进的性能水平。该方法能够生成高质量的多层试衣结果，有效解决了多层服装试衣中的遮挡和变形问题。

Conclusion: GO-MLVTON是首个针对多层虚拟试衣的方法，通过创新的遮挡学习和服装变形拟合技术，成功解决了多层服装试衣中的关键挑战，为虚拟试衣领域提供了新的解决方案。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [201] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: 提出了DiffFace-Edit数据集，包含超过200万张AI生成的人脸图像，特别关注细粒度区域编辑和检测器规避样本对检测模型的影响分析。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型能够产生难以察觉的细粒度人脸编辑，带来严重的隐私风险。现有AI生成人脸数据集缺乏对细粒度区域编辑样本的关注，且没有研究检测器规避样本（真实与伪造样本之间的拼接攻击）对检测器的实际影响。

Method: 构建DiffFace-Edit数据集，包含超过200万张AI生成的伪造图像，涵盖8个面部区域（如眼睛、鼻子）的编辑，包括单区域和多区域编辑组合。特别分析检测器规避样本对检测模型的影响，并进行数据集综合分析，提出结合IMDL方法的跨域评估。

Result: 创建了包含丰富细粒度区域编辑的大规模AI生成人脸数据集，特别关注检测器规避样本对检测性能的影响，为研究提供了新的评估基准。

Conclusion: DiffFace-Edit数据集填补了细粒度区域编辑AI生成人脸数据的空白，为研究检测器规避样本对检测模型的影响提供了重要资源，有助于提升人脸伪造检测技术的鲁棒性。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [202] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse是一个可扩展的框架，通过量化图表复杂度和基于确定性答案的逆向QA合成方法，生成复杂图表和高质量推理数据，解决开源视觉语言模型在图表推理领域缺乏高质量训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 当前开源视觉语言模型在图表推理能力发展上受到高质量训练数据缺乏的严重制约。现有数据集面临双重挑战：合成图表过于简单重复，而相关的问答对存在幻觉问题且缺乏复杂任务所需的推理深度。

Method: 1. 引入Rollout Posterior Entropy（RPE）量化图表复杂度，基于此开发复杂度感知的图表编码器，通过可执行程序自主合成多样化、高复杂度的图表。
2. 采用"答案优先"的逆向QA合成方法：直接从源代码提取确定性答案，基于这些锚点生成问题，并进行严格的一致性验证。
3. 基于模型失败率筛选样本，并提炼高质量的思维链推理过程，进一步提升难度和推理深度。

Result: 使用Qwen3-VL-30B-A3B-Thinking作为教师模型，构建了ChartVerse-SFT-600K和ChartVerse-RL-40K数据集。ChartVerse-8B模型在实验中取得了最先进的性能，超越了其教师模型，甚至能与更强的Qwen3-VL-32B-Thinking模型相媲美。

Conclusion: ChartVerse框架通过创新的图表复杂度量化和逆向QA合成方法，有效解决了图表推理领域高质量训练数据缺乏的问题，为开源视觉语言模型的发展提供了重要支持。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [203] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE是一个模型无关的框架，通过视觉集成层和上下文感知集成策略，让大型视觉语言模型能够自适应地优先考虑图像表示或依赖语言模型的推理能力，提升视觉中心任务的性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉中心任务（如图像分类）上表现不佳，往往落后于其基础的CLIP视觉编码器。需要解决模型在处理视觉任务时如何更好地利用图像表示的问题。

Method: 提出CARPE框架：1）引入视觉集成层；2）采用上下文感知集成策略，识别何时优先使用图像表示或依赖语言模型的推理能力；3）自适应加权视觉和文本模态，捕捉图像表示的不同方面。

Result: CARPE在图像分类基准上表现更好，同时也在各种视觉语言基准上提升了性能。该框架能与大多数开源LVLM（包含视觉编码器和语言模型）有效集成，适应不同架构。

Conclusion: CARPE通过上下文感知的集成策略和视觉集成层，增强了LVLM在视觉中心任务上的性能，同时保持了对各种架构的适应性，是提升视觉语言模型泛化能力的有效框架。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [204] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: 提出EGM方法，通过增加测试时计算量（生成更多tokens）来提升小型视觉语言模型的视觉定位能力，使其性能达到或超越大型模型，同时保持更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定位模型通常模型规模较大，部署和推理成本高。研究发现小型和大型VLM的主要差异在于语言模型部分，小型模型在视觉信息处理方面与大型模型相当，但语言理解能力不足导致定位性能较差。

Method: 提出EGM方法，通过增加测试时计算量（生成更多tokens）来弥补小型模型语言理解能力的不足。这种方法部署友好，因为每个token的生成成本远低于直接运行大型模型。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B达到91.4 IoU，平均延迟737ms（比Qwen3-VL-235B快5.9倍），而后者需要4320ms达到90.5 IoU。在新建立的amodal grounding任务中，该方法也能显著提升小型模型的性能。

Conclusion: EGM方法通过增加测试时计算量，能够显著提升小型视觉语言模型的视觉定位能力，使其性能达到或超越大型模型，同时保持更快的推理速度，提高了视觉定位的效率。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [205] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 本文提出了一种在人脸-语音关联任务中引入最大类别分离作为归纳偏置的方法，通过增强不同说话人之间的特征分离来提高多模态表示的性能。


<details>
  <summary>Details</summary>
Motivation: 当前人脸-语音关联研究主要通过损失函数来学习相似表示，但最近分类任务中的研究表明，最大类别分离作为归纳偏置能显著增强特征的判别能力。这一技术尚未在人脸-语音关联领域应用，本文旨在填补这一空白。

Method: 开发了一种人脸-语音关联方法，将不同说话人的多模态表示之间的最大类别分离作为归纳偏置。该方法结合了类间正交性损失来最有效地施加这种归纳偏置。

Result: 该方法在两种人脸-语音关联任务上都达到了最先进的性能。消融研究表明，将归纳偏置与类间正交性损失结合使用时效果最佳。

Conclusion: 这是首次在多模态学习中应用并证明了最大类别分离作为归纳偏置的有效性，为建立新范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [206] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一个用于多视图条件体素细化的体素-图像对齐Transformer模型，通过修复不完整噪声体素并利用多视图图像作为指导，实现了体素形状的精确修复。


<details>
  <summary>Details</summary>
Motivation: 现有体素形状通常存在不完整和噪声问题，特别是在从视觉基础模型获取的体素中存在严重合成损坏和真实伪影。需要一种能够利用多视图图像指导来精确修复体素的方法。

Method: 1. 图像索引：为2D图像标记提供明确的3D空间定位；2. 校正流目标：学习直接的体素细化轨迹；3. 混合流Transformer：实现鲁棒的跨模态融合。

Result: VIAFormer在纠正从强大视觉基础模型获得的体素形状中的严重合成损坏和真实伪影方面，建立了新的最先进水平。在真实世界3D创建流程中表现出实用性和可靠性。

Conclusion: VIAFormer为体素方法在大模型、大数据浪潮中蓬勃发展铺平了道路，通过体素-图像对齐和跨模态融合，为多视图条件体素细化提供了有效的解决方案。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [207] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

TL;DR: 本文提出融合CNN、LSTM和DeiT Transformer的架构，同时处理蔬菜分类、食品腐败检测和保质期预测三个任务，在自建数据集上表现优于多个深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 食品浪费是农业供应链中的关键挑战，准确有效的腐败检测有助于减少浪费。预测腐败信息对延长农业领域供应链管理寿命至关重要。

Method: 提出融合架构：CNN+CNN-LSTM和CNN+DeiT Transformer，同时处理蔬菜分类、食品腐败检测和保质期预测三个任务。开发了从新鲜到完全腐败的蔬菜图像数据集。

Result: 融合架构在蔬菜分类和腐败检测上优于CNN、VGG16、ResNet50、胶囊网络和DeiT Transformer。CNN+DeiT Transformer在蔬菜分类和腐败检测的F1分数分别为0.98和0.61，在腐败预测中的MSE和SMAPE分别为3.58和41.66%。

Conclusion: 提出的融合架构能有效处理农业供应链中的多任务问题，在嘈杂图像上验证了可靠性，并集成了LIME可视化模型决策。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [208] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE是一种简单有效的主动学习查询策略，在3D生物医学图像分割中能持续超越改进的随机采样基线，解决了类别不平衡和早期选择冗余问题。


<details>
  <summary>Details</summary>
Motivation: 当前主动学习方法在3D生物医学图像分割中无法持续超越改进的随机采样基线，缺乏可靠的解决方案，而专家标注3D数据既耗时又昂贵。

Method: 提出Class-stratified Scheduled Power Predictive Entropy (ClaSP PE)方法，结合类别分层查询确保覆盖代表性不足的结构，以及对数尺度功率噪声配合衰减调度，在早期AL阶段强制查询多样性，后期鼓励利用。

Result: 在nnActive基准测试的24个实验设置中，ClaSP PE是唯一能普遍超越改进随机基线的方法，在分割质量和标注效率方面均有统计显著提升。在四个未见数据集上无需手动调整也能稳健泛化。

Conclusion: ClaSP PE证明了主动学习方法可以在3D分割中持续超越随机基线，在接近实际生产场景中既保持性能又提高标注效率，开源实现和清晰部署指南使其易于实际应用。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [209] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: 提出DyDiLA（动态微分线性注意力）机制，解决线性扩散变换器中注意力权重过度平滑问题，提升生成质量


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiTs）在图像生成中表现出色，但自注意力的二次计算成本成为扩展瓶颈。线性注意力机制虽然降低计算成本，但导致生成性能下降，注意力权重过度平滑限制了表达能力。

Method: 提出DyDiLA机制，包含三个核心设计：1）动态投影模块，通过学习动态分配知识来解耦token表示；2）动态测量核，通过动态分配核函数来捕获token间的细粒度语义差异；3）token微分算子，通过计算token与其信息冗余之间的差异来实现更鲁棒的查询-键检索。基于DyDiLA构建了DyDi-LiT模型。

Result: DyDi-LiT在多个指标上持续优于当前最先进的模型，展示了强大的实际潜力。

Conclusion: DyDiLA机制有效解决了线性扩散变换器中注意力权重过度平滑的问题，显著提升了生成质量，为高效高质量的图像生成提供了新的解决方案。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [210] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: 提出注意力空间对比引导（ACG）方法，通过单次前向计算同时构建视觉-语言和纯语言注意力路径，减少大视觉语言模型中的幻觉问题，在保持生成质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决大视觉语言模型（LVLMs）中语言先验主导视觉证据导致的幻觉问题，如物体误识别和视觉不一致描述。现有方法通常需要多次前向计算，计算成本高。

Method: 提出注意力空间对比引导（ACG）：1）在自注意力层内同时构建视觉-语言和纯语言注意力路径；2）应用正交化校正去除与纯语言路径对齐的成分，选择性增强视觉贡献；3）通过单次前向计算实现高效引导。

Result: 在CHAIR和POPE基准测试中达到最先进的忠实度和字幕质量，同时显著降低计算成本。相比需要多次前向计算的对比解码方法，延迟降低高达2倍。

Conclusion: ACG为幻觉缓解提供了原则性且高效的替代方案，通过单次前向计算在模型表示上下文化中直接嵌入引导，有效平衡了视觉忠实度和计算效率。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [211] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 这篇论文是一篇关于大视觉语言模型在视觉谜题推理方面的综述，将视觉谜题作为诊断工具来评估LVLMs的推理能力，系统性地分类了现有的视觉谜题基准，并指出了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题长期以来作为人类认知的紧凑而揭示性的探针，能够以最少的先验知识来测试抽象、规则发现和系统推理能力。作者希望利用这些特性，将视觉谜题发展为评估大视觉语言模型推理能力的强大诊断工具，提供可控、可验证的替代方案来替代开放式的多模态基准。

Method: 论文采用综述研究方法，通过一个共同的抽象框架来理解视觉谜题，并根据目标推理机制（归纳、类比、算法、演绎和几何/空间）组织现有的基准测试。作者系统地综合了这些类别中的实证证据，建立了谜题设计与所需认知操作之间的联系。

Result: 研究发现当前模型存在一致的局限性：脆弱的泛化能力、感知与推理之间的紧密纠缠、流畅解释与忠实执行之间的持续差距。通过将视觉谜题视为诊断工具而非任务格式，论文详细阐述了LVLM推理的现状。

Conclusion: 这篇综述为大视觉语言模型的视觉谜题推理提供了一个统一的视角，指出了当前模型的局限性，并为未来的基准测试和具有推理意识的多模态系统的发展方向提供了关键指导。视觉谜题作为诊断工具可以帮助更好地理解和改进LVLMs的推理能力。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [212] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 提出HiT机制，用于Transformer模型在卫星上的持续灾害监测，通过历史注入技术减少99%存储需求，在Jetson Orin Nano上达到43 FPS，保持洪水检测精度。


<details>
  <summary>Details</summary>
Motivation: 自然灾害监测需要连续卫星观测，但受限于小型卫星的内存和计算资源。传统方法依赖地面处理基础设施，无法满足实时灾害评估需求。

Method: 提出History Injection机制（HiT），集成到Prithvi-tiny基础模型中，维护历史观测上下文，将原始图像大小减少99%以上存储需求，适用于星上变化检测系统。

Result: 在STTORM-CD洪水数据集上测试，HiT机制保持检测精度与双时相基线相当；HiT-Prithvi模型在Jetson Orin Nano上达到43 FPS，满足星上实时处理需求。

Conclusion: 建立了卫星持续自然灾害监测的实用框架，支持实时灾害评估，减少对地面处理基础设施的依赖，为星上智能处理提供可行方案。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [213] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

TL;DR: ParkingTwin是一种免训练、轻量级的在线流式3D重建系统，专门用于停车场数字孪生，解决了传统方法在稀疏视角、动态遮挡和极端光照下的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的停车场数字孪生重建面临三难困境：稀疏前向视角导致弱视差和几何求解困难；动态遮挡和极端光照阻碍稳定的纹理融合；神经渲染通常需要昂贵的离线优化，不符合边缘端流式处理的要求。

Method: 1) 基于OpenStreetMap语义拓扑的几何构建，直接生成度量一致的TSDF，避免盲目的几何搜索和优化；2) 几何感知的动态过滤，使用四模态约束场（法线/高度/深度一致性）实时剔除移动车辆和瞬态遮挡；3) CIELAB空间的照明鲁棒融合，通过自适应L通道加权和深度梯度抑制来解耦亮度和色度，减少光照突变下的接缝。

Result: 在入门级GTX 1660上达到30+ FPS；在68,000 m²真实世界数据集上，SSIM达到0.87（提升16.0%）；相比需要高端GPU（RTX 4090D）的3D高斯泼溅，实现约15倍的端到端加速，GPU内存减少83.3%；输出兼容Unity/Unreal的显式三角网格。

Conclusion: ParkingTwin提供了一种高效、轻量且训练免费的在线流式3D重建方案，适用于自动驾驶停车场的数字孪生应用，显著提升了实时性、鲁棒性和资源效率。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [214] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一个语言对齐的概念基础模型，通过分层稀疏自编码器从基础模型中提取多层次、人类可解释且空间定位的概念，为分类和分割任务提供高质量的概念解释。


<details>
  <summary>Details</summary>
Motivation: 现有语言对齐的视觉基础模型虽然在下游任务中表现良好，但其表示不透明，难以解释决策过程。现有的概念分解方法空间定位能力差，且仅限于图像分类任务。

Method: 使用分层稀疏自编码器和具有强语义表示的基础模型自动提取不同粒度的概念，通过分析概念的局部共现依赖关系定义概念关系，利用这些关系改进概念命名并获得更丰富的解释。

Result: 在基准数据上，Insight在分类和分割任务上的性能可与不透明的基础模型竞争，同时提供细粒度、高质量的概念解释。

Conclusion: Insight成功构建了一个语言对齐的概念基础模型，能够提供空间定位的、人类可解释的概念表示，在保持性能的同时实现了模型决策的可解释性。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [215] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 该论文提出了一种名为色彩空间判别分析(CSDA)的新算法，通过优化色彩表示来改进图像分割精度，在风力涡轮机叶片数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 许多现代图像分割算法忽视了色彩表示这一关键预处理步骤，导致次优的色彩表示阻碍了准确分割。特别是在特定领域的分割任务中，通用的色彩表示可能不够有效。

Method: 提出CSDA算法，将线性判别分析扩展到深度学习环境中。通过最大化多维有符号的类间可分性，同时最小化类内变异性，使用广义判别损失来自定义色彩表示。为确保稳定训练，引入了三种替代损失函数，实现了从判别色彩空间到分割过程的端到端优化。

Result: 在风力涡轮机叶片数据上的实验表明，该方法带来了显著的精度提升，验证了在特定领域分割任务中定制化预处理的重要性。

Conclusion: CSDA算法通过优化色彩表示显著提高了图像分割精度，证明了针对特定领域的分割任务，定制化的预处理步骤是至关重要的，不应被忽视。

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [216] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

TL;DR: MVGD-Net：利用运动不一致性检测视频中玻璃表面的新网络，通过跨尺度多模态融合、历史引导注意力等模块，结合大规模数据集，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在日常生活和专业环境中无处不在，对基于视觉的系统（如机器人和无人机导航）构成潜在威胁。现有研究主要关注视频玻璃表面检测（VGSD），但需要更有效的解决方案。

Method: 提出MVGD-Net网络，基于玻璃表面反射/透射层物体运动较慢的观察，利用运动不一致性检测玻璃。包含三个新模块：跨尺度多模态融合模块（CMFM）整合空间特征和光流图；历史引导注意力模块（HGAM）和时间交叉注意力模块（TCAM）增强时序特征；时空解码器（TSD）融合时空特征生成玻璃区域掩码。

Result: 构建了包含312个多样化玻璃场景、共19,268帧的大规模数据集。大量实验证明MVGD-Net在性能上优于相关最先进方法。

Conclusion: MVGD-Net通过有效利用视频中的运动不一致性线索，在玻璃表面检测任务上取得了优异性能，为基于视觉的系统提供了更可靠的玻璃检测解决方案。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [217] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出深度判别分析(DDA)和概率DDA(PDDA)方法，通过直接优化Fisher准则解决非线性可分数据问题，应用于风电叶片分割任务。


<details>
  <summary>Details</summary>
Motivation: 线性判别分析(LDA)虽然能提升类别可分性，但无法处理非线性可分数据。为了解决这一问题，需要开发能够直接优化Fisher准则的深度学习方法。

Method: 引入Deep Discriminant Analysis (DDA)，通过深度网络直接优化Fisher准则。为确保训练稳定性，采用了带符号的类间方差、sigmoid函数约束输出、将乘法关系转为加法关系等技术。提出了两种稳定的DDA损失函数，并加入概率损失形成Probabilistic DDA (PDDA)。

Result: PDDA能有效减少输出分布中的类别重叠，产生高度置信的预测并降低类内方差。在风电叶片分割任务中，PDDA展现出显著的性能提升和一致性改进。

Conclusion: 这是首次将DDA应用于图像分割任务，PDDA在风电能源维护等关键应用中表现出优越的性能和稳定性。

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [218] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: HAVEN框架通过视听实体融合与层次化索引结合智能搜索，实现长视频的连贯理解，在LVBench上达到84.1%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于分块检索增强生成的方法在处理长视频时存在信息碎片化和全局连贯性丢失的问题，需要新的解决方案来保持语义一致性和叙事连贯性。

Method: 1. 通过整合视觉和听觉流的实体级表示保持语义一致性；2. 将内容组织为全局摘要、场景、片段和实体四个层次的层次化结构；3. 采用智能搜索机制实现跨层次的动态检索和推理。

Result: 在LVBench上达到84.1%的整体准确率，在最具挑战性的推理类别中达到80.1%，在时间连贯性、实体一致性和检索效率方面表现优异。

Conclusion: HAVEN框架通过结构化多模态推理，实现了对长视频的全面且上下文一致的理解，为长视频理解建立了新的技术标准。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [219] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT是一种基于GPT框架的白质纤维束分割方法，通过引入轨迹片段（tracklets）将序列信息重新编码到token中，实现跨数据集的自动分割，在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 白质纤维束分割对于研究大脑结构连接、神经疾病和神经外科手术至关重要。当前任务面临挑战：不同纤维束之间、不同受试者和条件下存在差异，但又在跨半球和受试者间具有相似的3D结构。

Method: 提出TrackletGPT框架，采用类似语言模型的GPT架构，通过轨迹片段（tracklets）在token中重新引入序列信息。该方法能自动编码细粒度的子流线片段，扩展和优化了GPT模型在纤维束成像分割中的应用。

Result: 在TractoInferno和HCP数据集上的实验表明，TrackletGPT在平均DICE、重叠度和过度延伸分数上优于现有最先进方法，即使在跨数据集实验中也能保持优异性能。

Conclusion: TrackletGPT能够无缝泛化到不同数据集，实现全自动分割，通过轨迹片段编码细粒度信息，在纤维束分割任务中表现出优越性能，为解决白质纤维束分割的复杂性提供了有效解决方案。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [220] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [221] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该研究建立了跨域海洋生物监测的统一检测框架，发现场景结构因素比视觉退化对检测性能影响更大，并验证了在低成本边缘硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 海洋生物多样性监测需要在复杂水下环境中实现可扩展和可靠的检测，以支持保护和入侵物种管理。现有检测方案存在明显的部署差距，当迁移到新地点时性能会急剧下降。

Method: 开发统一信息管道，将异构数据集标准化为可比信息流，并在受控跨域协议下评估固定的、与部署相关的检测器。分析结构因素（场景构成、物体密度、上下文冗余）和视觉退化因素对性能的影响。

Result: 结构因素比视觉退化因素更能解释跨域性能损失，稀疏场景会引发特有的"上下文崩溃"故障模式。在低成本边缘硬件上通过运行时优化实现了实用的远程监测采样率。

Conclusion: 研究将重点从图像增强转向结构感知的可靠性，为一致的海洋生态系统评估提供了民主化工具，建立了跨域海洋入侵物种监测的基础检测层。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [222] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: PREGEN是一个高效的组合视频检索框架，无需微调预训练视觉语言模型，通过提取隐藏状态并训练轻量编码器实现先进的检索性能。


<details>
  <summary>Details</summary>
Motivation: 当前组合视频检索方法未能充分利用现代视觉语言模型，要么使用过时架构，要么需要计算昂贵的微调和缓慢的标题生成，限制了方法的效率和性能。

Method: 使用冻结的预训练视觉语言模型，将查询视频和修改文本输入VLM，提取每层最后一个token的隐藏状态，然后训练一个简单的编码器对这些池化表示进行编码，生成语义丰富且紧凑的检索嵌入。

Result: 在标准CoVR基准测试中显著超越所有现有方法，Recall@1提升+27.23和+69.59，对不同VLM主干具有鲁棒性，并在更复杂的文本修改上表现出强大的零样本泛化能力。

Conclusion: PREGEN是一个高效且强大的CoVR框架，通过避免VLM微调实现了最先进的性能，展示了其有效性和语义能力，为组合视频检索提供了新的解决方案。

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [223] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: 论文提出FBL（联邦平衡学习），通过在客户端进行样本平衡来预防非IID数据下的客户端漂移问题，利用边缘生成模型实现知识填充和知识采样。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，非独立同分布（non-iid）数据会导致全局模型出现客户端漂移，严重影响最终性能。现有方法大多基于损失函数或梯度来修正已经偏离的全局模型，但忽视了客户端样本的影响。

Method: 提出FBL方法，通过客户端样本平衡预防漂移问题。具体技术包括：1）使用边缘生成模型进行知识填充和知识采样，在客户端数据量固定的限制下实现样本平衡；2）设计知识对齐策略来弥合合成数据与真实数据之间的差距；3）设计知识丢弃策略进行正则化；4）将方法扩展到真实复杂场景，允许不同客户端采用不同方法。

Result: 大量实验表明，该方法优于最先进的基线方法。

Conclusion: 通过重新思考客户端的作用，提出从源头预防客户端漂移的联邦平衡学习方法，有效解决了非IID数据下的性能问题。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [224] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出无监督视频类别增量学习方法，无需标签和任务边界信息，通过深度特征提取和渐进式深度聚类实现持续学习


<details>
  <summary>Details</summary>
Motivation: 现有的监督类别增量学习方法需要标签和任务边界信息，成本高且不现实；需要探索无需标签的无监督视频增量学习方法

Method: 使用深度特征提取器获取视频特征，渐进式构建深度聚类序列，通过知识迁移将前任务模型作为初始状态进行持续学习

Result: 在UCF101、HMDB51和Something-to-Something V2三个视频动作识别数据集上显著优于基线方法

Conclusion: 提出了一种简单有效的无监督视频类别增量学习方法，在多个数据集上表现出色，为无标签视频学习提供了实用解决方案

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [225] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯的前馈方法，能够仅从少量输入图像生成高质量头部化身，并支持实时动画。


<details>
  <summary>Details</summary>
Motivation: 当前基于3D高斯的头部化身建模方法存在效率问题，通常需要大量多视角捕捉设备或单目视频配合每身份优化，限制了其可扩展性和对未见主体的易用性。

Method: 提出了一种前馈方法，直接从输入图像学习逐像素高斯表示，使用基于Transformer的编码器融合DINOv3和Stable Diffusion VAE的图像特征。为支持实时动画，扩展了显式高斯表示，引入轻量级MLP动态网络预测3D高斯形变，并使用预训练大型重建模型的点云图进行几何监督。

Result: 实验表明，该方法在渲染质量和推理效率上显著优于现有方法，同时支持实时动态化身动画。

Conclusion: 该方法通过高效的前馈架构，实现了仅需少量图像即可生成高质量、可实时动画的3D高斯头部化身，克服了现有方法的可扩展性和易用性限制。

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [226] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出了一种新的双流Transformer视频分类器，通过联合光学流和时间帧域的自注意力机制，提取时空信息用于视频动作识别。


<details>
  <summary>Details</summary>
Motivation: 运动表示在视频理解中至关重要，现有方法需要更有效地结合时空信息。Transformer网络的自注意力机制在许多应用中表现出色，但在视频分类中如何有效结合内容信息和运动信息仍有探索空间。

Method: 提出双流Transformer视频分类器：1）一个流处理内容帧，另一个流处理表示运动信息的光学流；2）在联合光学流和时间帧域中识别自注意力特征；3）通过Transformer编码器机制表示它们之间的关系。

Result: 在三个知名的人类活动视频数据集上取得了优秀的分类结果。

Conclusion: 提出的双流Transformer视频分类器能够有效提取时空信息，在视频动作识别任务上表现优异，证明了自注意力机制在联合光学流和时间帧域中的有效性。

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [227] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA是一个专为灾害响应设计的视觉问答基准数据集，包含1,395张真实灾害图像和4,405个专家标注的问答对，用于评估模型在灾害情境下的感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前通用视觉问答模型在灾害响应这种复杂且安全关键的场景中的适用性尚不明确，需要专门的基准来评估和改进模型在灾害情境下的推理能力。

Method: 基于FEMA ESF和OCHA MIRA等人道主义框架，构建包含洪水、野火、地震等多种灾害类型的真实图像数据集，设计涵盖情境感知和操作决策的二元、多选和开放式问题。

Result: 评估7个最先进的视觉语言模型发现：模型在二元问题上表现良好，但在细粒度定量推理、物体计数和上下文敏感解释方面存在困难，特别是在代表性不足的灾害场景中表现更差。

Conclusion: DisasterVQA为灾害响应提供了一个具有挑战性和实用性的基准，有助于指导开发更鲁棒、更具操作意义的视觉语言模型，推动灾害响应技术的进步。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [228] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出端到端管道，使用三相机系统捕捉车辆底盘视频，生成交互式3D模型，解决传统检查费力、在线买家难以查看底盘的问题。


<details>
  <summary>Details</summary>
Motivation: 传统车辆底盘检查需要检查员蹲下或爬入车底，工作强度大且危险；在线买家很少能看到底盘照片，影响购买信心。

Method: 1. 使用三相机系统同步捕捉车辆底盘视频；2. 开发针对广角镜头畸变和低视差场景的"rig-aware" Structure-from-Motion流程；3. 结合精确相机标定、同步视频流和相机配置的几何先验；4. 采用约束匹配策略，使用DISK特征提取器和LightGlue匹配器生成高质量稀疏点云；5. 基于高斯泼溅技术生成实时渲染的逼真3D模型。

Result: 系统能够生成交互式3D底盘模型，用户可旋转、缩放和切片查看，在几秒钟内检测锈蚀、泄漏或撞击损伤，实现了最先进的质量。

Conclusion: 该端到端管道显著改善了工作场所安全和买家信心，专门设计的SfM流程有效克服了广角畸变和低视差挑战，通过实验验证了设计选择的重要性。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [229] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练、无需额外信息的类无关目标计数方法，能同时处理图像中多个目标类别的计数问题。


<details>
  <summary>Details</summary>
Motivation: 现有类无关目标计数方法大多假设图像中只有单一目标类别，需要大量训练深度模型，且依赖视觉范例或文本提示等额外信息。这限制了方法的实用性和灵活性。

Method: 利用Segment Anything Model 2（SAM2）基础模型，结合自定义阈值版本的FINCH聚类算法，无需训练即可实现多类别目标计数。

Result: 在FSC-147和CARPK基准数据集上取得有竞争力的性能，提出了合成多类别数据集和更合适的F1评分评估指标。

Conclusion: OCCAM首次实现了无需训练、无需额外信息的多类别类无关目标计数，为实际应用提供了更实用的解决方案。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [230] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

TL;DR: MTV框架通过整合视觉-语言对比学习、自监督学习和密集空间监督，实现全局语义对齐与局部空间精度的统一，利用专家模型生成伪标签避免人工标注。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表示学习存在分裂：视觉语言模型擅长全局语义但对空间不敏感，自监督方法捕捉局部结构但缺乏高层语义。作者认为这两种范式本质互补，需要统一框架。

Method: 提出MTV多任务视觉预训练框架，联合优化共享主干网络，包含三个目标：视觉语言对比学习、自监督学习、密集空间监督。利用Depth Anything V2和OWLv2等专家模型生成大规模密集结构化伪标签。

Result: MTV实现"两全其美"性能，显著提升细粒度空间推理能力而不损害全局语义理解。系统分析了各目标的边际收益、任务协同与干扰、不同数据与模型规模的扩展行为。

Conclusion: 多任务学习结合高质量伪监督是构建更通用视觉编码器的可扩展路径，能够统一不同视觉表示学习范式的优势。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [231] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: 提出了OmniOVCD框架，利用SAM 3的解耦输出头，通过协同融合到实例解耦策略实现开放词汇变化检测，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的开放词汇变化检测方法多依赖CLIP进行类别识别，并需要额外模型如DINO提取特征，这种多模型组合会导致特征匹配问题和系统不稳定。而新推出的SAM 3集成了分割和识别能力，为OVCD任务提供了新可能性。

Method: 提出了OmniOVCD框架，利用SAM 3的解耦输出头，设计了协同融合到实例解耦策略。该策略首先融合SAM 3的语义、实例和存在性输出来构建土地覆盖掩码，然后将这些掩码分解为单独的实例掩码进行变化比较。

Result: 在四个公开基准测试（LEVIR-CD、WHU-CD、S2Looking和SECOND）上实现了SOTA性能，分别获得了67.2、66.5、24.5和27.1的IoU分数（类别平均），超越了所有先前方法。

Conclusion: OmniOVCD框架通过利用SAM 3的解耦输出头，解决了现有开放词汇变化检测方法的多模型组合问题，在保持高精度类别识别的同时维持了跨图像的实例级一致性，能够生成准确的变化掩码。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [232] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出可解释的深度统计测试框架，为深度双样本测试提供样本级和特征级解释，揭示驱动统计显著差异的具体样本和特征


<details>
  <summary>Details</summary>
Motivation: 现有深度双样本测试方法虽然检测能力强，但黑盒特性限制了在生物医学分析中的可解释性和实际应用；且多数事后解释方法依赖类别标签，不适用于无标签的统计测试场景

Method: 提出可解释的深度统计测试框架，通过样本级和特征级解释增强深度双样本测试，能够识别哪些具体样本和输入特征驱动了统计显著的组间差异

Result: 在生物医学影像数据上，该框架成功识别出有影响力的样本，并突出显示与疾病相关变异相关的解剖学意义区域，提供空间和实例层面的洞察

Conclusion: 该工作连接了统计推断和可解释AI，使医学影像中的无标签群体分析变得可解释，提高了深度统计测试的实际应用价值

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [233] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 该论文提出通过数据增强学习2D旋转等变性，而非设计等变性架构，来提升单目3D人体姿态估计性能，在常见基准上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前单目3D人体姿态估计方法通常采用两步法（先检测2D关节点，再进行2D到3D提升），但现有提升模型在处理旋转输入时容易失败。作者认为学习人体姿态及其平面内旋转比直接学习点对点映射更简单且几何基础更扎实。

Method: 提出通过数据增强让模型学习2D旋转等变性，而不是设计具有等变性的架构。这种方法让模型在训练过程中自然地学习旋转不变性，不显式约束参数空间。

Result: 在常见的人体姿态估计基准测试中，验证了2D旋转等变性本身就能提升模型对图像平面内旋转姿态的性能，且通过数据增强学习等变性的方法简单高效，超越了现有的等变性设计方法。

Conclusion: 通过数据增强学习2D旋转等变性是一种更直接有效的单目3D人体姿态估计方法，比设计等变性架构更简单且性能更好。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [234] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG是一个自主视觉规划框架，通过选择性注视机制和双阶段训练策略，解决了大模型处理知识密集型视觉查询时的视觉冗余和噪声问题，在多个基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 大模型在视觉理解方面取得了显著成功，但在处理涉及长尾实体或动态信息的知识密集型查询时，由于静态参数化知识的限制而表现不佳。现有的搜索增强方法存在视觉冗余和噪声问题，缺乏深度迭代反思，限制了处理复杂视觉查询的效果。

Method: 提出了Glance-or-Gaze框架，包含选择性注视机制，动态选择全局观察或高价值区域注视，在检索前过滤无关信息。采用双阶段训练策略：1）通过监督微调进行反思性GoG行为对齐；2）复杂度自适应强化学习，通过迭代推理增强处理复杂查询的能力。

Result: 在六个基准测试中展示了最先进的性能。消融研究证实选择性注视机制和复杂度自适应强化学习对有效视觉搜索都至关重要。

Conclusion: GoG框架通过从被动感知转向主动视觉规划，有效解决了大模型处理知识密集型视觉查询的局限性，通过选择性注视和迭代推理显著提升了性能。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [235] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: VTONGuard是一个大规模虚拟试穿图像检测基准数据集，包含超过77.5万张真实和合成图像，用于评估多种检测方法，并提出了集成辅助分割的多任务框架来提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在虚拟试穿领域的快速发展，AI生成的试穿内容越来越逼真，引发了关于真实性和负责任使用的担忧。需要建立一个标准化的评估基准来促进检测技术的发展。

Method: 1.构建VTONGuard数据集：包含超过775,000张真实和合成试穿图像，涵盖姿势、背景、服装风格等多种现实条件；2.在统一训练测试协议下系统评估多种检测范式；3.设计多任务框架，集成辅助分割来增强边界感知特征学习。

Result: 通过VTONGuard基准评估，揭示了各种方法的优缺点，并突出了跨范式泛化的持续挑战。提出的多任务框架在VTONGuard上实现了最佳整体性能。

Conclusion: VTONGuard基准数据集能够实现公平比较，促进开发更鲁棒的检测模型，并支持虚拟试穿技术在实际应用中的安全负责任部署。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [236] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR是一种基于Transformer的弱半监督目标检测方法，专门针对医学图像设计，使用单点标注生成伪框标签，降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 医学图像中的解剖标志检测对诊断和干预指导至关重要，但传统目标检测方法依赖昂贵的边界框标注。弱半监督目标检测(WSSOD)使用点标注可以减少标注时间，但医学图像中的解剖重叠、尺寸多变和结构模糊等挑战阻碍了准确的边界框推断。

Method: 基于Point-DETR构建，DExTeR将单点标注编码为对象查询，采用类引导的可变形注意力机制，利用点坐标和类别标签引导注意力采样。引入CLICK-MoE（类别、实例和常识混合专家）分离类别和实例表示以减少混淆。实施多点训练策略提高预测一致性。

Result: 在三个医学领域数据集（内窥镜、胸部X光和内窥镜超声）上实现了最先进的性能，证明能够显著降低标注成本同时保持高检测精度。

Conclusion: DExTeR是针对医学图像量身定制的弱半监督目标检测方法，通过创新的Transformer架构和训练策略，有效解决了医学图像中的特殊挑战，具有减少标注成本同时保持高精度的潜力。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [237] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: 提出STEC评估指标，用于衡量视频帧采样的质量，关注采样帧是否能充分捕捉视频信息内容，而非重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标主要关注感知质量或重建保真度，缺乏评估采样帧是否充分捕捉视频信息内容和代表性的方法。

Method: 提出STEC指标，基于时空帧熵(STFE)测量每帧空间信息，结合时间覆盖度和冗余度评估采样帧质量。

Result: 在MSR-VTT测试集上，STEC能清晰区分随机、均匀和内容感知等采样策略，并能揭示平均性能无法捕捉的个体视频鲁棒性模式。

Conclusion: STEC提供了一个任务无关的诊断信号，用于分析有限预算下的帧采样行为，作为通用视频理解评估工具具有实用价值。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [238] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出一种新的无监督图像去雾框架EID，利用图像信号的对称性，通过强制雾霾一致性和系统等变性，直接从原始雾霾图像中恢复清晰图像，无需精心设计的先验或大量无雾地面真值。


<details>
  <summary>Details</summary>
Motivation: 现有图像去雾方法依赖精心设计的先验或大量无雾地面真值，这些数据获取成本高或不切实际，特别是在科学成像领域。需要一种无需这些昂贵资源的方法。

Method: 提出等变图像去雾（EID）框架，利用图像信号的对称性，通过强制雾霾一致性和系统等变性直接从雾霾图像恢复清晰图像。还提出对抗学习策略来建模未知雾霾物理并促进EID学习。

Result: 在两个科学图像去雾基准测试（细胞显微镜和医学内窥镜）以及自然图像去雾上，EID显著优于最先进的方法。

Conclusion: 通过将等变学习与雾霾物理建模相结合，EID有望在科学成像中实现更通用和有效的雾霾去除。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [239] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

TL;DR: 该论文将基于扩散模型的单图像逆问题求解方法推广到多图像超分辨率MRI，提出了无需修改扩散模型或增加计算量的高效MISR方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型主要针对单图像逆问题，但MRI等模态通常采集多个互补的低分辨率测量值，需要多图像超分辨率方法。

Method: 利用DPS似然校正实现独立测量间的可分离梯度分解，将DPS、DMAP、DPPS等单图像方法推广到MISR，无需构建联合算子或修改扩散模型。

Result: 在4×/8×/16×各向异性退化条件下显著优于单图像超分辨率，实现了各向异性MRI体积的最先进超分辨率，可从常规2D多切片采集重建近各向同性解剖结构。

Conclusion: 扩散模型可有效扩展到多图像逆问题，DPS的似然校正使独立测量的梯度分解成为可能，为MRI等需要多图像采集的模态提供了高效重建方案。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [240] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: 论文提出HuDA，一个无需训练的简单奖励模型，通过整合人体检测置信度和时序提示对齐分数来量化并改进生成视频中的人体动作质量。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在复杂非刚性运动（如体育、舞蹈等人体动作）上仍存在困难，常出现肢体缺失、姿态扭曲或物理上不合理的动作，需要改进人体动作生成质量。

Method: HuDA整合两个现成模型：1）人体检测置信度评估外观质量；2）时序提示对齐分数捕捉动作真实性。使用该奖励函数进行Group Reward Policy Optimization (GRPO)后训练，无需额外训练或人工标注数据。

Result: HuDA在复杂人体动作生成上显著优于现有方法，击败Wan 2.1等SOTA模型，胜率达到73%。还能改善动物视频和人物-物体交互的生成质量。

Conclusion: HuDA证明了利用现成模型的简单奖励函数能有效量化并提升生成视频中的人体动作质量，且该方法具有普适性，能扩展到其他非刚性运动生成任务。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [241] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 该研究发现动态场景中3D框标注存在系统误差，提出离线估计方法修正标注，使轨迹符合物理规律并与传感器数据保持时空一致性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统依赖精确的3D框标注进行监督学习和性能评估。主动传感器（如LiDAR）在动态场景中扫描不同时间点的物体位置，传统标注方法未妥善处理时间错位问题，导致系统误差。研究发现现有公开数据集存在此类标注错误，影响算法性能评估的准确性。

Method: 提出新颖的离线估计方法，通过物理可行的轨迹修正3D框标注，确保标注与传感器数据在空间和时间上保持一致。首次定义了该问题的评估指标，并在Argoverse 2、MAN TruckScenes及专有数据集上进行验证。

Result: 方法将三个数据集的标注质量提升超过17%。量化分析显示原始标注误差最大达2.5米，动态物体受影响最严重。测试发现这些误差对基准测试的影响超过了当前最先进方法相对于先前方法的改进幅度。

Conclusion: 精确的3D框标注对于正确评估自动驾驶系统性能至关重要。提出的校正方法能有效提升标注质量，揭示现有数据集中的系统性误差，并强调准确标注在性能评估中的关键作用。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [242] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 提出一个通用的弃权框架来增强医学图像分割的噪声鲁棒性，通过选择性忽略噪声样本提升模型可靠性


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声是严重问题，导致模型过拟合和泛化性能下降。现有方法对分割领域的噪声标签问题研究不足，弃权机制在分类任务中有效但在分割中尚未验证

Method: 引入通用模块化弃权框架，包含两个关键组件：1) 指导弃权行为的知情正则化项；2) 基于幂律的自适应调整弃权惩罚算法。将该框架与三种不同损失函数集成，创建了GAC、SAC和ADS三种新型噪声鲁棒变体

Result: 在CaDIS和DSAD医学数据集上的实验表明，所提方法在多种噪声水平下都显著优于非弃权基线方法，特别是在高噪声水平下表现突出

Conclusion: 使模型能够选择性忽略被破坏的样本是构建更可靠分割模型的有效且可泛化策略，弃权机制在分割任务中同样具有强大潜力

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [243] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 论文提出Weather-R1，首个具有逻辑忠实性的气象推理视觉语言模型，通过LoCo-RFT方法解决自相矛盾推理问题，在WeatherQA基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在气象领域应用存在两个主要挑战：领域差距和推理忠实性差距。主流强化微调方法会导致自相矛盾推理，这在气象等高风险领域是不可接受的。

Method: 1. 构建WeatherQA气象多模态推理基准；2. 提出LoCo-RFT方法，通过引入逻辑一致性奖励来解决自相矛盾推理问题；3. 开发Weather-R1模型，实现气象领域的逻辑忠实性推理。

Result: Weather-R1在WeatherQA基准上比基线提升9.8个百分点，优于监督微调和强化微调，甚至超过原始Qwen2.5-VL-32B模型，证明了LoCo-RFT的有效性和Weather-R1的优越性。

Conclusion: LoCo-RFT方法能有效解决视觉语言模型在气象领域的自相矛盾推理问题，Weather-R1作为首个具有逻辑忠实性的气象推理模型，为高风险领域提供了可靠的解决方案。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [244] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: MM-OOD：利用多模态大语言模型（MLLMs）进行零样本OOD检测的新方法，通过多轮对话和图像-文本协同推理，显著提升近OOD和远OOD任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于CLIP的零样本OOD检测方法过度依赖文本空间知识，忽视了图像空间检测的固有挑战。现有方法主要利用大语言模型识别潜在异常，但未能充分利用多模态推理能力。

Method: 提出MM-OOD pipeline：1) 近OOD任务：直接将ID图像和文本提示输入MLLMs识别异常；2) 远OOD任务：采用"草图-生成-精炼"框架：先用文本提示草图化异常暴露，再生成视觉OOD样本，最后用多模态提示进行精炼。

Result: 在Food-101等广泛使用的多模态数据集上取得显著改进，同时在ImageNet-1K上验证了方法的可扩展性。

Conclusion: MM-OOD通过利用MLLMs的多模态推理和多轮对话能力，有效提升了OOD检测性能，特别是在区分近OOD和远OOD样本方面表现出色。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [245] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

TL;DR: 论文提出了SVGFormer，一种基于图结构的3D医学图像表示方法，通过语义超体素图代替传统密集体素网格，使用编码器-仅架构专注于特征学习而非空间重建。


<details>
  <summary>Details</summary>
Motivation: 传统3D医学视觉主干使用参数密集的编码器-解码器结构，将大量参数用于空间重建而非特征学习，这限制了模型效率和特征表示能力。

Method: 1. 内容感知分组阶段将3D体积分割成语义超体素图；2. 分层编码器结合补丁级Transformer和超体素级图注意力网络，同时建模细粒度区域内特征和跨区域依赖关系；3. 完全编码器-仅架构，所有可学习参数都用于特征编码。

Result: 在BraTS数据集上训练了两个专门模型：节点级分类模型达到F1分数0.875，肿瘤比例回归模型达到MAE 0.028，证明编码器能够学习判别性和局部化特征。

Conclusion: 基于图的编码器-仅范式为3D医学图像表示提供了准确且内在可解释的替代方案，从补丁到区域级别提供双重尺度可解释性。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [246] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff：基于扩散模型的文本到图像生成框架，通过3D布局控制和交互式编辑实现一致的多物体场景合成，消除变形导致的几何伪影


<details>
  <summary>Details</summary>
Motivation: 现有方法使用2D线索或迭代复制-变形-粘贴策略改进空间一致性，但常常扭曲物体几何结构，且在编辑过程中无法保持一致性。需要一种能同时强制执行3D几何约束和实例级语义绑定的统一框架

Method: 提出POCI-Diff框架：1)通过Blended Latent Diffusion将单个文本描述绑定到特定3D边界框，实现显式的每物体语义控制；2)采用无变形的生成编辑流程，通过重新生成而非像素变形支持物体插入、移除和变换；3)使用IP-Adapter基于参考图像调节扩散过程，保持物体身份和编辑一致性

Result: 实验结果表明，POCI-Diff生成与指定3D布局和编辑一致的高质量图像，在视觉保真度和布局一致性方面优于最先进方法，同时消除了变形引起的几何伪影

Conclusion: POCI-Diff通过统一的扩散过程实现了3D几何约束和实例级语义绑定，为文本到图像生成提供了具有一致性和交互性的3D布局控制与编辑能力，解决了现有方法在几何保持和编辑一致性方面的局限性

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [247] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

TL;DR: CVSI是一种细粒度零样本组合图像检索方法，通过互补的视觉-语义集成，在提供参考图像和修改文本时能更准确地检索目标图像。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本组合图像检索方法在捕捉细粒度变化和有效整合视觉与语义信息方面存在困难，主要依赖图像转文本或大语言模型生成描述，但往往无法捕捉互补的视觉信息和完整的语义上下文。

Method: CVSI包含三个关键组件：1）视觉信息提取：提取全局图像特征并使用预训练映射网络将图像转换为伪标记，结合修改文本和最可能添加的对象；2）语义信息提取：使用预训练描述模型生成多个参考图像描述，利用LLM生成修改后的描述和最可能添加的对象；3）互补信息检索：整合查询和数据库图像信息进行目标图像检索。

Result: 在三个公共数据集（CIRR、CIRCO、FashionIQ）上的广泛实验表明，CVSI显著优于现有的最先进方法。

Conclusion: CVSI通过互补的视觉-语义集成方法有效解决了现有零样本组合图像检索方法的局限性，在细粒度图像检索任务上取得了显著提升。

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [248] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: 提出VERIDAH算法，能够自动识别脊柱椎体异常枚举，在T2w和CT影像上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 临床中脊柱椎体数量异常（如11或13个胸椎，4或6个腰椎）具有重要临床意义，但现有深度学习方法无法自动识别这些异常，且临床报告中很少描述

Method: 提出VERIDAH算法，基于多个分类头结合加权椎体序列预测算法，能够处理任意视野图像

Result: 在T2w TSE矢状位图像上正确标记所有椎体的准确率达98.30%（vs 94.24%），CT图像上达99.18%（vs 77.26%）；胸椎异常识别准确率在T2w为87.80%，CT为96.30%；腰椎异常识别准确率在T2w为94.48%，CT为97.22%

Conclusion: VERIDAH算法在椎体标记和异常枚举识别方面优于现有方法，填补了自动识别椎体数量异常的技术空白，具有临床应用价值

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [249] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出了一种旋转等变的变分自编码器，用于在球面上建模自然光照，避免了2D投影，采用新型VN-ViT编码器和旋转等变条件神经场解码器，实现了更平滑的潜在空间插值和更好的潜在空间特性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么忽略了光照环境的球形和旋转等变特性，要么未能提供良好的潜在空间。逆渲染是一个不适定问题，但光照先验可以简化它。因此需要一种能够在球面上建模自然光照并保持旋转等变性的方法。

Method: 提出了旋转等变变分自编码器，使用新型向量神经元视觉变换器（VN-ViT）作为编码器，以及旋转等变条件神经场作为解码器。在编码器中，通过新型SO(2)-等变全连接层将等变性从SO(3)降低到SO(2)，这是向量神经元的扩展。

Result: 提出的SO(2)-等变全连接层在SO(2)-等变模型中优于标准向量神经元。与先前方法相比，该变分自编码器实现了更平滑的潜在空间插值，并提供了更良好行为的潜在空间。

Conclusion: 该方法成功解决了现有光照建模方法的局限性，通过保持旋转等变性和直接在球面上操作，为逆渲染问题提供了更有效的光照先验建模方案。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [250] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: 研究人员创建了DermaBench，这是一个皮肤科视觉问答基准测试，用于评估视觉语言模型在皮肤病学中的临床推理能力，弥补了现有数据集主要关注图像分类的不足。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在皮肤病学领域的评估主要局限于图像级别的分类任务（如病变识别），无法全面评估模型的多模态理解、语言基础化和临床推理能力，需要专门的视觉问答基准来评估模型对皮肤科图像的解读和临床推理能力。

Method: 基于多样皮肤科图像数据集（DDI），研究人员开发了DermaBench，包含656张临床图像，涵盖Fitzpatrick皮肤类型I-VI。通过分层标注方案，皮肤科专家对每张图像进行诊断、解剖部位、病变形态、分布、表面特征、颜色和图像质量等方面的标注，包括22个主要问题（单选、多选和开放式问题），最终产生约14,474个VQA风格标注。

Result: DermaBench作为仅元数据的数据集公开发布于哈佛Dataverse，包含丰富的临床标注，可用于评估视觉语言模型在皮肤科领域的多模态理解和临床推理能力。

Conclusion: DermaBench填补了皮肤科视觉问答基准的空白，为评估视觉语言模型在皮肤病学中的全面能力提供了标准化工具，有助于推动医疗AI在皮肤科领域的发展。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [251] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 论文研究如何通过课程学习策略提升跨视角动作识别的泛化能力，特别是从地面视角到空中视角的迁移，无需使用真实空中数据训练。


<details>
  <summary>Details</summary>
Motivation: 当前动作识别模型在训练数据视角单一（主要是地面视角）的情况下，难以泛化到如空中视角等不同领域。需要探索如何在不使用真实空中数据的情况下提升跨视角泛化能力。

Method: 采用两种课程学习策略：1）两阶段课程（直接在合成空中数据上微调）；2）渐进式课程（在多阶段扩展数据集后再微调）。使用两种架构（SlowFast和MViTv2）在REMAG数据集上评估。

Result: 结合两种域外数据（合成空中和真实地面）明显优于单域训练。两种课程策略在保持top-1准确率（相差3%以内）的同时显著提升训练效率：两阶段方法减少30-37%迭代次数，渐进式方法进一步减少9-30%。

Conclusion: 课程学习策略能够在跨视角动作识别中保持可比性能的同时显著提高训练效率，为跨域泛化提供有效解决方案。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [252] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D是一种无需训练的三维纹理形变框架，通过生成先验和渐进对齐策略实现几何保真和纹理一致的三维资产平滑过渡。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么只能处理几何形变而忽略纹理，要么将2D插值策略扩展到3D导致语义模糊、结构错位和纹理模糊，需要同时保持几何一致性、纹理对齐和鲁棒性的联合解决方案。

Method: 采用基于生成先验的无训练框架，遵循渐进对齐原则：1）条件空间中的语义对齐插值；2）SLAT引导的结构插值确保结构一致性；3）细粒度纹理融合传输外观细节。

Result: 构建了分级难度的Interp3DData数据集进行评估，在保真度、过渡平滑性和合理性方面，定量指标和人工研究均显示该方法显著优于先前方法。

Conclusion: Interp3D通过联合保持几何一致性和纹理对齐，实现了高质量的三维纹理形变，在动画、编辑和数字内容创作中具有重要应用价值。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [253] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE是一个概率式少样本学习框架，通过多粒度语义和描述引导增强来改进原型估计，利用基础类知识库和BLIP描述器提升新类识别性能。


<details>
  <summary>Details</summary>
Motivation: 少样本学习中从有限样本估计的原型往往存在偏差且泛化能力差。现有基于语义的方法主要在支持集侧应用，而查询表示保持不变，限制了性能提升。

Method: PMCE构建非参数知识库存储基础类视觉统计和CLIP编码的类别名嵌入；元测试时基于类别名相似度检索相关基础类，将统计信息作为先验与支持集原型融合。同时使用冻结的BLIP描述器生成实例级图像描述，轻量级增强器在基础类上训练，通过一致性正则优化支持原型和查询特征。

Result: 在四个基准测试中，PMCE均优于强基线方法，在MiniImageNet的1-shot设置中相比最强语义竞争对手获得高达7.71%的绝对增益。

Conclusion: PMCE通过整合多粒度语义信息和描述引导增强，有效缓解了少样本学习中原型估计偏差问题，显著提升了新类识别性能。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [254] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench是首个专注于多图像推理安全性的基准测试，包含2,676个实例和9种多图像关系分类。研究发现多图像推理能力越强的模型在安全基准上越脆弱，许多看似安全的回复实际上是误解或逃避性回应。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在多图像推理能力上的提升，这种进步可能带来新的安全风险。研究旨在评估这些模型在处理复杂多图像指令时的安全性表现。

Method: 创建了MIR-SafetyBench基准测试，包含2,676个实例，涵盖9种多图像关系分类。对19个多模态大语言模型进行了广泛评估，分析了攻击成功率、回复质量以及注意力熵等指标。

Result: 发现了一个令人担忧的趋势：多图像推理能力越强的模型在MIR-SafetyBench上越脆弱。许多被标记为安全的回复实际上是表面化的，常由误解或逃避性回应驱动。不安全的生成平均具有更低的注意力熵，表明模型可能过度专注于任务解决而忽视安全约束。

Conclusion: 多图像推理能力的提升可能伴随着新的安全风险，需要更全面的安全评估方法。模型可能过度关注任务解决而忽视安全约束，注意力熵可作为潜在的风险指标。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [255] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

TL;DR: GIC-DLC：一种硬件感知的灰度图像编解码器，通过训练查找表将神经网络的灵活性与布尔运算的效率相结合，在边缘设备上实现高效低功耗压缩。


<details>
  <summary>Details</summary>
Motivation: 神经图像编解码器虽然比传统方法（如PNG、JPEG-XL）有更高压缩比，但计算开销大，限制了在智能手机、相机、无人机等能源受限设备上的部署。

Method: 提出GIC-DLC（灰度图像压缩与可微逻辑电路），训练查找表将神经网络的灵活性与布尔运算的效率相结合，实现硬件友好的编解码器设计。

Result: 在灰度基准数据集上的实验表明，GIC-DLC在压缩效率上优于传统编解码器，同时能显著降低能耗和延迟。

Conclusion: 学习型压缩可以是硬件友好的，为边缘设备的低功耗图像压缩提供了有前景的方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [256] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一个深度学习架构，通过整合术前临床和影像数据来预测肺癌手术术后并发症风险，采用超球嵌入空间融合异构输入，并结合干预式深度学习模块提供可解释性建议。


<details>
  <summary>Details</summary>
Motivation: 术后并发症严重影响患者预后并增加医疗成本，需要更精准、可解释的预测方法来改善肺癌手术患者的风险管理。

Method: 提出MIRACLE深度学习架构，采用超球嵌入空间融合结构化临床记录和高维影像数据，并集成干预式深度学习模块，使领域专家能够基于临床经验交互调整预测建议。

Result: 在包含3,094名肺癌手术患者的真实世界数据集POC-L上验证，MIRACLE优于传统机器学习模型和当代大语言模型变体，实现了个性化且可解释的术后风险管理。

Conclusion: MIRACLE通过融合多模态数据和集成干预式学习，不仅提高了术后并发症预测的准确性，还增强了临床可解释性和实用性，为精准医疗决策提供了有力工具。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [257] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出新框架解决稀疏图像新视角合成问题，结合3D高斯泼溅与ViT骨干网络，通过双域细节感知模块和特征引导扩散网络实现高分辨率处理与高频细节保留。


<details>
  <summary>Details</summary>
Motivation: 现有基于ViT的3D高斯泼溅方法因计算成本限制只能处理低分辨率输入，且现有生成增强方法对3D结构不敏感，导致跨视角结构不一致，特别是在未观察区域。

Method: 1) 双域细节感知模块：突破ViT骨干分辨率限制，为高斯添加存储高频细节的特征；2) 特征引导扩散网络：在恢复过程中保持高频细节；3) 统一训练策略：联合优化ViT几何骨干和扩散细化模块。

Result: 实验表明该方法在多个数据集上保持卓越的生成质量。

Conclusion: 该框架成功解决了稀疏图像新视角合成中高分辨率处理和高频细节保留的挑战，实现了跨视角一致的高质量生成。

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [258] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

TL;DR: 提出ASBA网络，通过A线ROI状态空间模型和B线相位注意力机制，从高度稀疏采样的原始A扫描重建光学多普勒断层成像，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ODT成像依赖密集采样，导致扫描时间长、存储需求大，难以捕捉快速血流动态。现有稀疏采样方法效果有限，因为采样率保守且对血流和背景信号采用统一建模。

Method: 提出ASBA网络：1) A线ROI状态空间模型提取A线上稀疏分布的血流特征；2) B线相位注意力机制基于相位差捕获每个B线上的长程血流信号；3) 血流感知加权损失函数，优先准确重建血流信号。

Result: 在真实动物数据上的大量实验表明，该方法明显优于现有最先进的重建方法。

Conclusion: ASBA网络能够从高度稀疏采样的原始A扫描有效重建ODT图像，解决了密集采样带来的时间、存储和动态捕捉限制，为血流分析提供了更高效的解决方案。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [259] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出一种仅使用低剂量CT图像的自监督训练策略，通过渐进式盲点去噪机制和高斯噪声正则化，在Mayo数据集上优于现有自监督方法，性能媲美甚至超越代表性监督方法。


<details>
  <summary>Details</summary>
Motivation: 自监督学习可缓解对配对正常剂量CT数据的依赖，这类数据在临床实践中难以获取，因此需要仅使用低剂量CT图像的有效去噪方法。

Method: 1) 提出仅依赖低剂量CT图像的自监督训练策略；2) 引入渐进式盲点去噪机制，通过条件独立性实现更精细的去噪学习；3) 添加高斯噪声作为正则化，缓解过拟合。

Result: 在Mayo低剂量CT数据集上的大量实验表明，该方法持续优于现有自监督方法，性能达到或超过多个代表性监督去噪方法。

Conclusion: 提出的自监督方法仅需低剂量CT图像，通过渐进式盲点去噪和高斯噪声正则化，在低剂量CT图像去噪任务上表现出色，为临床实践提供了有效的解决方案。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [260] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: 论文提出IIR-VLM，一种增强视觉语言模型进行上下文实例级识别的方法，通过集成预训练的ILR专家模型作为辅助视觉编码器，使VLM能够以单样本方式学习新实例，并用于实例感知的视觉理解。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在实例级识别任务上表现不佳，远逊于领域特定的ILR模型，这限制了VLM在许多需要识别熟悉人物和对象的实际应用中的有效性。现有解决方案通常需要为每个实例单独训练，数据收集和训练成本高，且难以进行细粒度区分。

Method: 提出IIR-VLM框架，集成预训练的实例级识别专家模型作为辅助视觉编码器，提供专门的特征表示。这使得VLM能够以单样本上下文学习的方式学习新实例，并利用这些知识进行实例感知的视觉理解。

Result: 在现有的实例个性化基准测试中验证了IIR-VLM的有效性。同时在一个新的具有挑战性的基准测试上展示了其优越的ILR性能，该基准测试涵盖不同难度和多样类别（人物、面部、宠物和一般物体）。

Conclusion: IIR-VLM成功增强了视觉语言模型的实例级识别能力，通过集成专家模型实现了单样本上下文学习，解决了现有VLM在ILR任务上的局限性，为实际应用中的实例感知视觉理解提供了有效解决方案。

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [261] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种1D离散视觉分词器，能根据图像结构复杂度和细节水平自适应选择输出token数量，生成长度自适应的1D视觉token，兼容因果1D自回归视觉生成模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉生成模型中token数量固定的问题，让模型能根据图像复杂度自适应调整token数量，提高生成效率和质量，同时与因果1D自回归模型兼容。

Method: 1. 设计Soft Tail-dropping Adaptive Tokenizer (STAT)，编码图像为离散代码序列及每个token的保留概率；2. 使用自编码器目标训练；3. 正则化保留概率使其沿序列单调递减；4. 对齐保留概率分布与图像级复杂度度量。

Result: 在ImageNet-1k上，将STAT与普通因果自回归模型结合，相比其他概率模型家族获得了竞争性或更优的视觉生成质量，同时展现出之前自回归视觉生成尝试中难以实现的良好扩展行为。

Conclusion: STAT成功实现了长度自适应的1D视觉token生成，解决了自回归视觉生成中的扩展性问题，为视觉生成模型提供了更灵活高效的token化方案。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [262] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer是一个统一的时空视频转换框架，通过多视角信息和时序线索实现外观一致性和细粒度时序控制，在多种视频转换任务上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法大多依赖参考图像或任务特定的时序先验，未能充分利用视频固有的丰富时空信息，限制了视频生成的灵活性和泛化能力。

Method: 提出OmniTransfer框架，包含三个关键设计：1）任务感知位置偏置，自适应利用参考视频信息改善时序对齐或外观一致性；2）参考解耦因果学习，分离参考和目标分支实现精确参考转换并提高效率；3）任务自适应多模态对齐，使用多模态语义指导动态区分和处理不同任务。

Result: 实验表明OmniTransfer在外观（身份和风格）和时序（相机运动和视频效果）转换方面优于现有方法，同时在运动转换方面不使用姿态也能匹配姿态引导方法。

Conclusion: OmniTransfer为灵活、高保真的视频生成建立了新范式，能够统一处理多种视频转换任务。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [263] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B是一个10亿参数的端到端多语言视觉-语言模型，能将文档图像直接转换为干净、自然排序的文本，无需复杂的OCR流程。模型在包含扫描文档、法语文档和科学PDF的大规模高质量蒸馏数据集上训练，在OlmOCR-Bench上达到SOTA，同时比之前最佳模型小9倍且更快。模型还扩展了输出格式来预测嵌入式图像的标准化边界框，并通过恢复策略和RLVR进行定位训练。


<details>
  <summary>Details</summary>
Motivation: 传统的OCR流程通常脆弱且复杂，需要多个处理步骤。本文旨在开发一个端到端的模型，直接处理文档图像并输出干净、有序的文本，同时支持多语言文档和科学PDF。另一个动机是扩展模型能力，使其不仅能提取文本，还能定位文档中的嵌入式图像。

Method: 1) 使用大规模高质量蒸馏混合数据进行训练，覆盖扫描文档、法语文档和科学PDF；2) 扩展输出格式以预测嵌入式图像的标准化边界框；3) 通过恢复策略在预训练中引入定位能力；4) 使用基于IoU奖励的RLVR（强化学习与视觉推理）进一步细化定位；5) 通过检查点平均和任务算术合并提高模型鲁棒性。

Result: 在OlmOCR-Bench上达到最先进水平，同时比之前最佳模型小9倍且速度显著更快。模型能够准确提取文本并定位文档中的嵌入式图像。发布了Apache 2.0许可的模型检查点，以及数据集和LightOnOCR-bbox-bench评估基准。

Conclusion: LightOnOCR-2-1B展示了端到端文档理解模型的潜力，能够高效处理多语言文档和科学PDF，同时具备文本提取和图像定位能力。模型的小尺寸和快速推理使其具有实际应用价值，开源发布促进了该领域的研究和发展。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [264] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4是一个前馈框架，能够从单目视频和可选的3D参考网格合成高质量的4D动态物体，通过分解为静态3D形状生成和运动重建来解决4D合成的挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然2D、视频和3D内容生成技术取得了显著进展，但4D合成仍然面临训练数据有限和从单目视角恢复几何与运动固有的模糊性等挑战。

Method: 使用规范参考网格，模型学习紧凑的运动潜在表示并预测每帧顶点轨迹来恢复完整、时间一致的几何。可扩展的逐帧变换器使模型对变化的序列长度具有鲁棒性。

Result: 在标准基准测试和具有精确地面真实几何的新数据集上的评估显示，Motion 3-to-4在保真度和空间一致性方面优于先前的工作。

Conclusion: Motion 3-to-4通过分解4D合成任务，有效解决了从单目视频合成高质量4D动态物体的挑战，在质量和一致性方面超越了现有方法。

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [265] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩，仅用合成数据训练即可零样本泛化到真实视频。基于此构建大规模伪标注数据集MA-V，并用其训练SAM2-Matte模型，在真实视频上表现优于现有数据集训练模型。


<details>
  <summary>Details</summary>
Motivation: 视频抠图模型在实际应用中面临标注数据稀缺的挑战，这限制了模型在真实世界视频上的泛化能力。研究旨在解决这一问题，通过利用预训练模型和伪标注技术来扩展视频抠图的数据资源。

Method: 提出VideoMaMa模型，利用预训练视频扩散模型将粗糙分割掩码转换为精确alpha遮罩；开发可扩展的伪标注流程，构建大规模视频抠图数据集MA-V（包含5万+真实视频）；在MA-V上微调SAM2模型得到SAM2-Matte。

Result: VideoMaMa仅用合成数据训练即可零样本泛化到真实视频；构建的MA-V数据集包含5万+高质量标注视频；SAM2-Matte在真实视频上的鲁棒性优于基于现有抠图数据集训练的相同模型。

Conclusion: 大规模伪标注视频抠图数据对推动该领域研究至关重要，生成先验和易获取的分割线索能够驱动视频抠图技术的可扩展进步。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [266] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种统一图像识别与生成的新模型，通过超网络学习隐式神经表示，同时支持高质量重建和识别任务，在小嵌入空间中实现出色的视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前图像表示学习模型通常分别针对识别或生成任务设计，缺少能够同时支持两者的统一模型。识别模型通常使用对比学习获得分类、检测、分割有用的嵌入，而生成模型则通过像素级、感知和对抗损失训练重建图像。本文旨在弥合这一鸿沟，开发首个同时适用于识别和生成的统一表示学习模型。

Method: 1. 将模型训练为隐式神经表示的超网络，学习将图像映射到模型权重以实现快速准确重建
2. 将INR超网络与知识蒸馏相结合以提高泛化能力和性能
3. 学习前所未有的压缩嵌入空间，在各种视觉任务中表现出色

Result: 1. 完整模型在图像表示学习方面与最先进结果竞争
2. 通过高质量小嵌入实现生成能力
3. 学习的压缩嵌入空间在各种视觉任务中表现优异

Conclusion: 该研究成功开发了首个同时适用于识别和生成的统一图像表示学习模型，通过超网络和知识蒸馏的集成，不仅实现了与最先进识别模型竞争的性能，还具备高质量的生成能力，开辟了图像表示学习的新方向。

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [267] [CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration](https://arxiv.org/abs/2601.11556)
*Boyang Wang,Yash Vishe,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.LG

TL;DR: CSyMR-Bench：针对大语言模型的组合式符号音乐推理基准，包含126个需要结合多个原子分析的多选题，并提出了基于music21工具增强的代理框架来应对挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准过于强调孤立知识或原子分析，缺乏对连接音乐结构所需的组合式作曲推理能力的评估，因此需要构建更综合的音乐推理基准。

Method: 1) 从专家论坛和专业考试中收集并构建包含126个多选题的CSyMR-Bench数据集，每个问题需要结合多个原子分析；2) 提出基于music21库符号音乐分析工具的工具增强代理框架。

Result: CSyMR-Bench对现有方法构成显著挑战，而提出的工具增强代理框架在所有基线方法中表现最优，实现了5-7%的绝对准确率提升。

Conclusion: CSyMR-Bench填补了组合式符号音乐推理基准的空白，工具增强代理框架能有效提升大语言模型在复杂音乐推理任务上的表现，为音乐AI研究提供了新的评估标准和解决方案。

Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.

</details>


### [268] [AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control](https://arxiv.org/abs/2601.11568)
*Quang-Hung Bui,Anh Son Ta*

Main category: cs.LG

TL;DR: AdaFRUGAL通过动态调整梯度分割的超参数（子空间比例ρ和更新频率T），自动优化内存使用和计算开销，相比静态FRUGAL框架提供更实用的资源受限LLM训练方案。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型（LLM）时，优化器状态占用大量内存。现有的FRUGAL框架虽然通过梯度分割减少了内存占用，但其静态超参数（子空间比例ρ和更新频率T）需要手动调优，成本高昂且缺乏适应性。

Method: AdaFRUGAL引入两种动态控制机制：(1) 对子空间比例ρ采用线性衰减策略，逐步减少内存使用；(2) 基于损失感知的更新频率T调度策略，降低计算开销。

Result: 在大规模预训练（英语C4、越南语VietVault）和微调（GLUE）实验中，AdaFRUGAL在保持与AdamW和静态FRUGAL相当性能的同时，显著减少了GPU内存占用和训练时间。

Conclusion: AdaFRUGAL提供了内存使用与计算开销的良好权衡，为资源受限的LLM训练提供了更实用、自主的解决方案。

Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($ρ$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $ρ$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.

</details>


### [269] [Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces](https://arxiv.org/abs/2601.11572)
*Timo Aukusti Laine*

Main category: cs.LG

TL;DR: 使用量子力学启发的数学工具（哈密顿形式、线性代数）分析LLM嵌入空间的结构，发现L2归一化约束创造了适合哈密顿分析的结构化空间，并推导了余弦相似度与嵌入扰动的关系。


<details>
  <summary>Details</summary>
Motivation: 观察到LLM嵌入表现出离散的语义状态，这表明可以使用量子力学系统的数学工具来分析语义关系，为理解LLM内部表示提供新视角。

Method: 应用线性代数和哈密顿形式主义分析LLM嵌入空间，特别关注L2归一化约束，推导余弦相似度与嵌入向量扰动的关系，探索直接和间接语义转换，并从量子力学角度推导类似零点能量的概念。

Result: 证明L2归一化约束导致结构化嵌入空间适合哈密顿分析，建立了余弦相似度与嵌入扰动之间的数学关系，为语义转换提供了新的分析框架。

Conclusion: 这种量子力学启发的方法为深入理解LLM提供了有前景的途径，可能为减轻幻觉提供新方法，但解释需要谨慎考虑。

Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.

</details>


### [270] [GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment](https://arxiv.org/abs/2601.11574)
*Lukas Abrie Nel*

Main category: cs.LG

TL;DR: GRADE是一种用于大语言模型对齐的新方法，使用Gumbel-softmax重参数化替代高方差的策略梯度方法，在情感控制文本生成任务上表现优于PPO和REINFORCE。


<details>
  <summary>Details</summary>
Motivation: RLHF已成为对齐大语言模型的主流方法，但PPO等策略梯度方法存在梯度估计方差高、需要大量超参数调优和计算资源的问题。需要更稳定高效的替代方案。

Method: 提出GRADE方法，使用Gumbel-softmax重参数化和直通估计（GRADE-STE），通过离散令牌采样过程的可微分松弛实现端到端梯度传播，替代高方差的策略梯度估计。

Result: 在IMDB数据集的情感控制文本生成任务中，GRADE-STE获得0.763的测试奖励，优于PPO的0.510和REINFORCE的0.617，相对PPO提升50%。梯度方差比REINFORCE低14倍以上，训练动态更稳定。

Conclusion: GRADE为LLM对齐提供了更简单、更稳定、更有效的强化学习替代方案，在泛化能力和稳定性方面均表现优异。

Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.

</details>


### [271] [Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.11604)
*Jonaid Shianifar,Michael Schukat,Karl Mason*

Main category: cs.LG

TL;DR: 提出Hindsight Preference Replay (HPR)回放增强策略，通过重新标记历史经验中的偏好来提升多目标强化学习性能，在多个环境中显著改进预期效用和超体积指标。


<details>
  <summary>Details</summary>
Motivation: 现有方法CAPQL在训练时只使用特定偏好下收集的数据，导致其他偏好下的离轨数据未被充分利用，限制了学习效率。

Method: 提出Hindsight Preference Replay (HPR)回放增强策略，在不改变CAPQL架构和损失函数的情况下，对存储的转移进行重新标记，使用替代偏好来增强监督信号。

Result: 在六个MO-Gymnasium运动任务中，HPR-CAPQL在300,000步预算下，在五个环境中改进了超体积(HV)，在四个环境中改进了预期效用(EUM)。例如在mo-humanoid-v5中，EUM从323±125提升到1613±464，HV从0.52M提升到9.63M。

Conclusion: HPR是一种简单而有效的回放增强策略，能够在不修改算法架构的情况下显著提升多目标强化学习的性能，通过更密集地利用历史经验来改善偏好空间的学习。

Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augmentation strategy that retroactively relabels stored transitions with alternative preferences. This densifies supervision across the preference simplex without altering the CAPQL architecture or loss functions. Evaluated on six MO-Gymnasium locomotion tasks at a fixed 300000-step budget using expected utility (EUM), hypervolume (HV), and sparsity, HPR-CAPQL improves HV in five of six environments and EUM in four of six. On mo-humanoid-v5, for instance, EUM rises from $323\!\pm\!125$ to $1613\!\pm\!464$ and HV from 0.52M to 9.63M, with strong statistical support. mo-halfcheetah-v5 remains a challenging exception where CAPQL attains higher HV at comparable EUM. We report final summaries and Pareto-front visualizations across all tasks.

</details>


### [272] [A Multimodal Data Processing Pipeline for MIMIC-IV Dataset](https://arxiv.org/abs/2601.11606)
*Farzana Islam Adiba,Varsha Danduri,Fahmida Liza Piya,Ali Abbasi,Mehak Gupta,Rahmatollah Beheshti*

Main category: cs.LG

TL;DR: 该研究开发了一个针对MIMIC-IV数据集的多模态数据处理管道，能自动整合结构化数据、临床文本、波形和影像数据，大幅减少多模态处理时间并提高研究可重复性。


<details>
  <summary>Details</summary>
Motivation: MIMIC-IV数据集包含多种模态的医疗数据，但处理这些分散的数据需要大量手动预处理和对齐工作。现有管道要么只针对少量模态，要么不支持任意的下游应用。

Method: 在先前流行的单模态管道基础上扩展，开发了一个全面且可定制的多模态管道，支持自动化队列选择、跨模态时间对齐，并生成适用于任意静态和时间序列下游应用的标准多模态输出格式。

Result: 创建了一个完整的MIMIC-IV多模态数据处理管道，显著减少了多模态处理时间，增强了基于MIMIC研究的可重复性。提供了代码、简单UI和Python包，支持选择性集成（含嵌入功能）。

Conclusion: 该多模态管道为MIMIC-IV数据集的研究者提供了强大的工具，能够高效处理复杂的多模态医疗数据，促进临床机器学习研究的可重复性和易用性。

Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at https://github.com/healthylaife/MIMIC-IV-Data-Pipeline.

</details>


### [273] [Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction](https://arxiv.org/abs/2601.11609)
*Weinuo Ou*

Main category: cs.LG

TL;DR: 提出ApCM模型来解决LLM缺乏有效运行时记忆机制的问题


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型缺乏有效的运行时记忆机制，难以适应动态和个性化的交互需求

Method: 提出新颖的神经记忆存储架构——辅助预测压缩记忆模型（ApCM模型）

Result: 从摘要中无法得知具体实验结果

Conclusion: 通过ApCM模型架构来解决LLM记忆机制的局限性

Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).

</details>


### [274] [Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home](https://arxiv.org/abs/2601.11611)
*Marina Vicini,Martin Rudorfer,Zhuangzhuang Dai,Luis J. Manso*

Main category: cs.LG

TL;DR: 提出一种通过时间聚类和循环时间特征增强的人体活动识别方法，在智能家居环境中提高老年人活动监测的准确性


<details>
  <summary>Details</summary>
Motivation: 随着全球人口老龄化，需要支持老年人在家中独立安全生活。虽然使用PIR和门传感器等被动传感器监测日常活动受到关注，但现有方法在有效利用时间信息方面存在挑战

Method: 1. 将活动按早晨、下午、晚上进行时间聚类，为每个时段计算不同的互信息矩阵进行特征加权；2. 在特征向量中引入一天中的时间和星期几作为循环时间特征；3. 增加用户位置跟踪特征

Result: 在四个真实世界数据集中的三个上，相比现有最先进方法获得了更高的准确率和F1分数，在数据量较少的情况下提升最明显

Conclusion: 该方法通过有效整合时间信息提高了人体活动识别性能，展示了开发有效智能家居解决方案支持老年人在家养老的潜力

Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.

</details>


### [275] [A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia](https://arxiv.org/abs/2601.11615)
*Beyza Cinar,Louisa van den Boom,Maria Maleshkova*

Main category: cs.LG

TL;DR: 该综述论文分析了基于连续血糖监测数据的机器学习模型在预测1型糖尿病患者低血糖事件方面的研究现状，比较了不同预测时长下模型的性能表现，并探讨了影响性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病患者需要终身胰岛素治疗，但胰岛素治疗有导致低血糖的副作用，而低血糖会增加死亡风险。机器学习模型可以通过预测低血糖事件来改善糖尿病管理，提供最优预防方法。

Method: 该综述调查了基于1型糖尿病患者连续血糖监测数据训练的最先进机器学习模型。模型分为回归模型（预测血糖水平）和分类模型（基于定义标签识别事件）。比较了模型在短期（15-120分钟）和长期（3-24小时以上）预测时长下的性能表现。

Result: 研究结果表明：1）1小时以内的预测时长提供最佳结果；2）传统机器学习方法在分类任务中表现最好，深度学习在回归任务中表现最好，单个模型无法充分分类多个预测时长；3）模型性能受多变量数据集和输入序列长度影响；4）个性化数据能提升性能，但由于数据质量有限，基于人群的模型更受青睐。

Conclusion: 机器学习模型在预测1型糖尿病患者低血糖方面显示出潜力，特别是在短期预测中。未来研究需要解决多预测时长的分类挑战，并改进个性化模型的数据质量和可用性。

Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models are classified into regression and classification based, that forecast glucose levels and identify events based on defined labels, respectively. This review investigates state-of-the-art models trained on data of continuous glucose monitoring (CGM) devices from patients with T1D. We compare the models' performance across short-term (15 to 120 min) and long term (3 to more than 24 hours) prediction horizons (PHs). Particularly, we explore: 1) How much in advance can glucose values or a hypoglycemic event be accurately predicted? 2) Which models have the best performance? 3) Which factors impact the performance? and 4) Does personalization increase performance? The results show that 1) a PH of up to 1 hour provides the best results. 2) Conventional ML methods yield the best results for classification and DL for regression. A single model cannot adequately classify across multiple PHs. 3) The model performance is influenced by multivariate datasets and the input sequence length (ISL). 4) Personal data enhances performance but due to limited data quality population-based models are preferred.

</details>


### [276] [Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective](https://arxiv.org/abs/2601.11616)
*Feilong Liu*

Main category: cs.LG

TL;DR: 本文通过几何视角研究混合专家模型，发现路由机制将表示空间软划分为重叠的局部区域，降低局部敏感性，提高表示的有效秩。


<details>
  <summary>Details</summary>
Motivation: 混合专家架构通常以效率和条件计算为动机，但其对学习函数和表示几何性质的影响尚未得到充分表征。本文旨在通过几何视角理解MoE如何影响函数和表示空间的结构。

Method: 引入双雅可比-PCA谱几何探针，通过雅可比奇异值谱分析局部函数几何，通过加权PCA分析路由隐藏状态的表示几何。在允许精确雅可比计算的受控MLP-MoE设置中，比较了密集、Top-k和完全软路由架构。

Result: MoE路由持续降低局部敏感性，专家局部雅可比表现出较小的主导奇异值和更快的谱衰减。加权PCA显示专家局部表示将方差分布在更多主方向上，表明在相同输入分布下具有更高的有效秩。平均专家雅可比几乎正交，表明变换被分解为低重叠的专家特定子空间。Top-k路由产生更低秩、更集中的专家局部结构，而完全软路由产生更广泛、更高秩的表示。

Conclusion: MoE可几何解释为函数空间的软划分，在平坦化局部曲率的同时重新分配表示方差。路由机制将表示空间划分为重叠的局部区域，降低局部敏感性，提高表示的有效秩。

Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local function geometry via Jacobian singular-value spectra and representation geometry via weighted PCA of routed hidden states. Using a controlled MLP-MoE setting that permits exact Jacobian computation, we compare dense, Top-k, and fully-soft routing architectures under matched capacity. Across random seeds, we observe that MoE routing consistently reduces local sensitivity, with expert-local Jacobians exhibiting smaller leading singular values and faster spectral decay than dense baselines. At the same time, weighted PCA reveals that expert-local representations distribute variance across a larger number of principal directions, indicating higher effective rank under identical input distributions. We further find that average expert Jacobians are nearly orthogonal, suggesting a decomposition of the transformation into low-overlap expert-specific subspaces rather than scaled variants of a shared map. We analyze how routing sharpness modulates these effects, showing that Top-k routing produces lower-rank, more concentrated expert-local structure, while fully-soft routing yields broader, higher-rank representations. Together, these results support a geometric interpretation of MoEs as soft partitionings of function space that flatten local curvature while redistributing representation variance.

</details>


### [277] [Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention](https://arxiv.org/abs/2601.11618)
*Luis Rosario Freytes*

Main category: cs.LG

TL;DR: 几何注意力（GA）通过四个独立输入定义注意力层：载体、证据核规则、探测族和锚定/更新规则，将注意力机制分解为不变结构和建模选择，支持多种注意力变体。


<details>
  <summary>Details</summary>
Motivation: 现有注意力机制（如Transformer中的softmax注意力）缺乏统一的理论框架，难以进行系统比较和扩展。论文旨在建立几何注意力的形式化框架，分离注意力机制的不变结构和建模选择。

Method: 提出几何注意力（GA）框架，通过四个组件定义注意力层：有限载体（可寻址索引）、证据核规则（掩码原始分数和链接产生非负权重）、探测族（可观测量的处理）、锚定/更新规则（核选择和更新方式）。

Result: 该框架统一了多种注意力机制：标量关系工作表示和乘法组合性产生Gibbs权重；行锚定包含softmax核族；低秩交互对应点积分数；固定载体得到标准Transformer注意力；允许载体更新得到自适应载体和分层深度机制。

Conclusion: 几何注意力框架提供了形式化语言，分离了注意力机制的不变结构和建模选择，支持多核/混合核、基于计划的锚定（如熵最优传输/Sinkhorn）等扩展，为注意力机制的比较和扩展提供了理论基础。

Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.

</details>


### [278] [NoiseFormer -- Noise Diffused Symmetric Attention Transformer](https://arxiv.org/abs/2601.11619)
*Phani Kumar,Nyshadham,Jyothendra Varma,Polisetty V R K,Aditya Rathore*

Main category: cs.LG

TL;DR: 提出Noise Diffused Symmetric Attention Transformer，在保持对称注意力内存优势的同时，通过微小参数和计算开销提升模型性能，在GLUE基准测试中表现优于普通对称注意力，接近GPT2基础模型。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型规模急剧增长，内存占用巨大导致难以在单个GPU/AI加速器上部署，需要多设备并行计算从而大幅增加成本。稀疏注意力技术（如对称注意力）能减少参数但可能牺牲性能，因此需要一种既能保持内存优势又能提升性能的方法。

Method: 提出Noise Diffused Symmetric Attention Transformer统一架构，在对称点积注意力（Symmetric Attention）基础上引入噪声扩散机制，以微小参数和计算开销增强模型表现力。

Result: 在GPT2基础模型上验证，在多个GLUE基准任务中，所提模型的准确率表现介于普通对称注意力和GPT2基础模型之间，同时实现了显著模型大小缩减。

Conclusion: 提出的噪声扩散对称注意力Transformer在保持对称注意力内存优势的同时，通过最小开销显著提升了模型性能，为大型语言模型的高效部署提供了有前景的解决方案。

Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.

</details>


### [279] [Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System](https://arxiv.org/abs/2601.11638)
*Josafat Ribeiro Leal Filho,Antônio Augusto Fröhlich*

Main category: cs.LG

TL;DR: 该论文提出了一种基于Fisher信息的新实验框架，用于量化评估PINNs对物理系统动态行为的捕捉能力，而不仅仅是轨迹预测精度。


<details>
  <summary>Details</summary>
Motivation: 虽然PINNs已成为解决微分方程和建模物理系统的强大工具，但如何严格量化PINN是否准确捕捉了系统的完整动态行为（而不仅仅是简单轨迹预测）仍然是一个挑战。

Method: 提出使用可微动力系统的Fisher信息（$g_F^C$）作为评估指标，该指标测量确定性系统中的固有不确定性（如对初始条件的敏感性），并与相空间曲率和状态空间演化的净拉伸作用相关。通过比较原始解析模型和训练好的PINN的Fisher信息景观来评估PINN的保真度。

Result: 论文提出了一个实验方法学，使用汽车动力学模型来计算和比较解析模型和训练PINN的$g_F^C$。基于各自系统动态的Jacobian矩阵比较，为PINN在表示系统复杂动态特性方面的保真度提供了定量度量。

Conclusion: 如果PINN准确学习了物理系统的底层动态，那么从PINN学习到的运动方程推导出的Fisher信息景观将与原始解析模型的Fisher信息景观密切匹配。这种匹配表明PINN不仅捕捉了状态演化，还捕捉了关键的几何和稳定性特性。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information for differentiable dynamical systems, denoted $g_F^C$. This Fisher information, distinct from its statistical counterpart, measures inherent uncertainties in deterministic systems, such as sensitivity to initial conditions, and is related to the phase space curvature and the net stretching action of the state space evolution. We hypothesize that if a PINN accurately learns the underlying dynamics of a physical system, then the Fisher information landscape derived from the PINN's learned equations of motion will closely match that of the original analytical model. This match would signify that the PINN has achieved comprehensive fidelity capturing not only the state evolution but also crucial geometric and stability properties. We outline an experimental methodology using the dynamical model of a car to compute and compare $g_F^C$ for both the analytical model and a trained PINN. The comparison, based on the Jacobians of the respective system dynamics, provides a quantitative measure of the PINN's fidelity in representing the system's intricate dynamical characteristics.

</details>


### [280] [Global Optimization By Gradient from Hierarchical Score-Matching Spaces](https://arxiv.org/abs/2601.11639)
*Ming Li*

Main category: cs.LG

TL;DR: 该论文提出了一种通过分数匹配获取梯度的方法，将带复杂约束的优化问题统一为无约束的分层优化目标，首次实现了基于严格梯度的确定性全局优化方法，并揭示了全局优化与基于扩散的生成建模之间的深刻联系。


<details>
  <summary>Details</summary>
Motivation: 传统梯度下降方法存在局限性：只能找到局部最优解，且仅适用于连续可微问题和简单凸约束。需要突破这些限制，开发能处理各种复杂约束的全局优化方法。

Method: 通过分数匹配获取梯度，将所有带复杂约束的优化问题统一为无约束的分层优化目标。这种方法将优化问题转化为可进行确定性梯度优化的形式。

Result: 首次实现了基于严格梯度的确定性全局优化方法。通过简单构造和复杂实际实验验证了方法的有效性，并在理论和实践层面都取得了突破。

Conclusion: 该方法不仅解决了传统梯度下降的局限性，更重要的是揭示了全局优化与基于扩散的生成建模之间的深刻理论联系，为优化领域提供了新的视角和方法。

Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.

</details>


### [281] [Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning](https://arxiv.org/abs/2601.11657)
*Jack T. Beerman,Shobhan Roy,H. S. Udaykumar,Stephen S. Baek*

Main category: cs.LG

TL;DR: D-PARC架构通过可变形物理感知循环卷积，克服传统CNN在高度非线性流场预测中的局限性，以更小的网络规模实现比大型架构更优的精度。


<details>
  <summary>Details</summary>
Motivation: 当前卷积神经网络在处理高度非线性物理流场时表现不佳，单纯扩大网络规模对物理建模效果有限，需要借鉴混合拉格朗日-欧拉数值方法的物理直觉来改进架构。

Method: 提出可变形物理感知循环卷积（D-PARC），借鉴混合拉格朗日-欧拉方法的思路，通过可变形卷积核实现自适应学习策略，能够根据流场特性动态调整计算资源分配。

Result: 在Burgers方程、Navier-Stokes方程和反应流等多个物理系统中，D-PARC相比规模大得多的传统架构实现了更高的预测精度，且卷积核表现出反聚集行为和主动过滤策略。

Conclusion: 基于物理直觉的架构设计比单纯扩大网络规模更有效，D-PARC展示了精简网络中策略性学习的优势，为物理感知深度学习提供了更有效的发展路径。

Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D-PARC) to overcome the rigidity of CNNs. Across Burgers' equation, Navier-Stokes, and reactive flows, D-PARC achieves superior fidelity compared to substantially larger architectures. Analysis reveals that kernels display anti-clustering behavior, evolving into a learned "active filtration" strategy distinct from traditional h- or p-adaptivity. Effective receptive field analysis confirms that D-PARC autonomously concentrates resources in high-strain regions while coarsening focus elsewhere, mirroring adaptive refinement in computational mechanics. This demonstrates that physically intuitive architectural design can outperform parameter scaling, establishing that strategic learning in lean networks offers a more effective path forward for PADL than indiscriminate network expansion.

</details>


### [282] [Machine learning model for predicting surface wettability in laser-textured metal alloys](https://arxiv.org/abs/2601.11661)
*Mohammad Mohammadzadeh Sanandaji,Danial Ebrahimzadeh,Mohammad Ikram Haider,Yaser Mike Banad,Aleksandar Poleksic,Hongtao Ding*

Main category: cs.LG

TL;DR: 本研究提出一个机器学习框架，利用实验获得的形态和化学特征，准确预测激光纹理金属合金的润湿性。


<details>
  <summary>Details</summary>
Motivation: 表面润湿性在传热、润滑、微流体和表面涂层等应用中至关重要，但受拓扑结构和化学性质共同影响，传统方法难以准确预测。需要开发数据驱动方法来捕捉表面特性的复杂相互作用。

Method: 通过纳秒激光纹理化和化学浸渍处理在AA6061和AISI 4130合金上制备超亲水和超疏水表面。使用Laws纹理能量法和轮廓测量法量化表面形态，通过XPS表征表面化学特征（官能团极性、分子体积、峰面积分数等）。采用包含残差连接、批量归一化和dropout正则化的集成神经网络模型进行训练。

Result: 模型达到高预测精度（R² = 0.942，RMSE = 13.896），优于先前方法。特征重要性分析显示表面化学对接触角预测影响最大，拓扑特征也有显著贡献。

Conclusion: 该工作展示了人工智能通过捕捉表面特性的复杂相互作用来建模和预测润湿行为的潜力，为设计定制化功能表面提供了数据驱动途径。

Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA6061 and AISI 4130 alloys via nanosecond laser texturing followed by chemical immersion treatments. Surface morphology was quantified using the Laws texture energy method and profilometry, while surface chemistry was characterized through X-ray photoelectron spectroscopy (XPS), extracting features such as functional group polarity, molecular volume, and peak area fraction. These features were used to train an ensemble neural network model incorporating residual connections, batch normalization, and dropout regularization. The model achieved high predictive accuracy (R2 = 0.942, RMSE = 13.896), outperforming previous approaches. Feature importance analysis revealed that surface chemistry had the strongest influence on contact angle prediction, with topographical features also contributing significantly. This work demonstrates the potential of artificial intelligence to model and predict wetting behavior by capturing the complex interplay of surface characteristics, offering a data-driven pathway for designing tailored functional surfaces.

</details>


### [283] [Activation Sensitivity as a Unifying Principle for Post-Training Quantization](https://arxiv.org/abs/2601.11663)
*Bruce Changlong Xu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的PTQ理论框架，通过形式化激活敏感度来理解后训练量化方法，揭示AWQ和GPTQ是该框架下的互补近似。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练量化方法（如AWQ和GPTQ）虽然经验表现良好，但缺乏统一的理论基础，不清楚它们究竟在近似什么底层量。作者希望建立一个概念框架来统一理解这些方法。

Method: 通过一阶泰勒展开，形式化定义激活敏感度——即通道扰动对损失的期望影响。敏感度表现为梯度加权激活的平方范数，提供了捕获激活幅度和下游误差传播的原则性通道重要性度量。

Result: 在该框架下，AWQ和GPTQ被解释为互补的近似方法，分别在特定简化假设下恢复敏感度。作者分析了敏感度度量的设计空间，连接了梯度显著性、Fisher信息和基于Hessian的准则，并阐明了它们与经典剪枝方法的关系。

Conclusion: 本文提供了一个概念性基础，通过敏感度视角来理解和比较后训练量化方法，而不是提出新的量化算法。这为PTQ方法建立了统一的理论框架。

Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.

</details>


### [284] [Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction](https://arxiv.org/abs/2601.11667)
*Xiaojie Xia,Huigang Zhang,Chaoliang Zhong,Jun Sun,Yusuke Oishi*

Main category: cs.LG

TL;DR: 论文提出一种方法，通过块级局部蒸馏将预训练全注意力模型的权重转移到线性注意力模块，并采用贪心层替换策略，在不重新训练的情况下构建任务特定的混合注意力模型。


<details>
  <summary>Details</summary>
Motivation: Transformer的全注意力机制具有二次复杂度，限制了实际部署。线性注意力虽效率高但性能下降。混合模型虽能平衡效率与表达能力，但面临从头训练成本高和手动设计注意力类型布局困难的问题。

Method: 1. 通过块级局部蒸馏将预训练全注意力模块的权重转移到对应的线性注意力模块；2. 采用贪心层替换策略，迭代地将全注意力块替换为线性注意力块，同时监控目标任务的验证性能。

Result: 该方法能在不进行昂贵重新训练或神经架构搜索的情况下，通过单次高效处理为各种下游任务生成任务特定的混合模型，适用于任何预训练的全注意力骨干网络。

Conclusion: 提出的方法解决了混合注意力模型训练成本高和设计困难的问题，实现了效率与性能的良好平衡，能够灵活应用于不同任务和预训练模型。

Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.

</details>


### [285] [IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning](https://arxiv.org/abs/2601.11669)
*Wenwen Liao,Hang Ruan,Jianbo Yu,Xiaofeng Yang,Qingchao Jiang,Xuefeng Yan*

Main category: cs.LG

TL;DR: 提出IPEC方法，在测试时利用历史查询样本来优化原型估计，通过双过滤机制构建动态辅助集，提升小样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于度量的小样本学习方法在测试时假设批次独立，无法利用历史批次积累的宝贵知识，限制了性能提升。

Method: 提出IPEC方法：1）构建动态辅助集，通过双过滤机制（全局预测置信度和局部判别能力）筛选高置信度查询样本；2）将辅助集与支持集聚合以构建更稳定的原型；3）基于贝叶斯解释设计"预热-测试"两阶段推理协议。

Result: 在多个小样本分类任务上的大量实验结果表明，IPEC方法相比现有方法具有优越性能。

Conclusion: IPEC通过测试时利用历史查询样本信息优化原型估计，减少对初始支持集的依赖，有效提升了小样本分类性能，并为该方法提供了贝叶斯理论解释。

Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.

</details>


### [286] [A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning](https://arxiv.org/abs/2601.11670)
*Jinshi Liu,Pan Liu*

Main category: cs.LG

TL;DR: 提出CoVar理论框架，通过结合最大置信度(MC)和残差类方差(RCV)来改进半监督学习中的伪标签选择，避免固定置信度阈值的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统半监督学习中的伪标签选择通常依赖固定的置信度阈值，但深度网络经常存在过度自信问题：高置信度的预测可能错误，而靠近决策边界的低置信度信息样本却被丢弃。

Method: 基于熵最小化原理，推导出结合最大置信度(MC)和残差类方差(RCV)的可靠性度量。将伪标签选择建模为置信度-方差特征空间中的谱松弛问题，设计无阈值选择机制来区分高可靠性和低可靠性预测。

Result: 在PASCAL VOC 2012、Cityscapes、CIFAR-10和Mini-ImageNet数据集上，使用不同标签比例和骨干网络，CoVar作为插件模块持续改进了代表性半监督方法的性能。

Conclusion: 结合置信度和残差类方差比固定置信度阈值提供了更可靠的伪标签选择基础，有效纠正了过度自信但不稳定的预测。

Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: https://github.com/ljs11528/CoVar_Pseudo_Label_Selection.git)

</details>


### [287] [Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis](https://arxiv.org/abs/2601.11686)
*Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes*

Main category: cs.LG

TL;DR: 提出结合预测模型与大语言模型的混合框架，为野火风险管理生成结构化、可操作的报告


<details>
  <summary>Details</summary>
Motivation: 当前野火风险评估方法忽视实际作战需求，缺乏对多个风险维度的综合分析，限制了其在实际应急响应中的实用价值

Method: 开发混合框架：为气象危险、着火活动、干预复杂性、资源动员等多个风险维度分别建立预测模型，然后使用大语言模型将这些异构输出合成为结构化报告

Result: 论文是概念验证研究，尚未提供具体实验结果，但提出了解决当前局限性的创新方法框架

Conclusion: 多目标分析和混合框架能更好地满足应急响应人员的实际需求，提升野火风险管理的操作性和有效性

Abstract: Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.

</details>


### [288] [jBOT: Semantic Jet Representation Clustering Emerges from Self-Distillation](https://arxiv.org/abs/2601.11719)
*Ho Fung Tsoi,Dylan Rankin*

Main category: cs.LG

TL;DR: jBOT是一种基于自蒸馏的预训练方法，专门针对CERN大型强子对撞机的喷注数据，结合局部粒子级和全局喷注级蒸馏，学习支持异常检测和分类等下游任务的喷注表示。


<details>
  <summary>Details</summary>
Motivation: 自监督学习是一种无需标签即可学习特征表示的强大预训练方法，通常能从数据中捕获通用的底层语义，并可微调用于下游任务。本文旨在开发适用于高能物理喷注数据的预训练方法。

Method: jBOT预训练方法基于自蒸馏，结合局部粒子级蒸馏和全局喷注级蒸馏来学习喷注表示。该方法在未标记的喷注上进行预训练，并在冻结的嵌入空间中观察到涌现的语义类别聚类。

Result: 仅使用背景喷注预训练时，冻结嵌入中的聚类能够通过简单的基于距离的指标实现异常检测。学习到的嵌入微调后用于分类，相比从头训练的监督模型性能有所提升。

Conclusion: jBOT方法成功地将自监督学习应用于高能物理喷注数据，通过自蒸馏预训练获得了具有语义聚类特性的表示，支持异常检测和分类任务，且性能优于传统监督方法。

Abstract: Self-supervised learning is a powerful pre-training method for learning feature representations without labels, which often capture generic underlying semantics from the data and can later be fine-tuned for downstream tasks. In this work, we introduce jBOT, a pre-training method based on self-distillation for jet data from the CERN Large Hadron Collider, which combines local particle-level distillation with global jet-level distillation to learn jet representations that support downstream tasks such as anomaly detection and classification. We observe that pre-training on unlabeled jets leads to emergent semantic class clustering in the representation space. The clustering in the frozen embedding, when pre-trained on background jets only, enables anomaly detection via simple distance-based metrics, and the learned embedding can be fine-tuned for classification with improved performance compared to supervised models trained from scratch.

</details>


### [289] [Suspicious Alignment of SGD: A Fine-Grained Step Size Condition Analysis](https://arxiv.org/abs/2601.11789)
*Shenyang Deng,Boyao Liao,Zhuoli Ouyang,Tianyu Pang,Minhak Song,Yaoqing Yang*

Main category: cs.LG

TL;DR: 论文研究了SGD在病态优化中的"可疑对齐"现象，发现梯度与主导子空间的对齐会经历下降、上升、稳定的三阶段变化，且高度对齐时主导子空间更新反而无法有效降低损失。


<details>
  <summary>Details</summary>
Motivation: 研究随机梯度下降在病态优化问题中出现的"可疑对齐"现象，即梯度与Hessian主导子空间的对齐行为及其对优化效果的影响，解释为何高度对齐时主导子空间更新反而无效。

Method: 在高维二次设置中进行精细分析，提出自适应临界步长理论，区分对齐下降和对齐增加的不同步长区间，分析步长选择如何产生可疑对齐现象。

Result: 发现低对齐状态下存在临界步长η_t^*区分对齐行为，高对齐状态下对齐具有自校正特性；证明在充分病态条件下，存在步长区间使批量子空间更新降低损失而主导子空间更新增加损失；证明了恒定步长下SGD会经历初始对齐下降和高对齐稳定的两阶段行为。

Conclusion: 揭示了SGD在病态优化中的可疑对齐现象机制，为步长选择提供了理论指导，解释了为何主导子空间梯度更新在高度对齐时无效，深化了对SGD优化动态的理解。

Abstract: This paper explores the suspicious alignment phenomenon in stochastic gradient descent (SGD) under ill-conditioned optimization, where the Hessian spectrum splits into dominant and bulk subspaces. This phenomenon describes the behavior of gradient alignment in SGD updates. Specifically, during the initial phase of SGD updates, the alignment between the gradient and the dominant subspace tends to decrease. Subsequently, it enters a rising phase and eventually stabilizes in a high-alignment phase. The alignment is considered ``suspicious'' because, paradoxically, the projected gradient update along this highly-aligned dominant subspace proves ineffective at reducing the loss. The focus of this work is to give a fine-grained analysis in a high-dimensional quadratic setup about how step size selection produces this phenomenon. Our main contribution can be summarized as follows: We propose a step-size condition revealing that in low-alignment regimes, an adaptive critical step size $η_t^*$ separates alignment-decreasing ($η_t < η_t^*$) from alignment-increasing ($η_t > η_t^*$) regimes, whereas in high-alignment regimes, the alignment is self-correcting and decreases regardless of the step size. We further show that under sufficient ill-conditioning, a step size interval exists where projecting the SGD updates to the bulk space decreases the loss while projecting them to the dominant space increases the loss, which explains a recent empirical observation that projecting gradient updates to the dominant subspace is ineffective. Finally, based on this adaptive step-size theory, we prove that for a constant step size and large initialization, SGD exhibits this distinct two-phase behavior: an initial alignment-decreasing phase, followed by stabilization at high alignment.

</details>


### [290] [Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing](https://arxiv.org/abs/2601.11794)
*Abdelrahman Ramadan,Zahra Dorbeigi Namaghi,Emily Taylor,Lucas Edwards,Xan Giuliani,David S. McLagan,Sidney Givigi,Melissa Greeff*

Main category: cs.LG

TL;DR: PC²DAE是一种物理约束的降噪自编码器，通过架构设计直接嵌入物理约束来解决无人机野火监测中数据稀缺的传感器降噪问题。


<details>
  <summary>Details</summary>
Motivation: 无人机野火监测需要高分辨率大气测量，但低成本传感器存在基线漂移、交叉敏感性和响应延迟等问题，传统深度学习方法需要大量数据，而无人机飞行活动数据有限。

Method: 开发了PC²DAE物理约束降噪自编码器，通过softplus激活函数强制非负浓度估计，采用物理合理的时间平滑，架构包含针对黑碳、气体和CO₂传感器的分层解码头，提供精简版(21k参数)和宽版(204k参数)两种变体。

Result: 在仅7,894个样本(约2.2小时飞行数据)上评估，PC²DAE-Lean实现了67.3%平滑度提升和90.7%高频噪声减少，零物理违规，训练时间仅65秒，在数据稀缺情况下优于传统方法。

Conclusion: PC²DAE通过架构级物理约束有效解决了数据稀缺下的传感器降噪问题，精简版优于宽版表明在数据稀缺时，强归纳偏置比模型容量更重要，为边缘部署提供了实用解决方案。

Abstract: Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.

</details>


### [291] [Shapelets-Enriched Selective Forecasting using Time Series Foundation Models](https://arxiv.org/abs/2601.11821)
*Shivani Tomar,Seshu Tirupathi,Elizabeth Daly,Ivana Dusparic*

Main category: cs.LG

TL;DR: 提出了一个选择性预测框架，利用shapelets识别时间序列中的关键不可靠区域，允许用户选择性丢弃不可靠预测，降低预测误差。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列基础模型在零样本预测任务中表现出色，但在数据的关键区域预测不可靠，限制了在实际应用中的可用性，特别是在数据具有独特趋势时。

Method: 使用shapelets通过shift-invariant字典学习在目标域验证集上学习关键时间序列模式，基于与这些shapelets的距离相似性来识别不可靠预测区域。

Result: 在多个基准时间序列数据集上，该方法使零样本模型平均减少22.17%的误差，全样本微调模型减少22.62%的误差，显著优于随机选择方法。

Conclusion: 提出的选择性预测框架能够有效识别时间序列预测中的不可靠区域，提高基础模型在实际应用中的可靠性，特别是在数据具有独特趋势时。

Abstract: Time series foundation models have recently gained a lot of attention due to their ability to model complex time series data encompassing different domains including traffic, energy, and weather. Although they exhibit strong average zero-shot performance on forecasting tasks, their predictions on certain critical regions of the data are not always reliable, limiting their usability in real-world applications, especially when data exhibits unique trends. In this paper, we propose a selective forecasting framework to identify these critical segments of time series using shapelets. We learn shapelets using shift-invariant dictionary learning on the validation split of the target domain dataset. Utilizing distance-based similarity to these shapelets, we facilitate the user to selectively discard unreliable predictions and be informed of the model's realistic capabilities. Empirical results on diverse benchmark time series datasets demonstrate that our approach leveraging both zero-shot and full-shot fine-tuned models reduces the overall error by an average of 22.17% for zero-shot and 22.62% for full-shot fine-tuned model. Furthermore, our approach using zero-shot and full-shot fine-tuned models, also outperforms its random selection counterparts by up to 21.41% and 21.43% on one of the datasets.

</details>


### [292] [MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization](https://arxiv.org/abs/2601.11827)
*Andrea Rubbi,Amir Akbarnejad,Mohammad Vali Sanian,Aryan Yazdan Parast,Hesam Asadollahzadeh,Arian Amani,Naveed Akhtar,Sarah Cooper,Andrew Bassett,Pietro Liò,Lassi Paavolainen,Sattar Vakili,Mo Lotfollahi*

Main category: cs.LG

TL;DR: MixFlow是一个用于描述符控制生成的混合流匹配框架，通过联合学习描述符条件的基础分布和流场，显著改善了分布外泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的条件流匹配方法在分布偏移下泛化能力有限，难以在训练条件之外进行外推，这限制了条件生成建模的实际应用。

Method: MixFlow采用最短路径流匹配，联合学习描述符条件的基础分布（建模为可学习的描述符依赖混合分布）和描述符条件的流场，支持平滑插值和未见条件的外推。

Result: MixFlow在多个领域显著优于标准条件流匹配基线，包括单细胞转录组数据中未见扰动的响应预测和高通量显微镜药物筛选任务，展现出卓越的分布外泛化能力。

Conclusion: MixFlow提供了一个简单而强大的方法，用于在异构领域中实现鲁棒、可泛化和可控的生成建模，有效解决了条件生成模型在分布偏移下的泛化挑战。

Abstract: Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.

</details>


### [293] [AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training](https://arxiv.org/abs/2601.11864)
*Zhiyuan Li,Yuan Wu,Yi Chang*

Main category: cs.LG

TL;DR: AGGC是一种自适应分组梯度裁剪方法，通过按功能类型对参数分组并使用EMA历史行为调节每组梯度，解决传统全局裁剪的梯度异质性问题，提升LLM训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统全局梯度裁剪假设所有参数梯度同质，但实际不同功能模块梯度特性不同，导致"溢出效应"——不稳定参数迫使稳定参数过度缩放，影响训练稳定性。

Method: AGGC将参数按功能类型分组，每组使用EMA跟踪历史梯度行为，构建自适应区间同时缓解梯度爆炸和消失问题，采用时间相关调度机制平衡探索与收敛。

Result: 在LLaMA 2-7B、Mistral-7B、Gemma-7B等模型上，AGGC一致优于LoRA，经常超越全微调。GSM8K基准测试中，Mistral-7B+AGGC达到72.93%准确率，优于LoRA的69.5%。在RLVR任务中也能稳定训练Qwen 2.5和Llama 3.2模型。

Conclusion: AGGC通过模块化自适应裁剪策略有效解决传统梯度裁剪的局限性，特别是梯度异质性问题，轻量级设计可无缝集成到现有训练流程中，显著提升LLM训练稳定性。

Abstract: To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.

</details>


### [294] [TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures](https://arxiv.org/abs/2601.11880)
*Yingxiao Zhang,Jiaxin Duan,Junfu Zhang,Ke Feng*

Main category: cs.LG

TL;DR: TF-CoDiT是首个针对国债期货数据的语言控制扩散Transformer框架，通过离散小波变换和U型VAE处理低数据量学习，使用FinMAP协议标准化市场条件描述，在国债期货合成任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有扩散Transformer在股票价格和订单流等金融时序数据合成上已有成就，但在国债期货数据合成方面研究不足。国债期货数据具有低交易量、市场依赖性强、多变量间存在分组相关性等特点，需要专门的方法来处理这些挑战。

Method: 提出TF-CoDiT框架：1）将多通道一维时间序列转换为离散小波变换系数矩阵以应对低数据量学习；2）设计U型VAE分层编码跨通道依赖到潜变量，并通过解码连接潜空间和DWT空间，实现潜扩散生成；3）引入金融市场属性协议FinMAP，从7/8个视角识别17/23个经济指标，标准化每日/周期性市场动态描述。

Result: 在2015-2025年四种国债期货数据上进行了实验，定义了从一周到四个月不同持续时间的合成任务。TF-CoDiT能生成高度真实的数据，与真实数据的误差最多为MSE 0.433和MAE 0.453。进一步研究证明了TF-CoDiT在不同合约和时间跨度上的鲁棒性。

Conclusion: TF-CoDiT是首个专门针对国债期货数据合成的语言控制扩散Transformer框架，通过结合小波变换、分层VAE编码和标准化市场描述协议，有效解决了国债期货数据的低数据量、市场依赖和分组相关性等挑战，为金融数据合成提供了新的解决方案。

Abstract: Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.

</details>


### [295] [Approximation Algorithm for Constrained $k$-Center Clustering: A Local Search Approach](https://arxiv.org/abs/2601.11883)
*Chaoqi Jia,Longkun Guo,Kewen Liao,Zhigang Lu,Chao Chen,Jason Xue*

Main category: cs.LG

TL;DR: 提出基于支配匹配集变换的局部搜索框架，解决带约束的k中心聚类问题，获得最佳可能近似比2


<details>
  <summary>Details</summary>
Motivation: 传统k中心问题的最佳近似比为2，但带约束的k中心聚类（包含不能链接和必须链接约束）在理论上更具挑战性。尽管不相交的不能链接集允许常数因子近似，但局部搜索是否能达到这种保证仍是一个开放问题。

Method: 提出新颖的局部搜索框架，通过将约束k中心问题转化为支配匹配集问题，设计算法实现最佳近似比

Result: 实现了理论上的最佳可能近似比2，在真实世界和合成数据集上的实验结果表明，算法在解质量上优于基线方法

Conclusion: 通过将约束k中心问题转化为支配匹配集问题，提出的局部搜索框架成功解决了该问题的开放性问题，获得了理论上的最佳近似比，并在实践中表现出优越性能

Abstract: Clustering is a long-standing research problem and a fundamental tool in AI and data analysis. The traditional k-center problem, a fundamental theoretical challenge in clustering, has a best possible approximation ratio of 2, and any improvement to a ratio of 2 - ε would imply P = NP. In this work, we study the constrained k-center clustering problem, where instance-level cannot-link (CL) and must-link (ML) constraints are incorporated as background knowledge. Although general CL constraints significantly increase the hardness of approximation, previous work has shown that disjoint CL sets permit constant-factor approximations. However, whether local search can achieve such a guarantee in this setting remains an open question. To this end, we propose a novel local search framework based on a transformation to a dominating matching set problem, achieving the best possible approximation ratio of 2. The experimental results on both real-world and synthetic datasets demonstrate that our algorithm outperforms baselines in solution quality.

</details>


### [296] [From Relative Entropy to Minimax: A Unified Framework for Coverage in MDPs](https://arxiv.org/abs/2601.11890)
*Xihe Gu,Urbashi Mitra,Tara Javidi*

Main category: cs.LG

TL;DR: 提出基于加权参数化凹覆盖目标U_ρ的主动探索框架，统一多种覆盖目标，通过梯度算法引导状态-动作对探索


<details>
  <summary>Details</summary>
Motivation: 在无奖励MDP中，不同状态-动作对具有不同重要性和难度，需要主动构建明确的探索策略来优先考虑未充分探索的状态-动作对

Method: 提出加权参数化凹覆盖目标U_ρ家族，定义于状态-动作占用度量上，统一了多种覆盖目标；利用U_ρ的凹性和梯度闭式解开发梯度算法，主动引导占用分布朝向期望覆盖模式

Result: 随着ρ增加，探索策略越来越强调最少探索的状态-动作对，在极限情况下恢复最坏情况覆盖行为；算法能有效平衡探索覆盖

Conclusion: U_ρ框架为无奖励MDP中的主动探索提供了统一的理论和算法基础，通过参数ρ灵活控制探索策略的激进程度

Abstract: Targeted and deliberate exploration of state--action pairs is essential in reward-free Markov Decision Problems (MDPs). More precisely, different state-action pairs exhibit different degree of importance or difficulty which must be actively and explicitly built into a controlled exploration strategy. To this end, we propose a weighted and parameterized family of concave coverage objectives, denoted by $U_ρ$, defined directly over state--action occupancy measures. This family unifies several widely studied objectives within a single framework, including divergence-based marginal matching, weighted average coverage, and worst-case (minimax) coverage. While the concavity of $U_ρ$ captures the diminishing return associated with over-exploration, the simple closed form of the gradient of $U_ρ$ enables an explicit control to prioritize under-explored state--action pairs. Leveraging this structure, we develop a gradient-based algorithm that actively steers the induced occupancy toward a desired coverage pattern. Moreover, we show that as $ρ$ increases, the resulting exploration strategy increasingly emphasizes the least-explored state--action pairs, recovering worst-case coverage behavior in the limit.

</details>


### [297] [DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models](https://arxiv.org/abs/2601.11895)
*Pareesa Ameneh Golnari,Adarsh Kumarappan,Wen Wen,Xiaoyu Liu,Gabriel Ryan,Yuting Sun,Shengyu Fu,Elsie Nallipogu*

Main category: cs.LG

TL;DR: DevBench是一个基于真实开发遥测数据的代码补全基准测试，包含6种编程语言和6类任务，共1800个评估实例，旨在评估LLM在真实代码补全场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有代码补全基准测试缺乏生态效度，容易受到训练数据污染，且无法提供详细的诊断信息。DevBench旨在解决这些问题，提供更贴近实际开发场景的评估框架。

Method: 基于真实开发者遥测数据构建评估实例，结合功能正确性、相似性指标和LLM评估者（关注实用性和上下文相关性）进行多维度评估。避免训练数据污染，确保生态效度。

Result: 评估了9个最先进的模型，揭示了它们在语法精度、语义推理和实际效用方面的差异。提供了可操作的见解来指导模型选择和改进。

Conclusion: DevBench填补了现有基准测试的空白，为实际部署和针对性模型开发提供了必要的详细诊断信息，对LLM在代码补全领域的评估具有重要价值。

Abstract: DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.

</details>


### [298] [Task-tailored Pre-processing: Fair Downstream Supervised Learning](https://arxiv.org/abs/2601.11897)
*Jinwon Sohn,Guang Lin,Qifan Song*

Main category: cs.LG

TL;DR: 提出针对监督学习的公平性预处理新框架，通过HGR相关性分析传统数据公平方法的过强正则化问题，在保证公平性改进和效用保持之间取得平衡，并提供下游模型的理论保证。


<details>
  <summary>Details</summary>
Motivation: 现有公平监督学习预处理方法分为两类：数据公平（独立于下游模型）和任务定制公平（考虑监督学习任务）。作者认为数据公平方法从HGR相关性角度看施加了过强的正则化，因此需要开发更适合监督学习的新预处理方法。

Method: 提出针对监督学习的预处理框架，在获得预处理映射时权衡公平性和效用。研究在变换数据上学习的任意下游监督模型，找到保证其公平性改进和效用保持的充分条件。

Result: 在表格和图像数据集上的比较研究表明，该框架在多个下游模型中保持一致的权衡，优于现有竞争模型。对于计算机视觉数据，该方法仅改变与中心机器学习任务相关的必要语义特征来实现公平性。

Conclusion: 本文提出了一种针对监督学习的公平性预处理新方法，通过理论分析证明了其在改善下游模型公平性和保持效用方面的优势，为任务定制公平方法提供了首个下游保证的理论研究。

Abstract: Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.

</details>


### [299] [Communication-Corruption Coupling and Verification in Cooperative Multi-Objective Bandits](https://arxiv.org/abs/2601.11924)
*Ming Shi*

Main category: cs.LG

TL;DR: 该论文研究在对抗性腐败和有限验证下的合作随机多臂老虎机问题，揭示了通信协议如何影响腐败放大效应，并提出基于验证的学习策略。


<details>
  <summary>Details</summary>
Motivation: 在多智能体协作学习中，对抗性腐败会破坏反馈信号，而不同的通信协议（共享原始样本、统计摘要或推荐）可能放大腐败效应。需要理解通信与腐败的耦合关系，并设计能在腐败环境下有效学习的策略。

Method: 提出通信-腐败耦合框架，通过协议诱导的多重性功能量化腐败放大效应。分析三种通信协议：原始样本共享、统计摘要共享和仅推荐共享。建立信息理论界限，并研究验证观测如何恢复可学习性。

Result: 发现固定腐败预算Γ在不同通信协议下会产生从Γ到NΓ的有效腐败水平。原始样本共享可能遭受N倍放大，而摘要和推荐共享保持O(Γ)项。在Γ=Θ(NT)的高腐败区域，没有干净信息则无法实现次线性遗憾。验证观测能恢复可学习性，通过认证共享可使团队遗憾独立于Γ。

Conclusion: 通信协议显著影响对抗性腐败下的学习性能。设计通信策略时需考虑腐败放大效应，验证机制对高腐败环境至关重要。认证共享结合有限验证可实现近似集中式性能，为腐败环境下的多智能体协作学习提供理论指导。

Abstract: We study cooperative stochastic multi-armed bandits with vector-valued rewards under adversarial corruption and limited verification. In each of $T$ rounds, each of $N$ agents selects an arm, the environment generates a clean reward vector, and an adversary perturbs the observed feedback subject to a global corruption budget $Γ$. Performance is measured by team regret under a coordinate-wise nondecreasing, $L$-Lipschitz scalarization $φ$, covering linear, Chebyshev, and smooth monotone utilities. Our main contribution is a communication-corruption coupling: we show that a fixed environment-side budget $Γ$ can translate into an effective corruption level ranging from $Γ$ to $NΓ$, depending on whether agents share raw samples, sufficient statistics, or only arm recommendations. We formalize this via a protocol-induced multiplicity functional and prove regret bounds parameterized by the resulting effective corruption. As corollaries, raw-sample sharing can suffer an $N$-fold larger additive corruption penalty, whereas summary sharing and recommendation-only sharing preserve an unamplified $O(Γ)$ term and achieve centralized-rate team regret. We further establish information-theoretic limits, including an unavoidable additive $Ω(Γ)$ penalty and a high-corruption regime $Γ=Θ(NT)$ where sublinear regret is impossible without clean information. Finally, we characterize how a global budget $ν$ of verified observations restores learnability. That is, verification is necessary in the high-corruption regime, and sufficient once it crosses the identification threshold, with certified sharing enabling the team's regret to become independent of $Γ$.

</details>


### [300] [Trainability-Oriented Hybrid Quantum Regression via Geometric Preconditioning and Curriculum Optimization](https://arxiv.org/abs/2601.11942)
*Qingyu Meng,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出一种混合量子-经典回归框架，通过可学习的几何预处理器和课程优化协议改善量子神经网络的训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 量子神经网络在回归任务中常面临梯度噪声和优化条件差的问题，限制了其在实际应用中的可训练性和性能。

Method: 1. 设计混合量子-经典架构：在变分量子电路前加入轻量级经典嵌入层作为可学习的几何预处理器；2. 引入课程优化协议：逐步增加电路深度，从SPSA随机探索过渡到Adam梯度微调。

Result: 在PDE回归基准和标准回归数据集上，该框架在固定训练预算下优于纯QNN基线，收敛更稳定，在数据有限情况下表现更好，减少了与振荡分量相关的结构化误差。

Conclusion: 几何预处理结合课程训练是稳定量子回归的实用方法，能有效缓解量子神经网络在回归任务中的训练瓶颈。

Abstract: Quantum neural networks (QNNs) have attracted growing interest for scientific machine learning, yet in regression settings they often suffer from limited trainability under noisy gradients and ill-conditioned optimization. We propose a hybrid quantum-classical regression framework designed to mitigate these bottlenecks. Our model prepends a lightweight classical embedding that acts as a learnable geometric preconditioner, reshaping the input representation to better condition a downstream variational quantum circuit. Building on this architecture, we introduce a curriculum optimization protocol that progressively increases circuit depth and transitions from SPSA-based stochastic exploration to Adam-based gradient fine-tuning. We evaluate the approach on PDE-informed regression benchmarks and standard regression datasets under a fixed training budget in a simulator setting. Empirically, the proposed framework consistently improves over pure QNN baselines and yields more stable convergence in data-limited regimes. We further observe reduced structured errors that are visually correlated with oscillatory components on several scientific benchmarks, suggesting that geometric preconditioning combined with curriculum training is a practical approach for stabilizing quantum regression.

</details>


### [301] [Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration](https://arxiv.org/abs/2601.11953)
*Shiqing Gao,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 本文针对约束强化学习训练过程中约束违反严重的问题，提出MICE方法，通过引入内在成本估计来缓解成本价值函数低估，实现更安全的探索。


<details>
  <summary>Details</summary>
Motivation: 现有约束强化学习算法在训练过程中经常出现严重的约束违反，限制了其在安全关键场景中的应用。作者发现成本价值函数的低估是导致这些违反的关键因素。

Method: 提出记忆驱动的内在成本估计（MICE）方法：1）构建记忆模块存储先前探索的不安全状态以识别高风险区域；2）将内在成本定义为当前状态访问这些风险区域的伪计数；3）提出外在-内在成本价值函数，结合内在成本并采用偏差校正策略；4）在信任区域内制定优化目标及相应优化方法。

Result: 理论上为提出的成本价值函数提供收敛保证，并建立MICE更新的最坏情况约束违反界限。实验表明MICE显著减少了约束违反，同时保持与基线相当的策略性能。

Conclusion: MICE方法通过引入内在成本估计有效缓解了成本价值函数的低估问题，实现了更安全的探索，在约束强化学习中显著减少了训练过程中的约束违反。

Abstract: Constrained Reinforcement Learning (CRL) aims to maximize cumulative rewards while satisfying constraints. However, existing CRL algorithms often encounter significant constraint violations during training, limiting their applicability in safety-critical scenarios. In this paper, we identify the underestimation of the cost value function as a key factor contributing to these violations. To address this issue, we propose the Memory-driven Intrinsic Cost Estimation (MICE) method, which introduces intrinsic costs to mitigate underestimation and control bias to promote safer exploration. Inspired by flashbulb memory, where humans vividly recall dangerous experiences to avoid risks, MICE constructs a memory module that stores previously explored unsafe states to identify high-cost regions. The intrinsic cost is formulated as the pseudo-count of the current state visiting these risk regions. Furthermore, we propose an extrinsic-intrinsic cost value function that incorporates intrinsic costs and adopts a bias correction strategy. Using this function, we formulate an optimization objective within the trust region, along with corresponding optimization methods. Theoretically, we provide convergence guarantees for the proposed cost value function and establish the worst-case constraint violation for the MICE update. Extensive experiments demonstrate that MICE significantly reduces constraint violations while preserving policy performance comparable to baselines.

</details>


### [302] [Data-centric Prompt Tuning for Dynamic Graphs](https://arxiv.org/abs/2601.11954)
*Yufei Peng,Cheng Yang,Zhengjie Fan,Chuan Shi*

Main category: cs.LG

TL;DR: DDGPrompt是一个数据中心的提示框架，通过定义统一的节点表达特征矩阵和引入三个提示矩阵（时间偏置、边权重和特征掩码），在输入数据层面优化预训练节点嵌入，以提升动态图模型在下游任务中的适应性。


<details>
  <summary>Details</summary>
Motivation: 动态图建模复杂现实关系，但传统方法直接将预训练的节点时间嵌入应用于下游任务，由于任务差异大导致性能下降，尤其在少样本设置下。现有提示方法常与特定模型架构或预训练任务强耦合，难以适应新模型设计，且仅关注节点或时间特征而忽略空间结构信息，导致表达能力有限。

Method: 提出数据中心的提示框架DDGPrompt：1) 定义统一的节点表达特征矩阵，聚合节点的所有相关时间和结构信息，兼容多种动态图模型；2) 引入三个提示矩阵（时间偏置、边权重、特征掩码）来全面调整特征矩阵，实现节点嵌入的任务特定适应。

Result: 在四个公共动态图数据集上，在严格的少样本设置下评估DDGPrompt。实验结果表明，在标签有限和冷启动条件下，该方法显著优于传统方法和现有提示方法。

Conclusion: DDGPrompt通过数据中心的提示框架，有效解决了动态图模型在下游任务中的适应性问题，特别是在少样本和冷启动场景下，通过统一特征矩阵和多重提示机制实现了更好的任务特定适应。

Abstract: Dynamic graphs have attracted increasing attention due to their ability to model complex and evolving relationships in real-world scenarios. Traditional approaches typically pre-train models using dynamic link prediction and directly apply the resulting node temporal embeddings to specific downstream tasks. However, the significant differences among downstream tasks often lead to performance degradation, especially under few-shot settings. Prompt tuning has emerged as an effective solution to this problem. Existing prompting methods are often strongly coupled with specific model architectures or pretraining tasks, which makes it difficult to adapt to recent or future model designs. Moreover, their exclusive focus on modifying node or temporal features while neglecting spatial structural information leads to limited expressiveness and degraded performance. To address these limitations, we propose DDGPrompt, a data-centric prompting framework designed to effectively refine pre-trained node embeddings at the input data level, enabling better adaptability to diverse downstream tasks. We first define a unified node expression feature matrix that aggregates all relevant temporal and structural information of each node, ensuring compatibility with a wide range of dynamic graph models. Then, we introduce three prompt matrices (temporal bias, edge weight, and feature mask) to adjust the feature matrix completely, achieving task-specific adaptation of node embeddings. We evaluate DDGPrompt under a strict few-shot setting on four public dynamic graph datasets. Experimental results demonstrate that our method significantly outperforms traditional methods and prompting approaches in scenarios with limited labels and cold-start conditions.

</details>


### [303] [R$^2$PO: Decoupling Training Trajectories from Inference Responses for LLM Reasoning](https://arxiv.org/abs/2601.11960)
*Jingchu Wang,Bingbing Xu,Yige Yuan,Bin Xie,Xiaoqian Sun,Huawei Shen*

Main category: cs.LG

TL;DR: R²PO通过引入轻量级残差rollout头来解耦训练轨迹和推理响应，解决传统RL方法中单一策略在推理稳定性和训练多样性之间的矛盾，提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法使用单一策略同时生成推理响应和训练优化轨迹，导致推理响应稳定性与训练轨迹多样性之间存在目标冲突，这种冲突导致探索不足，从而损害推理能力。

Method: 提出R²PO（残差Rollout策略优化），在策略顶部引入轻量级残差Rollout头，将训练轨迹与推理响应解耦，在训练期间实现可控的轨迹多样化，同时保持推理生成的稳定性。

Result: 在多个基准测试中，该方法一致优于基线，在MATH-500上平均准确率提升3.1%，在APPS上提升2.4%，同时减少格式错误并缓解长度偏差以实现稳定优化。

Conclusion: R²PO通过解耦训练轨迹和推理响应，有效解决了强化学习在LLM推理中的探索与利用平衡问题，显著提升了推理性能并实现了更稳定的优化。

Abstract: Reinforcement learning has become a central paradigm for improving LLM reasoning. However, existing methods use a single policy to produce both inference responses and training optimization trajectories. The objective conflict between generating stable inference responses and diverse training trajectories leads to insufficient exploration, which harms reasoning capability. In this paper, to address the problem, we propose R$^2$PO (Residual Rollout Policy Optimization), which introduces a lightweight Residual Rollout-Head atop the policy to decouple training trajectories from inference responses, enabling controlled trajectory diversification during training while keeping inference generation stable. Experiments across multiple benchmarks show that our method consistently outperforms baselines, achieving average accuracy gains of 3.1% on MATH-500 and 2.4% on APPS, while also reducing formatting errors and mitigating length bias for stable optimization. Our code is publicly available at https://github.com/RRPO-ARR/Code.

</details>


### [304] [One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints](https://arxiv.org/abs/2601.11977)
*Ren He,Yinliang Xu,Jinfeng Wang,Jeremy Watson,Jian Song*

Main category: cs.LG

TL;DR: 提出MoE-Encoder模块，通过稀疏专家混合层增强预训练时间序列模型，解决电力系统多变量预测的复杂依赖和隐私约束问题


<details>
  <summary>Details</summary>
Motivation: 电力系统预测面临多变量时间序列复杂依赖、区域间隐私约束严格、传统方法需要大量专家知识且难以泛化、预训练模型零样本性能有限等挑战

Method: 在预训练预测模型的tokenization和encoding之间注入稀疏专家混合层，将多变量预测转化为专家引导的单变量任务，支持联邦学习中的本地训练和轻量参数共享

Result: 在公共多变量数据集上显著提升预测精度；联邦环境模拟显示仅传输MoE-Encoder参数即可高效适应新区域，性能下降最小

Conclusion: MoE-Encoder为时间序列基础模型提供了可扩展且隐私感知的扩展方案

Abstract: Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.

</details>


### [305] [Extreme Value Policy Optimization for Safe Reinforcement Learning](https://arxiv.org/abs/2601.12008)
*Shiqing Gao,Yihang Zhou,Shuai Shao,Haoyu Luo,Yiheng Bing,Jiaxin Ding,Luoyi Fu,Xinbing Wang*

Main category: cs.LG

TL;DR: 提出EVO算法，利用极值理论处理强化学习中的罕见高成本事件，显著降低约束违反率


<details>
  <summary>Details</summary>
Motivation: 传统约束强化学习使用期望约束，忽略了尾部分布中的罕见但高影响的极值事件（黑天鹅事件），可能导致严重的约束违反

Method: 提出EVO算法：1）使用极值理论建模和利用极端奖励和成本样本；2）引入极端分位数优化目标捕获成本尾部分布；3）提出极端优先重放机制增强罕见样本的学习信号

Result: 理论证明：建立了策略更新期间预期约束违反的上界，保证在零违反分位数水平的严格约束满足；实验证明：相比期望方法约束违反概率更低，比分位数回归方法方差更小，在训练期间显著减少约束违反同时保持竞争力

Conclusion: EVO算法有效解决了传统约束强化学习忽略极端事件的问题，通过极值理论方法显著提高了安全性，在现实应用中具有重要价值

Abstract: Ensuring safety is a critical challenge in applying Reinforcement Learning (RL) to real-world scenarios. Constrained Reinforcement Learning (CRL) addresses this by maximizing returns under predefined constraints, typically formulated as the expected cumulative cost. However, expectation-based constraints overlook rare but high-impact extreme value events in the tail distribution, such as black swan incidents, which can lead to severe constraint violations. To address this issue, we propose the Extreme Value policy Optimization (EVO) algorithm, leveraging Extreme Value Theory (EVT) to model and exploit extreme reward and cost samples, reducing constraint violations. EVO introduces an extreme quantile optimization objective to explicitly capture extreme samples in the cost tail distribution. Additionally, we propose an extreme prioritization mechanism during replay, amplifying the learning signal from rare but high-impact extreme samples. Theoretically, we establish upper bounds on expected constraint violations during policy updates, guaranteeing strict constraint satisfaction at a zero-violation quantile level. Further, we demonstrate that EVO achieves a lower probability of constraint violations than expectation-based methods and exhibits lower variance than quantile regression methods. Extensive experiments show that EVO significantly reduces constraint violations during training while maintaining competitive policy performance compared to baselines.

</details>


### [306] [Why Loss Re-weighting Works If You Stop Early: Training Dynamics of Unconstrained Features](https://arxiv.org/abs/2601.12011)
*Yize Zhao,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: 损失重加权在过参数化深度神经网络中无法改变最终学习阶段，但在训练早期能显著改善少数类学习，小规模模型揭示了这一现象。


<details>
  <summary>Details</summary>
Motivation: 尽管损失重加权在过参数化深度神经网络中无法改变最终学习结果，但经验证据表明它在训练早期对少数类学习有显著帮助。本文旨在通过设计简化模型来透明地展示和分析这一现象。

Method: 引入小规模模型（SSM），该模型抽象了深度神经网络架构和输入数据的复杂性，同时保留了类别不平衡的光谱结构信息。通过该模型分析标准经验风险最小化和损失重加权在学习动态上的差异。

Result: 小规模模型显示，标准经验风险最小化在训练早期优先学习多数类特征，从而延迟了少数类学习。相比之下，损失重加权恢复了平衡的学习动态，使得多数类和少数类特征能够同时学习。

Conclusion: 损失重加权在训练早期对改善少数类学习具有重要价值，特别是在处理类别不平衡问题时。小规模模型为理解这一现象提供了透明分析框架，揭示了重加权如何促进平衡学习动态。

Abstract: The application of loss reweighting in modern deep learning presents a nuanced picture. While it fails to alter the terminal learning phase in overparameterized deep neural networks (DNNs) trained on high-dimensional datasets, empirical evidence consistently shows it offers significant benefits early in training. To transparently demonstrate and analyze this phenomenon, we introduce a small-scale model (SSM). This model is specifically designed to abstract the inherent complexities of both the DNN architecture and the input data, while maintaining key information about the structure of imbalance within its spectral components. On the one hand, the SSM reveals how vanilla empirical risk minimization preferentially learns to distinguish majority classes over minorities early in training, consequently delaying minority learning. In stark contrast, reweighting restores balanced learning dynamics, enabling the simultaneous learning of features associated with both majorities and minorities.

</details>


### [307] [Learning to Factorize and Adapt: A Versatile Approach Toward Universal Spatio-Temporal Foundation Models](https://arxiv.org/abs/2601.12083)
*Siru Zhong,Junjie Qiu,Yangyu Wu,Yiqiu Liu,Yuanpeng He,Zhongwen Rao,Bin Yang,Chenjuan Guo,Hao Xu,Yuxuan Liang*

Main category: cs.LG

TL;DR: FactoST-v2 是一个增强的分解时空基础模型框架，通过分离通用时间学习和领域特定空间适应，实现全权重迁移和任意长度泛化，在零样本和少样本场景中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有时空基础模型的联合预训练计算成本高，且难以处理领域特定空间模式的异质性，需要更实用、可扩展的解决方案。

Method: 采用两阶段分解框架：第一阶段使用随机序列掩码预训练简约编码器主干，捕捉不变时间动态；第二阶段通过元自适应学习和提示，使用轻量适配器快速注入空间感知。

Result: FactoST-v2 在多个领域评估中达到最先进精度，线性效率显著优于现有基础模型，在零样本和少样本场景中表现优异，媲美领域特定专家基线。

Conclusion: 这种分解范式为真正通用的时空基础模型提供了实用、可扩展的路径，平衡了计算效率与跨领域泛化能力。

Abstract: Spatio-Temporal (ST) Foundation Models (STFMs) promise cross-dataset generalization, yet joint ST pretraining is computationally expensive and grapples with the heterogeneity of domain-specific spatial patterns. Substantially extending our preliminary conference version, we present FactoST-v2, an enhanced factorized framework redesigned for full weight transfer and arbitrary-length generalization. FactoST-v2 decouples universal temporal learning from domain-specific spatial adaptation. The first stage pretrains a minimalist encoder-only backbone using randomized sequence masking to capture invariant temporal dynamics, enabling probabilistic quantile prediction across variable horizons. The second stage employs a streamlined adapter to rapidly inject spatial awareness via meta adaptive learning and prompting. Comprehensive evaluations across diverse domains demonstrate that FactoST-v2 achieves state-of-the-art accuracy with linear efficiency - significantly outperforming existing foundation models in zero-shot and few-shot scenarios while rivaling domain-specific expert baselines. This factorized paradigm offers a practical, scalable path toward truly universal STFMs. Code is available at https://github.com/CityMind-Lab/FactoST.

</details>


### [308] [Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate](https://arxiv.org/abs/2601.12091)
*Qian Tan,Lei Jiang,Yuting Zeng,Shuoyang Ding,Xiaohua Xu*

Main category: cs.LG

TL;DR: 该研究揭示了大型语言模型存在系统性西方中心偏见，发现中文提示仅将偏见转向东亚视角而非消除偏见，并提出了多智能体文化辩论框架来缓解这种偏见。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要不足：评估方法强制将输出归入预定义的文化类别且缺乏中性选项；缓解方法依赖昂贵的多文化语料库或缺乏明确文化表征的智能体框架。需要更严谨的评估和有效的缓解方法来研究非西方语言提示是否能减轻LLM的西方中心偏见。

Method: 提出了CEBiasBench中英双语基准和多智能体投票框架，支持明确的"无偏见"判断。为解决持续存在的偏见，提出了多智能体文化辩论框架，为智能体分配不同的文化角色，并通过"求同存异"策略组织辩论。

Result: 研究发现中文提示仅将偏见转向东亚视角而非消除偏见。多智能体文化辩论框架在CEBiasBench上实现了57.6%的平均无偏见率，在阿拉伯语CAMeL基准上表现出良好的泛化能力。

Conclusion: 智能体框架中明确的文化表征对于跨文化公平至关重要，多智能体文化辩论框架是有效的训练免费偏见缓解方法。

Abstract: Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.

</details>


### [309] [PTL-PINNs: Perturbation-Guided Transfer Learning with Physics- Informed Neural Networks for Nonlinear Systems](https://arxiv.org/abs/2601.12093)
*Duarte Alexandrino,Ben Moseley,Pavlos Protopapas*

Main category: cs.LG

TL;DR: 提出了PTL-PINN框架，将微扰理论与迁移学习结合，通过求解近似线性微扰系统来高效解决非线性微分方程，比传统PINNs训练更快，计算速度比龙格-库塔方法快一个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统物理信息神经网络（PINNs）在建模非线性动力学时存在局限性：泛化能力有限且训练时间长。需要一种能高效解决非线性微分方程的新方法。

Method: 提出了PTL-PINN框架，结合微扰理论和迁移学习。通过求解近似线性微扰系统，使用闭式表达式，实现快速泛化，时间复杂度为矩阵向量乘法级别。

Result: PTL-PINNs在精度上与多种龙格-库塔方法相当，计算速度比传统方法快一个数量级。成功解决了非线性振荡器、Lotka-Volterra系统、KPP-Fisher方程和波动方程等多种问题。

Conclusion: 该工作将长期存在的微扰方法与PINNs联系起来，展示了微扰理论如何指导基础模型以接近经典求解器的速度解决非线性系统。

Abstract: Accurately and efficiently solving nonlinear differential equations is crucial for modeling dynamic behavior across science and engineering. Physics-Informed Neural Networks (PINNs) have emerged as a powerful solution that embeds physical laws in training by enforcing equation residuals. However, these struggle to model nonlinear dynamics, suffering from limited generalization across problems and long training times. To address these limitations, we propose a perturbation-guided transfer learning framework for PINNs (PTL-PINN), which integrates perturbation theory with transfer learning to efficiently solve nonlinear equations. Unlike gradient-based transfer learning, PTL-PINNs solve an approximate linear perturbative system using closed-form expressions, enabling rapid generalization with the time complexity of matrix-vector multiplication. We show that PTL-PINNs achieve accuracy comparable to various Runge-Kutta methods, with computational speeds up to one order of magnitude faster. To benchmark performance, we solve a broad set of problems, including nonlinear oscillators across various damping regimes, the equilibrium-centered Lotka-Volterra system, the KPP-Fisher and the Wave equation. Since perturbation theory sets the accuracy bound of PTL-PINNs, we systematically evaluate its practical applicability. This work connects long-standing perturbation methods with PINNs, demonstrating how perturbation theory can guide foundational models to solve nonlinear systems with speeds comparable to those of classical solvers.

</details>


### [310] [Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding](https://arxiv.org/abs/2601.12095)
*Hamidreza Sadeghi,Saeedeh Momtazi,Reza Safabakhsh*

Main category: cs.LG

TL;DR: 提出固定长度的数字嵌入向量，保留有理数域中的代数运算性质，以解决神经网络处理极小数和极大数时的数值不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 神经网络在处理极小数和极大数时面临溢出、下溢和输出不稳定等挑战，需要一种能保留代数性质同时避免数值不稳定的数字表示方法。

Method: 提出神经同构场（Neural Isomorphic Field）作为代数结构的神经抽象，使用固定长度的嵌入向量表示数字，这些向量能够保持加法、乘法和比较等代数运算的性质。

Result: 加法运算表现优异，在恒等性、封闭性和结合性等关键代数测试中准确率超过95%；乘法运算面临挑战，在不同代数性质上的准确率在53%到73%之间。

Conclusion: 该方法在保持加法运算的代数性质方面效果显著，但在乘法运算方面仍需改进，为数字嵌入在神经网络中的应用提供了有前景的方向。

Abstract: Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.

</details>


### [311] [SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data](https://arxiv.org/abs/2601.12124)
*Bing Hu,Yixin Li,Asma Bahamyirou,Helen Chen*

Main category: cs.LG

TL;DR: SynQP是一个用于合成数据隐私评估的开放框架，使用模拟敏感数据来评估隐私风险，并提出了新的身份披露风险度量方法。


<details>
  <summary>Details</summary>
Motivation: 健康应用中合成数据的使用引发隐私担忧，但由于缺乏开放的隐私评估框架和可访问的基准数据集，其采用受到阻碍。

Method: 引入SynQP框架，使用模拟敏感数据进行隐私评估，确保原始数据保密性。框架包含新的身份披露风险度量方法，更准确地评估机器学习模型的概率特性。

Result: 非私有模型在机器学习效能上达到接近完美水平（≥0.97）。隐私评估显示差分隐私（DP）持续降低身份披露风险和成员推理攻击风险，所有DP增强模型均低于0.09的监管阈值。

Conclusion: SynQP为改进隐私评估的透明度和可靠性提供了关键工具，使得合成数据在健康相关应用中的使用更加安全。

Abstract: The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at https://github.com/CAN-SYNH/SynQP

</details>


### [312] [SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics](https://arxiv.org/abs/2601.12131)
*Santosh Chapagain,MohammadReza EskandariNasab,Onur Vural,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi*

Main category: cs.LG

TL;DR: SolarGPT-QA是基于LLaMA-3的领域自适应大语言模型问答系统，专门用于空间天气和太阳物理教育，通过科学文献和GPT-4生成的大规模问答数据进行训练，在零样本设置下优于通用模型，并在教育解释方面与指令调优模型竞争。


<details>
  <summary>Details</summary>
Motivation: 太阳活动对卫星、航空、电网等关键基础设施有重大影响，极端事件可能造成巨大经济损失。虽然大语言模型在通用任务上表现良好，但缺乏领域专业知识和教学能力来清晰解释复杂的空间科学概念。

Method: 基于LLaMA-3基础模型构建领域自适应大语言模型SolarGPT-QA。使用科学文献和GPT-4生成的大规模问答数据进行训练，并通过Grok-3以学生友好的故事化风格进行精炼。结合领域自适应预训练和教学微调。

Result: 人类成对评估显示，SolarGPT-QA在零样本设置下优于通用模型，在教育解释方面与指令调优模型竞争相当。小型试点学生理解研究表明生成的解释清晰度和可访问性有所改善。消融实验表明结合领域自适应预训练和教学微调对平衡科学准确性和教育效果很重要。

Conclusion: 这项工作代表了向更广泛的SolarGPT框架迈出的初步步骤，该框架旨在用于空间科学教育和预测。领域自适应与教学微调的结合对于创建有效的教育工具至关重要。

Abstract: Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts.
  We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.

</details>


### [313] [EMoE: Eigenbasis-Guided Routing for Mixture-of-Experts](https://arxiv.org/abs/2601.12137)
*Anzhe Cheng,Shukai Duan,Shixuan Li,Chenzhong Yin,Mingxi Cheng,Shahin Nazarian,Paul Thompson,Paul Bogdan*

Main category: cs.LG

TL;DR: 本文提出了EMoE架构，通过基于学习正交特征基的路由机制，同时解决MoE中的负载不均衡和专家同质化问题。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型规模不断扩大导致计算需求不可持续，MoE架构虽能提高效率但存在两个根本问题：1)负载不均衡的"富者愈富"现象，少数专家被过度使用；2)专家同质化问题，专家学习冗余表示，违背了专家多样化的初衷。现有解决方案通常使用辅助负载均衡损失，虽能缓解不均衡但往往加剧同质化。

Method: 提出Eigen-Mixture-of-Experts (EMoE)架构，采用基于学习正交特征基的路由机制。该方法将输入token投影到共享的特征基上，并根据token与特征空间主成分的对齐程度进行路由。这种基于几何的数据划分本质上促进了专家使用的均衡性和专家专业化多样性。

Result: EMoE无需冲突的辅助损失函数就能同时实现负载均衡和专家专业化，解决了传统MoE架构中负载均衡与专家多样性之间的权衡问题。

Conclusion: EMoE通过基于正交特征基的路由机制，为MoE架构提供了更优的解决方案，能够同时解决负载不均衡和专家同质化问题，为实现更高效的深度学习模型提供了新途径。

Abstract: The relentless scaling of deep learning models has led to unsustainable computational demands, positioning Mixture-of-Experts (MoE) architectures as a promising path towards greater efficiency. However, MoE models are plagued by two fundamental challenges: 1) a load imbalance problem known as the``rich get richer" phenomenon, where a few experts are over-utilized, and 2) an expert homogeneity problem, where experts learn redundant representations, negating their purpose. Current solutions typically employ an auxiliary load-balancing loss that, while mitigating imbalance, often exacerbates homogeneity by enforcing uniform routing at the expense of specialization. To resolve this, we introduce the Eigen-Mixture-of-Experts (EMoE), a novel architecture that leverages a routing mechanism based on a learned orthonormal eigenbasis. EMoE projects input tokens onto this shared eigenbasis and routes them based on their alignment with the principal components of the feature space. This principled, geometric partitioning of data intrinsically promotes both balanced expert utilization and the development of diverse, specialized experts, all without the need for a conflicting auxiliary loss function. Our code is publicly available at https://github.com/Belis0811/EMoE.

</details>


### [314] [Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling](https://arxiv.org/abs/2601.12145)
*Xingyue Huang,Xueying Ding,Mingxuan Ju,Yozen Liu,Neil Shah,Tong Zhao*

Main category: cs.LG

TL;DR: 提出Threshold Differential Attention (TDA)，一种无注意力下沉的超稀疏注意力机制，通过极值阈值化和差分抑制视图解决长上下文处理问题。


<details>
  <summary>Details</summary>
Motivation: Softmax注意力在长上下文处理中存在结构限制：严格的归一化约束导致注意力分散到无关令牌上，随着序列长度增加，概率质量分散，出现注意力下沉问题。

Method: 提出TDA机制：1) 应用行级极值阈值化，通过长度相关的门控保留超过阈值的值；2) 借鉴差分transformer思想，减去抑制性视图增强表达能力；3) 实现超稀疏注意力(>99%精确零值)。

Result: 理论证明：TDA每行误报幸存者期望为O(1)，且随着上下文增长，独立视图间的共识误报匹配消失。实证结果：TDA在标准和长上下文基准测试中保持竞争力，同时消除注意力下沉。

Conclusion: TDA有效解决了Softmax注意力在长上下文中的结构限制，实现了无注意力下沉的超稀疏注意力机制，在计算效率、鲁棒性和性能之间取得了良好平衡。

Abstract: Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.

</details>


### [315] [Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses](https://arxiv.org/abs/2601.12178)
*Fallou Niakh*

Main category: cs.LG

TL;DR: 提出联邦学习框架用于校准参数化保险指数，针对可再生能源生产损失异质性，无需共享原始数据


<details>
  <summary>Details</summary>
Motivation: 解决可再生能源生产损失异质性下的参数化保险指数校准问题，传统方法需要共享敏感生产数据，存在隐私和安全风险

Method: 采用联邦学习框架，生产者使用Tweedie广义线性模型本地建模损失，通过联邦优化学习共同指数；支持异质性方差和链接函数，直接最小化全局偏差目标；比较FedAvg、FedProx和FedOpt算法

Result: 德国太阳能发电实证应用显示，联邦学习在中等异质性下能恢复可比较的指数系数，同时提供更通用和可扩展的框架

Conclusion: 联邦学习为参数化保险指数校准提供了有效的分布式解决方案，能在保护数据隐私的同时处理异质性，优于现有的近似聚合方法

Abstract: We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.

</details>


### [316] [Speculative Sampling with Reinforcement Learning](https://arxiv.org/abs/2601.12212)
*Chenan Wang,Daniel H. Shi,Haipeng Chen*

Main category: cs.LG

TL;DR: 提出了首个基于强化学习的推测采样框架Re-SpS，通过动态调整草稿树超参数，在保持输出质量的同时实现比现有方法更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有推测采样方法（如EAGLE-3）使用静态树结构超参数，限制了在不同上下文和领域中的灵活性和效率，需要更智能的动态调整机制。

Method: 提出Re-SpS强化学习框架：1）实时动态调整草稿树超参数；2）利用目标模型隐藏状态构建高效状态表示；3）引入多步动作持久化以改善上下文建模；4）学习平衡推测激进性与计算开销的上下文感知策略。

Result: 在五个多样化基准测试中：1）相比骨干LLM实现最高5.45倍加速；2）相比SOTA方法EAGLE-3实现最高1.12倍加速；3）输出保真度无损失。

Conclusion: Re-SpS通过强化学习动态优化草稿树超参数，显著提升了推测采样的效率和灵活性，为LLM推理加速提供了更智能的解决方案。

Abstract: Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.

</details>


### [317] [One-Sided Matrix Completion from Ultra-Sparse Samples](https://arxiv.org/abs/2601.12213)
*Hongyang R. Zhang,Zhenshuo Zhang,Huy L. Nguyen,Guanghui Lan*

Main category: cs.LG

TL;DR: 本文研究了超稀疏采样条件下的矩阵补全问题，提出了一种基于二阶矩矩阵的无偏估计方法，并通过梯度下降恢复矩阵结构，在理论保证下实现了高维稀疏数据的有效恢复。


<details>
  <summary>Details</summary>
Motivation: 矩阵补全在超稀疏采样场景下面临挑战，特别是当每个行仅包含少于矩阵秩的条目时。本文针对大规模稀疏面板数据集（行数远大于列数）的应用需求，研究如何在这种情况下准确估计矩阵的行空间或二阶矩矩阵。

Method: 提出无偏估计器，通过归一化二阶矩矩阵中每个非零项的观测频率，然后使用梯度下降来填补二阶矩矩阵的缺失条目。该归一化方法将n个二项随机变量的加权和除以总观测数。

Result: 在理论方面，证明了当行向量满足因子模型且满足不相干条件时，只要n ≥ O(dr⁵ε⁻²C⁻²log d)，梯度下降的任何局部最小值都是近似全局最优，并能以误差不超过ε²恢复二阶矩矩阵。实验方面，在MovieLens数据集上减少了88%的偏差，在Amazon评论数据集上分别减少了59%和38%的恢复误差。

Conclusion: 该方法在超稀疏采样条件下有效解决了矩阵补全问题，通过无偏估计和梯度下降相结合的策略，为大规模稀疏面板数据提供了理论保证和实际有效的恢复方案。

Abstract: Matrix completion is a classical problem that has received recurring interest across a wide range of fields. In this paper, we revisit this problem in an ultra-sparse sampling regime, where each entry of an unknown, $n\times d$ matrix $M$ (with $n \ge d$) is observed independently with probability $p = C / d$, for a fixed integer $C \ge 2$. This setting is motivated by applications involving large, sparse panel datasets, where the number of rows far exceeds the number of columns. When each row contains only $C$ entries -- fewer than the rank of $M$ -- accurate imputation of $M$ is impossible. Instead, we estimate the row span of $M$ or the averaged second-moment matrix $T = M^{\top} M / n$.
  The empirical second-moment matrix computed from observed entries exhibits non-random and sparse missingness. We propose an unbiased estimator that normalizes each nonzero entry of the second moment by its observed frequency, followed by gradient descent to impute the missing entries of $T$. The normalization divides a weighted sum of $n$ binomial random variables by the total number of ones. We show that the estimator is unbiased for any $p$ and enjoys low variance. When the row vectors of $M$ are drawn uniformly from a rank-$r$ factor model satisfying an incoherence condition, we prove that if $n \ge O({d r^5 ε^{-2} C^{-2} \log d})$, any local minimum of the gradient-descent objective is approximately global and recovers $T$ with error at most $ε^2$.
  Experiments on both synthetic and real-world data validate our approach. On three MovieLens datasets, our algorithm reduces bias by $88\%$ relative to baseline estimators. We also empirically validate the linear sampling complexity of $n$ relative to $d$ on synthetic data. On an Amazon reviews dataset with sparsity $10^{-7}$, our method reduces the recovery error of $T$ by $59\%$ and $M$ by $38\%$ compared to baseline methods.

</details>


### [318] [Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models](https://arxiv.org/abs/2601.12215)
*Megha Thukral,Cyrus Tanade,Simon A. Lee,Juhyeon Lee,Hao Zhou,Keum San Chun,Migyeong Gwak,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Mehrab Bin Morshed,Subramaniam Venkatraman,Sharanya Arcot Desai*

Main category: cs.LG

TL;DR: 提出MMR自监督预训练框架，通过小波多尺度分解和掩码重建任务学习PPG信号的层次化时频特征，在19个健康相关任务中的17个超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴基础模型大多忽略PPG信号的频谱结构，而许多健康相关任务需要从细粒度波形形态到全局节律动态的多分辨率特征。

Method: MMR框架：1) 使用小波多分辨率分解PPG信号；2) 随机掩码分解系数；3) 通过Transformer编码器重建被掩码的系数，强制模型整合跨时频尺度的信息。

Result: 使用约1700万个10秒PPG片段预训练，在19个健康相关任务中的17个超越或匹配当前最优的PPG基础模型、时序基础模型和其他自监督基线。

Conclusion: MMR展示了构建通用PPG基础模型的潜力，小波表示能捕获稳健且具有生理基础的特征。

Abstract: Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.

</details>


### [319] [Learning Longitudinal Health Representations from EHR and Wearable Data](https://arxiv.org/abs/2601.12227)
*Yuanyun Zhang,Han Zhou,Li Feng,Yilin Hong,Shi Li*

Main category: cs.LG

TL;DR: 本文提出了一种融合电子健康记录和可穿戴设备数据的多模态基础模型，通过联合表示这两种数据源作为连续时间潜在过程，显著提升了临床预测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据稀疏且不规则，而可穿戴设备提供密集连续的生理信号但缺乏语义基础。现有方法通常分别建模这些数据源或通过后期融合结合它们，无法充分利用两种数据源的互补优势。

Method: 提出多模态基础模型，将电子健康记录和可穿戴数据联合表示为连续时间潜在过程。模型使用模态特定编码器和共享的时间骨干网络，通过自监督和跨模态目标进行预训练，产生时间一致且临床基础的表征。

Result: 在生理预测和风险建模任务中，该模型优于仅使用电子健康记录或仅使用可穿戴数据的基线方法，特别是在长时程预测和缺失数据情况下表现更佳。

Conclusion: 联合电子健康记录和可穿戴数据的预训练能够产生更准确的纵向健康表征，证明多模态融合在临床预测中的重要性。

Abstract: Foundation models trained on electronic health records show strong performance on many clinical prediction tasks but are limited by sparse and irregular documentation. Wearable devices provide dense continuous physiological signals but lack semantic grounding. Existing methods usually model these data sources separately or combine them through late fusion. We propose a multimodal foundation model that jointly represents electronic health records and wearable data as a continuous time latent process. The model uses modality specific encoders and a shared temporal backbone pretrained with self supervised and cross modal objectives. This design produces representations that are temporally coherent and clinically grounded. Across forecasting physiological and risk modeling tasks the model outperforms strong electronic health record only and wearable only baselines especially at long horizons and under missing data. These results show that joint electronic health record and wearable pretraining yields more faithful representations of longitudinal health.

</details>


### [320] [Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention](https://arxiv.org/abs/2601.12231)
*Kaichuan Kong,Dongjie Liu,Xiaobo Jin,Shijie Xu,Guanggang Geng*

Main category: cs.LG

TL;DR: 本文提出了一种结合小波感知调制、多分辨率小波分解和分辨率自适应注意力的新框架，用于企业安全中的内部威胁检测，在CERT基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 企业内部威胁检测面临多通道、非平稳且异常稀少的用户活动日志数据挑战，现有方法难以有效捕捉复杂的行为模式并检测异常。

Method: 提出三阶段框架：1) 偏差感知调制方案抑制常规行为并放大异常偏差；2) 离散小波变换将日志信号分解为多分辨率表示；3) 可学习的注意力机制动态重加权最具判别性的频带。

Result: 在CERT r4.2基准测试中，该方法在不同时间粒度和场景下，在精确率、召回率和F1分数方面均优于现有基线方法。

Conclusion: 集成小波感知调制、多分辨率分解和自适应注意力的框架能有效处理多通道非平稳日志数据，提升内部威胁检测性能。

Abstract: Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.

</details>


### [321] [TimeGMM: Single-Pass Probabilistic Forecasting via Adaptive Gaussian Mixture Models with Reversible Normalization](https://arxiv.org/abs/2601.12288)
*Lei Liu,Tengyuan Liu,Hongwei Zhao,Jiahui Huang,Ruibo Guo,Bin Li*

Main category: cs.LG

TL;DR: TimeGMM是一个基于高斯混合模型的概率时间序列预测框架，能够单次前向传播捕捉复杂未来分布，通过GRIN模块处理时间-概率分布漂移，在多个指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有概率时间序列预测方法存在计算成本高或参数假设限制的问题，导致预测性能受限和分布不匹配。需要一种能够高效捕捉复杂未来分布的方法。

Method: 提出了TimeGMM框架，基于高斯混合模型捕捉复杂分布；设计了GRIN模块（GMM适应的可逆实例归一化）处理时间-概率分布漂移；整合了时间编码器（TE-Module）和条件时间-概率解码器（CTPD-Module）来联合捕捉时间依赖性和混合分布参数。

Result: TimeGMM在CRPS和NMAE指标上最大分别提升了22.48%和21.23%，在广泛实验中一致优于最先进方法。

Conclusion: TimeGMM通过高斯混合模型和创新的GRIN模块，能够高效准确地捕捉复杂未来分布，解决了现有方法的局限性，在概率时间序列预测任务中表现出色。

Abstract: Probabilistic time series forecasting is crucial for quantifying future uncertainty, with significant applications in fields such as energy and finance. However, existing methods often rely on computationally expensive sampling or restrictive parametric assumptions to characterize future distributions, which limits predictive performance and introduces distributional mismatch. To address these challenges, this paper presents TimeGMM, a novel probabilistic forecasting framework based on Gaussian Mixture Models (GMM) that captures complex future distributions in a single forward pass. A key component is GMM-adapted Reversible Instance Normalization (GRIN), a novel module designed to dynamically adapt to temporal-probabilistic distribution shifts. The framework integrates a dedicated Temporal Encoder (TE-Module) with a Conditional Temporal-Probabilistic Decoder (CTPD-Module) to jointly capture temporal dependencies and mixture distribution parameters. Extensive experiments demonstrate that TimeGMM consistently outperforms state-of-the-art methods, achieving maximum improvements of 22.48\% in CRPS and 21.23\% in NMAE.

</details>


### [322] [Distribution Shift Is Key to Learning Invariant Prediction](https://arxiv.org/abs/2601.12296)
*Hong Zheng,Fei Teng*

Main category: cs.LG

TL;DR: 论文研究发现，训练数据中的分布偏移程度越大，ERM方法反而可能比专门设计的OOD方法表现更好，因为大的分布偏移有助于模型学习不变性预测。


<details>
  <summary>Details</summary>
Motivation: 观察到经验风险最小化（ERM）有时会优于专门为分布外任务设计的方法，这促使研究者探究算法设计之外的原因，特别是训练域之间的分布偏移如何影响模型性能。

Method: 通过理论分析和实证验证相结合的方法：1）推导理论上限，证明分布偏移程度直接影响模型预测能力；2）证明在特定数据条件下，ERM解能达到与不变性预测模型相当的性能；3）实证验证分布偏移增加时，学习模型的预测接近Oracle或最优模型。

Result: 研究发现：1）大的分布偏移能提升模型能力，使其逼近不变性预测模型；2）在特定条件下，ERM可以达到与不变性预测模型相当的性能；3）训练数据分布偏移程度增加时，学习模型的预测确实接近Oracle或最优模型。

Conclusion: 分布偏移在模型学习中起着关键作用，大的分布偏移有助于学习不变性预测，这解释了为什么有时简单的ERM方法反而优于专门设计的OOD方法。这一发现为理解模型泛化能力提供了新视角。

Abstract: An interesting phenomenon arises: Empirical Risk Minimization (ERM) sometimes outperforms methods specifically designed for out-of-distribution tasks. This motivates an investigation into the reasons behind such behavior beyond algorithmic design. In this study, we find that one such reason lies in the distribution shift across training domains. A large degree of distribution shift can lead to better performance even under ERM. Specifically, we derive several theoretical and empirical findings demonstrating that distribution shift plays a crucial role in model learning and benefits learning invariant prediction. Firstly, the proposed upper bounds indicate that the degree of distribution shift directly affects the prediction ability of the learned models. If it is large, the models' ability can increase, approximating invariant prediction models that make stable predictions under arbitrary known or unseen domains; and vice versa. We also prove that, under certain data conditions, ERM solutions can achieve performance comparable to that of invariant prediction models. Secondly, the empirical validation results demonstrated that the predictions of learned models approximate those of Oracle or Optimal models, provided that the degree of distribution shift in the training data increases.

</details>


### [323] [Machine Learning as a Service (MLaaS) Dataset Generator Framework for IoT Environments](https://arxiv.org/abs/2601.12305)
*Deepak Kanneganti,Sajib Mistry,Sheik Fattah,Joshua Boland,Aneesh Krishna*

Main category: cs.LG

TL;DR: 提出MLaaS数据集生成器(MDG)框架，用于生成可配置、可复现的数据集来评估MLaaS服务选择与组合。该框架通过模拟真实MLaaS行为，记录详细功能属性、服务质量指标和组合特定指标，生成了超过一万个MLaaS服务实例的大规模基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的MLaaS（机器学习即服务）选择和组合研究缺乏系统化的评估数据集，难以进行可重复和全面的性能比较。需要一种能够生成可配置、可复现数据集的方法来推动数据驱动的MLaaS研究。

Method: MDG框架通过在多个人工智能和物联网环境中训练和评估不同的模型家族来模拟真实的MLaaS行为。框架记录功能属性、服务质量指标和组合特定指标，并内置组合机制来模拟服务在多种物联网条件下的交互行为。

Result: 生成了超过一万个MLaaS服务实例的大规模基准数据集。实验表明，使用MDG生成的数据集相比现有基线方法，能够显著提高服务选择的准确性和组合质量。

Conclusion: MDG为推进数据驱动的MLaaS选择和组合研究提供了实用且可扩展的基础。该框架生成的基准数据集能够支持系统化的服务性能分析和跨服务行为研究，为MLaaS领域的研究和开发提供了重要工具。

Abstract: We propose a novel MLaaS Dataset Generator (MDG) framework that creates configurable and reproducible datasets for evaluating Machine Learning as a Service (MLaaS) selection and composition. MDG simulates realistic MLaaS behaviour by training and evaluating diverse model families across multiple real-world datasets and data distribution settings. It records detailed functional attributes, quality of service metrics, and composition-specific indicators, enabling systematic analysis of service performance and cross-service behaviour. Using MDG, we generate more than ten thousand MLaaS service instances and construct a large-scale benchmark dataset suitable for downstream evaluation. We also implement a built-in composition mechanism that models how services interact under varied Internet of Things conditions. Experiments demonstrate that datasets generated by MDG enhance selection accuracy and composition quality compared to existing baselines. MDG provides a practical and extensible foundation for advancing data-driven research on MLaaS selection and composition

</details>


### [324] [Explanova: Automatically Discover Data Insights in N \times M Table via XAI Combined LLM Workflow](https://arxiv.org/abs/2601.12317)
*Yiming Huang*

Main category: cs.LG

TL;DR: Explanova是一个基于预设AutoML式工作流的自动化数据分析框架，使用本地小模型降低成本


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体框架（如DeepAnalyze、DataSage、Datawise）虽然强大，但依赖于LLM的智能体工具调用能力。作者提出是否可以用预设的AutoML式工作流来替代，实现更系统化的数据探索（包括变量统计、关系分析、解释等）

Method: 提出Explanova框架，采用预设的AutoML式工作流，遍历所有可能的数据探索路径（如变量自身统计、变量间关系、变量对所有其他变量的影响等），并使用本地小型LLM来降低成本

Result: Explanova相比现有基于大型LLM的智能体框架，能够实现类似的自动化数据分析功能，但成本更低

Conclusion: 预设的AutoML式工作流结合本地小型LLM是一种有效的自动化数据分析替代方案，能够在保持功能的同时显著降低成本

Abstract: Automation in data analysis has been a long-time pursuit. Current agentic LLM shows a promising solution towards it. Like DeepAnalyze, DataSage, and Datawise. They are all powerful agentic frameworks for automatic fine-grained analysis and are powered by LLM-based agentic tool calling ability. However, what about powered by a preset AutoML-like workflow? If we traverse all possible exploration, like Xn itself`s statistics, Xn1-Xn2 relationships, Xn to all other, and finally explain? Our Explanova is such an attempt: Cheaper due to a Local Small LLM.

</details>


### [325] [Ordered Local Momentum for Asynchronous Distributed Learning under Arbitrary Delays](https://arxiv.org/abs/2601.12322)
*Chang-Wei Shi,Shi-Shang Wang,Wu-Jun Li*

Main category: cs.LG

TL;DR: OrLoMo是首个实现异步分布式动量SGD（MSGD）局部更新的方法，通过按全局迭代顺序聚合局部动量，在异构计算环境中减少通信频率并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 异步分布式学习对训练大规模深度模型至关重要，尤其是在集群计算能力异构的情况下。局部更新广泛用于减少通信频率，但如何实现异步分布式MSGD（动量SGD）的局部更新尚未被探索。

Method: 提出OrLoMo（有序局部动量）方法：每个工作节点本地运行MSGD，服务器根据全局迭代索引顺序聚合来自各工作节点的局部动量。

Result: OrLoMo是首个实现异步分布式MSGD局部更新的方法。理论证明其在任意延迟下对非凸问题收敛。实验验证OrLoMo优于同步方法和其他异步方法。

Conclusion: OrLoMo成功解决了异步分布式MSGD局部更新的实现问题，在异构计算环境中通过有序聚合局部动量，有效加速收敛并提升性能。

Abstract: Momentum SGD (MSGD) serves as a foundational optimizer in training deep models due to momentum's key role in accelerating convergence and enhancing generalization. Meanwhile, asynchronous distributed learning is crucial for training large-scale deep models, especially when the computing capabilities of the workers in the cluster are heterogeneous. To reduce communication frequency, local updates are widely adopted in distributed learning. However, how to implement asynchronous distributed MSGD with local updates remains unexplored. To solve this problem, we propose a novel method, called \underline{or}dered \underline{lo}cal \underline{mo}mentum (OrLoMo), for asynchronous distributed learning. In OrLoMo, each worker runs MSGD locally. Then the local momentum from each worker will be aggregated by the server in order based on its global iteration index. To the best of our knowledge, OrLoMo is the first method to implement asynchronous distributed MSGD with local updates. We prove the convergence of OrLoMo for non-convex problems under arbitrary delays. Experiments validate that OrLoMo can outperform its synchronous counterpart and other asynchronous methods.

</details>


### [326] [IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning](https://arxiv.org/abs/2601.12330)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Ayesha Kanwal,Sidra Sultana,Nazia Perwaiz*

Main category: cs.LG

TL;DR: IceWatch是一个结合空间和时间视角的深度学习框架，用于预测冰川湖溃决洪水（GLOFs），通过多模态卫星数据和物理动力学模型提高预测的可靠性、实时性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统GLOF检测方法（水文建模、阈值监测、人工卫星图像分析）存在更新慢、依赖人工、云层干扰和缺乏现场数据导致精度下降等问题，需要更自动化和可靠的预测系统。

Method: 提出IceWatch框架：1）空间视觉组件RiskFlow使用CNN分类器分析Sentinel-2多光谱卫星图像，基于雪、冰和融水的空间模式预测GLOF；2）时间序列组件TerraFlow和TempFlow分别从NASA ITS_LIVE数据建模冰川流速、从MODIS LST记录预测近地表温度；通过协调预处理和同步实现多模态、物理信息融合的GLOF预测。

Result: 系统实现了强大的预测性能、快速实时数据处理、对噪声和缺失信息的鲁棒性，通过交叉验证提高了GLOF检测的可靠性和可解释性。

Conclusion: IceWatch为自动化、可扩展的GLOF预警系统开辟了道路，并具有整合多种传感器输入和全球冰川监测活动的潜力。

Abstract: Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.

</details>


### [327] [Time-Continuous Modeling for Temporal Affective Pattern Recognition in LLMs](https://arxiv.org/abs/2601.12341)
*Rezky Kam,Coddy N. Siswanto*

Main category: cs.LG

TL;DR: 论文提出了一种数据集和概念框架，让LLMs能够通过基于物理信息的神经网络，在时间和上下文学习中模拟真实世界的情感动态，为可解释的对话建模开辟了新可能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在情感理解和对话建模方面缺乏对真实世界情感动态的模拟能力，难以实现可解释的情感交互。需要结合物理学原理来建模情感随时间变化的动态过程。

Method: 开发了一个专门的数据集，并提出了概念框架，利用基于物理信息的神经网络（PINN）来模拟情感在时间和上下文中的动态变化，使LLMs能够学习情感演化的规律。

Result: 该方法使LLMs能够更准确地模拟真实世界的情感动态，通过物理学原理增强情感建模的可解释性，为对话系统提供了新的情感理解能力。

Conclusion: 将物理学原理与神经网络结合，为LLMs的情感建模提供了新的方向，使得对话系统能够更真实、可解释地模拟人类情感动态，具有重要的理论和应用价值。

Abstract: This paper introduces a dataset and conceptual framework for LLMs to mimic real world emotional dynamics through time and in-context learning leveraging physics-informed neural network, opening a possibility for interpretable dialogue modeling.

</details>


### [328] [LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH](https://arxiv.org/abs/2601.12355)
*Beicheng Xu,Weitong Qian,Lingching Tung,Yupeng Lu,Bin Cui*

Main category: cs.LG

TL;DR: LB-MCTS：结合大语言模型和贝叶斯优化的AutoML框架，通过蒙特卡洛树搜索结构解决CASH问题，在104个AMLB数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统贝叶斯优化在CASH问题上存在冷启动问题，而现有基于大语言模型的优化器在高维结构化CASH空间中泛化能力差，需要结合两者优势的解决方案

Method: 提出LB-MCTS框架，在大语言模型和贝叶斯优化之间建立协同，采用蒙特卡洛树搜索结构，通过选择性调优记忆（STM）最大化大语言模型推理能力，实现显式的探索-利用权衡，并随着数据积累从大语言模型驱动动态转向贝叶斯优化驱动

Result: 在104个AMLB数据集上的实验表明，LB-MCTS优于现有竞争基线方法

Conclusion: LB-MCTS成功融合了大语言模型的语义先验和贝叶斯优化的数据驱动优势，为CASH问题提供了有效的解决方案，显著降低了机器学习的技术门槛

Abstract: To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.

</details>


### [329] [Machine Learning-Based Framework for Real Time Detection and Early Prediction of Control Valve Stiction in Industrial Control Systems](https://arxiv.org/abs/2601.12362)
*Natthapong Promsricha,Chotirawee Chatpattanasiri,Nuttavut Kerdgongsup,Stavroula Balabani*

Main category: cs.LG

TL;DR: 提出基于机器学习的控制阀粘滞故障检测与预测框架，使用LSTM等深度学习模型，利用常规过程信号（OP和PV）实现提前4小时的粘滞预测。


<details>
  <summary>Details</summary>
Motivation: 控制阀粘滞是工业过程中的常见故障，会导致系统不稳定、设备磨损和维护成本增加。传统阀门缺乏实时监测，难以早期预测，需要开发基于常规数据的方法。

Method: 开发了三种深度学习模型：CNN、CNN-SVM混合模型和LSTM网络。使用基于斜率比分析的数据驱动标注方法处理真实炼油厂数据集，仅利用控制器输出（OP）和过程变量（PV）等常规信号。

Result: LSTM模型表现最佳，能够提前4小时预测控制阀粘滞故障，达到最高准确率。这是首个基于真实工业数据实现机器学习早期预测控制阀粘滞的研究。

Conclusion: 该框架可集成到现有控制系统中，支持预测性维护，减少停机时间，避免不必要的硬件更换，为工业过程控制提供有效的故障预测解决方案。

Abstract: Control valve stiction, a friction that prevents smooth valve movement, is a common fault in industrial process systems that causes instability, equipment wear, and higher maintenance costs. Many plants still operate with conventional valves that lack real time monitoring, making early predictions challenging. This study presents a machine learning (ML) framework for detecting and predicting stiction using only routinely collected process signals: the controller output (OP) from control systems and the process variable (PV), such as flow rate. Three deep learning models were developed and compared: a Convolutional Neural Network (CNN), a hybrid CNN with a Support Vector Machine (CNN-SVM), and a Long Short-Term Memory (LSTM) network. To train these models, a data-driven labeling method based on slope ratio analysis was applied to a real oil and gas refinery dataset. The LSTM model achieved the highest accuracy and was able to predict stiction up to four hours in advance. To the best of the authors' knowledge, this is the first study to demonstrate ML based early prediction of control valve stiction from real industry data. The proposed framework can be integrated into existing control systems to support predictive maintenance, reduce downtime, and avoid unnecessary hardware replacement.

</details>


### [330] [Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation](https://arxiv.org/abs/2601.12380)
*Ou Deng,Shoji Nishimura,Atsushi Ogihara,Qun Jin*

Main category: cs.LG

TL;DR: SNI是一个可解释的混合类型数据填补框架，通过可控先验特征注意力模块结合统计先验与神经网络注意力，提供特征依赖诊断和统计-神经权衡参数。


<details>
  <summary>Details</summary>
Motivation: 现实表格数据常同时包含连续测量值和分类记录，但缺失值普遍存在且会扭曲下游分析。现有方法要么缺乏解释性，要么难以平衡统计先验与数据驱动的非线性模式。

Method: 提出统计-神经交互（SNI）框架，包含可控先验特征注意力（CPFA）模块。该模块学习头部先验强度系数{λ_h}，软性地将注意力正则化向先验，同时允许在数据呈现非线性模式时进行数据驱动的偏离。除了填补外，SNI还将注意力图聚合成有向特征依赖矩阵，无需后置解释器即可总结填补器依赖的变量。

Result: 在六个数据集（ICU监测、人口调查、社会经济统计、工程应用）上评估SNI与六种基线方法。在30%MCAR/严格MAR缺失下，SNI在连续指标上通常具有竞争力，但在分类变量上常被准确率优先的基线方法（MissForest、MIWAE）超越；作为回报，它提供内在依赖诊断和明确的统计-神经权衡参数。还报告了MNAR压力测试（使用掩码感知变体）。

Conclusion: SNI在准确性和解释性之间提供了权衡。对于严重不平衡的分类目标存在局限性，但在需要解释性的部署场景中，这种权衡可能是合理的。该框架提供了无需后置解释器的特征依赖诊断能力。

Abstract: Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{λ_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.

</details>


### [331] [Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation](https://arxiv.org/abs/2601.12401)
*Jinmei Liu,Haoru Li,Zhenhong Sun,Chaofeng Chen,Yatao Bian,Bo Wang,Daoyi Dong,Chunlin Chen,Zhi Wang*

Main category: cs.LG

TL;DR: DRIFT提出了一种多样性激励的强化学习微调框架，解决生成模型微调中的多样性崩溃问题，通过采样、提示和优化三个角度提升生成多样性和任务对齐的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习微调大型生成模型时存在"多样性崩溃"的根本限制，即目标公式和优化过程会导致策略收敛到狄拉克分布，损失生成多样性，而实际应用需要同时保证任务对齐和生成多样性。

Method: 提出DRIFT框架，从三个角度激励输出多样性：1) 采样奖励集中子集过滤异常值防止过早崩溃；2) 使用随机变化的提示扩展条件空间；3) 通过基于势能的奖励塑造机制优化组内多样性。

Result: 实验显示DRIFT在任务对齐和生成多样性方面达到帕累托最优，在同等对齐水平下多样性提升9.08%-43.46%，在同等多样性水平下对齐提升59.65%-65.86%。

Conclusion: DRIFT成功解决了生成模型强化学习微调中的多样性崩溃问题，通过系统性激励多样性实现了任务对齐和生成多样性的平衡，为需要多样化候选生成的应用提供了有效解决方案。

Abstract: Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.

</details>


### [332] [Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants](https://arxiv.org/abs/2601.12405)
*Manasi Kanade,Abhi Thakkar,Gabriela Fernandes*

Main category: cs.LG

TL;DR: 开发并评估了一个可解释的机器学习框架，用于儿科牙科风险分层，该框架优先考虑可解释性、校准和伦理部署，而非最大预测准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管口腔健康结果与社会经济和人口统计学因素有很强的流行病学关联，但大多数牙科人工智能应用依赖于基于图像的诊断和黑盒预测模型，这在儿科人群中限制了透明度和伦理适用性。因此需要开发一个更透明、可解释的儿科牙科风险分层方法。

Method: 使用包含年龄、收入贫困比、种族/民族、性别和医疗史等人口水平儿科数据训练监督机器学习模型。使用ROC分析和校准曲线评估模型性能，通过SHAP实现可解释性，提供全局和个体层面的预测解释。

Result: 模型取得了适度的区分能力（AUC=0.61），具有保守的校准特性，在较高概率水平上低估了风险。SHAP分析显示年龄和收入贫困比是预测风险的最强贡献因素，其次是种族/民族和性别。

Conclusion: 可解释机器学习实现了透明的、以预防为导向的儿科牙科风险分层，支持人群筛查和公平资源分配，而非诊断决策。

Abstract: Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations.
  Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy.
  Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions.
  Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender.
  Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.

</details>


### [333] [Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF](https://arxiv.org/abs/2601.12415)
*Wang Zixian*

Main category: cs.LG

TL;DR: 该论文提出正交化策略优化（OPO）框架，将对齐方法解耦为采样几何和优化几何两个独立设计选择，解决传统KL散度导致的不稳定和梯度消失问题。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法（如PPO、DPO、IPO）隐式混淆了两个基本设计选择：采样几何和优化几何。KL散度对无界值信号施加指数惩罚，导致数值不稳定和高置信度下的梯度消失。

Method: 提出正交化策略优化（OPO）框架，通过α加权重要性采样与卡方诱导的二次正则化结合，在比率坐标中实现线性梯度动态的简单且良条件目标。

Result: OPO在保持峰值寻求行为的同时实现稳定优化，避免梯度饱和，为现有对齐方法提供统一视角，并为稳健的推理导向训练奠定基础。

Conclusion: 通过明确解耦采样几何和优化几何，OPO解决了传统对齐方法的不稳定性问题，为大型语言模型对齐提供了更稳健的优化框架。

Abstract: Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.

</details>


### [334] [Q-learning with Adjoint Matching](https://arxiv.org/abs/2601.14234)
*Qiyang Li,Sergey Levine*

Main category: cs.LG

TL;DR: 提出QAM算法，通过伴随匹配技术解决连续动作RL中扩散/流匹配策略优化的数值不稳定问题，在稀疏奖励任务上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 在连续动作强化学习中，如何高效优化表达性强的扩散或流匹配策略一直是个长期挑战。现有方法要么只利用价值信息丢弃梯度信息，要么采用近似方法牺牲策略表达性或引入偏差。

Method: 使用伴随匹配技术，将评论者的动作梯度转换为分步目标函数，避免了通过多步去噪过程进行反向传播的数值不稳定问题，同时结合时序差分备份进行评论者学习。

Result: 在离线RL和离线到在线RL的困难稀疏奖励任务中，QAM始终优于现有方法。

Conclusion: QAM通过伴随匹配技术有效解决了连续动作RL中扩散/流匹配策略优化的数值稳定性问题，提供了无偏且表达性强的策略优化方案。

Abstract: We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.

</details>


### [335] [Graph Attention Networks with Physical Constraints for Anomaly Detection](https://arxiv.org/abs/2601.12426)
*Mohammadhossein Homaei,Iman Khazrak,Ruben Molano,Andres Caro,Mar Avila*

Main category: cs.LG

TL;DR: 提出一种基于水力感知的图注意力网络，利用归一化的守恒定律违例作为特征，结合图注意力和双向LSTM学习时空模式，在水分配系统中实现高精度异常检测。


<details>
  <summary>Details</summary>
Motivation: 水分配系统面临日益增长的网络物理风险，现有数据驱动模型往往忽略网络拓扑结构且难以解释，而基于模型的方法又严重依赖参数准确性，需要一种既能考虑水力特性又具备可解释性的异常检测方法。

Method: 提出水力感知图注意力网络，使用归一化的质量守恒和能量平衡残差作为特征，结合图注意力机制和双向LSTM学习时空模式，并通过多尺度模块从节点级到网络级聚合检测分数。

Result: 在BATADAL数据集上达到F1分数0.979，比现有方法提升3.3个百分点，在15%参数噪声下仍保持高鲁棒性。

Conclusion: 该方法成功结合了物理模型和数据驱动方法的优势，通过引入水力感知特征和时空建模，实现了高精度、鲁棒的异常检测，为水分配系统安全监控提供了有效解决方案。

Abstract: Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.

</details>


### [336] [Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery](https://arxiv.org/abs/2601.12442)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: CANUF框架将贝叶斯深度学习与可微分符号推理结合，为科学AI提供可信的不确定性估计并满足领域约束


<details>
  <summary>Details</summary>
Motivation: 科学AI应用需要既提供可信不确定性估计又尊重领域约束的模型。现有不确定性量化方法缺乏融入符号科学知识的机制，而神经符号方法则缺乏系统的不确定性建模

Method: CANUF包含三个组件：从科学文献自动提取约束、具有变分推理的概率神经骨干、确保物理一致性的可微分约束满足层

Result: 在Materials Project、QM9分子属性和气候基准测试中，CANUF将预期校准误差降低34.7%（相比贝叶斯神经网络），同时保持99.2%的约束满足率。约束引导的重新校准贡献18.3%性能提升，约束提取精度达91.4%

Conclusion: CANUF提供了首个端到端可微分管道，同时解决科学预测中的不确定性量化、约束满足和可解释性说明问题

Abstract: Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.

</details>


### [337] [Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting](https://arxiv.org/abs/2601.12467)
*Saurish Nagrath*

Main category: cs.LG

TL;DR: 提出一个两阶段预测框架，将局部时间表示学习与全局依赖建模分离：先用CNN提取局部时间动态，再用Transformer建模全局依赖。


<details>
  <summary>Details</summary>
Motivation: Transformer在时间序列预测中表现优异，但其效果严重依赖于从原始多元时间序列数据中得到的输入表示的质量和结构。现有方法通常将局部特征提取和全局依赖建模耦合在一起，这可能影响预测效果。

Method: 两阶段框架：第一阶段使用CNN在固定长度的时间块上提取短期时间动态和非线性特征交互，生成紧凑的块级token嵌入，并使用token级自注意力进行精炼；第二阶段使用Transformer编码器处理token序列，建模块间时间依赖并生成每块预测。

Result: 在具有受控静态和动态因素的合成多元时间序列数据上的实验表明，所提出的基于块的token化策略相比卷积和基于块的Transformer基线，实现了有竞争力的预测性能。

Conclusion: 结果表明结构化时间表示的重要性，并证明将局部时间编码与基于注意力的全局建模解耦能产生更有效和稳定的时间序列预测。

Abstract: Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.

</details>


### [338] [Semidefinite Programming for Quantum Channel Learning](https://arxiv.org/abs/2601.12502)
*Mikhail Gennadievich Belov,Victor Victorovich Dubov,Vadim Konstantinovich Ivanov,Alexander Yurievich Maslov,Olga Vladimirovna Proshina,Vladislav Gennadievich Malyshkin*

Main category: cs.LG

TL;DR: 该论文研究基于经典数据重建量子信道的问题，当总保真度可表示为两个二次型之比时，可通过半定规划优化Choi矩阵来有效求解。


<details>
  <summary>Details</summary>
Motivation: 研究如何从实验观测的经典数据中重建量子信道，这对于量子信息处理和量子计算中的信道表征和验证具有重要意义。

Method: 利用半定规划方法优化Choi矩阵，将保真度优化问题转化为凸优化问题，使用多种商业SDP求解器进行数值求解。

Result: 测试表明该方法能有效重建各种形式的量子信道，且重建信道的Kraus秩通常远小于其最大可能值，仅需较小的Kraus秩即可描述实验数据。方法也成功应用于从数据重建投影算子。

Conclusion: 基于量子信道变换的经典计算模型具有潜力，可通过硬件优化的经典计算机实现。较小的Kraus秩量子信道通常足以描述实验观测数据，为量子信道重建提供了有效方法。

Abstract: The problem of reconstructing a quantum channel from a sample of classical data is considered. When the total fidelity can be represented as a ratio of two quadratic forms (e.g., in the case of mapping a mixed state to a pure state, projective operators, unitary learning, and others), Semidefinite Programming (SDP) can be applied to solve the fidelity optimization problem with respect to the Choi matrix. A remarkable feature of SDP is that the optimization is convex, which allows the problem to be efficiently solved by a variety of numerical algorithms. We have tested several commercially available SDP solvers, all of which allowed for the reconstruction of quantum channels of different forms. A notable feature is that the Kraus rank of the obtained quantum channel typically comprises less than a few percent of its maximal possible value. This suggests that a relatively small Kraus rank quantum channel is typically sufficient to describe experimentally observed classical data. The theory was also applied to the problem of reconstructing projective operators from data. Finally, we discuss a classical computational model based on quantum channel transformation, performed and calculated on a classical computer, possibly hardware-optimized.

</details>


### [339] [Cooperative Multi-agent RL with Communication Constraints](https://arxiv.org/abs/2601.12518)
*Nuoya Xiong,Aarti Singh*

Main category: cs.LG

TL;DR: 提出基策略预测技术，通过使用旧梯度预测策略更新并收集多个基策略的样本，减少基策略与当前策略的差距，从而在有限通信下实现有效的多智能体强化学习。


<details>
  <summary>Details</summary>
Motivation: 现有的合作多智能体强化学习通常假设能频繁访问全局信息（如团队奖励或其他智能体动作），这在去中心化系统中由于高通信成本而不现实。当通信受限时，智能体必须依赖过时信息来估计梯度和更新策略。重要性采样等处理缺失数据的方法在通信受限（缺失数据概率高）时变得不稳定，因为基策略已经过时。

Method: 提出基策略预测技术，利用旧梯度预测策略更新，并为一系列基策略收集样本。这减少了基策略与当前策略之间的差距，使算法能在一次通信轮次中收集预测基策略的样本，从而显著减少通信轮次需求。

Result: 理论上证明算法在势博弈中能以仅O(ε^{-3/4})通信轮次和O(poly(max_i|A_i|)ε^{-11/4})样本复杂度收敛到ε-纳什均衡，改进了现有最佳结果的通信成本和样本复杂度，且不依赖于联合动作空间大小的指数依赖。还将结果扩展到一般马尔可夫合作博弈中以找到智能体局部最优。

Conclusion: 基策略预测技术能有效解决有限通信下的多智能体强化学习问题，显著减少通信轮次需求，同时在理论和实验中都表现出优越性能，适用于模拟游戏和复杂环境中的MAPPO应用。

Abstract: Cooperative MARL often assumes frequent access to global information in a data buffer, such as team rewards or other agents' actions, which is typically unrealistic in decentralized MARL systems due to high communication costs. When communication is limited, agents must rely on outdated information to estimate gradients and update their policies. A common approach to handle missing data is called importance sampling, in which we reweigh old data from a base policy to estimate gradients for the current policy. However, it quickly becomes unstable when the communication is limited (i.e. missing data probability is high), so that the base policy in importance sampling is outdated. To address this issue, we propose a technique called base policy prediction, which utilizes old gradients to predict the policy update and collect samples for a sequence of base policies, which reduces the gap between the base policy and the current policy. This approach enables effective learning with significantly fewer communication rounds, since the samples of predicted base policies could be collected within one communication round. Theoretically, we show that our algorithm converges to an $\varepsilon$-Nash equilibrium in potential games with only $O(\varepsilon^{-3/4})$ communication rounds and $O(poly(\max_i |A_i|)\varepsilon^{-11/4})$ samples, improving existing state-of-the-art results in communication cost, as well as sample complexity without the exponential dependence on the joint action space size. We also extend these results to general Markov Cooperative Games to find an agent-wise local maximum. Empirically, we test the base policy prediction algorithm in both simulated games and MAPPO for complex environments.

</details>


### [340] [Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks](https://arxiv.org/abs/2601.12519)
*Abdullah Umut Hamzaogullari,Arkadas Ozakin*

Main category: cs.LG

TL;DR: 提出改进拉格朗日神经网络(LNNs)的方法，解决训练不稳定问题，使其能学习更复杂系统的拉格朗日量，包括双摆、三摆系统，并能处理相对论背景下的测地线运动。


<details>
  <summary>Details</summary>
Motivation: 拉格朗日神经网络可以从轨迹数据中学习任意拉格朗日量，但其不寻常的优化目标导致显著的训练不稳定性，限制了其在复杂系统中的应用。

Method: 提出三种改进：1) Hessian正则化方案，惩罚拉格朗日量对速度二阶导数中的非物理特征；2) 更适合学习拉格朗日量的激活函数；3) 物理感知的坐标缩放以改善稳定性。将这些技术与先前提出的稳定性改进方法进行系统评估。

Result: 改进架构成功训练了前所未有的复杂系统（包括三摆），在双摆系统中验证损失降低96.6%，稳定性提高90.68%。还能学习非相对论和广义相对论背景下的测地线运动拉格朗日量，首次从轨迹数据预测AdS₄时空度规下的测地线拉格朗日量。

Conclusion: 虽然该方法继承了原始LNN框架的一些限制（特别是Hessian可逆的要求），但显著扩展了LNNs在科学发现任务中的实际应用范围，为物理中几何结构的自动发现（包括从测地线轨迹提取时空度规张量分量）开辟了新可能性。

Abstract: Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.

</details>


### [341] [Approximating splits for decision trees quickly in sparse data streams](https://arxiv.org/abs/2601.12525)
*Nikolaj Tatti*

Main category: cs.LG

TL;DR: 针对稀疏二值特征和二元分类的流式决策树，提出近似最优分割的快速算法，在信息增益和基尼指数上实现(1+α)近似，时间复杂度优于O(d)


<details>
  <summary>Details</summary>
Motivation: 决策树是流行的分类器，流式决策树需要高效更新。传统方法在稀疏二值特征下寻找最优分割需要O(d)时间（d为特征数），对于稀疏数据（m≪d）效率不高，需要更快的近似算法

Method: 提出针对稀疏二值特征和二元分类的近似分割算法：1）对条件熵实现(1+α)近似，摊销时间复杂度O(α⁻¹(1+m log d) log log n)；2）对基尼指数实现(1+α)近似，摊销时间复杂度O(α⁻¹+m log d)。利用数据的稀疏性（m为数据点中1的数量）

Result: 实验表明算法能高效找到几乎最优的分割，速度快于基线方法，实际表现优于理论近似保证

Conclusion: 该算法针对稀疏二值特征数据显著提升了流式决策树分割的效率，在保证近似最优性的同时大幅降低计算复杂度，特别适用于m≪d的稀疏场景

Abstract: Decision trees are one of the most popular classifiers in the machine learning literature. While the most common decision tree learning algorithms treat data as a batch, numerous algorithms have been proposed to construct decision trees from a data stream. A standard training strategy involves augmenting the current tree by changing a leaf node into a split. Here we typically maintain counters in each leaf which allow us to determine the optimal split, and whether the split should be done. In this paper we focus on how to speed up the search for the optimal split when dealing with sparse binary features and a binary class. We focus on finding splits that have the approximately optimal information gain or Gini index. In both cases finding the optimal split can be done in $O(d)$ time, where $d$ is the number of features. We propose an algorithm that yields $(1 + α)$ approximation when using conditional entropy in amortized $O(α^{-1}(1 + m\log d) \log \log n)$ time, where $m$ is the number of 1s in a data point, and $n$ is the number of data points. Similarly, for Gini index, we achieve $(1 + α)$ approximation in amortized $O(α^{-1} + m \log d)$ time. Our approach is beneficial for sparse data where $m \ll d$. In our experiments we find almost-optimal splits efficiently, faster than the baseline, overperforming the theoretical approximation guarantees.

</details>


### [342] [Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem](https://arxiv.org/abs/2601.12543)
*Alireza Ghahtarani,Martin Cousineau,Amir-massoud Farahmand,Jorge E. Mendoza*

Main category: cs.LG

TL;DR: 该论文研究在线集中充电调度问题(OCCSP)，通过游戏化建模，使用专家演示训练学习智能体并结合DAgger算法改进，在理论和实验上证明了该方法在负载均衡和经济价值上的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决电动汽车动态到达情况下的实时集中充电调度问题，目标是平衡有限规划时间内的负载，同时考虑容量限制。现有方法在处理复杂约束和实时决策方面存在不足。

Method: 1. 将充电调度问题游戏化，建模为在时间和容量约束网格上放置充电块的游戏；2. 设计启发式策略；3. 使用专家演示训练学习智能体；4. 应用Dataset Aggregation (DAgger)算法改进学习效果；5. 开发图像到动作模型。

Result: 1. 理论分析表明游戏化降低了模型复杂度，获得了比基于向量方法更紧的泛化界；2. 实验验证了游戏化学习能有效增强负载均衡；3. 使用DAgger训练的图像到动作模型在所有基准方法中表现最优，包括启发式基线、基于向量方法和监督学习智能体；4. 敏感性分析显示方法具有鲁棒性；5. 在蒙特利尔地区的实际案例研究中，每年可降低数千万美元的系统成本，并显著推迟昂贵的电网升级需求。

Conclusion: 游戏化方法为在线集中充电调度问题提供了有效的解决方案，不仅理论上有更好的泛化性能，实际应用中也能带来显著的经济效益和运营改进，具有延迟电网升级投资的潜力。

Abstract: We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.

</details>


### [343] [Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory](https://arxiv.org/abs/2601.12557)
*Mark Moussa,Amber V. Young,Brianna Isola,Vasuda Trehan,Michael D. Himes,Nicholas Wogan,Giada Arney*

Main category: cs.LG

TL;DR: 本文提出两种机器学习架构（BCNN和SQuAT）用于从系外行星反射光谱预测生物特征物种通量，旨在为HWO等旗舰任务优化观测策略。


<details>
  <summary>Details</summary>
Motivation: 未来直接成像旗舰任务（如NASA的HWO）面临严格的时间和资源限制，需要高效筛选观测目标。传统方法难以从反射光谱中准确预测生物特征物种通量，特别是在观测条件多样化和数据有限的情况下。

Method: 提出两种机器学习架构：1）贝叶斯卷积神经网络（BCNN），能稳健量化认知和偶然不确定性；2）新颖的谱查询自适应Transformer（SQuAT），采用查询驱动注意力机制增强可解释性，将光谱特征与特定生物特征物种明确关联。

Result: 两种模型在涵盖广泛系外行星条件的增强数据集上都实现了相当高的预测准确性。BCNN在不确定性量化方面表现优异，SQuAT在光谱可解释性方面具有优势。

Conclusion: 这些方法有望成为加速目标筛选、优化观测计划和最大化HWO等旗舰任务科学回报的有力工具，为未来系外行星观测提供机器学习支持。

Abstract: Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.

</details>


### [344] [Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization](https://arxiv.org/abs/2601.12598)
*Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Emre Neftci*

Main category: cs.LG

TL;DR: 本文提出了SelectivBench——一套轻量级可定制的合成基准任务，用于系统评估序列模型的选择性能力，揭示了线性循环模型关键架构特征的作用。


<details>
  <summary>Details</summary>
Motivation: 线性循环神经网络作为Transformer注意力机制的高效替代方案，但其迭代改进引入了过多的架构机制，导致复杂性增加。现有基准任务要么过于简单无法揭示实质性差异，要么过于资源密集难以实验。需要一种系统化的评估框架来比较这些模型。

Method: 提出SelectivBench基准测试集，使用基于规则的语法生成可调整复杂度的序列，包含故意违反转换规则的不规则间隔。对线性循环模型进行分类，并系统评估它们在选择性能力上的表现。

Result: 评估显示线性循环模型在SelectivBench上的性能模式与大规模语言任务结果一致。分析揭示了关键架构特征的作用：门控和快速遗忘机制有助于回忆；状态内通道混合对选择性不必要但对泛化关键；softmax注意力因内存容量随序列长度扩展而保持优势。

Conclusion: SelectivBench为线性循环模型提供了针对性的高效探索平台，并为研究大规模评估中观察到的行为提供了受控环境。该基准能够系统揭示序列模型架构特征的作用机制。

Abstract: Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at https://github.com/symseqbench/selectivbench

</details>


### [345] [Beyond Softmax and Entropy: Improving Convergence Guarantees of Policy Gradients by f-SoftArgmax Parameterization with Coupled Regularization](https://arxiv.org/abs/2601.12604)
*Safwan Labbi,Daniil Tiapkin,Paul Mangold,Eric Moulines*

Main category: cs.LG

TL;DR: 提出基于广义f-softargmax的策略参数化方法替代softmax，结合f-散度正则化，改进了优化景观并获得了无需预处理的非渐近收敛保证


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法对策略参数化选择高度敏感，常用的softmax参数化会导致病态优化景观和指数级缓慢收敛。预处理虽然能缓解但计算昂贵，需要更高效的解决方案

Method: 提出使用广义f-softargmax参数化替代softmax，并结合相同f-散度的正则化器，形成f-PG方法。特别关注Tsallis散度，该方法能确保正则化目标满足Polyak-Lojasiewicz不等式

Result: 获得了有限MDP中随机策略梯度方法的第一个显式非渐近最后迭代收敛保证（无需预处理）。对于无正则化问题，f-PG（特别是Tsallis散度）实现了多项式样本复杂度，而标准softmax需要指数复杂度

Conclusion: f-softargmax参数化与相应f-散度正则化的组合有效解决了softmax策略梯度方法的收敛问题，为策略优化提供了更高效的理论保证和实际性能

Abstract: Policy gradient methods are known to be highly sensitive to the choice of policy parameterization. In particular, the widely used softmax parameterization can induce ill-conditioned optimization landscapes and lead to exponentially slow convergence. Although this can be mitigated by preconditioning, this solution is often computationally expensive. Instead, we propose replacing the softmax with an alternative family of policy parameterizations based on the generalized f-softargmax. We further advocate coupling this parameterization with a regularizer induced by the same f-divergence, which improves the optimization landscape and ensures that the resulting regularized objective satisfies a Polyak-Lojasiewicz inequality. Leveraging this structure, we establish the first explicit non-asymptotic last-iterate convergence guarantees for stochastic policy gradient methods for finite MDPs without any form of preconditioning. We also derive sample-complexity bounds for the unregularized problem and show that f-PG, with Tsallis divergences achieves polynomial sample complexity in contrast to the exponential complexity incurred by the standard softmax parameterization.

</details>


### [346] [What Trace Powers Reveal About Log-Determinants: Closed-Form Estimators, Certificates, and Failure Modes](https://arxiv.org/abs/2601.12612)
*Piyush Sao*

Main category: cs.LG

TL;DR: 该论文研究了通过迹幂估计大型对称正定矩阵对数行列式的方法，提出了基于矩生成函数的改进方法，证明了有限正矩估计的局限性，并提供了可证明的上下界估计。


<details>
  <summary>Details</summary>
Motivation: 在高斯过程推断和贝叶斯模型比较中，计算大型对称正定矩阵的对数行列式是一个关键问题。传统方法使用矩阵-向量乘积和多项式逼近，但本文探索了一种不同的模型：当矩阵幂可用时，通过迹幂来估计对数行列式。

Method: 1. 使用归一化特征值的矩生成函数 M(t) = E[X^t]，其中 X = λ/AM
2. 通过变换 K(t) = log M(t) 压缩数值范围
3. 利用 K(0) = K(1) = 0 的锚点，在连续整数点间插值 K 函数
4. 通过导数 K'(0) 估计对数行列式
5. 提供基于谱下界的可证明上下界估计
6. 使用间隙诊断判断点估计的可靠性

Result: 1. 证明了使用有限正矩的连续估计器无法在无界条件数下获得一致准确性
2. 提出了计算成本为 O(m) 的估计方法（m=4-8时接近常数时间）
3. 提供了可证明的对数行列式上下界
4. 开发了诊断工具来判断何时信任点估计或报告边界

Conclusion: 该研究提供了一种通过迹幂估计对数行列式的新方法，克服了传统多项式逼近在条件数较大时的发散问题。方法不仅提供点估计，还通过理论分析揭示了有限正矩估计的局限性，并提供了可证明的边界估计，增强了实际应用的可靠性。

Abstract: Computing $\log\det(A)$ for large symmetric positive definite matrices arises in Gaussian process inference and Bayesian model comparison. Standard methods combine matrix-vector products with polynomial approximations. We study a different model: access to trace powers $p_k = \tr(A^k)$, natural when matrix powers are available.
  Classical moment-based approximations Taylor-expand $\log(λ)$ around the arithmetic mean. This requires $|λ- \AM| < \AM$ and diverges when $κ> 4$. We work instead with the moment-generating function $M(t) = \E[X^t]$ for normalized eigenvalues $X = λ/\AM$. Since $M'(0) = \E[\log X]$, the log-determinant becomes $\log\det(A) = n(\log \AM + M'(0))$ -- the problem reduces to estimating a derivative at $t = 0$. Trace powers give $M(k)$ at positive integers, but interpolating $M(t)$ directly is ill-conditioned due to exponential growth. The transform $K(t) = \log M(t)$ compresses this range. Normalization by $\AM$ ensures $K(0) = K(1) = 0$. With these anchors fixed, we interpolate $K$ through $m+1$ consecutive integers and differentiate to estimate $K'(0)$. However, this local interpolation cannot capture arbitrary spectral features.
  We prove a fundamental limit: no continuous estimator using finitely many positive moments can be uniformly accurate over unbounded conditioning. Positive moments downweight the spectral tail; $K'(0) = \E[\log X]$ is tail-sensitive. This motivates guaranteed bounds. From the same traces we derive upper bounds on $(\det A)^{1/n}$. Given a spectral floor $r \leq λ_{\min}$, we obtain moment-constrained lower bounds, yielding a provable interval for $\log\det(A)$. A gap diagnostic indicates when to trust the point estimate and when to report bounds. All estimators and bounds cost $O(m)$, independent of $n$. For $m \in \{4, \ldots, 8\}$, this is effectively constant time.

</details>


### [347] [Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach](https://arxiv.org/abs/2601.12624)
*Shiqi Wang,Mahdi Khosravy,Neeraj Gupta,Olaf Witkowski*

Main category: cs.LG

TL;DR: 提出基于浮点编码、惩罚驱动的单目标进化框架，用于生成更隐蔽、攻击成功率更高的通用对抗扰动。


<details>
  <summary>Details</summary>
Motivation: 通用对抗扰动能用一个噪声模式攻击多个输入，进化算法因其能在非凸、无梯度环境中搜索而成为有前景的生成方法。

Method: 采用浮点编码基因表示以适应深度学习规模，结合动态进化算子和自适应调度，使用模块化PyTorch实现，并通过跨模型测试和周期性批次切换确保通用性。

Result: 在ImageNet数据集上实验表明，相比现有进化方法，该框架能生成范数更小、误分类效果更好、收敛更快的扰动。

Conclusion: 该方法展现了生成通用对抗扰动的鲁棒性和可扩展性，适用于多种深度学习架构。

Abstract: Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.

</details>


### [348] [Topology-Aware Multiscale Mixture of Experts for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.12637)
*Long D. Nguyen,Kelin Xia,Binh P. Nguyen*

Main category: cs.LG

TL;DR: MI-MoE：一种多尺度专家混合模块，通过拓扑感知的路由机制自适应地建模分子3D几何中的短、中、长程相互作用，可插入现有3D分子图神经网络并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D分子图神经网络通常使用固定的距离截断和最大邻居数等启发式方法来定义局部消息传递邻域，导致交互建模僵化且与数据无关。分子性质依赖于3D几何结构，需要自适应地捕捉不同几何尺度下的相互作用。

Method: 提出多尺度交互专家混合(MI-MoE)模块：1) 距离截断专家集合，显式捕获短、中、长程相互作用；2) 拓扑门控编码器，使用基于过滤的描述符（包括持续同调特征）将输入路由到不同专家；3) 作为即插即用模块，可集成到多种3D分子骨干网络中。

Result: MI-MoE在多种分子和聚合物性质预测基准数据集（涵盖回归和分类任务）上，能够持续改进多个强大的3D分子骨干网络的性能。

Conclusion: 拓扑感知的多尺度路由是3D分子图学习的有效原则，MI-MoE通过自适应地建模不同几何尺度下的相互作用，提升了分子性质预测的准确性。

Abstract: Many molecular properties depend on 3D geometry, where non-covalent interactions, stereochemical effects, and medium- to long-range forces are determined by spatial distances and angles that cannot be uniquely captured by a 2D bond graph. Yet most 3D molecular graph neural networks still rely on globally fixed neighborhood heuristics, typically defined by distance cutoffs and maximum neighbor limits, to define local message-passing neighborhoods, leading to rigid, data-agnostic interaction budgets. We propose Multiscale Interaction Mixture of Experts (MI-MoE) to adapt interaction modeling across geometric regimes. Our contributions are threefold: (1) we introduce a distance-cutoff expert ensemble that explicitly captures short-, mid-, and long-range interactions without committing to a single cutoff; (2) we design a topological gating encoder that routes inputs to experts using filtration-based descriptors, including persistent homology features, summarizing how connectivity evolves across radii; and (3) we show that MI-MoE is a plug-in module that consistently improves multiple strong 3D molecular backbones across diverse molecular and polymer property prediction benchmark datasets, covering both regression and classification tasks. These results highlight topology-aware multiscale routing as an effective principle for 3D molecular graph learning.

</details>


### [349] [Explanation Multiplicity in SHAP: Characterization and Assessment](https://arxiv.org/abs/2601.12654)
*Hyunseung Hwang,Seungeun Lee,Lucas Rosenblatt,Julia Stoyanovich,Steven Euijong Whang*

Main category: cs.LG

TL;DR: 论文揭示了SHAP等后验解释方法存在"解释多重性"问题：即使输入、任务和训练模型固定，重复运行SHAP也会产生多个内部有效但实质上不同的特征归因解释。作者提出了量化多重性的方法，并发现该现象普遍存在，即使在高置信度预测中也是如此。


<details>
  <summary>Details</summary>
Motivation: SHAP等后验解释方法常被用于高风险领域决策的验证和审计，但研究发现这些解释在不同运行中会存在显著差异。作者旨在系统研究这种"解释多重性"现象，量化其程度，并分析其来源和影响。

Method: 提出了量化特征归因解释多重性的方法论，区分模型训练/选择与解释管道内在随机性的来源。通过基于幅度和基于排序的度量指标分析解释稳定性，并推导随机基线值作为对比基准。

Result: 研究发现解释多重性普遍存在且持久，即使在高置信度预测中也是如此。基于幅度的度量可能显示稳定性，但基于排序的度量揭示top特征的身份和顺序存在显著变动。

Conclusion: 解释多重性是SHAP等后验解释方法的固有特性，需要开发与解释使用目的相匹配的度量和基线标准。当前解释的稳定性可能具有误导性，实际使用中需谨慎对待。

Abstract: Post-hoc explanations are widely used to justify, contest, and audit automated decisions in high-stakes domains. SHAP, in particular, is often treated as a reliable account of which features drove an individual prediction. Yet SHAP explanations can vary substantially across repeated runs even when the input, task, and trained model are held fixed. We term this phenomenon explanation multiplicity: multiple internally valid but substantively different explanations for the same decision. We present a methodology to characterize multiplicity in feature-attribution explanations and to disentangle sources due to model training/selection from stochasticity intrinsic to the explanation pipeline. We further show that apparent stability depends on the metric: magnitude-based distances can remain near zero while rank-based measures reveal substantial churn in the identity and ordering of top features. To contextualize observed disagreement, we derive randomized baseline values under plausible null models. Across datasets, model classes, and confidence regimes, we find explanation multiplicity is pervasive and persists even for high-confidence predictions, highlighting the need for metrics and baselines that match the intended use of explanations.

</details>


### [350] [Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks](https://arxiv.org/abs/2601.12662)
*Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti*

Main category: cs.LG

TL;DR: 本文提出基于图神经网络的多智能体强化学习框架，用于优化无线网络中自回归马尔可夫源的实时采样与估计策略，该策略可在结构相似的网络间迁移，且能适应非平稳环境。


<details>
  <summary>Details</summary>
Motivation: 在多跳无线网络中，节点通过缓存其他节点的样本并进行无线通信来最小化时间平均估计误差。由于动作空间维度高、网络拓扑复杂，传统分析方法难以获得最优策略。

Method: 提出图多智能体强化学习框架进行策略优化，利用图结构表示网络拓扑，设计可迁移的策略，支持在结构相似的图上直接应用已训练策略。

Result: 数值实验表明：1) 所提策略优于现有基线方法；2) 训练策略可迁移到更大规模网络，且性能增益随智能体数量增加而提升；3) 图训练过程能抵抗非平稳性；4) 循环机制对独立学习和集中训练分散执行都至关重要，并增强了对非平稳性的鲁棒性。

Conclusion: 图多智能体强化学习框架能有效解决复杂无线网络中的实时采样估计问题，所提策略具有可迁移性和对非平稳环境的适应性，为分布式网络优化提供了新思路。

Abstract: We address real-time sampling and estimation of autoregressive Markovian sources in dynamic yet structurally similar multi-hop wireless networks. Each node caches samples from others and communicates over wireless collision channels, aiming to minimize time-average estimation error via decentralized policies. Due to the high dimensionality of action spaces and complexity of network topologies, deriving optimal policies analytically is intractable. To address this, we propose a graphical multi-agent reinforcement learning framework for policy optimization. Theoretically, we demonstrate that our proposed policies are transferable, allowing a policy trained on one graph to be effectively applied to structurally similar graphs. Numerical experiments demonstrate that (i) our proposed policy outperforms state-of-the-art baselines; (ii) the trained policies are transferable to larger networks, with performance gains increasing with the number of agents; (iii) the graphical training procedure withstands non-stationarity, even when using independent learning techniques; and (iv) recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity.

</details>


### [351] [MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning](https://arxiv.org/abs/2601.12680)
*Zheng Fang,Wolfgang Mayer,Zeyu Zhang,Jian Wang,Hong-Yu Zhang,Wanli Li,Zaiwen Feng*

Main category: cs.LG

TL;DR: 提出MetaToolAgent（MTA）元学习方法，通过包含7个领域、155个工具、9377个问答对的综合数据集，提升LLM对未知工具的泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有工具选择方法局限于有限工具集，难以泛化到实际部署中遇到的新工具，限制了LLM在复杂现实任务中的工具协调能力

Method: 引入MetaToolAgent（MTA）元学习方法，通过构建跨7个领域、155个工具、9377个问答对的综合数据集，模拟现实集成场景，提升对未知工具的泛化能力

Result: 实验结果表明MTA在未见工具上显著优于基线方法，展示了构建灵活可扩展动态工具协调系统的潜力

Conclusion: MTA元学习方法能够有效提升LLM对未知工具的泛化能力，为构建灵活可扩展的动态工具协调系统提供了有前景的解决方案

Abstract: Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.

</details>


### [352] [Resource-Conscious RL Algorithms for Deep Brain Stimulation](https://arxiv.org/abs/2601.12699)
*Arkaprava Gupta,Nicholas Carter,William Zellers,Prateek Ganguli,Benedikt Dietrich,Vibhor Krishna,Parasara Sridhar Duggirala,Samarjit Chakraborty*

Main category: cs.LG

TL;DR: 提出一种新的时间与阈值触发的多臂老虎机强化学习方法（T3P MAB），用于帕金森病的自适应脑深部电刺激，能够同时调节频率和振幅，具有更好的样本效率和能耗表现。


<details>
  <summary>Details</summary>
Motivation: 传统脑深部电刺激使用固定频率和振幅，存在副作用和电池寿命短的问题。现有强化学习方法虽能自适应调节，但过于复杂，需要大量计算资源和长时间训练，难以在植入设备上部署。

Method: 提出T3P MAB强化学习方法，基于时间与阈值触发机制。该方法轻量化，无需离线训练阶段，能够在植入设备上实时运行。首次在多款微控制器单元上实现硬件部署，同时调节刺激信号的频率和振幅。

Result: T3P MAB方法比其他现有算法更有效，样本效率更高，收敛时间更短。在硬件上实现并测量能耗，证明其适合资源受限平台，功耗表现优于现有强化学习方法。

Conclusion: T3P MAB方法为脑深部电刺激提供了一种轻量级、自适应、可硬件部署的解决方案，能够同时优化频率和振幅参数，改善患者治疗效果并延长植入设备电池寿命。

Abstract: Deep Brain Stimulation (DBS) has proven to be a promising treatment of Parkinson's Disease (PD). DBS involves stimulating specific regions of the brain's Basal Ganglia (BG) using electric impulses to alleviate symptoms of PD such as tremors, rigidity, and bradykinesia. Although most clinical DBS approaches today use a fixed frequency and amplitude, they suffer from side effects (such as slurring of speech) and shortened battery life of the implant. Reinforcement learning (RL) approaches have been used in recent research to perform DBS in a more adaptive manner to improve overall patient outcome. These RL algorithms are, however, too complex to be trained in vivo due to their long convergence time and requirement of high computational resources.
  We propose a new Time & Threshold-Triggered Multi-Armed Bandit (T3P MAB) RL approach for DBS that is more effective than existing algorithms. Further, our T3P agent is lightweight enough to be deployed in the implant, unlike current deep-RL strategies, and even forgoes the need for an offline training phase. Additionally, most existing RL approaches have focused on modulating only frequency or amplitude, and the possibility of tuning them together remains greatly unexplored in the literature. Our RL agent can tune both frequency and amplitude of DBS signals to the brain with better sample efficiency and requires minimal time to converge. We implement an MAB agent for DBS for the first time on hardware to report energy measurements and prove its suitability for resource-constrained platforms. Our T3P MAB algorithm is deployed on a variety of microcontroller unit (MCU) setups to show its efficiency in terms of power consumption as opposed to other existing RL approaches used in recent work.

</details>


### [353] [Towards Spectroscopy: Susceptibility Clusters in Language Models](https://arxiv.org/abs/2601.12703)
*Andrew Gordon,Garrett Baker,George Wang,William Snell,Stan van Wingerden,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出了一种基于光谱学原理的神经网络分析方法，通过扰动数据分布并测量模型响应（敏感度）来揭示神经网络内部结构，识别出510个可解释的聚类模式。


<details>
  <summary>Details</summary>
Motivation: 受到光谱学通过测量系统对扰动的响应来推断内部结构的启发，作者希望将这一原理应用于神经网络，通过系统性地扰动输入数据来理解模型内部的表示和工作机制。

Method: 使用随机梯度朗之万动力学（SGLD）在局部吉布斯后验上计算敏感度χ_xy，即组件级观测值与数据分布扰动之间的协方差。开发了基于电导的聚类算法来分析敏感度空间中的模式。

Result: 在Pythia-14M模型上识别出510个可解释的聚类，涵盖语法模式、代码结构和数学符号等不同层次。与稀疏自编码器比较发现50%的聚类与SAE特征匹配，验证了两种方法能恢复相似的结构。

Conclusion: 该方法为神经网络的可解释性提供了新的光谱学视角，证明了通过测量模型对数据扰动的响应可以系统性地揭示其内部结构，并且与现有方法的结果具有一致性。

Abstract: Spectroscopy infers the internal structure of physical systems by measuring their response to perturbations. We apply this principle to neural networks: perturbing the data distribution by upweighting a token $y$ in context $x$, we measure the model's response via susceptibilities $χ_{xy}$, which are covariances between component-level observables and the perturbation computed over a localized Gibbs posterior via stochastic gradient Langevin dynamics (SGLD). Theoretically, we show that susceptibilities decompose as a sum over modes of the data distribution, explaining why tokens that follow their contexts "for similar reasons" cluster together in susceptibility space. Empirically, we apply this methodology to Pythia-14M, developing a conductance-based clustering algorithm that identifies 510 interpretable clusters ranging from grammatical patterns to code structure to mathematical notation. Comparing to sparse autoencoders, 50% of our clusters match SAE features, validating that both methods recover similar structure.

</details>


### [354] [Adaptively trained Physics-informed Radial Basis Function Neural Networks for Solving Multi-asset Option Pricing Problems](https://arxiv.org/abs/2601.12704)
*Yan Ma,Yumeng Ren*

Main category: cs.LG

TL;DR: 该研究提出了一种基于径向基函数神经网络(PIRBFNN)的物理信息机器学习算法，用于求解多资产期权定价的Black-Scholes偏微分方程。


<details>
  <summary>Details</summary>
Motivation: 传统方法在解决多维期权定价模型，特别是具有非光滑支付条件时存在计算效率和精度方面的挑战，需要开发更有效的数值求解方法。

Method: 开发了物理信息径向基函数神经网络(PIRBFNN)，结合了传统径向基函数配置法和物理信息神经网络的优势，采用PDE残差技术自适应优化隐藏神经元分布。

Result: 通过单资产欧式看跌期权、双资产交换期权和四资产篮子看涨期权的实验验证了方法的有效性，能够准确高效处理多维非光滑支付条件的期权定价模型。

Conclusion: PIRBFNN方法在金融偏微分方程求解中表现出色，为多维期权定价问题提供了准确高效的数值解决方案。

Abstract: The present study investigates the numerical solution of Black-Scholes partial differential equation (PDE) for option valuation with multiple underlying assets. We develop a physics-informed (PI) machine learning algorithm based on a radial basis function neural network (RBFNN) that concurrently optimizes the network architecture and predicts the target option price. The physics-informed radial basis function neural network (PIRBFNN) combines the strengths of the traditional radial basis function collocation method and the physics-informed neural network machine learning approach to effectively solve PDE problems in the financial context. By employing a PDE residual-based technique to adaptively refine the distribution of hidden neurons during the training process, the PIRBFNN facilitates accurate and efficient handling of multidimensional option pricing models featuring non-smooth payoff conditions. The validity of the proposed method is demonstrated through a set of experiments encompassing a single-asset European put option, a double-asset exchange option, and a four-asset basket call option.

</details>


### [355] [Trend-Adjusted Time Series Models with an Application to Gold Price Forecasting](https://arxiv.org/abs/2601.12706)
*Sina Kazemdehbashi*

Main category: cs.LG

TL;DR: 本文提出TATS模型，将时间序列预测重构为趋势预测和数值预测两部分，通过二元分类器预测趋势方向，再用LSTM/Bi-LSTM预测数值，最后基于趋势调整预测值，在金融时间序列上表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法（包括统计模型和LSTM等神经网络）通常直接预测数值，但作者认为将预测任务分解为趋势预测和数值预测两部分能提升性能。特别是对于波动性强的金融时间序列，准确捕捉趋势方向至关重要。

Method: 提出TATS模型：1）用二元分类器预测下一个时间点的趋势方向（上涨/下跌）；2）用LSTM或Bi-LSTM预测数值；3）基于预测的趋势调整数值预测结果。同时引入趋势检测准确率作为评估指标。

Result: 在黄金价格这一波动性金融时间序列上的实验表明，TATS模型相比标准LSTM和Bi-LSTM取得了显著更低的预测误差。同时发现传统评估指标（MSE、MAE）不足以全面评估模型性能，趋势检测准确率是重要补充指标。

Conclusion: 将时间序列预测重构为趋势预测和数值预测两部分是有效的，TATS模型通过趋势调整机制提升了预测精度。未来评估时间序列模型时应同时考虑数值误差和趋势捕捉能力。

Abstract: Time series data play a critical role in various fields, including finance, healthcare, marketing, and engineering. A wide range of techniques (from classical statistical models to neural network-based approaches such as Long Short-Term Memory (LSTM)) have been employed to address time series forecasting challenges. In this paper, we reframe time series forecasting as a two-part task: (1) predicting the trend (directional movement) of the time series at the next time step, and (2) forecasting the quantitative value at the next time step. The trend can be predicted using a binary classifier, while quantitative values can be forecasted using models such as LSTM and Bidirectional Long Short-Term Memory (Bi-LSTM). Building on this reframing, we propose the Trend-Adjusted Time Series (TATS) model, which adjusts the forecasted values based on the predicted trend provided by the binary classifier. We validate the proposed approach through both theoretical analysis and empirical evaluation. The TATS model is applied to a volatile financial time series (the daily gold price) with the objective of forecasting the next days price. Experimental results demonstrate that TATS consistently outperforms standard LSTM and Bi-LSTM models by achieving significantly lower forecasting error. In addition, our results indicate that commonly used metrics such as MSE and MAE are insufficient for fully assessing time series model performance. Therefore, we also incorporate trend detection accuracy, which measures how effectively a model captures trends in a time series.

</details>


### [356] [Decoding Rewards in Competitive Games: Inverse Game Theory with Entropy Regularization](https://arxiv.org/abs/2601.12707)
*Junyi Liao,Zihan Zhu,Ethan Fang,Zhuoran Yang,Vahid Tarokh*

Main category: cs.LG

TL;DR: 提出统一框架用于零和矩阵博弈与马尔可夫博弈中基于熵正则化的奖励函数恢复，解决逆问题非唯一性与数据有限性挑战，建立可识别性理论并提出高效算法。


<details>
  <summary>Details</summary>
Motivation: 逆强化学习与博弈论中，从观察到的智能体行为推断其内在奖励函数是核心问题。现有方法面临逆问题固有的模糊性、可行奖励的非唯一性以及观测数据覆盖有限等挑战，需要系统性的理论框架与算法。

Method: 1. 建立基于量化响应均衡的奖励函数可识别性理论；2. 提出适用于静态与动态场景的统一奖励函数学习算法；3. 算法可结合最大似然估计等方法；4. 提供理论保证与数值验证。

Result: 1. 在线性假设下证明了奖励函数在量化响应均衡中的可识别性；2. 算法在理论保证下具有可靠性与样本效率；3. 数值研究验证了框架在实际竞争环境中的有效性。

Conclusion: 本文为竞争环境中的奖励函数恢复提供了统一的理论与算法框架，解决了逆问题的非唯一性挑战，为理解竞争决策过程提供了新见解，并在静态与动态场景中均展现出实用价值。

Abstract: Estimating the unknown reward functions driving agents' behaviors is of central interest in inverse reinforcement learning and game theory. To tackle this problem, we develop a unified framework for reward function recovery in two-player zero-sum matrix games and Markov games with entropy regularization, where we aim to reconstruct the underlying reward functions given observed players' strategies and actions. This task is challenging due to the inherent ambiguity of inverse problems, the non-uniqueness of feasible rewards, and limited observational data coverage. To address these challenges, we establish the reward function's identifiability using the quantal response equilibrium (QRE) under linear assumptions. Building upon this theoretical foundation, we propose a novel algorithm to learn reward functions from observed actions. Our algorithm works in both static and dynamic settings and is adaptable to incorporate different methods, such as Maximum Likelihood Estimation (MLE). We provide strong theoretical guarantees for the reliability and sample efficiency of our algorithm. Further, we conduct extensive numerical studies to demonstrate the practical effectiveness of the proposed framework, offering new insights into decision-making in competitive environments.

</details>


### [357] [Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off](https://arxiv.org/abs/2601.12730)
*Zhaochun Li,Chen Wang,Jionghao Bai,Shisheng Cui,Ge Lan,Zhou Zhao,Yue Wang*

Main category: cs.LG

TL;DR: DCPO是一种基于分布中心的强化学习方法，通过分布层面的正则化实现可控熵，解决GRPO训练中探索不足的问题，相比GRPO平均提升20%性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的强化学习训练存在探索不足的问题，熵值单调下降，样本收敛，探索能力衰减。现有的修复方法多是样本中心的，依赖于"幸运"的信息样本，缺乏对策略的原则性控制，效果有限且不稳定。

Method: 提出分布中心策略优化(DCPO)，从分布中心的角度重新思考强化学习，将熵调节重新定义为分布层面的正则化。DCPO完全在策略内实现可控熵，无需从外部分布采样，能够在保持训练稳定性的同时实现高效探索。

Result: 在多个模型和七个基准测试中，DCPO相比GRPO平均提升约20%的性能。该方法用分布层面的原则替代了样本层面的启发式方法，为可控探索和更强的探索-利用权衡提供了理论支撑。

Conclusion: DCPO提供了一种理论上有依据且灵活的框架，用于实现可控探索和更强的探索-利用权衡，解决了现有样本中心方法的局限性。

Abstract: The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in https://github.com/597358816/DCPO.

</details>


### [358] [A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection](https://arxiv.org/abs/2601.12745)
*Miao Ye,Jing Cui,Yuan huang,Qian He,Yong Wang,Jiwen Zhang*

Main category: cs.LG

TL;DR: 本文针对无线传感器网络多时序模态数据的异常检测问题，提出了一种结合时空相关特征提取和图神经网络的自监督多任务学习框架，在公开数据集和实际数据集上取得了优异的检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前多时序模态数据异常检测方法存在时空相关特征提取不足、异常样本标注成本高、样本不平衡等问题，需要针对WSN图结构数据特点设计更有效的检测方案。

Method: 1. 改进Mamba模型，结合多尺度策略和模态间融合方法，设计包含变分图卷积模块的异常检测骨干网络；2. 设计"预训练-图提示-微调"的自监督多任务训练策略，包含无负对比学习、预测和重构三个子任务。

Result: 在公开数据集和实际采集数据集上，F1指标分别达到91.30%和92.31%，相比现有方法具有更好的检测性能和泛化能力。

Conclusion: 提出的结合时空相关特征提取和自监督多任务学习的框架能有效解决WSN多时序模态数据异常检测的挑战，降低标注成本并提升检测性能。

Abstract: Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.

</details>


### [359] [A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining](https://arxiv.org/abs/2601.12751)
*Manjish Pal*

Main category: cs.LG

TL;DR: 该论文提出了基于布尔函数理论的图神经网络表达性分析框架，引入子群体布尔同构概念，并设计了能处理高复杂度布尔函数定义子群体的公平算法。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络的表达性分析框架（如Weisfeiler-Lehman、双连通性、同态等）无法充分捕捉复杂子群体结构，特别是在公平性应用中处理由高复杂度布尔函数定义的子群体时存在局限性。

Method: 1. 提出基于布尔函数理论的表达性分析框架；2. 引入子群体布尔同构作为新的表达性度量；3. 识别傅里叶度、电路类别和影响作为表达性的关键障碍；4. 设计基于电路遍历的公平算法，能够处理如奇偶性等高复杂度布尔函数定义的子群体。

Result: 1. 理论证明子群体布尔同构严格包含现有表达性度量；2. 在真实世界图上实验表明，该方法在现有方法失败的交叉群体上实现了较低的公平性差距；3. 提供了首个专门针对公平性的图神经网络表达性原理性处理。

Conclusion: 该研究为图神经网络的表达性分析提供了新的理论框架，特别针对公平性应用，提出的算法能够有效处理复杂布尔函数定义的子群体，为解决图神经网络中的公平性问题提供了理论基础和实用方法。

Abstract: We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.

</details>


### [360] [Eddy-Resolving Global Ocean Forecasting with Multi-Scale Graph Neural Networks](https://arxiv.org/abs/2601.12775)
*Yuta Hirabayashi,Daisuke Matusoka,Konobu Kimura*

Main category: cs.LG

TL;DR: 提出基于多尺度图神经网络的全球海洋预报模型，改进10天短期预测精度和多尺度海洋变率表征


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的海洋模型在全球涡旋解析预报中应用有限，准确表征多尺度海洋动力学仍面临挑战

Method: 采用编码器-处理器-解码器架构，使用两种不同分辨率的球面网格捕获多尺度海洋动力学，结合海洋状态变量和大气表面变量作为节点输入

Result: 模型准确表征了广泛的空间尺度，短期预测的均方根误差显示预测技能有所改进

Conclusion: 该模型提供了更准确的短期预报和改进的多尺度海洋动力学表征，有潜力推进数据驱动的全球涡旋解析海洋预报

Abstract: Research on data-driven ocean models has progressed rapidly in recent years; however, the application of these models to global eddy-resolving ocean forecasting remains limited. The accurate representation of ocean dynamics across a wide range of spatial scales remains a major challenge in such applications. This study proposes a multi-scale graph neural network-based ocean model for 10-day global forecasting that improves short-term prediction skill and enhances the representation of multi-scale ocean variability. The model employs an encoder-processor-decoder architecture and uses two spherical meshes with different resolutions to better capture the multi-scale nature of ocean dynamics. In addition, the model incorporates surface atmospheric variables along with ocean state variables as node inputs to improve short-term prediction accuracy by representing atmospheric forcing. Evaluation using surface kinetic energy spectra and case studies shows that the model accurately represents a broad range of spatial scales, while root mean square error comparisons demonstrate improved skill in short-term predictions. These results indicate that the proposed model delivers more accurate short-term forecasts and improved representation of multi-scale ocean dynamics, thereby highlighting its potential to advance data-driven, eddy-resolving global ocean forecasting.

</details>


### [361] [Distilling Time Series Foundation Models for Efficient Forecasting](https://arxiv.org/abs/2601.12785)
*Yuqi Li,Kuiye Ding,Chuanguang Yang,Szu-Yu Chen,Yingli Tian*

Main category: cs.LG

TL;DR: DistilTS是首个专门为时间序列基础模型设计的知识蒸馏框架，通过水平加权目标和时间对齐策略解决任务难度差异和架构差异问题，能在保持预测性能的同时大幅压缩模型参数并加速推理。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型虽然预测性能强，但参数量大导致部署成本高。现有的知识蒸馏技术针对通用机器学习任务设计，不适用于时间序列预测的特殊需求，需要专门针对TSFMs的蒸馏框架。

Method: DistilTS提出两个关键技术：1) 水平加权目标，平衡不同预测水平的学习权重，避免短期预测主导优化；2) 时间对齐策略，减少教师模型和学生模型之间的架构差异，在时间序列预测中实现更好的对齐。

Result: 在多个基准测试中，DistilTS实现了与完整大小TSFMs相当的预测性能，同时将参数减少高达1/150，推理速度提升高达6000倍。

Conclusion: DistilTS成功解决了TSFMs知识蒸馏中的任务难度差异和架构差异问题，为时间序列基础模型的高效部署提供了有效的压缩解决方案。

Abstract: Time Series foundation models (TSFMs) deliver strong forecasting performance through large-scale pretraining, but their large parameter sizes make deployment costly. While knowledge distillation offers a natural and effective approach for model compression, techniques developed for general machine learning tasks are not directly applicable to time series forecasting due to the unique characteristics. To address this, we present DistilTS, the first distillation framework specifically designed for TSFMs. DistilTS addresses two key challenges: (1) task difficulty discrepancy, specific to forecasting, where uniform weighting makes optimization dominated by easier short-term horizons, while long-term horizons receive weaker supervision; and (2) architecture discrepancy, a general challenge in distillation, for which we design an alignment mechanism in the time series forecasting. To overcome these issues, DistilTS introduces horizon-weighted objectives to balance learning across horizons, and a temporal alignment strategy that reduces architectural mismatch, enabling compact models. Experiments on multiple benchmarks demonstrate that DistilTS achieves forecasting performance comparable to full-sized TSFMs, while reducing parameters by up to 1/150 and accelerating inference by up to 6000x. Code is available at: https://github.com/itsnotacie/DistilTS-ICASSP2026.

</details>


### [362] [Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs](https://arxiv.org/abs/2601.12807)
*Zixing Song,Irwin King*

Main category: cs.LG

TL;DR: 提出SIT-Graph框架，通过半监督指令微调解决图学习中标注数据稀缺问题，利用未标注节点增强LLMs在图任务上的性能


<details>
  <summary>Details</summary>
Motivation: 当前图指令微调方法需要大量标注数据，但在社交等领域获取专家标注成本高且慢，且未充分利用未标注节点中的潜在关联信息

Method: 提出模型无关的SIT-Graph框架，采用迭代自训练过程：先用标注节点微调模型，然后为未标注节点生成置信度过滤的伪响应，以此策略性增强数据集进行下一轮微调

Result: 将SIT-Graph集成到最先进的图指令微调方法中，在文本属性图基准测试上显著提升性能，在低标注比例设置下实现超过20%的改进

Conclusion: SIT-Graph有效解决了图学习中标注数据稀缺问题，通过半监督学习充分利用未标注节点信息，为LLMs在图分析任务中的应用提供了更高效的解决方案

Abstract: The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.

</details>


### [363] [Fisher-Orthogonal Projected Natural Gradient Descent for Continual Learning](https://arxiv.org/abs/2601.12816)
*Ishir Garg,Neel Kolhe,Andy Peng,Rohan Gopalam*

Main category: cs.LG

TL;DR: 提出FOPNG优化器，通过Fisher正交投影约束参数更新，在连续学习中防止灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 连续学习需要神经网络在顺序任务中获得新知识，但关键挑战是在学习新任务时避免灾难性遗忘旧任务知识

Method: 提出Fisher正交投影自然梯度下降(FOPNG)优化器，将梯度投影到先前任务梯度的Fisher正交补空间，在信息几何框架下统一自然梯度下降和正交梯度方法

Result: 在标准连续学习基准测试(Permuted-MNIST、Split-MNIST、Rotated-MNIST、Split-CIFAR10、Split-CIFAR100)上表现出强结果

Conclusion: FOPNG通过Fisher正交约束提供了对参数更新的理论保证，更新方向具有重参数化不变性，保证在Fisher度量下的下降，并有助于保留先前任务的输出

Abstract: Continual learning aims to enable neural networks to acquire new knowledge on sequential tasks. However, the key challenge in such settings is to learn new tasks without catastrophically forgetting previously learned tasks. We propose the Fisher-Orthogonal Projected Natural Gradient Descent (FOPNG) optimizer, which enforces Fisher-orthogonal constraints on parameter updates to preserve old task performance while learning new tasks. Unlike existing methods that operate in Euclidean parameter space, FOPNG projects gradients onto the Fisher-orthogonal complement of previous task gradients. This approach unifies natural gradient descent with orthogonal gradient methods within an information-geometric framework. The resulting update direction is invariant under reparameterization, guarantees descent in the Fisher metric, and helps preserve prior task outputs. We provide theoretical analysis establishing the properties of the projected update, describe efficient and practical implementations using the diagonal Fisher, and demonstrate strong results on standard continual learning benchmarks such as Permuted-MNIST, Split-MNIST, Rotated-MNIST, Split-CIFAR10, and Split-CIFAR100.

</details>


### [364] [Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations](https://arxiv.org/abs/2601.12839)
*Gyuyeon Na,Minjung Park,Soyoun Kim,Jungbin Shin,Sangmi Chai*

Main category: cs.LG

TL;DR: RDLI框架通过嵌入专家启发式逻辑信号和宏观经济上下文，在极端标签稀缺下显著提升加密货币异常轨迹检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有GNN方法在检测加密货币异常交易轨迹时面临两大挑战：一是极端标签稀缺（仅0.01%），二是传统GNN难以捕捉资金分散、分层等逻辑驱动的多跳洗钱模式，限制了其在FATF旅行规则等监管要求下的取证可问责性。

Method: 提出关系域逻辑集成（RDLI）框架，将专家启发式规则转化为可微分的逻辑感知潜在信号嵌入表示学习。同时引入检索基础上下文（RGC）模块，将异常评分条件化于监管和宏观经济上下文，减少因良性市场波动导致的误报。

Result: 在极端标签稀缺（0.01%）条件下，RDLI比最先进的GNN基线方法在F1分数上提升28.9%。微观专家用户研究进一步证实，RDLI的路径级解释在可信度、实用性和清晰度方面显著优于现有方法。

Conclusion: 将领域逻辑与上下文基础相结合对于提高加密货币异常检测的准确性和可解释性至关重要。RDLI框架不仅能检测传统消息传递方法难以发现的复杂交易流，还能提供更可信的解释，满足监管合规要求。

Abstract: Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.

</details>


### [365] [Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates](https://arxiv.org/abs/2601.12859)
*Luca Schaufelberger,Aline Hartgers,Kjell Jorner*

Main category: cs.LG

TL;DR: PuckerFlow是一个用于环状分子构象生成的机器学习模型，通过在Cremer-Pople空间进行流匹配，能够高效可靠地生成多样且精确的环状构象。


<details>
  <summary>Details</summary>
Motivation: 环状分子在化学和生物学中广泛应用，其受限的构象柔性对药物发现和催化功能至关重要，但可靠采样环系统的构象集合仍然具有挑战性。

Method: 引入PuckerFlow生成模型，在Cremer-Pople空间进行流匹配，这是一个捕捉环相关自由度的低维内部坐标系，能够设计性地生成有效闭合环。

Result: PuckerFlow在几乎所有定量指标上都优于其他构象生成方法，能够生成既多样又精确的构象，特别适用于催化和药物发现中的环系统。

Conclusion: 该工作实现了环状结构的高效可靠构象生成，为建模结构-性质关系和跨化学与生物学应用的属性引导环生成铺平了道路。

Abstract: Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.

</details>


### [366] [Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition](https://arxiv.org/abs/2601.12879)
*Mohammed Mudassir Uddin,Shahnawaz Alam,Mohammed Kaif Pasha*

Main category: cs.LG

TL;DR: HAGD框架将神经网络电路发现复杂度从O(2^n)降至O(n² log n)，通过分层抽象、可微搜索和多分辨率方法提取可解释计算电路。


<details>
  <summary>Details</summary>
Motivation: 现有机制可解释性方法面临指数级搜索复杂性和普遍多义性问题，难以从十亿参数语言模型中提取稀疏计算电路。

Method: 提出分层归因图分解(HAGD)框架，包含跨层转码器提取单义特征、图神经网络元学习预测拓扑结构、因果干预协议验证电路。

Result: 在GPT-2、Llama-7B到70B、Pythia模型上验证，模块算术任务行为保留达91%，可解释子图规模可控，跨架构电路结构相似度平均67%。

Conclusion: 该框架为大规模模型可解释性提供初步基础，同时揭示了当前归因方法的显著局限性，需要未来进一步改进。

Abstract: Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.

</details>


### [367] [AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs](https://arxiv.org/abs/2601.12893)
*Ting Dang,Soumyajit Chatterjee,Hong Jia,Yu Wu,Flora Salim,Fahim Kawsar*

Main category: cs.LG

TL;DR: AdaNODEs：针对时间序列预测任务的源无关测试时自适应方法，利用神经常微分方程适应分布偏移，仅需更新有限参数，在单维和高维数据上分别相对提升5.88%和28.4%。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法主要针对独立数据设计，忽视了时间序列数据的特性和预测任务的需求，需要专门针对时间序列预测的源无关自适应方法。

Method: 基于神经常微分方程构建自适应框架，考虑时间序列分布偏移的独特特性，提出新的损失函数专门处理预测任务的自适应，仅更新有限模型参数以减少内存使用。

Result: 在单维和高维时间序列数据上分别相对现有最优方法提升5.88%和28.4%，在更高严重程度的分布偏移下表现出更强的鲁棒性。

Conclusion: AdaNODEs有效解决了时间序列预测中的测试时自适应问题，通过神经常微分方程框架和新损失函数，在保持低内存消耗的同时显著提升预测性能。

Abstract: Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.

</details>


### [368] [Supervised Learning for the (s,S) Inventory Model with General Interarrival Demands and General Lead Times](https://arxiv.org/abs/2601.12900)
*Eliran Sherzer,Yonit Barron*

Main category: cs.LG

TL;DR: 提出基于神经网络的监督学习框架，用于近似(s,S)库存系统在非马尔可夫设置下的稳态性能指标，替代昂贵的仿真计算。


<details>
  <summary>Details</summary>
Motivation: 传统(s,S)库存模型在非马尔可夫系统（需求间隔时间和提前期服从一般分布）中分析困难，通常依赖成本高昂的仿真来评估长期性能指标。

Method: 1. 使用仿真生成训练标签；2. 训练神经网络模型；3. 输入少量低阶矩分布特征；4. 预测库存水平稳态分布、期望周期时间、缺货概率等指标。

Result: 神经网络能提供近乎即时的性能预测，仅需少量分布矩作为输入即可准确捕捉稳态分布，在广泛系统参数范围内表现出高精度，有效替代重复昂贵的仿真运行。

Conclusion: 该框架为分析复杂随机系统提供了高效快速的替代方案，且易于扩展到其他库存模型。

Abstract: The continuous-review (s,S) inventory model is a cornerstone of stochastic inventory theory, yet its analysis becomes analytically intractable when dealing with non-Markovian systems. In such systems, evaluating long-run performance measures typically relies on costly simulation.
  This paper proposes a supervised learning framework via a neural network model for approximating stationary performance measures of (s,S) inventory systems with general distributions for the interarrival time between demands and lead times under lost sales. Simulations are first used to generate training labels, after which the neural network is trained. After training, the neural network provides almost instantaneous predictions of various metrics of the system, such as the stationary distribution of inventory levels, the expected cycle time, and the probability of lost sales. We find that using a small number of low-order moments of the distributions as input is sufficient to train the neural networks and to accurately capture the steady-state distribution. Extensive numerical experiments demonstrate high accuracy over a wide range of system parameters. As such, it effectively replaces repeated and costly simulation runs. Our framework is easily extendable to other inventory models, offering an efficient and fast alternative for analyzing complex stochastic systems.

</details>


### [369] [Deep Temporal Graph Clustering: A Comprehensive Benchmark and Datasets](https://arxiv.org/abs/2601.12903)
*Meng Liu,Ke Liang,Siwei Wang,Xingchen Hu,Sihang Zhou,Xinwang Liu*

Main category: cs.LG

TL;DR: 该论文提出了针对时间图聚类任务的新基准BenchTGC，解决了现有聚类技术不适用和数据集不适用两大挑战。


<details>
  <summary>Details</summary>
Motivation: 时间图聚类是一个新兴但关注度不足的任务，现有静态图聚类方法无法直接适用，且缺乏专门的数据集，阻碍了该领域的发展。

Method: 提出了BenchTGC基准框架，包括：1）设计时间图聚类范式框架；2）改进现有聚类技术以适应时间图；3）开发专门适用于时间图聚类任务的数据集。

Result: 通过大量实验验证了BenchTGC的优势，证明了时间图聚类任务的必要性和重要性，展示了其在动态复杂现实场景中的基础作用。

Conclusion: BenchTGC为时间图聚类研究提供了首个全面基准，解决了技术和数据集两大瓶颈，推动了该领域的发展，并开源了代码和数据。

Abstract: Temporal Graph Clustering (TGC) is a new task with little attention, focusing on node clustering in temporal graphs. Compared with existing static graph clustering, it can find the balance between time requirement and space requirement (Time-Space Balance) through the interaction sequence-based batch-processing pattern. However, there are two major challenges that hinder the development of TGC, i.e., inapplicable clustering techniques and inapplicable datasets. To address these challenges, we propose a comprehensive benchmark, called BenchTGC. Specially, we design a BenchTGC Framework to illustrate the paradigm of temporal graph clustering and improve existing clustering techniques to fit temporal graphs. In addition, we also discuss problems with public temporal graph datasets and develop multiple datasets suitable for TGC task, called BenchTGC Datasets. According to extensive experiments, we not only verify the advantages of BenchTGC, but also demonstrate the necessity and importance of TGC task. We wish to point out that the dynamically changing and complex scenarios in real world are the foundation of temporal graph clustering. The code and data is available at: https://github.com/MGitHubL/BenchTGC.

</details>


### [370] [CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction](https://arxiv.org/abs/2601.12917)
*He Sun,Jinrui Zhou,Li Li,Mingjun Xiao*

Main category: cs.LG

TL;DR: CooperLLM是一个云辅助的边缘-端协同联邦微调框架，结合移动设备上的零阶优化和云端的梯度修正，显著降低内存使用并提升收敛速度和精度。


<details>
  <summary>Details</summary>
Motivation: 在移动设备上微调大语言模型面临高内存和计算成本挑战，而现有的联邦学习方法要么依赖内存密集的反向传播，要么使用收敛慢、精度低的零阶优化方法。

Method: 提出CooperLLM框架：移动客户端在私有数据上执行轻量级零阶优化更新，云端在辅助公共数据上使用反向传播微调，并通过注入引导扰动来修正本地更新。采用流水线调度和自适应压缩来优化计算通信重叠和内存使用。

Result: 在多个Transformer模型和数据集上的实验表明，CooperLLM将设备内存减少高达86.4%，加速收敛8.8倍，并比最先进的零阶优化基线提升准确率高达10个百分点。

Conclusion: CooperLLM通过云辅助的边缘-端协同设计，有效解决了移动设备上大语言模型联邦微调的内存和收敛问题，在保护隐私的同时实现了高效的个性化。

Abstract: Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.

</details>


### [371] [An efficient heuristic for geometric analysis of cell deformations](https://arxiv.org/abs/2601.12928)
*Yaima Paz Soto,Silena Herold Garcia,Ximo Gual-Arnau,Antoni Jaume-i-Capó,Manuel González-Hidalgo*

Main category: cs.LG

TL;DR: 提出一种基于形状空间和模板对齐的镰状红细胞自动分类方法，通过固定参数化和模板对齐简化计算，在监督分类和无监督聚类中达到96.03%准确率。


<details>
  <summary>Details</summary>
Motivation: 镰状细胞病导致红细胞变形，影响血液流动和氧气输送，全球患病率高且对医疗系统负担重。自动分类镰状细胞对减少专家工作量、避免量化错误和评估病情严重性至关重要。

Method: 将红细胞建模为形状空间中的封闭平面曲线，采用弹性距离（对旋转、平移、缩放和重新参数化不变）。创新点包括：(1) 基于细胞主轴使用固定参数化计算距离；(2) 在计算距离前，使用该参数化将每个细胞与两个模板对齐。这简化了计算，无需在所有可能参数化中最小化距离。

Result: 在监督分类和无监督聚类中均达到96.03%的准确率。方法在保持或提高形状空间模型准确性的同时，显著降低了计算成本。

Conclusion: 该方法实现了高效的红细胞分类，通过固定参数化和模板对齐策略，在保证高准确率的前提下大幅减少了计算复杂度，适用于资源有限地区。

Abstract: Sickle cell disease causes erythrocytes to become sickle-shaped, affecting their movement in the bloodstream and reducing oxygen delivery. It has a high global prevalence and places a significant burden on healthcare systems, especially in resource-limited regions. Automated classification of sickle cells in blood images is crucial, allowing the specialist to reduce the effort required and avoid errors when quantifying the deformed cells and assessing the severity of a crisis. Recent studies have proposed various erythrocyte representation and classification methods. Since classification depends solely on cell shape, a suitable approach models erythrocytes as closed planar curves in shape space. This approach employs elastic distances between shapes, which are invariant under rotations, translations, scaling, and reparameterizations, ensuring consistent distance measurements regardless of the curves' position, starting point, or traversal speed. While previous methods exploiting shape space distances had achieved high accuracy, we refined the model by considering the geometric characteristics of healthy and sickled erythrocytes. Our method proposes (1) to employ a fixed parameterization based on the major axis of each cell to compute distances and (2) to align each cell with two templates using this parameterization before computing distances. Aligning shapes to templates before distance computation, a concept successfully applied in areas such as molecular dynamics, and using a fixed parameterization, instead of minimizing distances across all possible parameterizations, simplifies calculations. This strategy achieves 96.03\% accuracy rate in both supervised classification and unsupervised clustering. Our method ensures efficient erythrocyte classification, maintaining or improving accuracy over shape space models while significantly reducing computational costs.

</details>


### [372] [Online Continual Learning for Time Series: a Natural Score-driven Approach](https://arxiv.org/abs/2601.12931)
*Edoardo Urettini,Daniele Atzeni,Ioanna-Yvonni Tsaknaki,Antonio Carta*

Main category: cs.LG

TL;DR: NatSR方法将在线持续学习与时间序列预测结合，通过自然梯度下降和t分布似然实现鲁棒优化，结合重放缓冲和动态尺度启发式方法，在变化环境中取得优于现有方法的预测性能。


<details>
  <summary>Details</summary>
Motivation: 在线持续学习（OCL）方法能够在变化环境中适应新知识而不遗忘过去知识，这与在线时间序列预测（OTSF）的需求高度契合——OTSF需要在时间演变的数据中同时实现快速适应和长期记忆。现有研究已经将OCL应用于OTSF，但理论和实践联系仍需加强。

Method: 1. 将神经网络优化重构为参数滤波问题，证明自然梯度下降是一种得分驱动方法并证明其信息理论最优性
2. 使用Student's t分布似然结合自然梯度实现有界更新，提高对异常值的鲁棒性
3. 提出NatSR方法，结合鲁棒优化器、重放缓冲和动态尺度启发式方法，改进在机制漂移时的快速适应能力

Result: 实证结果表明，NatSR在预测性能上优于更复杂的现有先进方法，证明了该方法在在线时间序列预测中的有效性。

Conclusion: 通过建立时间序列方法与在线持续学习之间的理论和实践联系，NatSR方法成功地将鲁棒优化技术与重放缓冲机制结合，在变化环境中实现了更好的预测性能，为在线时间序列预测提供了新的有效解决方案。

Abstract: Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.

</details>


### [373] [Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning](https://arxiv.org/abs/2601.12965)
*Doheon Kim*

Main category: cs.LG

TL;DR: 论文为基于分数的扩散模型提供了理论解释，说明为什么使用乘法噪声调节的神经网络模型虽然不能完全学习正确的分数函数，但在实践中仍能生成令人满意的样本。


<details>
  <summary>Details</summary>
Motivation: Song和Ermon（2020）的研究表明，使用乘法噪声调节的神经网络虽然不能完全学习正确的分数函数，但实践中仍能生成好的样本。这一矛盾现象缺乏理论解释，本文旨在填补这一空白。

Method: 通过研究相关微分方程的确定性动力学，分析基于分数的扩散模型的采样过程，为乘法噪声调节模型的有效性提供理论解释。

Result: 研究揭示了尽管乘法噪声调节的模型结构限制了其表示空间变量与噪声之间更一般关系的能力，但通过分析确定性动力学，可以解释为什么这些模型在实践中仍然有效。

Conclusion: 本文为基于分数的扩散模型中乘法噪声调节方法的有效性提供了理论依据，解释了模型结构限制与实践表现良好之间的看似矛盾现象。

Abstract: Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.

</details>


### [374] [Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients](https://arxiv.org/abs/2601.12971)
*Pancheng Niu,Jun Guo,Qiaolin He,Yongming Chen,Yanchao Shi*

Main category: cs.LG

TL;DR: 论文提出ACR-PINN框架，通过层动态注意力机制增强表示能力，采用冲突解决梯度更新策略优化训练，显著提升PINN求解PDE的性能。


<details>
  <summary>Details</summary>
Motivation: 传统PINN存在表示能力有限和优化困难的问题，特别是在处理竞争物理约束和冲突梯度时性能受限，需要从架构-优化协同设计的角度改进。

Method: 1. 提出层动态注意力机制(LDA-PINN)增强表示灵活性；2. 将PINN训练重构为多任务学习问题，引入冲突解决梯度更新策略(GC-PINN)；3. 整合两者形成ACR-PINN框架，保持标准PINN损失形式。

Result: 在Burgers、Helmholtz、Klein-Gordon方程和盖驱动空腔流等基准PDE问题上，ACR-PINN相比标准PINN收敛更快，相对L2和L∞误差显著降低。

Conclusion: 架构-优化协同设计能有效提升PINN求解器的鲁棒性和精度，为改进物理信息神经网络提供了新思路。

Abstract: Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.

</details>


### [375] [PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient](https://arxiv.org/abs/2601.12988)
*Zijian Wang,Tiancheng Huang,Hanqi Li,Da Ma,Lu Chen,Kai Yu*

Main category: cs.LG

TL;DR: PaperCompass框架通过分离高层规划与细粒度执行，使用Draft-and-Follow Policy Optimization训练方法，在科学论文问答任务中提高效率而不牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 科学文献快速增长使得研究人员难以通过人工阅读跟踪新进展。现有基于大语言模型的自主代理方法要么依赖工程化提示，要么使用传统SFT-RL训练流程，两者都可能导致过度探索和低效产出。

Method: 提出PaperCompass框架，将高层规划与细粒度执行分离：先起草显式计划大纲行动序列，然后通过详细推理实例化每个步骤（选择函数调用参数）。引入Draft-and-Follow Policy Optimization训练方法，联合优化草稿计划和最终解决方案，可视为轻量级分层强化学习。

Result: 在基于论文的问答基准测试中，PaperCompass相比强基线提高了效率而不牺牲性能，达到与更大模型相当的结果。理论分析支持DFPO具有有利的优化特性，确保稳定可靠的训练过程。

Conclusion: PaperCompass通过分离规划与执行、采用DFPO训练方法，有效缩小了大语言模型中的"知-行"差距，为科学文献处理提供了更高效的自主代理解决方案。

Abstract: The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.

</details>


### [376] [HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads](https://arxiv.org/abs/2601.13013)
*Xiaohui Zhao,Xinjian Zhao,Jiahui Zhang,Guoyu Liu,Houzhi Wang,Shu Wu*

Main category: cs.LG

TL;DR: 提出HT-GNN模型，通过超图监督模块、Transformer时序编码器和任务自适应专家混合机制，解决新闻流广告中LTV预测面临的用户群体异质性和动态行为序列挑战。


<details>
  <summary>Details</summary>
Motivation: 新闻流广告中的LTV预测面临两大挑战：1）基于人口统计的目标定位导致不同用户群体的LTV分布差异巨大；2）动态营销策略产生不规则的行为序列，用户参与模式快速变化。需要同时建模人口统计异质性和时间动态性。

Method: 提出超时序图神经网络（HT-GNN），包含三个核心组件：1）超图监督模块捕获跨用户群体的关系；2）基于Transformer的时间编码器，具有自适应加权机制；3）任务自适应专家混合，包含动态预测塔，用于多时间范围的LTV预测。

Result: 在百度广告平台的1500万用户数据上进行实验，HT-GNN在所有指标和预测时间范围上都持续优于现有最先进方法。

Conclusion: HT-GNN通过联合建模人口统计异质性和时间动态性，有效解决了LTV预测中的挑战，为新闻流广告平台的竞价和预算分配优化提供了有力工具。

Abstract: Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.

</details>


### [377] [PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning](https://arxiv.org/abs/2601.13020)
*Zhiyan Hou,Haiyun Guo,Haokai Ma,Yandu Sun,Yonghui Yang,Jinqiao Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的持续指令调优方法PASs-MoE-LoRA，通过路径激活子空间来校准路由和稳定重要秩方向，解决了传统MoE-LoRA方法中路由器和专家共同漂移的问题，在保持准确性的同时有效减轻遗忘。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在持续指令调优中面临灾难性遗忘问题。现有的基于LoRA的混合专家方法中，路由器和专家被无差别地联合更新，导致路由偏好与专家适应路径共同漂移，逐渐偏离早期阶段的输入-专家专业化，这种现象被称为"未对齐共同漂移"，会模糊专家职责并加剧遗忘。

Method: 提出路径激活子空间(PASs)，这是一个由LoRA诱导的子空间，反映了每个专家中哪些低秩路径方向被输入激活。基于PASs，提出固定容量的PASs-MoE-LoRA方法，包含两个组件：1) PAS引导的重新加权，使用每个专家的路径激活信号校准路由；2) PAS感知的秩稳定，选择性地稳定对先前任务重要的秩方向。

Result: 在持续指令调优基准测试中，该方法在准确性和抗遗忘性方面一致优于一系列传统持续学习基线和MoE-LoRA变体，且不增加额外参数。

Conclusion: PASs-MoE-LoRA方法通过路径激活子空间有效解决了持续指令调优中的路由漂移问题，在保持模型容量的同时显著提升了抗遗忘能力，为多模态大语言模型的持续学习提供了有效的解决方案。

Abstract: Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.

</details>


### [378] [Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis](https://arxiv.org/abs/2601.13021)
*Nataša Petrović,Gabriel Moyà-Alcover,Antoni Jaume-i-Capó,Jose Maria Buades Rubio*

Main category: cs.LG

TL;DR: 提出一种基于集成学习的镰状细胞病诊断支持系统，通过特征选择和模型优化实现更好的泛化性能


<details>
  <summary>Details</summary>
Motivation: 为镰状细胞病提供基于外周血涂片图像的自动化诊断支持，关注模型的泛化能力和可解释性

Method: 预处理和分割显微图像，提取高质量特征；使用集成机器学习方法（随机森林和额外树分类器）进行分类；开发特征重要性分析方法以减少复杂性和提高可解释性

Result: 随机森林和额外树分类器集成获得F1分数90.71%，SDS分数93.33%，优于梯度提升分类器（F1 87.32%，SDS 89.51%），在新数据集上表现出更好的泛化性能

Conclusion: 所提出的集成学习方法在镰状细胞病诊断中表现出优异的泛化能力和分类性能，通过特征选择提高了模型可解释性，为临床诊断提供了有效支持

Abstract: This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.

</details>


### [379] [Analysis of Long Range Dependency Understanding in State Space Models](https://arxiv.org/abs/2601.13048)
*Srividya Ravikumar,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.LG

TL;DR: 对S4D模型进行首个系统性核可解释性研究，分析其在真实世界源代码漏洞检测任务中的表现，发现不同架构下S4D核呈现不同滤波特性，影响长程建模能力。


<details>
  <summary>Details</summary>
Motivation: 虽然状态空间模型在长序列任务上表现优异，但现有研究大多关注预测准确性而忽视可解释性。本研究旨在填补这一空白，对S4D模型进行系统性核可解释性分析。

Method: 通过在时域和频域分析S4D核，研究其在真实世界源代码漏洞检测任务中的表现。分析不同模型架构下S4D核的行为特性。

Result: 研究发现S4D的长程建模能力在不同架构下差异显著，直接影响模型性能。S4D核可表现为低通、带通或高通滤波器，具体取决于架构设计。

Conclusion: 分析结果为设计更好的S4D基模型提供了指导，强调了架构选择对模型滤波特性和长程建模能力的重要影响。

Abstract: Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.

</details>


### [380] [TinyML-Enabled IoT for Sustainable Precision Irrigation](https://arxiv.org/abs/2601.13054)
*Kamogelo Taueatsoala,Caitlyn Daniels,Angelina J. Ramsunar,Petrus Bronkhorst,Absalom E. Ezugwu*

Main category: cs.LG

TL;DR: 本文提出了一种面向小规模农户的边缘优先物联网框架，集成TinyML实现离线精准灌溉，显著降低用水量并适用于网络受限的农村环境。


<details>
  <summary>Details</summary>
Motivation: 小规模农户面临水资源短缺、气候模式不稳定以及缺乏先进、可负担的农业技术等问题，需要一种无需云依赖的智能灌溉解决方案。

Method: 采用四层架构，使用低成本硬件（ESP32微控制器作为边缘推理节点，Raspberry Pi作为本地边缘服务器），集成多种环境传感器，通过比较集成模型选择梯度提升作为最优算法，并转换为轻量级TinyML推理引擎部署到ESP32上，使用基于MQTT的局域网协议进行本地通信。

Result: 梯度提升模型表现最佳（R²=0.9973，MAPE=0.99%），优于随机森林模型（R²=0.9916，MAPE=1.81%）。部署后的系统在受控环境中显著降低用水量，预测灌溉需求的准确度高（MAPE<1%），离线功能验证了其在资源受限农村环境中的可行性。

Conclusion: 该研究提供了一个实用、经济高效的蓝图，通过设备端人工智能弥合农业技术鸿沟，提高水资源利用效率，适合在资源受限的农村环境中可持续、可扩展地部署。

Abstract: Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.

</details>


### [381] [METIS: Mentoring Engine for Thoughtful Inquiry & Solutions](https://arxiv.org/abs/2601.13075)
*Abhinav Rajeev Kumar,Dhruv Trehan,Paras Chopra*

Main category: cs.LG

TL;DR: METIS是一个工具增强、阶段感知的AI导师系统，帮助本科生从研究想法到完成论文。它在多个评估中优于GPT-5和Claude Sonnet 4.5，特别是在文档支撑的阶段。


<details>
  <summary>Details</summary>
Motivation: 许多学生缺乏专业研究指导，需要AI导师帮助学生从研究想法发展到完成论文。

Method: 构建METIS系统，具备文献搜索、指导方针、方法论检查和记忆功能，采用阶段感知的架构。通过LLM作为评委的成对偏好、学生角色评分标准、多轮辅导和证据/合规性检查进行评估。

Result: 在90个单轮提示中，LLM评委在71%的情况下偏好METIS胜过Claude Sonnet 4.5，在54%的情况下偏好METIS胜过GPT-5。学生评分在清晰度、可操作性和约束匹配方面更高。在多轮会话中，METIS的最终质量略高于GPT-5。优势集中在文档支撑的阶段（D-F）。

Conclusion: METIS作为AI研究导师在帮助学生完成研究论文方面表现出色，特别是在需要文档支持的阶段。失败模式包括过早的工具路由、浅层支撑和偶尔的阶段分类错误。

Abstract: Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.

</details>


### [382] [Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement](https://arxiv.org/abs/2601.13100)
*Aaron R. Flouro,Shawn P. Chadwick*

Main category: cs.LG

TL;DR: 提出递归元蒸馏的算子理论框架，证明在温和条件下KL散度收缩，确保收敛到基教师分布而非误差累积。


<details>
  <summary>Details</summary>
Motivation: 当前概率域知识蒸馏已建立温度缩放、多教师聚合和偏差-方差权衡的公理框架，但递归或多代蒸馏的数学行为理解不足，现有方法依赖经验启发式。

Method: 引入递归元蒸馏的公理化和算子理论框架，将迭代知识蒸馏形式化为概率分布算子序列，并明确定锚到基教师。定义有效元教师构造的结构公理，证明存在满足这些公理的非平凡算子族。

Result: 在温和可实现性和凸性假设下，锚定递归蒸馏诱导KL散度收缩，产生向基教师分布的几何收敛和唯一全局吸引不动点。

Conclusion: 该框架是基础性而非算法性的，描述了递归蒸馏何时在数学上适定且收敛而非误差累积，独立于模型架构、优化细节或具体算子实例化，为理解迭代和多教师蒸馏的稳定性、偏差-方差行为和失败模式提供理论基础。

Abstract: Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.
  We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.
  The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.

</details>


### [383] [FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference](https://arxiv.org/abs/2601.13143)
*Chaeyoung Jung,Youngjoon Jang,Seungwoo Lee,Joon Son Chung*

Main category: cs.LG

TL;DR: FastAV是首个针对音频-视觉大语言模型的token剪枝框架，通过注意力权重分析token重要性，采用两阶段剪枝策略，在不依赖完整注意力图的情况下减少40%以上计算量，同时保持或提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 虽然token剪枝在标准大语言模型和视觉语言模型中已有研究，但在音频-视觉大语言模型中尚未得到关注。多模态集成显著增加了token需求，导致计算开销增大，需要专门的剪枝方法来解决这一问题。

Method: 提出基于注意力权重的token重要性评估方法，采用两阶段剪枝策略：1）在中间层进行全局剪枝，移除整体影响力较小的token；2）在后续层进行精细剪枝，考虑对下一个token生成的影响。该方法完全兼容FlashAttention等高效注意力机制。

Result: 在两种代表性音频-视觉大语言模型上，FastAV能够减少超过40%的FLOPs（浮点运算次数），同时保持甚至提升了模型性能。

Conclusion: FastAV是首个专门为音频-视觉大语言模型设计的token剪枝框架，通过有效的两阶段剪枝策略显著降低了计算开销，同时保持了模型性能，与高效注意力机制完全兼容，为多模态大模型的优化提供了有效解决方案。

Abstract: In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.

</details>


### [384] [Training instability in deep learning follows low-dimensional dynamical principles](https://arxiv.org/abs/2601.13160)
*Zhipeng Zhang,Zhenjie Yao,Kai Li,Lei Yang*

Main category: cs.LG

TL;DR: 本文提出一个统一动力学视角，将训练稳定性视为学习系统的内在属性，通过受控扰动审计识别训练稳定性规律，发现高性能常与稳定性脱钩、受控随机性能缓冲学习动态、低维潜在元状态偏差能预测性能崩溃。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然经验性能优异，但训练过程本身的稳定性仍未被充分理解。训练作为一个高维动力系统，对优化、数据、参数或学习信号的微小扰动都可能引发突然且不可逆的崩溃，损害可复现性和可扩展性。

Method: 提出统一动力学视角，将训练稳定性组织为四个相互作用的维度：优化稳定性、环境/数据稳定性、参数稳定性和学习信号稳定性。通过受控扰动审计训练轨迹来操作化这一视角，在不修改学习算法的情况下探测学习动态对结构化扰动的响应。

Result: 在强化学习和大型语言模型训练中发现三个重复规律：1) 高性能常与训练稳定性脱钩；2) 受控随机性一致地缓冲跨范式的学习动态；3) 低维潜在元状态的偏差系统地先于可观察的性能崩溃。

Conclusion: 这些发现将训练稳定性确立为学习系统可测量和可比较的动力学属性，为超越最终性能结果研究学习动态提供了描述性基础。

Abstract: Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.
  We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.
  Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.

</details>


### [385] [NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness](https://arxiv.org/abs/2601.13162)
*Ali Shafiee Sarvestani,Jason Schmidt,Arman Roohi*

Main category: cs.LG

TL;DR: DesignII是一个神经符号框架，通过将符号规则监督集成到神经网络中，显著提升对抗鲁棒性和可解释性，在GTSRB数据集上比标准对抗训练提高约3倍的鲁棒性增益。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络存在对抗脆弱性和缺乏可解释性的关键局限，尤其是在自动驾驶等安全敏感场景中。需要一种既能增强对抗鲁棒性又能提高可解释性的方法。

Method: 提出DesignII神经符号框架，将领域知识编码为形状、颜色等外观属性的逻辑约束，通过语义和符号逻辑损失在训练中强制执行。使用FGSM和PGD攻击在GTSRB数据集上评估，采用标准对抗训练预算ε=8/255。

Result: FGSM-Neuro-Symbolic和PGD-Neuro-Symbolic模型相比标准对抗训练基线分别提升18.1%和17.35%的对抗精度，鲁棒性增益约为标准对抗训练的3倍，且不降低干净样本准确率。与LNL-MoEx等transformer防御相比，使用ResNet18仅训练10个epoch即可达到相当或更优的鲁棒性。

Conclusion: 符号推理为构建鲁棒且可解释的AI提供了有效途径，神经符号框架能显著提升对抗鲁棒性而不牺牲干净样本性能，相比复杂架构具有计算效率优势。

Abstract: Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.

</details>


### [386] [LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations](https://arxiv.org/abs/2601.13190)
*Vittoria De Pellegrini,Tariq Alkhalifah*

Main category: cs.LG

TL;DR: 提出LAViG-FLOW框架，使用潜在自回归视频生成扩散模型学习饱和度与压力场的耦合演化，比传统数值求解器快数个数量级


<details>
  <summary>Details</summary>
Motivation: 传统高保真多相流模拟器在需要大量前向运行进行反演和不确定性量化时计算成本过高，需要更高效的替代方案

Method: 使用专用2D自编码器压缩每个状态变量，通过视频扩散变换器(VDiT)建模时间上的耦合分布，先训练学习耦合关系，再自回归微调以超越观测时间窗口

Result: 在开源CO2封存数据集上评估，LAViG-FLOW生成的饱和度和压力场在时间上保持一致，运行速度比传统数值求解器快数个数量级

Conclusion: LAViG-FLOW为地下多相流场建模和预测提供了一种高效准确的替代方案，适用于地质CO2封存和地热生产等应用

Abstract: Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.

</details>


### [387] [A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms](https://arxiv.org/abs/2601.13243)
*Yapeng Li,Jiakuo Yu,Zhixin Liu,Xinnan Liu,Jing Yu,Songze Li,Tonghua Su*

Main category: cs.LG

TL;DR: 该论文系统评估了不同LLM推理范式（直接生成、思维链、多智能体系统）的性能与成本-准确性权衡，并提出了新的开放式基准MIMeBench来评估语义抽象和对比辨别能力。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM推理范式（如思维链和多智能体系统）在推理任务中扮演关键角色，但它们的相对有效性、成本-准确性权衡以及适用场景仍然缺乏系统理解，特别是复杂推理结构是否总能带来性能提升尚不明确。

Method: 1. 对多种推理范式进行统一评估：直接单模型生成、思维链增强的单模型推理、代表性多智能体系统工作流；2. 使用针对性角色隔离分析探究多智能体系统中角色特定能力需求；3. 分析成本-准确性权衡；4. 引入新的开放式基准MIMeBench，专注于语义抽象和对比辨别能力。

Result: 1. 增加结构复杂性并不总能改善推理性能，其效果高度依赖于推理范式本身的特性和适用性；2. 某些多智能体系统工作流在成本和准确性之间取得了有利平衡，而另一些则因边际收益而产生了过高开销；3. MIMeBench提供了超越封闭式准确性的替代评估维度，能够精细评估难以用现有基准捕捉的语义能力。

Conclusion: 论文揭示了LLM推理范式的性能边界和适用条件，强调了范式选择应根据任务特性而非盲目追求结构复杂性。MIMeBench的引入为评估LLM语义能力提供了新工具，推动了更全面的LLM推理能力评估框架。

Abstract: Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.

</details>


### [388] [Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks](https://arxiv.org/abs/2601.13244)
*Prateek Munjal,Clement Christophe,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.LG

TL;DR: 指令微调对LLM推理能力的提升有限，更多是表面模式匹配而非本质推理增强。基础模型在零样本思维链设置下表现更好，而指令微调模型仅在有few-shot示例时才表现优异，且对分布偏移脆弱。


<details>
  <summary>Details</summary>
Motivation: 探究指令微调是否真正提升LLM的推理能力，还是仅仅诱导了表面层级的模式匹配。现有研究对此问题缺乏清晰认识，需要系统评估不同设置下的模型表现。

Method: 在标准数学基准测试（GSM8K）、结构扰动变体和领域迁移任务（MedCalc）上评估基础模型和指令微调模型。采用零样本思维链和few-shot设置进行对比分析。

Result: 1. 在零样本CoT设置下，基础模型在GSM8K上始终优于指令微调模型（Llama3-70B下降高达32.67%）；2. 指令微调模型仅在提供few-shot示例时才能匹配或超越基础模型；3. 在领域特定MedCalc基准上，基础模型优于指令微调模型；4. 指令微调模型在扰动数据集上表现急剧下降。

Conclusion: 指令微调的优势不稳定且高度依赖评估设置，模型更多依赖于特定提示模式而非内在推理能力。微调增益在分布偏移下脆弱，表明当前指令微调方法可能主要提升表面模式匹配而非本质推理能力。

Abstract: Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.

</details>


### [389] [Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification](https://arxiv.org/abs/2601.13272)
*Aaron Pim,Tristan Pryer*

Main category: cs.LG

TL;DR: 提出了一个基于蒙特卡洛dropout的多级蒙特卡洛框架，通过重用dropout掩码构建层级耦合估计器，减少方差并提高不确定性量化效率


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛dropout是深度学习不确定性量化的常用方法，但需要大量前向传播才能获得准确的预测矩估计，计算成本高。需要开发更高效的估计方法来降低方差、提高计算效率

Method: 将dropout掩码作为认知随机性来源，通过前向传播次数定义保真度层级，重用dropout掩码构建粗-细耦合估计器，形成预测均值和方差的伸缩MLMC估计器

Result: 推导了偏差、方差和有效成本的显式表达式，制定了层级间的样本分配规则。在正向和逆向PINNs-Uzawa基准测试中验证了预测方差率，在相同计算成本下相比单级MC-dropout获得了效率提升

Conclusion: 提出的多级蒙特卡洛框架能够有效减少蒙特卡洛dropout的采样方差，在固定计算预算下提高不确定性量化的效率，为深度学习模型提供了更高效的不确定性量化方法

Abstract: We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.

</details>


### [390] [Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning](https://arxiv.org/abs/2601.13284)
*Duygu Nur Yaldiz,Evangelia Spiliopoulou,Zheng Qi,Siddharth Varia,Srikanth Doss,Nikolaos Pappas*

Main category: cs.LG

TL;DR: 该研究发现强化学习微调(RLVR)虽然能提升任务性能，但会导致模型极度过度自信；而监督微调(SFT)校准效果更好但性能提升较小。作者提出了校准感知的强化学习方法来解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地应用于决策任务，不仅需要准确性，还需要可靠的置信度估计。良好校准的置信度能让下游系统决定何时信任模型、何时转向备用机制。

Method: 1. 系统研究监督微调(SFT)和强化学习(RLVR)两种微调范式的校准特性；2. 通过针对性实验诊断RLVR失败原因；3. 提出校准感知的强化学习公式，直接调整决策标记的概率。

Result: RLVR提升任务性能但产生极度过度自信的模型，SFT校准效果更好但性能增益较小。提出的校准感知强化学习方法在保持RLVR准确性的同时缓解了过度自信，将ECE分数降低了最多9个点。

Conclusion: 决策标记在推理轨迹中作为决策提取步骤，不携带置信度信息，这阻碍了强化学习呈现校准的替代方案。通过直接调整决策标记概率的方法，可以在保持性能的同时改善校准效果。

Abstract: Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.

</details>


### [391] [CooperBench: Why Coding Agents Cannot be Your Teammates Yet](https://arxiv.org/abs/2601.13295)
*Arpandeep Khatua,Hao Zhu,Peter Tran,Arya Prabhudesai,Frederic Sadrieh,Johann K. Lieberwirth,Xinkai Yu,Yicheng Fu,Michael J. Ryan,Jiaxin Pei,Diyi Yang*

Main category: cs.LG

TL;DR: CooperBench评测发现AI编码代理在协作任务中表现糟糕，成功率比单独执行低30%，揭示了当前AI缺乏社交智能的"协调诅咒"问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在复杂工作中越来越多地协作，它们需要发展协调能力成为有效队友。但作者假设当前代理缺乏这些能力，需要建立基准来测试和推动AI社交智能的发展。

Method: 引入CooperBench基准，包含12个库4种编程语言的600多个协作编码任务。每个任务分配两个代理不同的功能，这些功能可以独立实现但可能在没有适当协调的情况下冲突。任务基于真实开源仓库和专家编写的测试。通过大规模模拟评估最先进的编码代理。

Result: 发现"协调诅咒"：代理协作时的平均成功率比单独执行两个任务低30%。分析揭示三个关键问题：1)通信渠道充斥着模糊、时机不当和不准确的消息；2)即使有有效通信，代理也会偏离承诺；3)代理对他人计划和通信持有错误期望。但也观察到罕见的涌现协调行为，如角色分工、资源分配和谈判。

Conclusion: 研究提出了协作编码的新基准，并呼吁从追求个体代理能力转向发展社交智能。当前AI代理缺乏人类团队的协调能力，这限制了它们在真实协作环境中的有效性。

Abstract: Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.

</details>


### [392] [Verifying Local Robustness of Pruned Safety-Critical Networks](https://arxiv.org/abs/2601.13303)
*Minh Le,Phuong Cao*

Main category: cs.LG

TL;DR: 研究剪枝对深度神经网络形式化验证的影响，发现轻剪枝（MNIST 40%）和重剪枝（JPL 70-90%）能提升验证性，最佳剪枝比例因数据集而异。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的形式化验证对于安全关键应用至关重要，但大规模模型的验证计算成本高昂，阻碍了实际应用。需要探索模型压缩（如剪枝）对验证性能的影响。

Method: 使用最先进的α,β-CROWN验证器，在不同剪枝比例下评估ResNet4模型，在MNIST和NASA JPL Mars Frost Identification数据集上进行测试。

Result: 发现剪枝与验证性之间存在非线性关系：MNIST数据集上40%的轻剪枝和JPL数据集上70-90%的重剪枝能改善验证性，使模型在证明的L∞鲁棒性上优于未剪枝基准。

Conclusion: 减少连接性简化了形式化求解器的搜索空间，最佳剪枝比例在不同数据集间差异显著。这为在高风险环境中部署高效且经过形式化验证的DNN提供了关键见解。

Abstract: Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.

</details>


### [393] [Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans](https://arxiv.org/abs/2601.13350)
*Abdel Djalil Sad Saoud,Fred Maurice Ngolè Mboula,Hanane Slimani*

Main category: cs.LG

TL;DR: 提出一种基于谱嵌入的域适应方法，将平滑传输计划解释为二分图邻接矩阵，从而获得域不变特征表示。


<details>
  <summary>Details</summary>
Motivation: 训练和推理数据之间的分布偏移是机器学习中的核心挑战，传统基于最优传输的域适应方法依赖Monge映射近似，对正则化策略和超参数敏感，可能导致有偏的域对齐。

Method: 将平滑传输计划解释为连接源域和目标域的二分图邻接矩阵，通过谱嵌入推导域不变样本表示。

Result: 在音乐流派识别、音乐-语音判别、电缆缺陷检测与分类等多个声学适应基准任务上取得了总体强劲的性能。

Conclusion: 提出的谱嵌入方法能够有效解决域适应问题，在多个实际应用场景中表现出色。

Abstract: Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.

</details>


### [394] [On the Relation of State Space Models and Hidden Markov Models](https://arxiv.org/abs/2601.13357)
*Aydin Ghojogh,M. Hadi Sepanj,Benyamin Ghojogh*

Main category: cs.LG

TL;DR: 本文系统比较了HMMs、线性高斯状态空间模型、卡尔曼滤波和现代NLP状态空间模型，分析它们的相似性和差异性，并探讨了经典概率模型与现代深度学习模型之间的关系。


<details>
  <summary>Details</summary>
Motivation: 状态空间模型（SSMs）和隐马尔可夫模型（HMMs）是建模序列数据的核心框架，但在潜变量性质、概率假设、推理方法和训练范式上存在根本差异。随着S4、Mamba等确定性状态空间模型在NLP中的兴起，需要系统梳理经典概率模型与现代神经序列模型之间的关系。

Method: 通过概率图模型的视角分析这些模型的数学表述，比较前向后向推理和卡尔曼滤波等推理算法，并对比期望最大化（EM）和基于梯度的优化等学习过程。系统性地识别结构相似性和语义差异。

Result: 明确了这些模型在何时等价、何时根本不同，以及现代NLP状态空间模型与经典概率模型的关系。揭示了控制理论、概率建模和现代深度学习之间的桥梁。

Conclusion: 本文为理解状态空间模型、隐马尔可夫模型和现代序列模型提供了统一框架，澄清了它们之间的关系，有助于在信号处理、控制理论和机器学习等领域的交叉研究。

Abstract: State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.
  In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.

</details>


### [395] [CausationEntropy: Pythonic Optimal Causation Entropy](https://arxiv.org/abs/2601.13365)
*Kevin Slote,Jeremie Fish,Erik Bollt*

Main category: cs.LG

TL;DR: CausationEntropy是一个Python包，实现了最优因果熵(oCSE)算法及其优化扩展，用于从动态系统和耦合振荡器中揭示因果网络，区分直接与间接路径。


<details>
  <summary>Details</summary>
Motivation: 提供一个健壮、易用的因果网络建模工具，支持多种信息论因果发现算法，作为复杂动态系统因果发现的基准工具。

Method: 实现oCSE算法及其优化扩展，包含高斯、kNN、几何kNN、KDE和泊松等多种熵估计器，提供合成数据生成和可视化工具。

Result: 发布了CausationEntropy 1.1版本，包含新功能模块，可通过PyPi安装，有完整文档和代码示例，采用MIT开源许可。

Conclusion: 该软件包将成为复杂动态系统因果发现的重要基准工具，其模块化结构支持未来扩展。

Abstract: Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.

</details>


### [396] [Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility](https://arxiv.org/abs/2601.13398)
*Nickil Maveli,Antonio Vergari,Shay B. Cohen*

Main category: cs.LG

TL;DR: RTCE基准测试揭示当前代码LLMs在往返代码执行一致性方面存在不足，无法保持编码与解码操作间的双向映射关系。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLMs在基准测试中表现良好，但在往返代码执行中缺乏一致性推理能力，需要新的评估方法来测试模型是否能在正向和反向执行中保持一致的映射关系。

Method: 提出了RoundTripCodeEval（RTCE）基准测试，包含四个不同的代码执行推理任务，通过免执行的精确匹配评估双射保真度，测试模型在各种算法和方向上的编码-解码映射一致性。

Result: 评估了最先进的代码LLMs，使用了零样本提示、监督微调和自我反思机制，每种方法都带来了适度改进，但都无法弥合差距，表明当前LLMs难以实现真正的往返一致性。

Conclusion: 当前LLMs缺乏内部一致性，无法实现可信的代码推理。RTCE揭示了现有I/O预测、执行推理或往返自然语言基准测试无法测量的新见解，表明模型在双向代码执行一致性方面存在根本性局限。

Abstract: LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.

</details>


### [397] [TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction](https://arxiv.org/abs/2601.13422)
*Dahai Yu,Rongchao Xu,Dingyi Zhuang,Yuheng Bu,Shenhao Wang,Guang Wang*

Main category: cs.LG

TL;DR: TrustEnergy：用于准确可靠用户级能源使用预测的统一框架，结合分层时空表征和顺序保形分位数回归，在预测精度和不确定性量化方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有能源使用预测方法大多忽视空间相关性或无法扩展到个体化预测，且由于极端天气等因素导致的动态不确定性，现有工作未能充分探索不确定性量化，限制了用户级预测的准确性和可靠性。

Method: 提出TrustEnergy框架，包含两个关键技术组件：(1)分层时空表征模块，使用新型记忆增强时空图神经网络捕捉宏观和微观能源使用模式；(2)顺序保形分位数回归模块，动态调整不确定性边界，确保随时间推移的有效预测区间，无需对底层数据分布做强假设。

Result: 与佛罗里达州电力供应商合作实施评估，结果显示TrustEnergy相比最先进基线方法，预测精度提升5.4%，不确定性量化改进5.7%。

Conclusion: TrustEnergy框架通过有效捕捉时空相关性和动态不确定性量化，实现了准确可靠的用户级能源使用预测，为电网管理、基础设施规划和灾害响应等实际应用提供了更好的解决方案。

Abstract: Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.

</details>


### [398] [A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization](https://arxiv.org/abs/2601.13435)
*Shuozhe Li,Du Cheng,Leqi Liu*

Main category: cs.LG

TL;DR: WaveLSFormer：一种基于可学习小波变换的长短期Transformer模型，用于日内交易策略学习，通过多尺度分解和收益导向决策学习，显著提升盈利能力和风险调整收益。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列的日内交易策略学习面临严重噪声、非平稳性和资产间强横截面依赖等挑战。传统方法难以有效处理这些复杂特征，需要开发能够同时进行多尺度分解和收益导向决策学习的新型模型。

Method: 提出WaveLSFormer模型，包含三个核心组件：1）可学习小波前端，通过端到端训练滤波器组生成低/高频分量，并使用频谱正则化确保稳定且分离良好的频带；2）低引导高频注入模块，用高频线索细化低频表示并控制训练稳定性；3）Transformer骨干网络，输出多空头寸组合，通过风险预算重缩放，直接优化交易目标和风险感知正则化。

Result: 在五年小时级别数据、六个行业组、十个随机种子的广泛实验中，WaveLSFormer持续优于MLP、LSTM和Transformer基线模型。在所有行业平均表现中，累计总策略收益为0.607±0.045，夏普比率为2.157±0.166，在盈利能力和风险调整收益方面显著超越最强基线。

Conclusion: WaveLSFormer通过可学习小波分解和多尺度信息融合，有效解决了金融时间序列分析中的噪声和非平稳性问题，为日内交易策略学习提供了强大的端到端框架，在保持训练稳定性的同时显著提升了交易性能。

Abstract: Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.

</details>


### [399] [BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions](https://arxiv.org/abs/2601.13445)
*Ashish S. Nair,Sandipp Krishnan Ravi,Itzel Salgado,Changjie Sun,Sayan Ghosh,Liping Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于DeepSDF的涡轮叶片专用隐式生成框架，实现了性能感知和可制造的三维几何生成与重建。


<details>
  <summary>Details</summary>
Motivation: 传统涡轮叶片设计方法存在性能感知不足、制造约束考虑不充分的问题，需要一种能够同时考虑工程性能和制造可行性的数据驱动生成框架。

Method: 采用连续符号距离函数(SDF)表示法，建立可解释的近似高斯潜在空间，通过神经网络将工程描述符映射到潜在代码，支持插值和高斯采样生成。

Result: 实现了高精度重建，表面距离误差控制在最大叶片尺寸的1%以内，对未见设计具有良好泛化能力，超越了传统二维引导或无约束三维方法。

Conclusion: 该框架为涡轮叶片的数据驱动建模和概念生成提供了实用且可解释的解决方案，在性能感知和制造约束集成方面具有显著优势。

Abstract: Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.

</details>


### [400] [Fairness-informed Pareto Optimization : An Efficient Bilevel Framework](https://arxiv.org/abs/2601.13448)
*Sofiane Tanji,Samuel Vaiter,Yassine Laguel*

Main category: cs.LG

TL;DR: BADR是一个双层自适应重标量化框架，能够为任意公平性指标恢复最优的帕累托高效模型，解决了现有方法在公平性和性能权衡中的帕累托低效问题。


<details>
  <summary>Details</summary>
Motivation: 现有公平机器学习方法常产生帕累托低效模型，某些群体的性能可以在不损害其他群体的情况下得到提升。传统处理方法（如公平性正则化）存在此问题，而现有帕累托高效方法又偏向特定公平视角，无法适应文献中广泛研究的各种公平性指标。

Method: 提出BADR（Bilevel Adaptive Rescalarisation）框架，包含双层优化：下层是加权经验风险最小化任务（权重为各群体的凸组合），上层优化所选公平性目标。开发了两种大规模单循环算法BADR-GD和BADR-SGD，并建立了收敛保证。

Result: 开发了开源Python工具箱badr，支持多种学习任务和公平性指标。大量数值实验表明BADR相比现有帕累托高效公平性方法具有优势。

Conclusion: BADR提供了一个简单通用的框架，能够为任意公平性指标恢复最优帕累托高效模型，解决了现有方法的局限性，并通过开源工具实现了大规模应用。

Abstract: Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.

</details>


### [401] [Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay](https://arxiv.org/abs/2601.13456)
*Sahasra Kokkula,Daniel David,Aaditya Baruah*

Main category: cs.LG

TL;DR: 针对联邦学习中时序概念漂移导致灾难性遗忘的问题，作者提出客户端经验回放方法，通过在本地训练时混合少量历史样本，无需修改服务器聚合，有效恢复性能至78-82%


<details>
  <summary>Details</summary>
Motivation: 联邦学习在时序概念漂移（客户端数据分布随时间变化）下表现不佳，标准FedAvg在季节性漂移场景中会遭受灾难性遗忘，准确率从74%大幅下降至28%

Method: 提出客户端经验回放方法：每个客户端维护一个小型缓冲区存储历史样本，在本地训练时将缓冲区的历史样本与当前数据混合训练。该方法无需修改服务器聚合机制

Result: 在Fashion-MNIST数据集上的实验表明，使用每类50个样本的缓冲区可将性能恢复至78-82%，有效防止遗忘。消融研究显示存在明显的记忆-准确率权衡关系

Conclusion: 客户端经验回放是一种简单有效的解决联邦学习中时序概念漂移问题的方法，无需修改服务器端，通过少量历史样本即可显著缓解灾难性遗忘问题

Abstract: Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.

</details>


### [402] [Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics](https://arxiv.org/abs/2601.13463)
*Brandon B. Le,D. Keller*

Main category: cs.LG

TL;DR: 提出一个基于数据内在特性的诊断框架，通过量子资格指标指导量子与经典深度学习模型的选择，应用于强子物理中的分类、回归问题及康普顿形状因子提取。


<details>
  <summary>Details</summary>
Motivation: 随着量子机器学习架构的成熟，核心挑战已不再是构建这些架构，而是识别它们相对于经典方法具有实际优势的应用场景。特别是在数据驱动的强子物理问题中，需要系统性的工具来指导模型选择。

Method: 引入一个诊断框架，核心是定量量子资格指标，该指标基于数据的内在特性（复杂度、噪声、维度等）来指导量子与经典深度神经网络的选择。通过受控的分类和回归研究，分析模型性能与数据特性的系统趋势，并将这些趋势提炼为预测性准则。

Result: 研究表明，相对模型性能遵循数据复杂度、噪声和维度的系统趋势，这些趋势可以提炼为预测性准则。在深度虚拟康普顿散射中提取康普顿形状因子的应用中，量子资格指标成功识别出量子模型有利的运动学区域。

Conclusion: 该工作为在精确强子物理中部署量子机器学习工具建立了一个原则性框架，通过数据驱动的诊断工具系统性地指导量子与经典模型的选择，识别量子优势的应用场景。

Abstract: As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.

</details>


### [403] [Preconditioning Benefits of Spectral Orthogonalization in Muon](https://arxiv.org/abs/2601.13474)
*Jianhao Ma,Yu Huang,Yuejie Chi,Yuxin Chen*

Main category: cs.LG

TL;DR: 论文通过研究简化版Muon优化器在矩阵分解和线性Transformer上下文学习两个问题上的表现，证明了其线性收敛特性且收敛复杂度与条件数无关，优于梯度下降和Adam优化器。


<details>
  <summary>Details</summary>
Motivation: Muon优化器作为利用梯度谱正交化的大语言模型预训练里程碑算法，其底层机制特别是梯度正交化的作用仍未得到充分理解。很少有工作提供端到端分析来严格解释其在具体应用中的优势。

Method: 通过两个案例研究简化版Muon优化器的有效性：矩阵分解和线性Transformer的上下文学习。对这两个问题，证明了简化Muon以线性收敛，且迭代复杂度与相关条件数无关。

Result: 分析显示Muon动态在谱域中解耦为一系列独立的标量序列，每个序列表现出相似的收敛行为。理论形式化了谱正交化诱导的预条件效应，为Muon在这些矩阵优化问题中的有效性提供了见解。

Conclusion: 该研究为理解Muon优化器提供了理论基础，揭示了其谱正交化机制的优势，表明该优化器在矩阵优化问题中确实优于传统方法，并可能推广到更广泛的应用场景。

Abstract: The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.

</details>


### [404] [A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model](https://arxiv.org/abs/2601.13476)
*Jinhao Li,Hao Wang*

Main category: cs.LG

TL;DR: 提出PRAIM框架，利用大语言模型和检索增强记忆解决电动汽车充电数据缺失问题，显著提升插补精度并改善下游预测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中电动汽车充电数据常存在缺失记录，现有插补方法难以处理复杂的多模态充电数据，且通常采用"一站一模型"范式，忽略了站间相关性。

Method: PRAIM框架使用预训练语言模型编码异构数据（时间序列需求、日历特征、地理空间上下文），通过检索增强记忆从整个充电网络检索相关示例，采用变分神经架构的单统一插补模型。

Result: 在四个公共数据集上的实验表明，PRAIM在插补精度和保持原始数据统计分布方面显著优于现有基线方法，并能大幅提升下游预测性能。

Conclusion: PRAIM通过结合大语言模型和检索增强记忆，有效解决了电动汽车充电数据缺失问题，为数据驱动的电动汽车基础设施应用提供了更可靠的解决方案。

Abstract: The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.

</details>


### [405] [StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing](https://arxiv.org/abs/2601.13522)
*Shuang Li*

Main category: cs.LG

TL;DR: 提出了一种基于Tucker分解的随机交替最小化算法，用于低秩张量感知问题，避免了昂贵的张量投影，通过核心张量和因子矩阵上的高效小批量更新实现快速收敛。


<details>
  <summary>Details</summary>
Motivation: 现有低Tucker秩张量恢复方法要么在完整张量变量上操作并需要昂贵的张量投影，要么采用因子化公式但仍依赖完整梯度计算，而大多数随机因子化方法仅限于张量分解设置，缺乏高效的随机优化方法。

Method: 提出了一种直接在Tucker分解下的核心张量和因子矩阵上操作的随机交替最小化算法，避免了重复的张量投影，并在低维张量因子上实现高效的小批量更新。

Result: 在合成张量感知实验中，该算法在墙上时钟时间方面相比代表性的随机张量恢复基线表现出更优的收敛行为。

Conclusion: 该方法为低Tucker秩张量感知提供了一种高效的随机优化框架，避免了昂贵的张量操作，在实际计算时间上具有优势。

Abstract: Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.

</details>


### [406] [MN-TSG:Continuous Time Series Generation with Irregular Observations](https://arxiv.org/abs/2601.13534)
*Xu Zhang,Junwei Deng,Chang Xu,Hao Li,Jiang Bian*

Main category: cs.LG

TL;DR: MN-TSG提出了一种基于专家混合NCDE的框架，用于不规则采样时间序列的连续生成，通过动态参数化专家函数和解耦设计提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列生成方法通常假设规则采样和固定输出分辨率，但现实场景中数据往往不规则采样且稀疏观测，这在临床监测等应用中尤为关键。NCDE虽能建模不规则时间序列，但在捕捉复杂动态模式和支撑连续生成方面仍有局限。

Method: 提出MN-TSG框架，核心是MoE-NCDE架构：1) 使用动态参数化的专家函数；2) 采用解耦设计优化MoE动态；3) 利用现有TSG模型学习专家混合与生成时间序列的联合分布，使框架不仅能生成新样本，还能为每个样本生成合适的专家配置。

Result: 在10个公共和合成数据集上的实验表明，MN-TSG在从不规则到规则和不规则到连续的生成任务中，均一致优于强基线方法。

Conclusion: MN-TSG通过结合专家混合NCDE与现有TSG模型，有效解决了不规则采样时间序列的连续生成问题，为临床监测等实际应用提供了更好的解决方案。

Abstract: Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.
  Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.
  The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.
  Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.

</details>


### [407] [Patterning: The Dual of Interpretability](https://arxiv.org/abs/2601.13548)
*George Wang,Daniel Murfet*

Main category: cs.LG

TL;DR: 论文提出"图案化"(patterning)作为机制可解释性的对偶问题：给定期望的泛化形式，确定产生它的训练数据


<details>
  <summary>Details</summary>
Motivation: 机制可解释性主要关注从已训练模型中理解其内部结构，但反过来，如何通过设计训练数据来引导模型学习特定内部结构或泛化行为是一个未充分探索的问题

Method: 基于敏感性(susceptibilities)的方法，通过测量可观测量后验期望值对数据分布微小变化的响应，然后逆转向这个线性响应关系来确定能引导模型达到目标内部配置的数据干预

Result: 在小语言模型中，通过沿主要敏感性方向重新加权训练数据，可以加速或延迟特定结构（如归纳电路）的形成；在括号平衡任务中，即使多个算法都能达到完美训练准确率，图案化可以通过针对每个解决方案的局部学习系数来选择模型学习的算法

Conclusion: 用于读取内部结构的相同数学框架可以被逆转向写入内部结构，建立了机制可解释性与其对偶问题之间的统一理论框架

Abstract: Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.

</details>


### [408] [ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits](https://arxiv.org/abs/2601.13563)
*Aryan Karmore*

Main category: cs.LG

TL;DR: ButterflyMoE是一种创新的专家混合模型压缩方法，通过几何参数化将多个专家视为共享量化基板的不同视角，实现亚线性内存增长，解决了传统MoE模型线性内存扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型需要存储N个独立的专家权重矩阵，内存需求为O(N·d²)，这超出了边缘设备的存储预算。现有的压缩方法如量化、剪枝和低秩分解只能减少常数因子，无法解决线性扩展的根本瓶颈。

Method: ButterflyMoE将专家视为共享量化基板的几何重定向，而不是独立的权重矩阵。通过应用学习到的旋转到共享的三元原型上，每个专家可以从不同角度利用共享容量，实现O(d² + N·d log d)的内存需求。

Result: 在256个专家时实现了150倍的内存减少，且精度损失可忽略。这使得64个专家可以适配4GB设备，而标准MoE只能支持8个专家。几何参数化打破了线性扩展的限制。

Conclusion: ButterflyMoE通过几何参数化方法成功解决了MoE模型的内存线性扩展问题，实现了亚线性内存增长，使更多专家能在有限内存设备上部署，为边缘设备上的大规模MoE应用开辟了新途径。

Abstract: Linear memory scaling stores $N$ independent expert weight matrices requiring $\mathcal{O}(N \cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\mathcal{O}(d^2 + N \cdot d \log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.

</details>


### [409] [Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework](https://arxiv.org/abs/2601.13564)
*Yanheng Li,Zhichen Pu,Lijiang Yang,Zehao Zhou,Yi Qin Gao*

Main category: cs.LG

TL;DR: LUMOS是一个数据和物理驱动的荧光分子逆设计框架，通过结合生成器和预测器的共享潜在表示，实现从规格到分子的直接设计，并在多目标优化中优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 传统生成-评分-筛选方法在荧光分子设计中效率低下，机器学习预测泛化性不可靠，量子化学计算成本过高，需要一种更高效、可靠的逆设计框架。

Method: 结合神经网络与快速TD-DFT计算构建互补预测器；采用属性引导的扩散模型与多目标进化算法集成；通过共享潜在表示耦合生成器和预测器。

Result: LUMOS在荧光属性预测的准确性、泛化性和物理合理性方面均优于基线模型；在多目标分子优化中表现优异；TD-DFT和MD模拟验证了其生成符合目标规格的有效荧光团。

Conclusion: LUMOS建立了一个数据和物理双驱动的通用荧光团逆设计框架，能够高效探索化学空间并满足多目标和约束条件的设计需求。

Abstract: Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.

</details>


### [410] [Self-Improvement as Coherence Optimization: A Theoretical Account](https://arxiv.org/abs/2601.13566)
*Tianyi Qiu,Ahmed Hani Ismail,Zhonghao He,Shi Feng*

Main category: cs.LG

TL;DR: 该论文提出"一致性优化"理论框架，解释语言模型无需外部监督的自我提升机制，证明其等价于描述长度正则化，并在半监督学习场景下具有最优性。


<details>
  <summary>Details</summary>
Motivation: 现有研究发现语言模型可以通过辩论、自举、内部一致性最大化等方法在无外部监督情况下提升准确性，甚至匹配有监督微调性能，但这些方法为何有效缺乏理论解释。

Method: 提出一致性优化理论框架，将各种无监督自我提升方法统一为寻找最可压缩且联合可预测的上下文到行为映射，证明其等价于描述长度正则化，并从理论角度分析其最优性。

Result: 理论证明一致性优化是描述长度正则化的等价形式，在正则化器来自预训练模型的情况下，对半监督学习具有最优性。初步实验支持理论预测。

Conclusion: 一致性优化理论解释了无反馈自我提升为何有效，并预测了其成功或失败的条件，为理解语言模型自我改进机制提供了理论基础。

Abstract: Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.

</details>


### [411] [DRGW: Learning Disentangled Representations for Robust Graph Watermarking](https://arxiv.org/abs/2601.13569)
*Jiasen Li,Yanwei Liu,Zhuoyi Shang,Xiaoyan Gu,Weiping Wang*

Main category: cs.LG

TL;DR: 提出首个基于解耦表征学习的图水印框架DRGW，解决了现有方法在透明度、鲁棒性和可检测性上的不足


<details>
  <summary>Details</summary>
Motivation: 现有图水印方法通常基于图结构或纠缠的图表示，这种信息耦合和不可控的离散化过程会损害水印的透明度和鲁棒性，需要一种新的解决方案

Method: 1) 设计对抗训练编码器学习不变结构表示并导出统计独立的水印载体；2) 设计图感知可逆神经网络提供无损水印嵌入和提取通道；3) 开发结构感知编辑器将潜在修改转换为离散图编辑

Result: 在多种基准数据集上的实验证明DRGW具有优越的有效性

Conclusion: DRGW通过解耦表征学习解决了图水印的透明度、鲁棒性和可检测性问题，是首个有效结合这些特性的框架

Abstract: Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.

</details>


### [412] [GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds](https://arxiv.org/abs/2601.13570)
*Tingting Dan,Jiaqi Ding,Guorong Wu*

Main category: cs.LG

TL;DR: GeoDynamics是一个几何状态空间神经网络，直接在对称正定矩阵流形上追踪大脑状态轨迹，用于建模任务驱动状态变化和疾病早期标记。


<details>
  <summary>Details</summary>
Motivation: 现有方法将大脑视为松散连接区域或强加简化网络先验，缺乏真正的整体性和自组织动态系统视角。大脑功能连接矩阵位于黎曼流形而非欧几里得空间，捕获这些矩阵的轨迹对于理解认知和行为至关重要。

Method: GeoDynamics将每个连接矩阵嵌入到流形感知的循环框架中，学习平滑且尊重几何的转移，直接在对称正定矩阵流形上追踪潜在大脑状态轨迹。

Result: GeoDynamics揭示了任务驱动状态变化以及阿尔茨海默病、帕金森病和自闭症的早期标记。在人类动作识别基准测试中验证了其可扩展性和鲁棒性。

Conclusion: GeoDynamics提供了一个真正整体和自组织的动态系统视角，能够建模复杂时空动态，不仅适用于神经科学，还可扩展到其他领域。

Abstract: State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.

</details>


### [413] [Behavior Knowledge Merge in Reinforced Agentic Models](https://arxiv.org/abs/2601.13572)
*Xiangchi Yuan,Dachuan Shi,Chunhui Zhang,Zheyuan Liu,Shenglong Yao,Soroush Vosoughi,Wenke Lee*

Main category: cs.LG

TL;DR: RAM（Reinforced Agent Merging）是一个专为RL训练的智能体模型设计的分布感知合并框架，解决了传统合并方法在RL智能体上效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法主要针对监督微调（SFT）设计，不适用于RL训练的智能体模型。RL产生的任务向量具有高度稀疏和异质特性，而SFT合并方法假设向量是密集且全局可比的，这种不匹配导致合并时关键任务特定行为被稀释。

Method: RAM框架显式区分共享参数更新和任务特定唯一参数更新，对共享组件进行平均，同时选择性保留和重新缩放唯一组件，以抵消参数更新稀释效应。

Result: 在多个智能体领域和模型架构上的实验表明，RAM不仅超越了现有的合并基线，还能解锁智能体间的协同潜力，在某些领域甚至优于专门的智能体性能。

Conclusion: RAM是针对RL训练智能体模型的有效合并框架，解决了传统SFT合并方法在RL场景下的局限性，能够更好地保留任务特定能力并实现智能体间的协同增强。

Abstract: Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.

</details>


### [414] [FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning](https://arxiv.org/abs/2601.13578)
*Qian Feng,JiaHang Tu,Mintong Kang,Hanbin Zhao,Chao Zhang,Hui Qian*

Main category: cs.LG

TL;DR: 提出了FG-OrIU框架，首次在特征和梯度层面统一正交约束来实现深度遗忘，解决增量去学习中浅层遗忘问题


<details>
  <summary>Details</summary>
Motivation: 现有增量去学习方法主要通过抑制参数或混淆知识，缺乏对特征和梯度层面的显式约束，导致浅层遗忘，残余信息仍可恢复，这种不完整的遗忘存在安全风险并破坏保留平衡

Method: 提出FG-OrIU框架，通过SVD分解特征空间，将遗忘类和保留类特征分离到不同子空间；实施双重正交约束：特征正交投影确保遗忘类和保留类特征分离，梯度正交投影防止遗忘知识重新引入和保留类被破坏；动态子空间适应合并新遗忘子空间并压缩保留子空间

Result: 大量实验证明了该方法的有效性，实现了深度遗忘效果，其中遗忘效应是不可逆的

Conclusion: FG-OrIU通过在特征和梯度层面统一正交约束，解决了增量去学习中的浅层遗忘问题，实现了深度遗忘并保持了移除与保留之间的稳定平衡

Abstract: Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.

</details>


### [415] [Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models](https://arxiv.org/abs/2601.13580)
*Ahmad Al-Zuraiqi*

Main category: cs.LG

TL;DR: NOT是一种模块化适应框架，允许将预训练Transformer层作为可重用检查点进行领域适应，通过移植独立训练的"供体器官"层到兼容模型中，实现高效、隐私保护的专家知识共享。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法将训练参数与特定模型实例和训练数据紧密耦合，缺乏灵活性和隐私保护。NOT旨在创建可重用、可移植的检查点，实现隐私保护的领域专业知识共享。

Method: 从预训练模型中提取连续层子集作为"供体器官"，在领域特定数据上独立训练，保存为独立检查点文件，然后移植到兼容的接收模型中，无需原始训练数据。

Result: 在124M到20B参数的三种解码器架构上，NOT显著优于现有适应方法，困惑度比LoRA提高一个数量级，训练速度更快。方法具有位置依赖性，早期插入位置效果最佳。

Conclusion: Transformer中间层支持解码器架构的高效模块化迁移，通过检查点分发实现隐私保护的专家知识共享。目前方法仅限于解码器模型，编码器架构效果有限。

Abstract: We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.

</details>


### [416] [Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments](https://arxiv.org/abs/2601.13592)
*Hao Jing,Sa Xiao,Haoyu Li,Huadong Xiao,Wei Xue*

Main category: cs.LG

TL;DR: 该研究使用残差卷积神经网络替代RRTMG辐射方案，实现了离线训练在线耦合的混合预报框架，在保持精度的同时将计算速度提升约8倍。


<details>
  <summary>Details</summary>
Motivation: 辐射过程是数值模型中最耗时的物理过程，机器学习方法可以模拟辐射过程以提高计算效率。研究从业务角度探讨混合预报框架中嵌入深度神经网络的关键限制，特别是耦合兼容性和长期积分稳定性这两个基本瓶颈。

Method: 采用残差卷积神经网络来近似中国气象局全球业务系统中的RRTMG辐射方案。采用离线训练和在线耦合方法：1）通过模型模拟生成包含所有有云和无云大气柱的综合数据集；2）通过经验回放增强数据集稳定性，并基于物理意义施加额外输出约束；3）使用基于LibTorch的耦合方法，更适合实时业务计算。

Result: 混合模型能够按要求执行十天积分预报。两个月的业务回算实验表明，机器学习模拟器达到了与传统物理方案相当的精度，同时将计算速度提高了约八倍。

Conclusion: 研究成功构建了稳定高效的混合预报框架，解决了机器学习模型与数值预报系统耦合的关键技术问题，为业务应用提供了可行的解决方案。

Abstract: Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.

</details>


### [417] [Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models](https://arxiv.org/abs/2601.13599)
*Linrui Ma,Yufei Cui,Kai Han,Yunhe Wang*

Main category: cs.LG

TL;DR: 本文提出Diffusion in Diffusion框架，通过"先草稿后精炼"的两阶段方法解决块扩散语言模型的不可逆性和短视问题，在OpenWebText数据集上创下离散扩散模型新基准。


<details>
  <summary>Details</summary>
Motivation: 块扩散语言模型作为半自回归范式，结合了自回归和扩散模型的优势，但其严格的单向块依赖导致不可逆性，并牺牲了扩散模型著名的全局规划能力。需要解决这些问题。

Method: 提出Diffusion in Diffusion框架：1) 使用小块进行块扩散生成快速草稿；2) 通过具有更大双向感受野的全局双向扩散来精炼草稿；3) 使用快照置信度重掩码识别需要修改的关键token；4) 应用混合尺度训练扩展块扩散模型的全局能力。

Result: 在OpenWebText数据集上，仅使用基线模型26%的微调预算，将生成困惑度从25.7降至21.9，显著缩小了与自回归模型的性能差距，为离散扩散模型设定了新基准。

Conclusion: Diffusion in Diffusion框架有效解决了块扩散模型的不可逆性和短视问题，通过两阶段草稿-精炼方法结合了快速生成和全局规划的优势，在效率和性能上都取得了显著提升。

Abstract: Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.

</details>


### [418] [Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data](https://arxiv.org/abs/2601.13608)
*Zhipeng Chang,Ting He,Wenrui Hao*

Main category: cs.LG

TL;DR: FIPA（Fisher-Informed Parameterwise Aggregation）是一种针对联邦学习的二阶聚合方法，使用参数特定的Fisher信息矩阵权重替代客户端级别的标量权重，以解决非IID数据下的客户端漂移问题。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，当数据是非独立同分布（non-IID）时，标准的FedAvg等方法对所有参数应用相同的标量权重，导致客户端更新严重错位，产生客户端漂移并降低全局模型性能。

Method: 提出FIPA方法，使用Fisher信息矩阵为每个参数提供特定的权重，实现真正的参数级别缩放，捕捉每个客户端数据对不同参数的独特影响。通过低秩近似保持通信和计算效率。

Result: 在非线性函数回归、偏微分方程学习和图像分类任务中，FIPA始终优于基于平均的聚合方法，并且可以与最先进的客户端优化算法有效结合，进一步提高图像分类精度。

Conclusion: FIPA为异构数据分布下的联邦学习提供了显著优势，通过参数特定的二阶聚合有效缓解客户端漂移问题，在各种任务中表现出优越性能。

Abstract: Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.

</details>


### [419] [Quadratic Upper Bound for Boosting Robustness](https://arxiv.org/abs/2601.13645)
*Euijin You,Hyang-Won Lee*

Main category: cs.LG

TL;DR: 本文提出一种二次上界损失函数，用于缓解快速对抗训练中因对抗空间探索不足导致的鲁棒性下降问题，显著提升了现有方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 快速对抗训练虽然能减少训练时间，但往往因对抗空间探索不足而导致鲁棒性下降。需要一种方法来缓解这种鲁棒性退化问题。

Method: 推导出对抗训练损失函数的二次上界，并将该上界损失与现有的快速对抗训练方法结合使用。

Result: 实验结果表明，将QUB损失应用于现有方法能显著提升鲁棒性。通过多种指标证明，这种改进可能源于所得模型损失曲面的平滑化。

Conclusion: 提出的二次上界损失函数能有效解决快速对抗训练中的鲁棒性下降问题，通过平滑损失曲面来提升模型的对抗鲁棒性。

Abstract: Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.

</details>


### [420] [TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation](https://arxiv.org/abs/2601.13653)
*Xingjian Wu,Junkai Lu,Zhengyu Li,Xiangfei Qiu,Jilin Hu,Chenjuan Guo,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: TimeART是一个融合强大大数据分析工具与大型语言模型推理能力的框架，作为完全自主的时间序列问答智能体数据科学家，在多个TSQA任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列分析主要依赖人工数据科学家，成本高且缺乏自动化，需要开发能够自动分析和解释时间序列数据的解决方案。

Method: 1. 提出TimeART框架，融合现成数据分析工具的能力和LLMs的推理能力；2. 收集10万条专家轨迹语料TimeToolBench；3. 设计四阶段训练策略，让时间序列推理模型从早期经验和自我反思中学习。

Result: 基于TimeToolBench训练的8B参数时间序列推理模型，结合TimeART框架，在多个时间序列问答任务上取得了一致的state-of-the-art性能。

Conclusion: TimeART框架开创了自主时间序列推理的新方法，通过融合工具能力和LLM推理，实现了完全自主的时间序列问答智能体数据科学家。

Abstract: Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.

</details>


### [421] [Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery](https://arxiv.org/abs/2601.13676)
*Fabian Greifeneder,Wolfgang Fenz,Benedikt Alkin,Johannes Brandstetter,Michael Giretzlehner,Philipp Moser*

Main category: cs.LG

TL;DR: 提出基于深度学习的脑组织变形模拟替代模型，使用通用物理变换器直接处理大规模网格数据，通过随机教师强制策略减少误差累积，实现实时神经外科手术模拟。


<details>
  <summary>Details</summary>
Motivation: 传统数值求解器难以满足神经外科手术模拟器的实时性能要求，需要开发能够准确模拟脑组织非线性变形且满足实时交互需求的解决方案。

Method: 基于通用物理变换器构建深度学习替代模型，直接在大型网格数据上操作；使用非线性有限元模拟生成的大规模数据集进行训练；提出随机教师强制策略，在训练中逐渐减少真实输入比例，增加模型预测比例，以减少自回归推理中的误差累积。

Result: 模型能够准确高效地预测多种瞬态脑变形场景，可扩展到15万个节点的网格；随机教师强制技术显著改善长期滚动的稳定性，将最大预测误差从6.7毫米降低到3.5毫米；在消费级推理硬件上实现每模拟步骤低于10毫秒的运行时间，可集成到交互式神经外科模拟环境中。

Conclusion: 提出的深度学习框架能够实现快速、平滑且准确的动态脑组织生物力学模拟，为现实手术训练环境奠定基础，解决了传统方法在实时性能方面的局限性。

Abstract: Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.

</details>


### [422] [Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation](https://arxiv.org/abs/2601.13698)
*Arjun Nichani,Hsiang Hsu,Chun-Fu,Chen,Haewon Jeong*

Main category: cs.LG

TL;DR: 本文通过信息论工具Chernoff信息研究公平性、隐私性和准确性三者之间的关系，揭示这种关系具有数据依赖性，并提出了在未知分布数据上估计Chernoff信息的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管公平性和隐私性都是可信机器学习的重要支柱，但两者之间的关系以及它们与准确性的相互作用尚未得到充分研究。本文旨在探索公平性、隐私性和准确性这三者之间的数据依赖关系。

Method: 使用信息论度量Chernoff信息，定义Noisy Chernoff Difference工具来分析三者关系。对于合成数据，展示该值在三种不同数据分布下的行为模式。提出在未知分布数据上估计Chernoff信息的方法，并将框架应用于真实数据集。

Result: 研究发现Noisy Chernoff Difference根据数据分布表现出三种不同的行为模式，并揭示了这些模式对应的公平性和隐私性含义。此外，该值可以作为公平性-准确性曲线陡峭度的代理指标。

Conclusion: 公平性、隐私性和准确性之间的关系具有数据依赖性，Noisy Chernoff Difference为理解这种关系提供了统一的分析框架。该研究有助于建立对三者动态关系的统一理解。

Abstract: Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.

</details>


### [423] [Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction](https://arxiv.org/abs/2601.13710)
*Sayeed Shafayet Chowdhury,Snehasis Mukhopadhyay,Shiaofen Fang,Vijay R. Ramakrishnan*

Main category: cs.LG

TL;DR: 本研究比较了监督机器学习与生成式AI在预测慢性鼻窦炎手术效果方面的表现，发现ML模型（特别是MLP）在准确性、校准和临床决策价值上优于GenAI，建议采用ML为主、GenAI为辅的工作流程。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医学影像领域已有广泛应用，但在临床数据上进行前瞻性决策支持的实际应用仍然有限。本研究旨在探讨如何利用术前临床数据预测慢性鼻窦炎手术效果，识别那些术后效果不佳、本应避免手术的患者。

Method: 使用前瞻性收集的队列数据（所有患者均接受手术），比较监督机器学习（逻辑回归、树集成方法和自研MLP）与生成式AI（ChatGPT、Claude、Gemini、Perplexity）的表现。所有模型接收相同的结构化输入，输出被约束为二元推荐加置信度。建立了可复现的表格数据到GenAI的评估协议，并进行亚组分析。

Result: 最佳ML模型（MLP）达到85%的准确率，在校准和决策曲线净收益方面表现优越。GenAI模型在零样本设置下的区分度和校准表现不佳。值得注意的是，GenAI的解释与临床医生的启发式思维以及MLP的特征重要性一致，都强调基线SNOT-22评分、CT/内镜严重程度、息肉表型以及心理/疼痛共病。提供了可复现的评估协议和亚组分析。

Conclusion: 研究结果支持采用"ML为主、GenAI增强"的工作流程：部署经过校准的ML模型进行手术候选者的初步分诊，同时使用GenAI作为解释工具，以增强透明度和促进共享决策制定。

Abstract: Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.

</details>


### [424] [EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory](https://arxiv.org/abs/2601.13748)
*Tien-Dat Pham,Xuan-The Tran*

Main category: cs.LG

TL;DR: EEG-Titans：一种用于癫痫发作预测的双分支架构，通过神经记忆机制建模长时上下文，在CHB-MIT数据集上达到99.46%的段级敏感度，并能在高噪声下降低误报率。


<details>
  <summary>Details</summary>
Motivation: 癫痫发作预测面临挑战：发作前动态可能跨越长时间，临床相关特征可能细微且短暂。现有深度学习模型在捕捉局部时空模式和保持长时上下文信息之间存在权衡。

Method: 提出EEG-Titans双分支架构：结合滑动窗口注意力捕捉短期异常，以及循环记忆通路总结随时间渐进的慢趋势。采用神经记忆机制进行长上下文建模，并为高噪声受试者设计分层上下文策略扩展感受野。

Result: 在CHB-MIT头皮EEG数据集上，按时间顺序保留协议评估，EEG-Titans在18名受试者中达到99.46%的平均段级敏感度。分层上下文策略能显著减少误报（极端情况下降至0.00 FPR/h），同时保持敏感度。

Conclusion: 基于记忆增强的长上下文建模能够在临床约束评估下提供稳健的癫痫发作预测，在保持高敏感度的同时有效降低误报率，特别是对于噪声较大的记录。

Abstract: Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation

</details>


### [425] [vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting](https://arxiv.org/abs/2601.13768)
*Wenzhen Yue,Ruohao Guo,Ji Shi,Zihan Hao,Shiyu Hu,Xianghua Ying*

Main category: cs.LG

TL;DR: vLinear是一个基于线性模型的高效多变量时间序列预测器，通过vecTrans模块降低计算复杂度，并使用WFMLoss目标函数提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的预测器通常依赖自注意力机制或其变体来捕捉多变量相关性，这通常会产生O(N²)的计算复杂度（N为变量数量）。为了解决这个问题，需要开发更高效的模型。

Method: 提出vLinear框架，包含两个核心组件：1) vecTrans模块，使用可学习向量建模多变量相关性，将复杂度降低到O(N)；2) WFMLoss目标函数，采用最终序列导向的加权流匹配损失，包含路径和时域加权策略。

Result: vLinear在22个基准测试和124个预测设置中达到最先进的性能。vecTrans可以无缝集成到基于Transformer的预测器中，提供高达5倍的推理加速和一致的性能提升。WFMLoss作为即插即用的目标函数，能持续改进现有预测器。

Conclusion: vLinear通过vecTrans模块高效建模多变量相关性，结合WFMLoss目标函数显著提升预测精度，为多变量时间序列预测提供了有效且高效的解决方案。

Abstract: In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at https://anonymous.4open.science/r/vLinear.

</details>


### [426] [Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks](https://arxiv.org/abs/2601.13776)
*Thibaut Boissin,Franck Mamalet,Valentin Lafargue,Mathieu Serrurier*

Main category: cs.LG

TL;DR: Orthogonium是一个统一的PyTorch库，提供正交和1-Lipschitz神经网络层，解决现有实现碎片化、有限和计算需求高的问题，支持卷积标准特性同时保持数学保证。


<details>
  <summary>Details</summary>
Motivation: 正交和1-Lipschitz神经网络层对于认证对抗鲁棒性、稳定生成模型和可靠循环网络至关重要，但现有实现存在碎片化、功能有限和计算需求高的问题，阻碍了这些技术的大规模采用。

Method: 开发Orthogonium库，提供统一、高效、全面的正交和1-Lipschitz层实现，支持标准卷积特性（步长、膨胀、分组、转置等），同时保持严格的数学保证，并通过优化实现在大规模基准测试中减少开销。

Result: 库的优化实现在ImageNet等大规模基准测试中减少了开销，并通过严格测试发现了现有实现中的关键错误，证明了标准化可靠工具的重要性。Orthogonium显著降低了采用门槛，支持跨多种应用的可扩展实验和集成。

Conclusion: Orthogonium为需要正交性和鲁棒Lipschitz约束的深度学习应用提供了一个标准化、高效且可靠的解决方案，有望推动相关技术在认证对抗鲁棒性等领域的广泛应用。

Abstract: Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at https://github.com/deel-ai/orthogonium.

</details>


### [427] [Principled Latent Diffusion for Graphs via Laplacian Autoencoders](https://arxiv.org/abs/2601.13780)
*Antoine Siraudin,Christopher Morris*

Main category: cs.LG

TL;DR: LG-Flow提出了一种潜在图扩散框架，通过置换等变自编码器将图压缩到低维潜在空间，然后使用扩散变换器进行生成，解决了传统图扩散模型二次复杂度和稀疏图建模效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图扩散模型存在两个主要问题：1）节点数量的二次复杂度，限制了模型规模和效率；2）在稀疏图中大量容量浪费在建模不存在的边上。同时，图生成需要近乎无损的重建，因为邻接矩阵中的单个错误就可能导致整个样本无效。

Method: 提出LG-Flow框架，包含两个核心组件：1）置换等变自编码器，将每个节点映射到固定维度的嵌入，从这些嵌入中可以可证明地恢复完整的邻接矩阵；2）在潜在空间中训练带有流匹配的扩散变换器进行生成。潜在表示维度与节点数量线性相关，消除了二次瓶颈。

Result: LG-Flow在保持与最先进图扩散模型竞争性能的同时，实现了高达1000倍的加速。该方法支持无向图和有向无环图的近乎无损重建，使得训练更大、更具表达力的模型变得可行。

Conclusion: LG-Flow成功解决了图扩散模型的效率和重建质量难题，通过潜在空间压缩和扩散变换器的结合，为大规模图生成提供了高效且有效的解决方案。

Abstract: Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.

</details>


### [428] [PAtt: A Pattern Attention Network for ETA Prediction Using Historical Speed Profiles](https://arxiv.org/abs/2601.13793)
*ByeoungDo Kim,JunYeop Na,Kyungwook Tak,JunTae Kim,DongHyeon Kim,Duckky Kim*

Main category: cs.LG

TL;DR: 提出基于注意力机制的历史道路速度模式ETA预测模型，通过时空注意力有效提取路径各点的时空特征，实现轻量高效且准确的到达时间估计。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和智能交通系统普及，准确可靠的ETA预测在导航、出行规划和交通管理中日益重要。然而，交通流的动态复杂性使ETA预测充满挑战，传统方法要么简单组合实时和历史数据，要么依赖复杂规则计算，而现有深度学习模型计算成本高且未能有效捕捉关键的时空模式。

Method: 提出基于注意力机制的ETA模型，利用历史道路速度模式的注意力机制。模型通过注意力机制提取和利用路径上每个时空点累积的时空特征，有效处理ETA预测中固有的时空因果关系。该架构保持模型轻量化和可扩展性的同时实现高效准确的ETA估计。

Result: 使用真实世界驾驶数据集验证，模型在有效整合道路特征、实时交通状况和历史速度模式（以任务感知方式）方面优于现有基线方法。

Conclusion: 该基于注意力机制的ETA模型能够有效捕捉时空模式，在保持计算效率的同时提供准确的到达时间预测，为自动驾驶和智能交通系统提供了实用的解决方案。

Abstract: In this paper, we propose an ETA model (Estimated Time of Arrival) that leverages an attention mechanism over historical road speed patterns. As autonomous driving and intelligent transportation systems become increasingly prevalent, the need for accurate and reliable ETA estimation has grown, playing a vital role in navigation, mobility planning, and traffic management. However, predicting ETA remains a challenging task due to the dynamic and complex nature of traffic flow. Traditional methods often combine real-time and historical traffic data in simplistic ways, or rely on complex rule-based computations. While recent deep learning models have shown potential, they often require high computational costs and do not effectively capture the spatio-temporal patterns crucial for ETA prediction. ETA prediction inherently involves spatio-temporal causality, and our proposed model addresses this by leveraging attention mechanisms to extract and utilize temporal features accumulated at each spatio-temporal point along a route. This architecture enables efficient and accurate ETA estimation while keeping the model lightweight and scalable. We validate our approach using real-world driving datasets and demonstrate that our approach outperforms existing baselines by effectively integrating road characteristics, real-time traffic conditions, and historical speed patterns in a task-aware manner.

</details>


### [429] [ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks](https://arxiv.org/abs/2601.13824)
*Xiaohong Yang,Tong Xie,Minghui Liwang,Chikai Shang,Yang Lu,Zhenzhen Jiao,Liqun Fu,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: ELSA是一个用于边缘网络LLM微调的新框架，通过结合分裂学习和分层联邦学习，解决了设备资源限制、数据异构性和隐私风险三大挑战。


<details>
  <summary>Details</summary>
Motivation: 边缘网络训练大型语言模型面临设备资源受限、数据高度异构和隐私风险增加三个根本性挑战，需要一种能够同时解决这些问题的分布式训练框架。

Method: ELSA采用三个关键创新：1）基于语义指纹的客户端聚类机制；2）将LLM分为三部分跨客户端和边缘服务器分配；3）基于计算草图和语义子空间正交扰动的轻量通信方案。

Result: 在多种NLP任务上的实验表明，ELSA在适应性、收敛行为和鲁棒性方面始终优于现有方法，为资源受限的边缘侧LLM微调提供了可扩展且隐私感知的解决方案。

Conclusion: ELSA成功整合了分裂学习和分层联邦学习，为边缘网络中的LLM微调提供了一个高效、可扩展且隐私保护的框架，解决了资源约束、数据异构和隐私风险的关键挑战。

Abstract: Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.

</details>


### [430] [Optimal L2 Regularization in High-dimensional Continual Linear Regression](https://arxiv.org/abs/2601.13844)
*Gilad Karpel,Edward Moroshko,Ran Levinstein,Ron Meir,Daniel Soudry,Itay Evron*

Main category: cs.LG

TL;DR: 论文研究过参数化连续线性回归中的泛化问题，发现各向同性正则化能缓解标签噪声，最优正则化强度随任务数T呈T/ln T比例增长。


<details>
  <summary>Details</summary>
Motivation: 研究连续学习中的泛化问题，特别是在过参数化线性回归设置中，探索各向同性正则化如何影响多任务学习中的泛化性能。

Method: 在连续线性回归设置中，使用L2（各向同性）正则化训练模型，推导高维状态下任意线性教师模型的期望泛化损失闭式解。

Result: 各向同性正则化在单教师和多i.i.d.教师设置下都能缓解标签噪声；最优固定正则化强度随任务数T呈T/ln T比例增长。

Conclusion: 该研究首次在理论连续学习中证明最优正则化强度的T/ln T缩放规律，为连续学习系统设计提供了实用指导。

Abstract: We study generalization in an overparameterized continual linear regression setting, where a model is trained with L2 (isotropic) regularization across a sequence of tasks. We derive a closed-form expression for the expected generalization loss in the high-dimensional regime that holds for arbitrary linear teachers. We demonstrate that isotropic regularization mitigates label noise under both single-teacher and multiple i.i.d. teacher settings, whereas prior work accommodating multiple teachers either did not employ regularization or used memory-demanding methods. Furthermore, we prove that the optimal fixed regularization strength scales nearly linearly with the number of tasks $T$, specifically as $T/\ln T$. To our knowledge, this is the first such result in theoretical continual learning. Finally, we validate our theoretical findings through experiments on linear regression and neural networks, illustrating how this scaling law affects generalization and offering a practical recipe for the design of continual learning systems.

</details>


### [431] [Inverting Self-Organizing Maps: A Unified Activation-Based Framework](https://arxiv.org/abs/2601.13851)
*Alessandro Londei,Matteo Benati,Denise Lanzieri,Vittorio Loreto*

Main category: cs.LG

TL;DR: 论文提出MUSIC方法，利用自组织映射（SOM）的激活模式（与原型点的平方距离）进行精确输入重构和可控语义变换，无需采样、潜在先验或编码器-解码器架构。


<details>
  <summary>Details</summary>
Motivation: 自组织映射（SOM）广泛应用于可视化、聚类和向量量化，但传统方法主要关注数据投影而非精确重构。本研究旨在探索SOM激活模式的反转能力，实现精确输入恢复和可控语义变换，为数据增强和潜在空间探索提供新视角。

Method: 基于欧氏距离几何原理，利用D+1个仿射独立参考点的距离唯一确定D维空间中的点。推导相应线性系统，提出MUSIC更新规则，通过修改选定原型点的平方距离同时保持其他距离不变，实现确定性几何流。使用Tikhonov正则化稳定更新规则，确保高维数据集上的平滑运动。

Result: 在合成高斯混合、MNIST和Faces in the Wild数据集上验证，MUSIC能够产生平滑、可解释的轨迹，揭示学习流形的底层几何结构。无扰动时能精确恢复输入，指定目标聚类或原型时能产生连贯的语义变化同时保持在数据流形上。

Conclusion: SOM激活模式可在温和几何条件下精确反转，MUSIC方法基于原型几何实现了可控的潜在探索和数据增强，展示了SOM反转相对于无监督聚类的优势，为基于原型几何的数据操作提供了新框架。

Abstract: Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.

</details>


### [432] [Multi-Objective Hierarchical Optimization with Large Language Models](https://arxiv.org/abs/2601.13892)
*Andrej Schwanke,Lyubomir Ivanov,David Salinas,Frank Hutter,Arber Zela*

Main category: cs.LG

TL;DR: 该论文提出了一种基于大语言模型的分层搜索策略，用于多目标优化问题。通过将输入空间自适应分区并引导LLM在特定高潜力子空间生成候选解，显著提升了LLM在多目标优化中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理能力方面表现出色，但在多目标优化领域尚未成为即用型选择。传统优化方法在基准测试中表现优异，因为它们能处理数值输入、平衡探索与利用、处理多个冲突目标。本文旨在弥补这一差距，让LLM在多目标优化中发挥更大作用。

Method: 提出了一个结构化的分层搜索策略：1）将输入空间自适应划分为不相交的超矩形区域；2）使用复合评分函数对这些区域进行排名；3）将LLM的生成过程限制在特定高潜力子空间内。这样LLM只需进行局部推理，无需考虑问题的全局结构。

Result: 在标准正则性假设下，算法生成的候选解在Hausdorff距离下收敛到真实的Pareto集。实证结果表明，该方法在合成和真实世界基准测试中：1）始终优于基于全局LLM的多目标优化器；2）与标准进化算法和贝叶斯优化算法性能相当。

Conclusion: 通过将LLM作为代理模型和候选采样器集成到分层搜索框架中，成功解决了LLM在多目标优化中的局限性。该方法使LLM能够有效处理数值优化问题，同时保持了传统优化方法的性能水平。

Abstract: Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.

</details>


### [433] [TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography](https://arxiv.org/abs/2601.13897)
*Ankita Joshi,Ashutosh Sharma,Anoushkrit Goel,Ranjeet Ranjan Jha,Chirag Ahuja,Arnav Bhavsar,Aditya Nigam*

Main category: cs.LG

TL;DR: 提出TractRLFusion：基于GPT的策略融合框架，整合多个强化学习策略以改进白质纤维束重建的准确性和解剖可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统纤维束成像方法在准确重建白质纤维束并减少虚假连接方面存在挑战，需要更先进的深度学习方法来提高重建质量。

Method: 采用GPT-based策略融合框架，通过两阶段训练数据选择实现有效策略融合，再通过多批评器微调增强鲁棒性和泛化能力。

Result: 在HCP、ISMRM和TractoInferno数据集上的实验表明，TractRLFusion在准确性和解剖可靠性方面优于单个RL策略以及最先进的经典和DRL方法。

Conclusion: TractRLFusion通过整合多个RL策略提供了一种有效的纤维束成像方法，能够更准确地重建白质纤维束并减少虚假连接。

Abstract: Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.

</details>


### [434] [Differentiable Logic Synthesis: Spectral Coefficient Selection via Sinkhorn-Constrained Composition](https://arxiv.org/abs/2601.13953)
*Gorgi Pavlov*

Main category: cs.LG

TL;DR: 论文提出了一种名为Hierarchical Spectral Composition的分层谱组合架构，用于通过梯度下降学习精确的布尔逻辑，解决了传统神经网络在量化后性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 通过梯度下降学习精确布尔逻辑面临挑战：神经网络通常收敛到"模糊"的近似解，在量化后性能会下降。需要一种能够学习精确布尔表示并能有效量化的方法。

Method: 引入分层谱组合架构，从冻结的布尔傅里叶基中选择谱系数，通过Sinkhorn约束路由和列符号调制进行组合。该方法基于流形约束超连接(mHC)的见解，将路由矩阵投影到Birkhoff多面体上以保持恒等映射和稳定训练。通过列符号调制实现布尔否定功能。

Result: 在四个复杂度递增的阶段中验证：n=2时达到100%准确率；n=3时梯度下降达到76%准确率，但枚举证明所有操作都存在最优三元掩码；n=4时通过谱合成（结合精确Walsh-Hadamard系数、三元量化和MCMC细化）在所有操作上达到100%准确率。所有操作在GPU上实现单周期组合逻辑推理，速度为10,959 MOps/s。

Conclusion: 证明了所有测试函数都存在三元多项式阈值表示，但随着维度增加，找到这些表示需要超越纯梯度下降的方法。该方法展示了硬件高效的神经符号逻辑合成的可行性。

Abstract: Learning precise Boolean logic via gradient descent remains challenging: neural networks typically converge to "fuzzy" approximations that degrade under quantization. We introduce Hierarchical Spectral Composition, a differentiable architecture that selects spectral coefficients from a frozen Boolean Fourier basis and composes them via Sinkhorn-constrained routing with column-sign modulation. Our approach draws on recent insights from Manifold-Constrained Hyper-Connections (mHC), which demonstrated that projecting routing matrices onto the Birkhoff polytope preserves identity mappings and stabilizes large-scale training. We adapt this framework to logic synthesis, adding column-sign modulation to enable Boolean negation -- a capability absent in standard doubly stochastic routing.
  We validate our approach across four phases of increasing complexity: (1) For n=2 (16 Boolean operations over 4-dim basis), gradient descent achieves 100% accuracy with zero routing drift and zero-loss quantization to ternary masks. (2) For n=3 (10 three-variable operations), gradient descent achieves 76% accuracy, but exhaustive enumeration over 3^8 = 6561 configurations proves that optimal ternary masks exist for all operations (100% accuracy, 39% sparsity). (3) For n=4 (10 four-variable operations over 16-dim basis), spectral synthesis -- combining exact Walsh-Hadamard coefficients, ternary quantization, and MCMC refinement with parallel tempering -- achieves 100% accuracy on all operations. This progression establishes (a) that ternary polynomial threshold representations exist for all tested functions, and (b) that finding them requires methods beyond pure gradient descent as dimensionality grows. All operations enable single-cycle combinational logic inference at 10,959 MOps/s on GPU, demonstrating viability for hardware-efficient neuro-symbolic logic synthesis.

</details>


### [435] [RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning](https://arxiv.org/abs/2601.13964)
*Cheol-Hui Lee,Hwa-Yeon Lee,Dong-Joo Kim*

Main category: cs.LG

TL;DR: RL-BioAug 使用标签高效的强化学习代理来自主确定 EEG 对比学习的最佳数据增强策略，仅用 10% 的标签数据指导，显著提升睡眠分期和癫痫检测任务的性能。


<details>
  <summary>Details</summary>
Motivation: 由于 EEG 信号的非平稳性（统计特性随时间变化），静态或随机的数据增强策略往往无法保留内在信息，这限制了对比学习在 EEG 任务中的性能。需要一种能够自主适应信号特性的智能增强方法。

Method: 提出 RL-BioAug 框架，利用标签高效的强化学习（RL）代理来自主确定最优的数据增强策略。仅使用 10% 的标签数据来指导代理的策略学习，而编码器则在严格的自监督方式下学习鲁棒表征。

Result: 在 Sleep-EDFX 和 CHB-MIT 数据集上，RL-BioAug 显著优于随机选择策略，Macro-F1 分数分别提升了 9.69% 和 8.80%。代理为不同任务选择了不同的最优策略：睡眠分期主要选择时间掩码（62%概率），癫痫检测主要选择裁剪与重缩放（77%概率）。

Conclusion: RL-BioAug 有潜力取代传统的基于启发式的数据增强方法，为 EEG 分析建立一种新的自主数据增强范式。框架展示了仅用少量标签数据指导就能学习任务特定增强策略的有效性。

Abstract: The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{https://github.com/dlcjfgmlnasa/RL-BioAug}{https://github.com/dlcjfgmlnasa/RL-BioAug}.

</details>


### [436] [A universal linearized subspace refinement framework for neural networks](https://arxiv.org/abs/2601.13989)
*Wenbo Cao,Weiwei Zhang*

Main category: cs.LG

TL;DR: LSR（线性化子空间精炼）是一种架构无关的框架，通过在固定训练网络状态下利用雅可比诱导的线性残差模型，解决降维最小二乘问题，获得显著优于标准梯度训练的精炼线性预测器。


<details>
  <summary>Details</summary>
Motivation: 神经网络通常使用基于梯度的方法训练，但在许多应用中，其最终预测精度远未达到模型表达能力可达到的水平。梯度训练可能无法充分利用模型潜力，即使局部线性化产生凸问题时也是如此。

Method: LSR利用固定训练网络状态下的雅可比诱导线性残差模型，通过解决该子空间内的降维直接最小二乘问题，计算线性化残差模型的子空间最优解。对于具有复合损失结构的算子约束问题，进一步引入迭代LSR，交替进行一次性LSR和监督非线性对齐。

Result: LSR系统地暴露了梯度训练未充分利用的精度水平，经常实现数量级的误差减少。在监督函数逼近、数据驱动算子学习和物理信息算子微调等任务中表现出显著优势。

Conclusion: 损失引起的数值病态性（而非非凸性或模型表达能力）可能是实际瓶颈。LSR通过将非线性神经表示与固定线性化点的降维线性求解器结合，为监督学习、算子学习和科学计算提供了数值基础广泛的精炼框架。

Abstract: Neural networks are predominantly trained using gradient-based methods, yet in many applications their final predictions remain far from the accuracy attainable within the model's expressive capacity. We introduce Linearized Subspace Refinement (LSR), a general and architecture-agnostic framework that exploits the Jacobian-induced linear residual model at a fixed trained network state. By solving a reduced direct least-squares problem within this subspace, LSR computes a subspace-optimal solution of the linearized residual model, yielding a refined linear predictor with substantially improved accuracy over standard gradient-trained solutions, without modifying network architectures, loss formulations, or training procedures. Across supervised function approximation, data-driven operator learning, and physics-informed operator fine-tuning, we show that gradient-based training often fails to access this attainable accuracy, even when local linearization yields a convex problem. This observation indicates that loss-induced numerical ill-conditioning, rather than nonconvexity or model expressivity, can constitute a dominant practical bottleneck. In contrast, one-shot LSR systematically exposes accuracy levels not fully exploited by gradient-based training, frequently achieving order-of-magnitude error reductions. For operator-constrained problems with composite loss structures, we further introduce Iterative LSR, which alternates one-shot LSR with supervised nonlinear alignment, transforming ill-conditioned residual minimization into numerically benign fitting steps and yielding accelerated convergence and improved accuracy. By bridging nonlinear neural representations with reduced-order linear solvers at fixed linearization points, LSR provides a numerically grounded and broadly applicable refinement framework for supervised learning, operator learning, and scientific computing.

</details>


### [437] [Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment](https://arxiv.org/abs/2601.14022)
*Rodrigo Pereira David,Luciano Araujo Dourado Filho,Daniel Marques da Silva,João Alfredo Cal-Braz*

Main category: cs.LG

TL;DR: 论文提出了一种基于机器学习的框架，用于在相同真实驾驶条件下公平比较内燃机车和电动车的CO2排放。


<details>
  <summary>Details</summary>
Motivation: 道路运输脱碳需要一致透明的方法来比较不同车辆技术的CO2排放，现有方法缺乏在相同驾驶条件下对ICEV和EV的直接公平比较。

Method: 使用循环神经网络分别训练ICEV和EV模型，学习从驾驶变量（速度、加速度、温度）到内部执行变量（扭矩、油门）和瞬时CO2当量排放率的映射，通过保持相同驾驶条件和环境背景来构建反事实场景。

Result: 该框架能够在统一瞬时排放指标下公平评估动力总成技术，为真实驾驶条件下的车辆碳性能评估提供可扩展、可信的数据驱动基础。

Conclusion: 提出的机器学习框架为ICEV和EV的运营评估提供了公平可比的方法，支持在相同真实驾驶条件下对动力总成技术进行可重复的碳排放评估。

Abstract: Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.

</details>


### [438] [Universal Approximation Theorem for Input-Connected Multilayer Perceptrons](https://arxiv.org/abs/2601.14026)
*Vugar Ismailov*

Main category: cs.LG

TL;DR: 提出IC-MLP架构，在隐藏层神经元中增加原始输入的仿射连接，证明了深度IC-MLP在非线性激活函数下的通用逼近能力


<details>
  <summary>Details</summary>
Motivation: 传统MLP隐藏层仅接收前一层的输出，本文探索在隐藏层神经元中增加原始输入的仿射连接，研究这种架构的表达能力和逼近特性

Method: 提出输入连接多层感知机(IC-MLP)，每个隐藏神经元除了接收前一层输出外，还接收原始输入的仿射连接。在单变量和向量输入设置下进行理论分析，推导网络函数的迭代公式

Result: 证明了深度IC-MLP在非线性激活函数下能够逼近闭区间上的任何连续函数（单变量情况），并扩展到多维输入在紧致子集上的连续函数逼近

Conclusion: IC-MLP架构具有与传统MLP相同的通用逼近能力，但通过增加输入连接提供了不同的网络结构，为神经网络架构设计提供了新的理论视角

Abstract: We introduce the Input-Connected Multilayer Perceptron (IC-MLP), a feedforward neural network architecture in which each hidden neuron receives, in addition to the outputs of the preceding layer, a direct affine connection from the raw input. We first study this architecture in the univariate setting and give an explicit and systematic description of IC-MLPs with an arbitrary finite number of hidden layers, including iterated formulas for the network functions. In this setting, we prove a universal approximation theorem showing that deep IC-MLPs can approximate any continuous function on a closed interval of the real line if and only if the activation function is nonlinear. We then extend the analysis to vector-valued inputs and establish a corresponding universal approximation theorem for continuous functions on compact subsets of $\mathbb{R}^n$.

</details>


### [439] [PAC-Private Responses with Adversarial Composition](https://arxiv.org/abs/2601.14033)
*Xiaochen Zhu,Mayuri Sridhar,Srinivas Devadas*

Main category: cs.LG

TL;DR: 提出一种基于模型输出的隐私保护方法，通过PAC隐私框架控制互信息，在适应性和对抗性查询下实现线性隐私累积，在极低隐私预算下保持高模型效用。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型常通过API部署，传统权重隐私方法（如DP-SGD）在API场景下噪声过大且效用低。模型权重随训练数据变化大，但模型对特定输入的输出维度更低且更稳定，因此直接在模型输出上实施隐私保护更有优势。

Method: 采用PAC隐私框架，通过控制互信息（MI）为任意黑盒函数提供基于实例的隐私保证。提出新算法通过自适应噪声校准实现对抗性组合，证明在适应性和对抗性查询下互信息保证线性累积。

Result: 在表格、视觉和NLP任务上实验显示，该方法在极小的每查询隐私预算下实现高效用。在CIFAR-10上达到87.79%准确率，每步MI预算仅2^{-32}。能服务100万查询同时将成员推理攻击成功率上界控制在51.08%，相当于(0.04,10^{-5})-DP保证。通过私有响应标注公共数据蒸馏模型，在ImageNet子集上蒸馏的模型在CIFAR-10上达到91.86%准确率，MIA成功率上界50.49%，相当于(0.02,10^{-5})-DP。

Conclusion: 该方法在模型输出层面实施隐私保护，通过PAC隐私框架和自适应噪声校准，在适应性和对抗性查询场景下实现了线性隐私累积，在极低隐私预算下保持了高模型效用，为API部署的机器学习模型提供了有效的隐私保护方案。

Abstract: Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs.
  We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying.
  Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.

</details>


### [440] [LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems](https://arxiv.org/abs/2601.14053)
*Badri N. Patro,Vijay S. Agneeswaran*

Main category: cs.LG

TL;DR: LLMOrbit提出了一个2019-2025年大语言模型的循环分类法，分析了50多个模型，识别了数据稀缺、成本增长和能耗三大危机，并揭示了打破扩展瓶颈的六种范式：测试时计算、量化、分布式边缘计算、模型融合、高效训练和小型专用模型。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能从基础Transformer架构发展到接近人类水平的推理能力系统，需要系统梳理大语言模型的发展脉络。该研究旨在通过全面分类法导航LLM领域，分析架构创新、训练方法和效率模式，并识别限制暴力扩展方法的关键瓶颈。

Method: 采用LLMOrbit循环分类法，通过八个相互关联的轨道维度分析2019-2025年间超过50个模型和15个组织。该方法从架构创新、训练方法、效率模式等多个角度系统评估现代LLM、生成式AI和智能体系统的发展。

Result: 识别了三大危机：数据稀缺（2026-2028年将耗尽9-27T tokens）、指数级成本增长（5年内从300万美元增至3亿美元以上）、不可持续的能耗（增长22倍）。发现了打破扩展瓶颈的六种范式，包括测试时计算、量化等技术，以及后训练增益、效率革命和民主化三大范式转变。

Conclusion: 大语言模型领域正面临扩展瓶颈，但通过测试时计算、量化、分布式边缘计算等创新范式可以突破这些限制。后训练技术、效率优化和开源民主化正在重塑LLM发展轨迹，推动从被动生成到工具使用智能体的演进。

Abstract: The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.

</details>


### [441] [Optimizing Energy and Data Collection in UAV-aided IoT Networks using Attention-based Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2601.14092)
*Babacar Toure,Dimitrios Tsilimantos,Omid Esrafilian,Marios Kountouris*

Main category: cs.LG

TL;DR: 提出基于注意力机制的多目标强化学习架构，解决无人机数据采集中的能量消耗与数据收集权衡问题，在未知信道条件下实现自适应路径规划。


<details>
  <summary>Details</summary>
Motivation: 无人机在无线网络数据采集中应用广泛，但现有AI方法存在训练数据有限、忽略任务多目标本质、难以适应动态环境等问题。

Method: 采用注意力机制的多目标强化学习架构，无需无线信道先验知识，通过单一模型适应不同权衡偏好和动态场景参数，无需微调或重新训练。

Result: 大量仿真表明，该方法在性能、模型紧凑性、样本效率和泛化能力方面显著优于现有强化学习方案，能够适应未见过的场景。

Conclusion: 提出的注意力多目标强化学习架构有效解决了无人机路径规划中的多目标权衡问题，具备良好的自适应能力和泛化性能，推动了AI在无人机实际部署中的应用。

Abstract: Due to their adaptability and mobility, Unmanned Aerial Vehicles (UAVs) are becoming increasingly essential for wireless network services, particularly for data harvesting tasks. In this context, Artificial Intelligence (AI)-based approaches have gained significant attention for addressing UAV path planning tasks in large and complex environments, bridging the gap with real-world deployments. However, many existing algorithms suffer from limited training data, which hampers their performance in highly dynamic environments. Moreover, they often overlook the inherently multi-objective nature of the task, treating it in an overly simplistic manner. To address these limitations, we propose an attention-based Multi-Objective Reinforcement Learning (MORL) architecture that explicitly handles the trade-off between data collection and energy consumption in urban environments, even without prior knowledge of wireless channel conditions. Our method develops a single model capable of adapting to varying trade-off preferences and dynamic scenario parameters without the need for fine-tuning or retraining. Extensive simulations show that our approach achieves substantial improvements in performance, model compactness, sample efficiency, and most importantly, generalization to previously unseen scenarios, outperforming existing RL solutions.

</details>


### [442] [Causal feature selection framework for stable soft sensor modeling based on time-delayed cross mapping](https://arxiv.org/abs/2601.14099)
*Shi-Shun Chen,Xiao-Yang Li,Enrico Zio*

Main category: cs.LG

TL;DR: 本文提出基于时滞交叉映射的因果特征选择框架，解决工业过程软测量建模中忽略时滞因果和变量相互依赖的问题，提升模型准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有因果特征选择方法忽略工业过程中的两个关键特性：1) 变量间的因果关系存在时滞，而现有方法多在同一时间维度分析因果关系；2) 工业过程变量相互依赖，与传统因果推断方法的去相关假设相矛盾。这导致基于现有方法的软测量模型准确性和稳定性不足。

Method: 提出基于时滞交叉映射的因果特征选择框架：1) 时滞收敛交叉映射(TDCCM)用于总体因果推断；2) 时滞偏交叉映射(TDPCM)用于直接因果推断；3) 基于验证集模型性能自动确定因果阈值，实现自动化特征选择。

Result: 两个真实工业案例研究表明：TDCCM取得了最高的平均性能，而TDPCM在最差情况下改善了软测量的稳定性和性能。

Conclusion: 提出的时滞交叉映射框架能有效处理工业过程中的时滞因果关系和变量相互依赖问题，显著提升软测量模型的准确性和稳定性。代码已开源。

Abstract: Soft sensor modeling plays a crucial role in process monitoring. Causal feature selection can enhance the performance of soft sensor models in industrial applications. However, existing methods ignore two critical characteristics of industrial processes. Firstly, causal relationships between variables always involve time delays, whereas most causal feature selection methods investigate causal relationships in the same time dimension. Secondly, variables in industrial processes are often interdependent, which contradicts the decorrelation assumption of traditional causal inference methods. Consequently, soft sensor models based on existing causal feature selection approaches often lack sufficient accuracy and stability. To overcome these challenges, this paper proposes a causal feature selection framework based on time-delayed cross mapping. Time-delayed cross mapping employs state space reconstruction to effectively handle interdependent variables in causality analysis, and considers varying causal strength across time delay. Time-delayed convergent cross mapping (TDCCM) is introduced for total causal inference, and time-delayed partial cross mapping (TDPCM) is developed for direct causal inference. Then, in order to achieve automatic feature selection, an objective feature selection strategy is presented. The causal threshold is automatically determined based on the model performance on the validation set, and the causal features are then selected. Two real-world case studies show that TDCCM achieves the highest average performance, while TDPCM improves soft sensor stability and performance in the worst scenario. The code is publicly available at https://github.com/dirge1/TDPCM.

</details>


### [443] [Riemannian Liquid Spatio-Temporal Graph Network](https://arxiv.org/abs/2601.14115)
*Liangsi Lu,Jingchao Wang,Zhaorong Dai,Hanqian Liu,Yang Shi*

Main category: cs.LG

TL;DR: RLSTG是一种将连续时间液体动力学与黎曼流形几何归纳偏置相结合的新型框架，用于建模具有非欧几里得结构的时空图。


<details>
  <summary>Details</summary>
Motivation: 传统Liquid Time-Constant网络(LTCs)虽然擅长建模不规则采样动态，但局限于欧几里得空间，在表示具有固有非欧结构(如层次结构和循环)的真实世界图时会产生几何失真，降低表示质量。

Method: 提出黎曼液体时空图网络(RLSTG)，在弯曲流形上直接制定常微分方程(ODE)，统一连续时间液体动力学与黎曼流形几何归纳偏置，能够准确捕捉静态和动态时空图的内在几何结构。

Result: 在真实世界基准测试中，通过结合先进的时间动态和黎曼空间表示，RLSTG在具有复杂结构的图上表现出优越性能。提供了严格的理论保证，将LTCs的稳定性定理扩展到黎曼领域。

Conclusion: RLSTG通过将连续时间液体动力学与黎曼流形几何相结合，成功克服了传统LTCs在非欧结构图建模中的几何失真问题，为复杂时空图提供了更准确的表示和更好的性能。

Abstract: Liquid Time-Constant networks (LTCs), a type of continuous-time graph neural network, excel at modeling irregularly-sampled dynamics but are fundamentally confined to Euclidean space. This limitation introduces significant geometric distortion when representing real-world graphs with inherent non-Euclidean structures (e.g., hierarchies and cycles), degrading representation quality. To overcome this limitation, we introduce the Riemannian Liquid Spatio-Temporal Graph Network (RLSTG), a framework that unifies continuous-time liquid dynamics with the geometric inductive biases of Riemannian manifolds. RLSTG models graph evolution through an Ordinary Differential Equation (ODE) formulated directly on a curved manifold, enabling it to faithfully capture the intrinsic geometry of both structurally static and dynamic spatio-temporal graphs. Moreover, we provide rigorous theoretical guarantees for RLSTG, extending stability theorems of LTCs to the Riemannian domain and quantifying its expressive power via state trajectory analysis. Extensive experiments on real-world benchmarks demonstrate that, by combining advanced temporal dynamics with a Riemannian spatial representation, RLSTG achieves superior performance on graphs with complex structures. Project Page: https://rlstg.github.io

</details>


### [444] [Penalizing Localized Dirichlet Energies in Low Rank Tensor Products](https://arxiv.org/abs/2601.14173)
*Paris A. Karakasis,Nicholas D. Sidiropoulos*

Main category: cs.LG

TL;DR: 本文研究了张量积B样条(TPBS)回归模型，探索了Dirichlet能量作为平滑度度量，提出了基于局部Dirichlet能量的正则化方法，并在过拟合情况下优于神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究TPBS模型在回归任务中的应用，探索Dirichlet能量作为平滑度度量。发现全局Dirichlet能量正则化在某些情况下会失效（完美插值但能量指数小），需要更有效的正则化策略。

Method: 1) 推导TPBS模型的Dirichlet能量闭式表达式；2) 提出基于训练点附近小超立方体的局部Dirichlet能量正则化；3) 基于预训练TPBS模型，提出两种从不完整样本进行推断的估计器。

Result: 1) TPBS模型在过拟合情况下对大多数数据集优于神经网络；2) 其他情况下性能相当；3) TPBS模型对过拟合更鲁棒且始终受益于正则化；4) 神经网络对过拟合更敏感且利用正则化效果较差。

Conclusion: TPBS模型在回归任务中表现出色，特别是对过拟合更鲁棒，且能有效利用正则化。局部Dirichlet能量正则化解决了全局正则化的局限性，提供了更有效的平滑度控制。

Abstract: We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.

</details>


### [445] [A model of errors in transformers](https://arxiv.org/abs/2601.14175)
*Suvrat Raju,Praneeth Netrapalli*

Main category: cs.LG

TL;DR: 该论文研究LLM在需要确定性输出的任务（如算术）上的错误率，提出了一个基于注意力机制小误差累积的二参数模型来定量描述准确率与任务复杂度的关系。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在算术等需要确定性输出的重复性任务中产生错误的原因，挑战关于LLM错误是由于"推理崩溃"或无法表达"组合函数"的观点，寻找更根本的机制解释。

Method: 从"有效场论"视角出发，将LLM的众多参数重组为两个关键参数：基本噪声率和可能错误预测的token数量。通过注意力机制的小误差累积模型，推导出准确率与任务复杂度的定量关系，并使用Gemini 2.5 Flash、Gemini 2.5 Pro和DeepSeek R1进行大量实证测试验证。

Result: 在多种任务中，预测的准确率与观测到的准确率高度一致，表明二参数模型能很好地描述LLM的错误率。但也发现了一些偏差情况。同时展示了如何构建提示来降低错误率。

Conclusion: LLM在确定性任务中的错误源于注意力机制的小误差累积，而非"推理崩溃"或组合能力不足。提出的二参数模型为理解LLM错误率提供了新视角，并可用于指导提示工程来改善性能。

Abstract: We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.

</details>


### [446] [Differentiated Pickup Point Offering for Emission Reduction in Last-Mile Delivery](https://arxiv.org/abs/2601.14196)
*Albina Galiullina,Wouter van Heeswijk,Tom van Woensel*

Main category: cs.LG

TL;DR: 该研究提出差异化取货点提供(DPO)政策，通过为每位顾客推荐单一取货点(而非无限制选择)，在保留送货上门选项的同时，联合减少送货卡车路线和顾客出行产生的碳排放。


<details>
  <summary>Details</summary>
Motivation: 取货点作为送货上门的可持续替代方案，通过订单整合可以缩短配送路线并提高首次投递成功率。然而，当顾客驾车取货时，这些效益可能被抵消。因此需要一种能同时减少送货卡车和顾客出行排放的政策。

Method: 采用基于强化学习的方法，在动态随机环境中设计DPO政策。该方法考虑顾客与取货点之间的空间关系及其对未来路线整合的影响，为每位到达顾客推荐单一取货点。

Result: 差异化取货点提供可显著减少总碳排放量：相比纯送货上门最多减少9%排放，相比无限制取货点选择和最近取货点分配等替代政策平均减少2%。在密集城市环境中效果尤为明显。

Conclusion: 差异化取货点提供是减少总碳排放的有效策略，特别是在密集城市环境中。明确考虑顾客到达和选择的动态特性对于顾客不太倾向于选择取货点配送的情况尤为重要。

Abstract: Pickup points are widely recognized as a sustainable alternative to home delivery, as consolidating orders at pickup locations can shorten delivery routes and improve first-attempt success rates. However, these benefits may be negated when customers drive to pick up their orders. This study proposes a Differentiated Pickup Point Offering (DPO) policy that aims to jointly reduce emissions from delivery truck routes and customer travel. Under DPO, each arriving customer is offered a single recommended pickup point, rather than an unrestricted choice among all locations, while retaining the option of home delivery. We study this problem in a dynamic and stochastic setting, where the pickup point offered to each customer depends on previously realized customer locations and delivery choices. To design effective DPO policies, we adopt a reinforcement learning-based approach that accounts for spatial relationships between customers and pickup points and their implications for future route consolidation. Computational experiments show that differentiated pickup point offerings can substantially reduce total carbon emissions. The proposed policies reduce total emissions by up to 9% relative to home-only delivery and by 2% on average compared with alternative policies, including unrestricted pickup point choice and nearest pickup point assignment. Differentiated offerings are particularly effective in dense urban settings with many pickup points and short inter-location distances. Moreover, explicitly accounting for the dynamic nature of customer arrivals and choices is especially important when customers are less inclined to choose pickup point delivery over home delivery.

</details>


### [447] [InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning](https://arxiv.org/abs/2601.14209)
*Matthew Y. R. Yang,Hao Bai,Ian Wu,Gene Yang,Amrith Setlur,Aviral Kumar*

Main category: cs.LG

TL;DR: 提出Intervention Training (InT)方法，通过模型自身对推理过程进行细粒度信用分配，识别错误步骤并提出单步干预，然后结合监督微调，显著提升强化学习训练效果。


<details>
  <summary>Details</summary>
Motivation: 传统结果奖励强化学习在最终答案层面分配信用，导致错误轨迹中正确中间步骤被惩罚，成功轨迹中无关步骤被强化。需要解决信用分配问题，但训练过程奖励模型准确识别纠正性推理步骤仍然困难。

Method: 提出干预训练(InT)范式：模型基于数学推理数据集中可用的参考解，识别自身推理中的第一个错误，提出单步干预将轨迹导向正确解。然后对错误点前的推理加上干预进行监督微调，将错误定位到具体步骤。

Result: 经过InT和后续RL微调后，在IMO-AnswerBench上比4B参数基础模型提升近14%准确率，优于更大的开源模型如gpt-oss-20b。InT为RL训练提供了更好的初始化。

Conclusion: InT通过让模型对自己的推理轨迹进行细粒度信用分配，有效解决了传统RL的信用分配问题，显著提升了推理能力，为语言模型推理训练提供了新范式。

Abstract: Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.

</details>


### [448] [Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228)
*Punit Kumar,Vaibhav Saran,Divyesh Patel,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: 提出一個可解釋的敗血症決策支持框架，整合分層、資料增強、離線強化學習和理由生成，提升ICU治療準確性與可解釋性。


<details>
  <summary>Details</summary>
Motivation: 敗血症是ICU主要死因之一，及時準確的治療決策對患者預後影響重大，但現有系統缺乏可解釋性，臨床醫生難以信任。

Method: 包含四個核心組件：1)基於聚類的患者風險分層；2)使用VAE和擴散模型的合成資料增強；3)基於AWR的離線強化學習代理，結合輕量注意力編碼器和集成模型；4)多模態LLM驅動的理由生成模組。

Result: 在MIMIC-III和eICU資料集上評估，該方法實現了高治療準確性，同時為臨床醫生提供可解釋且穩健的政策建議。

Conclusion: 提出的框架不僅提高了敗血症治療決策的準確性，還通過可解釋的建議增強了臨床醫生的信任，為ICU決策支持系統提供了新方向。

Abstract: Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.

</details>


### [449] [KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning](https://arxiv.org/abs/2601.14232)
*Egor Cherepanov,Daniil Zelezetsky,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: KAGE-Env是一个JAX原生的2D平台游戏环境，将观察过程分解为可独立控制的视觉轴，保持底层控制问题不变，从而能够系统分析像素策略在视觉分布偏移下的泛化失败。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉强化学习基准往往将多种偏移源纠缠在一起，阻碍了系统分析。需要一种能够分解视觉偏移因素、保持底层动态和奖励不变的基准，以研究像素策略在纯粹视觉分布偏移下的泛化能力。

Method: 开发KAGE-Env环境，将观察过程分解为可独立控制的视觉轴；基于此构建KAGE-Bench基准，包含6个已知轴套件、34个训练-评估配置对，隔离个体视觉偏移；使用标准PPO-CNN基线进行评估。

Result: 观察到强烈的轴依赖失败：背景和光度偏移通常导致任务完全失败，而智能体外观偏移相对温和；某些偏移能保持前进运动但破坏任务完成，表明仅靠回报可能掩盖泛化失败；JAX实现支持单GPU上每秒3300万环境步，实现快速可重复的视觉因素扫描。

Conclusion: KAGE提供了分析视觉泛化的干净抽象，揭示了像素策略对不同类型视觉偏移的敏感性差异，并证明仅依赖回报指标可能无法全面评估泛化性能。该基准支持快速、可重复的视觉因素研究。

Abstract: Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying control problem fixed. By construction, varying a visual axis affects performance only through the induced state-conditional action distribution of a pixel policy, providing a clean abstraction for visual generalization. Building on this environment, we define KAGE-Bench, a benchmark of six known-axis suites comprising 34 train-evaluation configuration pairs that isolate individual visual shifts. Using a standard PPO-CNN baseline, we observe strong axis-dependent failures, with background and photometric shifts often collapsing success, while agent-appearance shifts are comparatively benign. Several shifts preserve forward motion while breaking task completion, showing that return alone can obscure generalization failures. Finally, the fully vectorized JAX implementation enables up to 33M environment steps per second on a single GPU, enabling fast and reproducible sweeps over visual factors. Code: https://avanturist322.github.io/KAGEBench/.

</details>


### [450] [Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression](https://arxiv.org/abs/2601.14238)
*Shaurya Mathur,Shreyas Bellary Manjunath,Nitin Kulkarni,Alina Vereshchaka*

Main category: cs.LG

TL;DR: FireCastRL是一个结合深度学习预测和强化学习调度的主动式AI框架，用于野火预测和智能扑救策略


<details>
  <summary>Details</summary>
Motivation: 传统野火管理主要是被动响应，只在火灾发生后进行扑救。野火频率和强度不断增加，造成生态系统破坏、社区损失以及每年数十亿美元的扑救成本和经济损失。需要从被动转向主动的预防和应对策略。

Method: 1. 使用深度时空模型预测野火起火点；2. 对高风险预测区域，部署预训练的强化学习智能体，在物理信息驱动的3D模拟环境中执行直升机灭火单位的实时扑救战术；3. 生成威胁评估报告帮助应急响应者优化资源分配和规划。

Result: 1. 提出了FireCastRL主动AI框架；2. 公开发布了包含950万个样本的大规模时空数据集，包含用于野火预测的环境变量；3. 展示了深度学习和强化学习如何结合支持野火预测和战术响应。

Conclusion: 该研究展示了深度学习预测和强化学习调度相结合，能够实现从被动响应到主动预防的野火管理转变，为应急响应提供智能化的预测和战术支持工具。

Abstract: Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecasting with intelligent suppression strategies. Our framework first uses a deep spatiotemporal model to predict wildfire ignition. For high-risk predictions, we deploy a pre-trained reinforcement learning (RL) agent to execute real-time suppression tactics with helitack units inside a physics-informed 3D simulation. The framework generates a threat assessment report to help emergency responders optimize resource allocation and planning. In addition, we are publicly releasing a large-scale, spatiotemporal dataset containing $\mathbf{9.5}$ million samples of environmental variables for wildfire prediction. Our work demonstrates how deep learning and RL can be combined to support both forecasting and tactical wildfire response. More details can be found at https://sites.google.com/view/firecastrl.

</details>


### [451] [Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow](https://arxiv.org/abs/2601.14243)
*Haocheng Xi,Charlie Ruan,Peiyuan Liao,Yujun Lin,Han Cai,Yilong Zhao,Shuo Yang,Kurt Keutzer,Song Han,Ligeng Zhu*

Main category: cs.LG

TL;DR: 本文提出Jet-RL框架，首次全面研究FP8 RL训练，解决了现有BF16训练+FP8推理策略在长视野任务中的不稳定性问题，实现了端到端16%加速且保持精度。


<details>
  <summary>Details</summary>
Motivation: 现有RL训练中推理阶段占用超过70%训练时间，量化训练特别是FP8精度有望缓解这一瓶颈。但常用的BF16训练+FP8推理策略在长视野和复杂任务中会出现严重训练不稳定和精度崩溃问题。

Method: 提出Jet-RL框架，采用统一的FP8精度流同时用于训练和推理，最小化数值差异，消除低效的步骤间校准需求，实现稳健稳定的RL优化。

Result: Jet-RL在推理阶段实现33%加速，训练阶段41%加速，端到端相比BF16训练实现16%加速，在所有设置中保持稳定收敛且精度损失可忽略。

Conclusion: 统一的FP8精度流是解决RL训练中数值不匹配问题的关键，Jet-RL框架为高效RL训练提供了实用解决方案，在保持精度的同时显著提升训练效率。

Abstract: Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [452] [RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models](https://arxiv.org/abs/2601.11801)
*Nitish Sontakke,K. Niranjan Kumar,Sehoon Ha*

Main category: cs.RO

TL;DR: RobotDesignGPT：基于大语言模型的自动化机器人设计框架，通过自然语言提示和参考图像生成机器人设计，利用视觉反馈提升设计质量


<details>
  <summary>Details</summary>
Motivation: 当前机器人设计过程依赖领域专家知识和大量人工工作，现有方法多为基于规则的语法或模块组合方法，需要专业知识来指定组件和模块

Method: 提出RobotDesignGPT框架，利用预训练视觉语言模型的通用知识和推理能力，从用户简单提示和参考图像合成初始机器人设计，采用新颖的视觉反馈方法提升设计质量

Result: 框架能够设计出受自然启发的视觉吸引人且运动学有效的机器人，涵盖从有腿动物到飞行生物的各种类型，通过消融研究和用户研究验证了框架的有效性

Conclusion: RobotDesignGPT通过利用大语言模型的通用知识，显著减少了机器人设计过程中的人工干预，提高了设计效率和质量

Abstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.

</details>


### [453] [Optimal Thruster Configuration for 6-DOF Control of a Small Satellite](https://arxiv.org/abs/2601.11802)
*Suguru Sato,Jinaykumar Patel,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 该论文研究小型卫星的推进器配置优化，从24推进器配置出发，寻找能够实现六自由度控制的有效配置组，并从中选出总推力最小的配置，通过交会对接任务验证了减少推进器数量仍能保持足够机动性。


<details>
  <summary>Details</summary>
Motivation: 随着小型卫星（如立方星、纳卫星、皮卫星、飞卫星）在低地球轨道的广泛应用，轨道维持和姿态控制变得越来越重要。传统方法使用多个推进器进行主动轨道控制，这些推进器经过适当排列也能产生姿态控制所需的扭矩。

Method: 从24推进器配置出发，提出了一套能够实现完整六自由度控制的推进器配置组（称为可行配置组）。然后在这些可行配置组中寻找需要最小总推力来实现六自由度指令的配置组。最后从每组中选出一个配置，通过代表性的交会对接任务评估其姿态控制性能。

Result: 研究发现，即使在推进器数量减少的情况下，仍能实现足够的机动性。论文确定了能够实现六自由度控制的有效推进器配置组，并从中找到了总推力需求最小的优化配置。

Conclusion: 该研究表明，通过优化的推进器配置，小型卫星可以在减少推进器数量的同时保持足够的六自由度控制能力，这对于降低卫星成本、重量和复杂性具有重要意义。

Abstract: With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.

</details>


### [454] [Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles](https://arxiv.org/abs/2601.11832)
*Suguru Sato,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 本文提出了一种三维流体动力学启发的无人机编队碰撞避免框架，利用三维双偶极子或椭球体模型生成局部速度场，引导无人机执行平滑、无碰撞的机动，无需轨迹重规划。


<details>
  <summary>Details</summary>
Motivation: 传统势场方法存在局部最小值问题，需要显式轨迹重规划，且难以在动态环境中实现平滑、实时的碰撞避免。本文旨在开发一种基于流体动力学的框架，实现无人机编队在动态环境中的自然、平滑避障。

Method: 将移动障碍物建模为三维双偶极子或椭球体，利用拉普拉斯方程的调和特性生成局部速度场，引导无人机平滑避障。集成虚拟刚体（VRB）编队策略来保持编队几何形状和轨迹跟踪。

Result: 仿真结果表明该方法在单个和多无人机场景中均具有可行性和可扩展性，能够处理多种编队几何形状与移动障碍物的相遇情况。实现了安全、平滑且计算高效的避障机动，适用于实时应用。

Conclusion: 提出的基于流体动力学的三维碰撞避免框架能够有效解决传统势场方法的局部最小值问题，无需显式轨迹重规划，实现了无人机编队在动态环境中的平滑、实时避障，具有实际应用价值。

Abstract: This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.

</details>


### [455] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

TL;DR: 研究人员开发了一款能够在草地上自主导航、识别并拾取垃圾的机器人，通过STC算法规划路径、RTK GPS精确定位、ResNet50神经网络识别垃圾，最终实现了80%的整体成功率。


<details>
  <summary>Details</summary>
Motivation: 美国有500亿件垃圾，其中草地上的垃圾问题尤为严重，因为野餐者经常将垃圾留在草地上。为解决这一问题，需要开发能够自主清理草地垃圾的机器人系统。

Method: 1. 使用生成树覆盖算法规划覆盖路径；2. 采用实时动态GPS进行厘米级精确定位导航；3. 使用ResNet50卷积神经网络进行垃圾识别（准确率94.52%）；4. 设计针对草地垃圾的专用拾取机制。

Result: 系统整体成功率达到80%，证明了自主垃圾拾取机器人在草地上的可行性。ResNet50模型识别准确率为94.52%，RTK GPS提供每秒厘米级定位精度。

Conclusion: 研究证明，在草地上使用自主导航、识别和拾取垃圾的机器人是可行的解决方案，能够有效解决草地垃圾问题，未来有望推广应用。

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [456] [Visual-Language-Guided Task Planning for Horticultural Robots](https://arxiv.org/abs/2601.11906)
*Jose Cuaran,Kendall Koe,Aditya Potnis,Naveen Kumar Uppalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 本文提出了一个基于视觉语言模型（VLM）的模块化框架，用于指导农业机器人任务规划，并通过创建综合基准测试发现VLM在短时任务中表现稳健，但在长时复杂任务中存在性能显著下降的问题。


<details>
  <summary>Details</summary>
Motivation: 当前作物监测系统缺乏高级推理能力，无法有效支持精准农业。为了解决这个问题，需要开发能够进行高级任务规划和决策的智能系统。

Method: 提出一个模块化框架，使用视觉语言模型（VLM）来指导机器人任务规划，将输入查询与动作原语交错执行。创建了一个全面的基准测试，涵盖单作和多作环境中的短期和长期作物监测任务。

Result: VLM在短期任务中表现稳健（与人类成功率相当），但在具有挑战性的长期任务中表现出显著的性能下降。特别关键的是，当依赖噪声语义地图时，系统会失败，这揭示了当前VLM在持续机器人操作中上下文定位的关键局限性。

Conclusion: 这项工作提供了一个可部署的框架，并对VLM在复杂农业机器人应用中的能力和局限性提供了重要见解，为未来改进指明了方向。

Abstract: Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.

</details>


### [457] [Model selection and real-time skill assessment for suturing in robotic surgery](https://arxiv.org/abs/2601.12012)
*Zhaoyang Jacopo Hu,Alex Ranne,Alaa Eldin Abdelaal,Kiran Bhattacharyya,Etienne Burdet,Allison M. Okamura,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 本文研究基于达芬奇手术系统数据，通过多模态深度学习模型实时预测手术技能水平（OSATS评分），发现融合运动学和视觉数据的模型优于单模态模型，且专家级训练数据能提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动化反馈系统在机器人辅助手术中具有客观评估技能水平的潜力，本研究旨在实现基于OSATS评分的手术技能水平实时预测，为手术训练和评估提供支持。

Method: 使用达芬奇手术系统采集的同步运动学和视觉数据，构建单模态基线模型和多模态融合模型，采用平均斯皮尔曼相关系数评估性能，并进行基于技能水平的分层交叉验证训练。

Result: 融合模型在实时预测中持续优于单模态模型；预测趋势与外科医生手势相关；基于高技能水平数据训练的模型性能更好，且能良好泛化到相似技能水平的参与者。

Conclusion: 多模态学习能提供更稳定、精细的手术表现评估，专家级训练数据对模型泛化具有重要价值，这为机器人辅助手术的实时技能评估系统开发提供了理论支持。

Abstract: Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.

</details>


### [458] [BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies](https://arxiv.org/abs/2601.12116)
*Hang Xu,Yizhou Chen,Dongjie Yu,Yi Ren,Jia PanI*

Main category: cs.RO

TL;DR: 提出了一种基于关键姿态协调感知一致性策略的双臂操作框架，通过分层模仿学习实现多阶段任务的高效执行。


<details>
  <summary>Details</summary>
Motivation: 当前工业机器人虽然可靠高效，但在双臂协同操作方面仍面临挑战，特别是协调双臂动作和处理多阶段任务的复杂性。现有生成模型在模仿学习中虽有进展，但很少同时考虑多阶段特性和推理速度的重要性。

Method: 提出关键姿态条件协调感知一致性策略，采用分层模仿学习框架：高层关键姿态预测器识别子阶段目标，底层轨迹生成器基于一致性模型，通过单次推理生成动作序列。创新性地结合机器人中心动作特征和任务中心操作风格来识别双臂关键姿态。

Result: 仿真和真实世界实验表明，该方法在成功率和操作效率方面显著优于基线方法。

Conclusion: 所提出的关键姿态条件协调感知一致性策略能有效解决双臂操作中的多阶段协调问题，提高任务执行的成功率和效率。

Abstract: Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.

</details>


### [459] [Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting](https://arxiv.org/abs/2601.12122)
*Jose Cuaran,Naveen K. Upalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出基于移动机械臂的主动3D重建框架，结合Octomap与3D高斯泼溅，实现园艺场景的高效语义重建，提升水果计数和体积估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统农业场景语义重建依赖人工扫描或固定相机，成为流程瓶颈。需要自动化、高效的主动重建方法支持表型分析和产量估计等任务。

Method: 集成Octomap与3D高斯泼溅：低分辨率Octomap提供概率占据信息用于视点选择和避障规划；3D高斯泼溅利用几何、光度和语义信息优化3D高斯集合实现高保真重建。引入策略增强分割噪声鲁棒性并减少内存消耗。

Result: 仿真实验表明：相比纯占据方法，在运行效率和重建精度上均更优。相比0.01m分辨率Octomap，无噪声条件下水果级F1分数提升6.6%，有分割噪声时提升达28.6%；运行时间减少50%。

Conclusion: 该方法为农业机器人实现可扩展、实时的语义重建提供了潜力，能够支持精确的水果计数和体积估计任务。

Abstract: Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.

</details>


### [460] [Neural Process-Based Reactive Controller for Autonomous Racing](https://arxiv.org/abs/2601.12143)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 提出基于Attentive Neural Process的实时非线性控制框架，结合物理先验和CBF安全过滤，用于高速赛车场景的间隙导航


<details>
  <summary>Details</summary>
Motivation: 随着基于注意力的神经网络在安全关键领域应用增加，需要确保统计基础和可证明安全的决策制定

Method: 使用Attentive Neural Process和物理信息扩展PI-AttNP，结合CBF控制屏障函数过滤机制确保碰撞避免

Result: 在F1TENTH式阿克曼转向赛车环境中验证，PI-AttNP实现更快收敛和更好预测精度，CBF提供可证明的安全保证

Conclusion: 提出的框架在保持竞争性闭环性能的同时，确保实时约束满足，为安全关键控制提供轻量级可验证安全层

Abstract: Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.

</details>


### [461] [Learning Legged MPC with Smooth Neural Surrogates](https://arxiv.org/abs/2601.12169)
*Samuel A. Moore,Easop Lee,Boyuan Chen*

Main category: cs.RO

TL;DR: 该论文提出一种光滑神经代理模型和鲁棒学习方法，解决学习型MPC在腿式机器人中遇到的接触事件刚度、非物理非光滑性及非高斯误差分布问题，显著提升了学习型腿式机器人MPC的可靠性、可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在腿式机器人中整合深度学习与模型预测控制时面临三个关键挑战：1) 接触事件的刚度特征可能从数据中继承；2) 可能出现额外的非物理局部非光滑性；3) 快速状态变化导致训练数据产生非高斯模型误差。这些问题阻碍了学习模型与在线规划的有效集成。

Method: 提出光滑神经代理模型，这是一种具有可调光滑度的神经网络，旨在为接触轨迹优化提供信息丰富的预测和导数。同时采用重尾似然函数进行模型训练，以更好地匹配腿式机器人动力学中观察到的经验误差分布。

Result: 在零样本运动任务中，简单行为下累积成本降低10-50%；在标准神经动力学模型经常失败的困难场景中，光滑化使执行成功率从0/5提升到5/5，累积成本降低2-50倍，实现了数量级的鲁棒性绝对改进而非渐进性能提升。

Conclusion: 通过光滑神经代理模型和鲁棒学习方法，显著改善了学习型腿式机器人MPC的可靠性、可扩展性和泛化性，为复杂动态系统中学习模型与在线规划的集成提供了有效解决方案。

Abstract: Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.

</details>


### [462] [A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics](https://arxiv.org/abs/2601.12244)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 本文综述了水下群体机器人技术，聚焦生物启发的协调机制、通信策略和系统设计，提出了多维度分类框架，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 海洋作业复杂性增加，需要智能机器人系统支持海洋观测、探索和资源管理。水下群体机器人通过集体协调扩展单个自主平台能力，但该领域研究碎片化，缺乏算法、通信和硬件设计的整合。

Method: 综合分析了生物启发的协调机制、通信策略和系统设计考量。研究了人工鱼群算法、鲸鱼优化算法、珊瑚礁优化、海洋捕食者算法等关键海洋特定算法。提出了一个多维度分类框架，从通信依赖性、环境适应性、能源效率和群体可扩展性评估现有方法。

Result: 统一了生物启发协调算法、通信模式和系统设计方法。通过集成分析，确定了收敛趋势、关键挑战，并为水下群体系统的实际部署指明了未来研究方向。

Conclusion: 水下群体机器人技术具有巨大潜力，但需要跨学科整合。通过统一算法、通信和系统设计方法，可以推动该领域发展，实现实际海洋应用部署。

Abstract: The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.

</details>


### [463] [An Efficient and Multi-Modal Navigation System with One-Step World Model](https://arxiv.org/abs/2601.12277)
*Wangtian Shen,Ziyang Meng,Jinming Ma,Mingliang Zhou,Diyun Xiang*

Main category: cs.RO

TL;DR: 提出轻量级导航世界模型，采用单步生成范式和3D U-Net架构，大幅降低推理延迟，实现实时导航规划


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的端到端导航策略在3D空间推理和物理世界理解方面存在不足，而现有的导航世界模型通常计算延迟过高，无法实现实时部署

Method: 提出轻量级导航世界模型，采用单步生成范式而非多步扩散过程，使用3D U-Net骨干网络配合高效时空注意力机制，并集成到基于优化的规划框架中处理多模态目标导航

Result: 在仿真和真实环境中的闭环实验表明，系统相比现有基线方法具有更高的效率和鲁棒性，实现了实时控制

Conclusion: 该轻量级导航世界模型成功解决了现有方法的高延迟问题，实现了高效的实时导航规划，为移动机器人导航提供了实用解决方案

Abstract: Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.

</details>


### [464] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: OPENNAVMAP是一个轻量级、无结构的拓扑度量系统，利用3D几何基础模型实现按需重建，在多会话建图中实现高效协同定位。


<details>
  <summary>Details</summary>
Motivation: 传统基于结构的建图方法维护成本高，在特征缺失环境或视角变化大的众包数据中表现不佳，需要可扩展、可维护的地图表示来支持大规模视觉导航。

Method: 提出基于动态规划的序列匹配、几何验证和置信度校准优化的统一方法，实现从粗到精的子图对齐，无需预建3D模型。

Result: 在Map-Free基准测试中优于运动结构和回归基线，平均平移误差0.62m；在15km多会话数据中保持全局一致性，绝对轨迹误差低于3m；成功完成12个自主图像目标导航任务。

Conclusion: OPENNAVMAP为大规模视觉导航提供了一种高效、轻量级的无结构拓扑度量解决方案，在保持准确性的同时显著降低了维护成本。

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [465] [From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots](https://arxiv.org/abs/2601.12353)
*Jie Wang,Peng Du,Yiyuan Zhang,Zhexin Xie,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文综述了水下仿生软体机器人的最新进展，分析了它们在海洋探索中的设计考量，并探讨了从仿生原理到实际应用的转化路径。


<details>
  <summary>Details</summary>
Motivation: 传统水下机器人在极端水压下面临挑战，且会产生噪音并破坏水下生态系统。受水生生物启发的仿生软体机器人能够应对这些挑战，成为海洋探索的有前景方向。

Method: 通过文献综述方法，分析水下仿生软体机器人的最新进展，从设计考量（包括期望功能、仿生灵感、环境压力、温度、光照和生物多样性等）进行系统分析。

Result: 仿生软体机器人能够承受高水压、减小阻力、实现高效操作和传感，并以环保方式与环境互动，展现出在海洋探索中的巨大潜力。

Conclusion: 水下仿生软体机器人是海洋探索的promising领域，论文提出了从仿生原理到实际应用的转化路径，并为下一代水下软体机器人的发展指明了潜在方向。

Abstract: Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.

</details>


### [466] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: R-VoxelMap是一种新型体素建图方法，采用几何驱动的递归平面拟合策略，通过离群点检测与重用机制和基于点分布的有效性检查算法，提升LiDAR里程计的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有VoxelMap及其变体通常使用体素内所有点进行平面拟合和检查，这会导致三个主要问题：离群点引起的平面参数偏差、大平面的过分割、以及不同物理平面的错误合并。这些问题影响了建图精度和定位性能。

Method: 1. 采用几何驱动的递归构建策略，基于离群点检测与重用流程
2. 对每个体素，首先使用RANSAC分离离群点并拟合精确平面
3. 剩余离群点传播到更深的八叉树层级进行递归处理
4. 设计基于点分布的有效性检查算法，防止错误的平面合并

Result: 在多种开源LiDAR(-IMU) SLAM数据集上的广泛实验表明，R-VoxelMap相比其他最先进方法实现了更高的精度，同时保持了相当的效率和内存使用。

Conclusion: R-VoxelMap通过递归平面拟合策略有效解决了传统体素建图中的离群点问题，提高了建图精度和定位性能，代码将在GitHub上开源。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [467] [VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research](https://arxiv.org/abs/2601.12395)
*Chao Wang,Anna Belardinelli,Michael Gienger*

Main category: cs.RO

TL;DR: VR2VR：一个用于触觉人机交互研究的双VR头显平台，允许参与者与隐藏的操作员在同一物理空间中体验不同的虚拟化身，支持精准的触觉交互和实验控制。


<details>
  <summary>Details</summary>
Motivation: 触觉丰富的人机交互研究面临成本高、开发慢的挑战：物理机器人成本高昂，VR原型通常移除物理接触或破坏身体与触觉的紧密耦合。需要一种能够支持触觉交互且易于原型设计的平台。

Method: 开发VR2VR平台：使用两个共位的VR头显，参与者看到虚拟机器人，操作员隐藏在物理空间中。通过运动追踪和面部信号实时映射机器人的上半身手势、头部/视线行为和面部表情。操作员可以物理触摸参与者，通过逆运动学将手指和手部运动映射到机器人，实现精准接触。

Result: VR2VR系统实现了：1）精确的运动重定向用于肢体遥操作；2）实验控制能力，可以重定向或选择性启用非语言通道（如仅头部vs头部+眼睛vs头部+眼睛+面部表情），同时保持物理交互恒定；3）通过基于触摸的Wizard-of-Oz HRI研究验证了平台可行性。

Conclusion: VR2VR降低了快速原型设计和严格评估具身化、以触觉为中心的机器人行为的障碍，为触觉丰富的人机交互研究提供了灵活且可控的实验平台。

Abstract: Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors.

</details>


### [468] [Learning Diverse Skills for Behavior Models with Mixture of Experts](https://arxiv.org/abs/2601.12397)
*Wangtian Shen,Jinming Ma,Mingliang Zhou,Ziyang Meng*

Main category: cs.RO

TL;DR: 本文提出Di-BM方法，通过混合专家模型学习多样化技能，解决模仿学习在多任务设置中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型在单任务学习中表现优异，但在多任务设置中，任务间干扰会导致平均效应，使性能下降。需要解决多任务模仿学习中的技能干扰问题。

Method: 提出Di-BM方法，采用混合专家模型，每个专家与不同的观察分布相关联，使其专注于观察空间的子区域。使用基于能量的模型表示专家特定的观察分布，并与相应的动作模型联合训练。该方法具有即插即用特性，可无缝集成到标准模仿学习方法中。

Result: 在多个真实世界机器人操作任务上的大量实验表明，Di-BM显著优于现有最先进的基线方法。此外，在新型任务上微调预训练的Di-BM表现出更优的数据效率和专家学习知识的可重用性。

Conclusion: Di-BM通过混合专家模型成功解决了模仿学习在多任务设置中的性能下降问题，实现了多样化技能学习，提高了多任务性能和知识迁移效率。

Abstract: Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.

</details>


### [469] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

TL;DR: ReWorld是一个通过强化学习对齐视频世界模型与物理真实性、任务完成能力、具身合理性和视觉质量的框架，针对接触丰富的机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频的世界模型主要关注视觉生成质量，但忽视了物理保真度、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，这限制了它们在下游任务中的应用。

Method: 首先构建大规模视频偏好数据集，训练分层奖励模型以捕捉符合人类偏好的多维度奖励；然后提出实用的对齐算法，通过计算高效的PPO风格算法对基于流的世界模型进行后训练。

Result: 综合实验和理论分析表明，ReWorld显著提高了生成rollouts的物理保真度、逻辑连贯性、具身合理性和视觉质量，超越了先前的方法。

Conclusion: ReWorld框架成功地将强化学习应用于视频世界模型的对齐，解决了物理真实性和任务逻辑等关键问题，为机器人学习提供了更高质量的世界模型。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [470] [KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter](https://arxiv.org/abs/2601.12463)
*Zi Cong Guo,James R. Forbes,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: KILO-EKF结合标准EKF预测步与基于Koopman启发的数据驱动测量模型校正步，通过将测量值提升到特征空间实现线性状态关系，提供灵活处理复杂传感器建模的递归滤波方法。


<details>
  <summary>Details</summary>
Motivation: 传统EKF依赖于精确的传感器模型和校准，但实际应用中传感器可能复杂、校准不良或缺乏准确参数模型。需要一种能灵活处理复杂传感器、减少对显式参数模型依赖的滤波方法。

Method: 提出Koopman启发的学习观测扩展卡尔曼滤波（KILO-EKF）：1）使用标准EKF进行预测；2）通过数据学习Koopman启发的测量模型进行校正；3）将测量值提升到特征空间使其与状态呈线性关系；4）从地面真实训练数据中以闭式形式学习线性高斯测量模型，无需迭代优化；5）推理时使用学习到的提升函数计算雅可比矩阵进行标准EKF更新。

Result: 在四旋翼无人机定位任务中使用IMU、UWB传感器和向下激光进行验证：1）相比多种传感器校准水平的EKF基线，KILO-EKF获得更好的精度和一致性；2）显著优于依赖不完美几何模型的EKF；3）保持实时推理和快速训练能力。

Conclusion: KILO-EKF展示了Koopman启发的测量学习作为传统基于模型校准的可扩展替代方案的有效性，能够灵活处理复杂传感器，减少对精确参数模型的依赖，同时保持滤波效率和实时性能。

Abstract: We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.

</details>


### [471] [Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions](https://arxiv.org/abs/2601.12479)
*Miquel Kegeleirs,Lorenzo Garattoni,Gianpiero Francesca,Mauro Birattari*

Main category: cs.RO

TL;DR: 提出一种去中心化的行人重识别方法，使用自然语言而非视觉嵌入作为表示模态，通过视觉语言模型生成文本描述，在机器人集群中协作聚类并生成可解释的个体描述。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉嵌入的行人重识别方法存在不透明、难以解释的问题，需要中心化协调。本文旨在开发一种去中心化、可解释的方法，利用自然语言作为主要表示形式，提高透明度和可解释性。

Method: 1. 每个机器人使用视觉语言模型(VLM)本地检测并生成个体外观的文本描述；2. 在集群中无中心协调地比较和聚类这些文本描述；3. 通过语言模型将每个聚类提炼成代表性描述；4. 支持自然语言查询和解释性集群行为。

Result: 初步实验表明，该方法在身份一致性和可解释性方面与基于嵌入的方法具有竞争力，尽管目前在文本相似度计算和计算负载方面存在限制。能够实现去中心化的感知和通信。

Conclusion: 提出了一种新颖的去中心化行人重识别方法，使用自然语言作为表示模态，提高了透明度和可解释性。该方法支持自然语言查询和解释性集群行为，为未来语义导航和语言环境感知奠定了基础，但主动导航仍是未来研究方向。

Abstract: We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.

</details>


### [472] [Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands](https://arxiv.org/abs/2601.12523)
*Cem Suulker,Muhie Al Haimus,Thomas Mack,Mohammad Sheikhsofla,Neri Niccolò Dei,Reza Kashef,Hadi Sadati,Federica Barontini,Fanny Ficuciello,Alberto Arezzo,Bruno Siciliano,Sebastien Ourselin,Kaspar Althoefer*

Main category: cs.RO

TL;DR: 本文提出一种通过在外壁引入屈曲点来降低尖端生长外翻机器人弯曲刚度的被动方法，使用不可拉伸的直径缩减环带显著提高机器人在复杂弯曲路径中的导航能力。


<details>
  <summary>Details</summary>
Motivation: 现有尖端生长外翻机器人的导航解决方案通常依赖集成在机器人本体的人工肌肉或主动尖端转向机制，这些方法增加了结构复杂性，并损害了外翻机器人固有的柔软性和顺应性优势。因此需要一种既能提高导航能力，又不牺牲软性特征的解决方案。

Method: 采用被动方法降低弯曲刚度，通过在机器人外壁定期集成不可拉伸的直径缩减环带，有意引入屈曲点。这些环带在机器人身体上形成局部刚度降低区域，利用机器人与环境的自然交互实现平滑、顺应的导航。同时开发了基于Cosserat杆的数学模型来量化这种行为。

Result: 实验结果显示，环带能将机器人尖端弯曲时的刚度降低高达91%，使机器人能够稳定通过180度弯曲路径，最小弯曲半径达到25毫米，显著优于标准外翻机器人在相同条件下的35毫米。在结肠模型中的案例研究进一步验证了该方法的可行性。

Conclusion: 该方法在不牺牲柔软性或增加机械复杂性的情况下，显著提高了外翻机器人的可操纵性，扩展了其在高度弯曲路径中的应用潜力，特别是在管道检查或结肠镜等医疗程序中。

Abstract: Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.

</details>


### [473] [RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments](https://arxiv.org/abs/2601.12701)
*Yunpeng Lyu,Chao Cao,Ji Zhang,Howie Choset,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 该论文研究带概率终端的哈密顿路径问题(HPP-PT)，其中每个顶点有终止概率，目标是最小化期望路径成本。提出RPT*搜索算法保证最优性，并开发HATS系统用于自主目标搜索。


<details>
  <summary>Details</summary>
Motivation: 传统路由问题很少考虑不确定性，但在目标搜索等应用中，机器人需要基于位置概率信息访问所有候选位置寻找目标，路径成本具有历史依赖性，现有方法效率低或不适用。

Method: 提出RPT*搜索算法，利用动态规划在新状态空间中规避历史依赖问题，设计新颖启发式加速计算。基于RPT*构建分层自主目标搜索(HATS)系统，结合贝叶斯滤波或自主探索。

Result: 仿真和真实机器人实验表明，该方法能自然平衡利用和探索，平均比基线方法更快找到目标。RPT*算法具有最优性保证。

Conclusion: 该工作解决了带概率终端的路由问题，提出的RPT*算法和HATS系统有效处理了历史依赖性和不确定性，在目标搜索任务中表现出色。

Abstract: Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.

</details>


### [474] [AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation](https://arxiv.org/abs/2601.12742)
*Xuecheng Chen,Zongzhuo Liu,Jianfa Ma,Bang Du,Tiantian Zhang,Xueqian Wang,Boyu Zhou*

Main category: cs.RO

TL;DR: AirHunt：一个无人机物体导航系统，通过异步双路径架构融合视觉语言模型的语义推理与路径规划，实现室外环境中零样本泛化的开放集物体搜索


<details>
  <summary>Details</summary>
Motivation: 现有系统难以将视觉语言模型集成到实际空中系统中，存在推理频率与实时规划的严重不匹配、3D场景理解有限、以及缺乏平衡语义引导与运动效率的统一机制等问题

Method: 采用双路径异步架构，建立VLM推理与路径规划的协同接口；提出主动双任务推理模块利用几何和语义冗余进行选择性VLM查询；设计语义-几何一致规划模块在统一框架中动态协调语义优先级与运动效率

Result: 在多样化物体导航任务和环境中评估，相比现有方法实现了更高的成功率、更低的导航误差和更短的飞行时间；真实世界实验验证了其在复杂挑战性环境中的实际能力

Conclusion: AirHunt通过有效融合VLM语义推理与连续路径规划，解决了现有系统的关键限制，实现了高效、准确的开放集物体导航，为实际空中系统提供了可行的解决方案

Abstract: Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.

</details>


### [475] [FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation](https://arxiv.org/abs/2601.12790)
*Yang Zhang,Jianming Ma,Liyun Yan,Zhanxiang Cao,Yazhou Zhang,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: FocusNav是一个用于人形机器人的空间选择性注意力框架，通过自适应调制感知场来平衡长距离导航目标和实时运动稳定性。


<details>
  <summary>Details</summary>
Motivation: 在非结构化和动态环境中，人形机器人的局部导航面临重大挑战，需要在长距离导航目标和即时运动稳定性之间取得平衡。

Method: 提出了FocusNav框架，包含两个核心模块：1) 路径点引导的空间交叉注意力机制(WGSCA)，将环境特征聚合锚定到预测的无碰撞路径点序列；2) 稳定性感知选择性门控模块(SASG)，在检测到不稳定时自动截断远端信息，使策略优先考虑即时立足点安全。

Result: 在Unitree G1人形机器人上的大量实验表明，FocusNav在挑战性场景中显著提高了导航成功率，在碰撞避免和运动稳定性方面均优于基线方法。

Conclusion: FocusNav框架能够实现动态复杂环境中的鲁棒导航，通过自适应感知调制有效平衡了导航意图和稳定性需求。

Abstract: Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.

</details>


### [476] [Contact-Aware Neural Dynamics](https://arxiv.org/abs/2601.12796)
*Changwei Jing,Jai Krishna Bandi,Jianglong Ye,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 提出一种隐式模拟到现实对齐框架，通过接触感知的神经动力学模型直接对齐模拟器与现实世界动力学，特别针对接触丰富的任务


<details>
  <summary>Details</summary>
Motivation: 高保真物理模拟对机器人学习至关重要，但模拟到现实的差距仍然存在，尤其是在涉及复杂、动态、不连续交互（如物理接触）的任务中。显式系统辨识通常不足以对齐现实世界中复杂、高维、状态相关的动力学

Method: 将现成模拟器作为基础先验，学习接触感知的神经动力学模型，利用真实世界观测（特别是机器人手的触觉接触信息）来精炼模拟状态。该模型能够建模接触丰富任务中固有的非光滑不连续性

Result: 学习的正向动力学模型提高了状态预测精度，能够有效预测策略性能，并精炼在标准模拟器中训练的纯模拟策略，为模拟到现实对齐提供了可扩展的数据驱动方法

Conclusion: 通过隐式模拟到现实对齐框架，结合触觉接触信息，能够有效建模接触丰富的任务中的非光滑不连续性，为机器人学习提供了一种数据驱动的模拟到现实对齐解决方案

Abstract: High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.

</details>


### [477] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

TL;DR: FRoM-W1是一个开源框架，通过自然语言实现通用人形机器人全身运动控制，包含H-GPT（语言驱动人体运动生成）和H-ACT（机器人运动控制）两阶段，在Unitree H1和G1机器人上验证有效。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人的动作通常是硬编码或专门训练的，这限制了其通用性。需要一种能够通过自然语言指令灵活控制机器人全身运动的方法。

Method: 两阶段框架：1) H-GPT：利用大规模人类数据训练语言驱动的人体全身运动生成模型，采用Chain-of-Thought技术提升指令理解泛化能力；2) H-ACT：将生成的人体运动重定向为机器人动作，通过强化学习在物理仿真中预训练和微调运动控制器，并通过模块化仿真到现实模块部署到真实机器人。

Result: 在HumanML3D-X基准测试中表现出优越的人体全身运动生成性能；在Unitree H1和G1机器人上，强化学习微调持续提高了运动跟踪精度和任务成功率。

Conclusion: FRoM-W1框架通过自然语言实现了通用的人形机器人全身运动控制，开源该框架有望推动人形智能的发展。

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [478] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

TL;DR: SAG (Sparse ActionGen) 提出了一种稀疏动作生成方法，通过自适应剪枝-重用机制加速扩散策略，实现实时视觉运动控制。


<details>
  <summary>Details</summary>
Motivation: 扩散策略虽然能建模多模态动作分布，但多步去噪过程使其难以满足实时控制需求。现有缓存加速方法使用静态调度，无法适应机器人-环境交互的动态特性，导致性能次优。

Method: SAG采用自适应剪枝-重用机制：1) 全局识别可剪枝计算；2) 重用缓存激活值替代剪枝计算；3) 参数化观察条件扩散剪枝器进行环境感知自适应；4) 采用高效参数和推理设计；5) 引入跨时间步和块的"之字形"重用策略。

Result: 在多个机器人基准测试中，SAG实现了高达4倍的生成速度提升，且不牺牲性能。

Conclusion: SAG通过自适应稀疏化机制有效解决了扩散策略的实时性瓶颈，为实时机器人控制提供了高效解决方案。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [479] [PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning](https://arxiv.org/abs/2601.12901)
*Hongchen Li,Tianyu Li,Jiazhi Yang,Haochen Tian,Caojun Wang,Lei Shi,Mingyang Shang,Zengrong Lin,Gaoqiang Wu,Zhihui Hao,Xianpeng Lang,Jia Hu,Hongyang Li*

Main category: cs.RO

TL;DR: PlannerRFT：基于扩散规划的强化微调框架，通过双分支优化同时优化轨迹分布和引导去噪过程，实现样本高效的场景自适应多模态轨迹生成


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的规划器虽然通过强化微调提升鲁棒性，但难以生成多模态、场景自适应的轨迹，限制了奖励信息在微调过程中的利用效率

Method: 提出PlannerRFT框架，采用双分支优化：一个分支优化轨迹分布，另一个分支自适应引导去噪过程以进行更有前景的探索，且不改变原始推理流程；同时开发nuMax优化模拟器，实现比原生nuPlan快10倍的并行学习

Result: 实验表明PlannerRFT实现了最先进的性能，并在学习过程中出现了明显的行为涌现

Conclusion: PlannerRFT为扩散规划器提供了一种样本高效的强化微调方法，能够生成多模态、场景自适应的轨迹，显著提升了奖励信息的利用效率

Abstract: Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.

</details>


### [480] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 提出基于高斯混合模型的无监督方法，实时准确识别动态手势变化，用于人机交互中机器人任务控制


<details>
  <summary>Details</summary>
Motivation: 实现人类与机器人之间无缝交互，通过动态手势控制多个机器人操作任务，解决手势动态变化带来的识别挑战

Method: 使用基于高斯混合模型的无监督模型，能够识别不同手势的多种动态变化，实现实时识别

Result: 训练和实时测试都显示出高准确率，证明了该方法的有效性

Conclusion: 提出的无监督高斯混合模型方法能够准确识别动态手势变化，为机器人任务控制提供了有效的实时交互解决方案

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [481] [ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation](https://arxiv.org/abs/2601.12925)
*Weize Xie,Yi Ding,Ying He,Leilei Wang,Binwen Bai,Zheyi Zhao,Chenyang Wang,F. Richard Yu*

Main category: cs.RO

TL;DR: ForeDiffusion通过注入预测的未来视图表征来增强扩散策略，解决现有方法仅依赖短期观察和单一去噪损失的局限性，在复杂任务中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略在任务复杂度增加时成功率显著下降，主要面临两个限制：1) 仅依赖短期观察作为条件；2) 训练目标局限于单一去噪损失，导致误差累积和抓取偏差。

Method: 提出Foresight-Conditioned Diffusion (ForeDiffusion)，将预测的未来视图表征注入扩散过程，使策略具备前瞻性以纠正轨迹偏差。采用双损失机制，结合传统去噪损失和未来观察一致性损失进行统一优化。

Result: 在Adroit套件和MetaWorld基准测试中，ForeDiffusion在整体任务上平均成功率80%，在复杂任务中比现有主流扩散方法提升23%，并在所有任务中保持更稳定的性能。

Conclusion: 通过注入未来视图表征和双损失机制，ForeDiffusion成功解决了现有扩散策略的局限性，显著提升了复杂机器人操作任务的性能，为视觉运动控制提供了更有效的解决方案。

Abstract: Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.

</details>


### [482] [Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design](https://arxiv.org/abs/2601.12939)
*Kaleem Arshid,Ali Krayani,Lucio Marcenaro,David Martin Gomez,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 提出基于主动推理的无人机群自主轨迹设计框架，整合概率推理与自学习，实现分布式任务分配、路径排序和运动规划


<details>
  <summary>Details</summary>
Motivation: 传统无人机群控制方法在动态环境中适应性有限，需要更智能、可扩展且认知基础扎实的框架来实现自主轨迹设计

Method: 使用遗传算法与排斥力生成专家轨迹训练分层世界模型，在线运行时通过最小化当前信念与模型预测状态之间的差异来推断动作

Result: 仿真结果显示比Q-Learning更快收敛、更高稳定性和更安全导航，验证了框架的可扩展性和认知基础

Conclusion: 主动推理框架为智能无人机群控制提供了有效的解决方案，具有适应性、稳定性和安全性优势

Abstract: This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.

</details>


### [483] [Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration](https://arxiv.org/abs/2601.12952)
*Shibo Shao,Dong Zhou,Guanghui Sun,Liwen Zhang,Mingxuan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种基于模仿学习的航天器交会对接控制框架(IL-SRD)，通过从专家演示中直接学习控制策略，减少对精确建模的依赖，实现可靠的六自由度交会对接控制。


<details>
  <summary>Details</summary>
Motivation: 现有航天器交会对接控制方法主要依赖预定义动力学模型，在实际在轨环境中鲁棒性有限。需要减少对精确建模的依赖，提高控制系统的鲁棒性。

Method: 提出IL-SRD框架，采用基于Transformer的模仿学习方法。创新性地提出锚定解码器目标机制，将解码器查询条件限制在与状态相关的锚点上，显式约束控制生成过程。同时引入时间聚合机制来缓解Transformer模型顺序预测带来的误差累积问题。

Result: 大量仿真结果表明，IL-SRD框架实现了精确且节能的无模型交会对接控制。鲁棒性评估进一步证实其在显著未知干扰下仍能保持竞争力的性能。

Conclusion: IL-SRD框架通过模仿学习成功解决了传统方法对精确建模的依赖问题，实现了可靠的六自由度交会对接控制，具有实际应用价值。

Abstract: Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.

</details>


### [484] [Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization](https://arxiv.org/abs/2601.12993)
*Hao Luo,Ye Wang,Wanpeng Zhang,Sipeng Zheng,Ziheng Xi,Chaoyi Xu,Haiweng Xu,Haoqi Yuan,Chi Zhang,Yiqing Wang,Yicheng Feng,Zongqing Lu*

Main category: cs.RO

TL;DR: Being-H0.5是一个以人为中心的VLA基础模型，通过人类交互数据作为"母语"，使用统一动作空间和MoF架构，实现跨具身机器人的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型面临形态异构性和数据稀缺的挑战，难以在不同机器人平台间实现稳健的跨具身泛化。

Method: 提出人类中心学习范式，将人类交互轨迹视为通用"母语"；引入统一动作空间映射异构控制；使用Mixture-of-Transformers架构和MoF框架解耦共享运动基元；采用流形保持门控和通用异步分块技术增强稳定性。

Result: 在模拟基准测试中达到SOTA：LIBERO（98.9%）和RoboCasa（53.9%）；在五个机器人平台上展示强大的跨具身能力。

Conclusion: Being-H0.5通过人类中心范式和统一建模方法，成功解决了跨具身泛化挑战，为异构机器人系统提供了有效的VLA基础模型。

Abstract: We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

</details>


### [485] [Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks](https://arxiv.org/abs/2601.13042)
*Yijun Zhou,Muhan Hou,Kim Baraka*

Main category: cs.RO

TL;DR: 比较VR控制器与SpaceMouse在静态和动态任务中的表现，发现VR在动态任务中具有显著优势，包括更高的成功率、更短的执行时间和更好的用户体验。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量演示数据，遥操作是收集这些数据的主要方式。现有研究主要关注静态任务（离散、分段动作），但演示数据也包含需要反应控制的动态任务。动态任务对接口有根本不同的需求，静态任务的评估结果无法推广到动态任务。

Method: 采用被试内设计，比较VR控制器和SpaceMouse在2个静态任务和2个动态任务中的表现（N=25）。评估指标包括：成功率、任务时长、累积成功率，以及NASA-TLX工作负荷量表、SUS可用性量表和开放式反馈。

Result: VR控制器在所有指标上均表现出统计显著优势：在动态任务中成功率更高、所有任务中成功执行时间更短、尝试中更早获得成功，且工作负荷显著更低、可用性显著更高。

Conclusion: VR遥操作接口在动态任务中优于传统SpaceMouse，现有VR系统很少开源或不适合动态任务，因此作者开源了他们的VR接口以填补这一空白。

Abstract: Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.

</details>


### [486] [Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones](https://arxiv.org/abs/2601.13088)
*Harry Huang,Talia Xu,Marco Zúñiga Zamalloa*

Main category: cs.RO

TL;DR: 该论文提出了一种使用光能进行能量收集和导航的紧凑型自持式轻于空气无人机，通过高保真仿真框架、太阳能集成系统和单信标光导航算法实现了持久自主运行。


<details>
  <summary>Details</summary>
Motivation: 微型无人机在GPS拒止环境中的续航短和导航不可靠限制了其应用。轻于空气无人机虽然能效更高，但设计复杂且缺乏简单低基础设施的自主导航解决方案。

Method: 1. 开发高保真仿真框架分析LTA空气动力学并选择稳定高效配置；2. 在气囊上集成太阳能电池实现净正能量；3. 基于单光信标开发三种光寻算法实现"点即走"导航系统。

Result: 在80klux光照下，每收集4分钟能量可飞行1分钟，实现可持续运行。单信标导航能在室内外环境中（中等风力下）追踪7米外的光源，展示了持久自主运行的可行性。

Conclusion: 该系统为室内外监测提供了持久自主运行的可能路径，为轻于空气无人机的实际应用转化提供了实用方案。

Abstract: Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.
  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.
  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.

</details>


### [487] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

TL;DR: 提出融合大语言模型和视觉语言模型的自主海港检测框架，用LLM进行符号规划、VLM进行语义检测，实现无人机与无人船的协同检测


<details>
  <summary>Details</summary>
Motivation: 现有海港检测方法依赖人工操作和传统计算机视觉技术，缺乏可扩展性和上下文理解能力，需要更智能、自适应的检测系统

Method: 1. LLM模块将自然语言任务指令转换为带依赖图的符号规划；2. VLM模块进行实时语义检测和合规性评估；3. 轻量化设计适配资源受限的海事平台；4. 在MBZIRC海事模拟器和真实机器人试验中验证

Result: 框架在模拟环境和真实机器人试验中得到验证，实现了上下文感知和自适应监测，轻量化设计适合资源受限平台

Conclusion: LLM和VLM的协同为自主海港检测提供了创新解决方案，推动了智能、自主检测系统的发展，相关代码和视频已开源

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [488] [Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation](https://arxiv.org/abs/2601.13177)
*Behnam Moradkhani,Raghav Sankaranarayanan,Pejman Kheradmand,Harshith Jella,Nicholas Ahn,Ajmal Zemmar,Yash Chitalia*

Main category: cs.RO

TL;DR: 提出了一种用于脊髓刺激手术的机器人导航系统ExoNav，能够精确导航到腹侧和外侧硬膜外空间，提高电机神经元刺激效果。


<details>
  <summary>Details</summary>
Motivation: 脊髓刺激主要用于疼痛管理，最近在促进脊髓损伤患者功能恢复方面显示有效。但有效刺激运动神经元需要将电极放置在腹侧或外侧硬膜外空间，这对当前手动导航方法提出了重大挑战。

Method: 采用Cosserat杆框架建立肌腱驱动力与机器人整体形状之间的关系。研究并实现了重力等外部载荷的影响。基于ExoNav的螺旋形状，通过增加插入和旋转自由度实现跟随领导者运动。

Result: 四个原型测试的RMSE值分别为1.76mm、2.33mm、2.18mm和1.33mm。三个FTL实验试验显示末端执行器位置与期望路径对齐，最大RMSE为3.75mm。在体模模型中，机器人成功导航到侧方和腹侧脊髓目标，并能导航到背根神经节。

Conclusion: ExoNav机器人系统能够精确导航到脊髓刺激的目标位置，在存在重力引起的变形情况下仍能计算最佳肌腱张力以跟随期望路径。该系统在运动功能恢复和疼痛管理方面都具有潜在应用价值。

Abstract: Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.

</details>


### [489] [Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations](https://arxiv.org/abs/2601.13196)
*Jacob Swindell,Marija Popović,Riccardo Polvara*

Main category: cs.RO

TL;DR: 该论文研究了在无人机杂草测绘中，不同高斯过程离散化表示对测绘质量和任务性能的影响，发现离散化选择显著影响探索行为和效率。


<details>
  <summary>Details</summary>
Motivation: 无人机精准农业杂草测绘对精准农业至关重要。传统方法依赖固定的预定义飞行路径和密集的离线处理，而信息路径规划（IPP）能够自适应地收集最需要的数据。高斯过程（GP）映射提供了带有内置不确定性的杂草分布连续模型，但GP必须离散化才能用于自主规划。虽然存在多种离散化技术，但离散表示选择的影响尚不清楚。

Method: 研究采用配备向下摄像头的无人机，实现基于地图不确定性、旅行成本和覆盖惩罚的采样位置选择的滚动时域IPP策略。研究了多种表示GP后验的离散化策略，并使用其诱导的地图分区来生成规划的候选视点。

Result: 在真实世界杂草分布上的实验表明，表示选择显著影响探索行为和效率。离散化不仅是表示细节，而且是影响在线无人机杂草测绘中规划动态、覆盖效率和计算负载的关键设计选择。

Conclusion: 离散化表示选择在无人机杂草测绘中具有重要影响，它塑造了规划动态、覆盖效率和计算负载，是系统设计的关键考虑因素。

Abstract: Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.

</details>


### [490] [MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation](https://arxiv.org/abs/2601.13232)
*Kourosh Darvish,Arjun Sohal,Abhijoy Mandal,Hatem Fakhruldeen,Nikola Radulov,Zhengxue Zhou,Satheeshkumar Veeramani,Joshua Choi,Sijie Han,Brayden Zhang,Jeeyeoun Chae,Alex Wright,Yijie Wang,Hossein Darvish,Yuchi Zhao,Gary Tom,Han Hao,Miroslav Bogdanovic,Gabriella Pizzuto,Andrew I. Cooper,Alán Aspuru-Guzik,Florian Shkurti,Animesh Garg*

Main category: cs.RO

TL;DR: MATTERIX是一个GPU加速的多尺度机器人仿真框架，用于创建化学实验室的数字孪生，加速实验流程开发，减少实际物理实验需求。


<details>
  <summary>Details</summary>
Motivation: 当前材料发现依赖大量实际物理实验，这限制了可扩展性。需要开发新方法减少对昂贵真实世界实验的依赖，加速实验流程开发。

Method: 开发了MATTERIX多尺度GPU加速仿真框架，整合真实物理模拟和逼真渲染，通过模块化GPU加速语义引擎模拟逻辑状态和连续行为，支持分层计划定义和模块化技能库。

Result: 成功实现了从仿真到现实的转移，在机器人化学实验设置中验证了方法的有效性，能够测试假设的自动化工作流程，减少对昂贵真实实验的依赖。

Conclusion: MATTERIX框架能够加速化学实验室工作流程开发，通过创建高保真数字孪生环境，显著减少对实际物理实验的依赖，促进材料发现的自动化。

Abstract: Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .

</details>


### [491] [Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation](https://arxiv.org/abs/2601.13250)
*Ante Marić,Giammarco Caroleo,Alessandro Albini,Julius Jankowski,Perla Maiolino,Sylvain Calinon*

Main category: cs.RO

TL;DR: 提出基于去噪扩散的逆触觉传感器模型，用于在视觉受限环境下进行物体位姿估计，通过粒子滤波器集成实现高效采样和准确估计


<details>
  <summary>Details</summary>
Motivation: 在视觉信息受限（遮挡或环境影响）的操纵场景中，触觉感知为物体位姿估计提供了有前景的传感方式。然而，由于触觉数据的部分可观测性（单次观测对应多种可能的接触配置），传统基于视觉的估计方法难以有效利用触觉数据。

Method: 1. 使用去噪扩散学习逆触觉传感器模型，以分布式触觉传感器的观测为条件；2. 基于符号距离场的几何传感器模型在仿真中训练；3. 推理时通过单步投影强制执行接触约束；4. 在线位姿估计中，通过结合生成假设和先验信念粒子的提议方案，将逆模型与粒子滤波器集成。

Result: 在仿真和真实世界的平面位姿估计场景中验证了方法有效性，无需视觉数据或紧密的初始位姿先验。在推箱场景中评估了对未建模接触和传感器动态的鲁棒性。与局部采样基线相比，逆传感器模型提高了采样效率和估计精度，同时在具有不同触觉可区分性的物体上保持了多模态信念。

Conclusion: 基于扩散的逆触觉传感器模型能够有效解决触觉感知中的部分可观测性问题，结合粒子滤波器实现高效的在线位姿估计，在视觉受限的操纵任务中具有实用价值。

Abstract: Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability.

</details>


### [492] [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](https://arxiv.org/abs/2601.13252)
*Mahmud S. Zango,Jianglin Lan*

Main category: cs.RO

TL;DR: 这篇综述论文回顾了面向纳米无人机（nano-UAVs）在极端SWaP约束下的自主导航技术，重点分析了亚100mW计算环境中的传感、计算和控制架构，探讨了从几何方法到边缘AI范式的转变，并指出了当前存在的技术差距和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机（重量<50g，处理器功耗<100mW）的自主导航面临极端的SWaP约束，这使其与标准机器人范式有根本区别。现有技术需要专门针对这种亚100mW计算环境进行优化，而当前研究存在分散性和不完整性，需要系统性的综述来指导未来发展。

Method: 采用系统性综述方法，综合分析纳米无人机自主导航领域的最新进展：1）分析传感、计算和控制架构的硬件-软件协同设计；2）比较几何方法到边缘AI范式的转变，包括量化深度神经网络在超低功耗SoC上的部署和神经形态事件控制；3）评估密集光流、优化SLAM和学习飞行控制等技术；4）识别技术差距并提出发展路线图。

Result: 研究发现：1）视觉导航和相对姿态估计已取得显著进展；2）但在长期续航、动态环境中的鲁棒避障、强化学习策略的"仿真到现实"迁移等方面仍存在持续差距；3）提出了融合轻量级经典控制和数据驱动感知的混合架构作为解决方案。

Conclusion: 纳米无人机自主导航需要硬件-软件协同设计的专门方法。虽然已有进展，但需解决长期续航、动态避障和仿真到现实迁移等关键挑战。未来应发展融合经典控制和数据驱动感知的混合架构，以实现GPS拒止环境中完全自主、敏捷的纳米无人机。

Abstract: Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

</details>


### [493] [CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments](https://arxiv.org/abs/2601.13361)
*Pranay Meshram,Charuvahan Adhivarahan,Ehsan Tarkesh Esfahani,Souma Chowdhury,Chen Wang,Karthik Dantu*

Main category: cs.RO

TL;DR: CLEAR提出了一种连接土地覆盖高程抽象表示方法，通过边界感知的空间分解和递归平面拟合，为长距离非结构化环境导航提供可扩展的地形抽象表示，比现有方法更高效可靠。


<details>
  <summary>Details</summary>
Motivation: 现有地形抽象方法（网格和四叉树）在数十平方公里尺度上无法同时保持语义和几何结构，导致自主地面车辆在实时约束下的路径规划不可行或不可靠。

Method: CLEAR结合边界感知空间分解和递归平面拟合，生成凸的、语义对齐的区域，并编码为地形感知图。

Result: 在9-100平方公里地图上的物理模拟评估显示，CLEAR比原始网格规划快10倍，仅增加6.7%成本，比其他抽象基线提供6-9%更短、更可靠的路径。

Conclusion: CLEAR具有可扩展性，适用于灾难响应、国防和行星探索等长距离导航应用。

Abstract: Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.

</details>


### [494] [Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections](https://arxiv.org/abs/2601.13389)
*Zhaohui Liang,Chengyuan Ma,Keke Long,Xiaopeng Li*

Main category: cs.RO

TL;DR: 本文提出了一个评估生态驾驶策略的统一框架，通过控制鲁棒性和环境适应性两个互补标准来分析性能，并应用于真实车辆实验，揭示了不同控制器在跟踪精度和适应性之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 当前生态驾驶策略评估通常依赖简化的仿真或实验条件，存在一定假设限制。为了更全面评估生态驾驶方法的实际性能，需要建立能够量化内部执行变异和外部环境扰动影响的统一评估框架。

Method: 提出统一评估框架，通过两个互补标准：控制鲁棒性（量化内部执行变异导致的性能退化）和环境适应性（量化外部环境扰动导致的性能退化）。定义形式化指标，并将这些指标应用于多个生态驾驶控制器的真实世界车辆实验评估。

Result: 研究结果显示：基于优化的控制器在不同扰动水平下提供更一致的性能，而解析控制器在名义条件下表现相当但对执行和时序变异更敏感。揭示了跟踪精度和适应性之间的关键权衡关系。

Conclusion: 通过统一的控制鲁棒性和环境适应性评估框架，能够更全面地评估生态驾驶策略的实际性能，为控制器设计和选择提供重要指导，特别是在考虑实际应用中的不确定性和环境变化时。

Abstract: Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.

</details>


### [495] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

TL;DR: 提出一种结合混合神经网络和脉冲神经网络滤波的机器人视觉导航框架，用于增强未建模障碍物检测和定位的情境感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人导航系统在动态不可预测环境中难以有效检测未建模障碍物，且计算资源消耗大。需要一种既能准确理解环境又能快速高效处理的解决方案。

Method: 采用双通路架构：ANN组件处理低频静态空间特征，SNN组件实时处理动态事件传感器数据。系统包含预开发的SNN滤波器，直接使用脉冲编码输入进行定位和状态估计，检测到的异常通过ANN通路上下文信息验证并持续跟踪。

Result: 仿真结果显示，该方法在保持接近纯SNN实现的计算效率的同时，提供了可接受的检测精度。SNN-only实现仅需少量资源成本。

Conclusion: 该框架代表了神经形态导航系统的重大进展，特别适用于在不可预测动态环境中运行的机器人，实现了准确环境理解和高效处理的平衡。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [496] [The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study](https://arxiv.org/abs/2601.13529)
*Pejman Kheradmand,Kent K. Yamamoto,Emma Webster,Keith Sowards,Gianna Hatheway,Katharine L. Jackson,Sabino Zani,Julie A. Raffi,Diandra N. Ayala-Peacock,Scott R. Silva,Joanna Deaton Bertram,Yash Chitalia*

Main category: cs.RO

TL;DR: 本文提出了一种用于宫颈癌间质近距离放疗的手持式肌腱驱动可操纵导丝（OncoReach），旨在克服传统直针路径限制，通过可操纵设计从微创内侧入路到达外侧靶区。


<details>
  <summary>Details</summary>
Motivation: 宫颈癌是全球女性癌症负担的重要组成部分。传统的间质近距离放疗使用直针，限制了手术规划只能采用线性针道路径，无法灵活到达特定靶区位置。

Method: 开发了OncoReach可操纵导丝，与标准ISBT 15号和13号针兼容。通过评估针规、球形关节数量和位置等设计参数，包括不对称圆盘设计，优化弯曲柔顺性和轴向刚度。使用自由空间实验量化不同配置的尖端偏转，采用两管Cosserat杆模型预测针道中心线形状。将最佳配置集成到可重复使用的手持原型中，支持手动驱动。

Result: 开发了患者来源的多复合子宫和骨盆体模模型进行试点研究。结果显示，可操纵导丝能够从微创的内侧入路点转向，成功到达最外侧的靶区，证明了可操纵导丝在临床中的重要性。

Conclusion: OncoReach可操纵导丝为宫颈癌间质近距离放疗提供了创新的解决方案，通过可操纵设计克服了传统直针的路径限制，有望改善手术规划灵活性和治疗效果。

Abstract: Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets.

</details>


### [497] [LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI](https://arxiv.org/abs/2601.13556)
*Jianan Wang,Siyang Zhang,Bin Li,Juan Chen,Jingtao Qi,Zhuo Zhang,Chen Qian*

Main category: cs.RO

TL;DR: LogicEnvGen：一种基于LLM的模拟环境生成方法，通过分析任务执行逻辑构建决策树和行为计划，生成逻辑多样化的环境作为智能体测试用例，显著提高故障检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有环境生成方法过于关注视觉真实性而忽视逻辑多样性，这限制了智能体适应性和规划鲁棒性的全面评估。需要从测试角度出发，生成逻辑多样化的模拟环境作为测试用例。

Method: 采用自顶向下范式：1) 分析任务执行逻辑，构建决策树结构的行为计划；2) 合成逻辑轨迹集；3) 使用启发式算法优化轨迹集减少冗余；4) 为每个逻辑轨迹实例化具体环境；5) 使用约束求解确保物理合理性。

Result: 实验证明基准方法缺乏逻辑多样性，LogicEnvGen实现了1.04-2.61倍的多样性提升，在揭示智能体故障方面的性能提高了4.00%-68.00%。

Conclusion: LogicEnvGen通过生成逻辑多样化的模拟环境，显著提升了智能体测试的全面性和有效性，填补了现有环境生成方法在逻辑多样性方面的空白。

Abstract: Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.

</details>


### [498] [Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction](https://arxiv.org/abs/2601.13574)
*Guanyu Xu,Jiaqi Wang,Dezhong Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于光学波导传感的软、柔性、可拉伸的硅胶膜，通过数据驱动模型解码变形依赖的光强信号，实现实时3D几何重建。


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法在低光照或遮挡条件下不可靠，而现有的形状感知膜存在结构复杂、大变形适应性差、易受电磁干扰等问题。

Method: 采用多层弹性体复合材料，嵌入液态金属导线，边缘安装LED，中心分布光电二极管，通过光学波导传感采集变形光强信号，使用数据驱动模型重建3D点云。

Result: 在140mm方形膜上实现90Hz实时重建，平均重建误差1.3mm（Chamfer距离），对高达25mm的凹陷保持准确度。

Conclusion: 该框架为可变形机器人系统提供了可扩展、鲁棒、低剖面的全局形状感知解决方案。

Abstract: Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.

</details>


### [499] [A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint](https://arxiv.org/abs/2601.13639)
*Deyun Qin,Zezhi Liu,Hanqian Luo,Xiao Liang,Yongchun Fang*

Main category: cs.RO

TL;DR: 本文提出了一种用于机器人操作的单次多模态主动感知框架，通过解耦视角质量评估与架构设计，支持异构任务需求，并利用跨注意力机制融合多模态特征直接预测最优相机位姿调整。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法依赖迭代优化，导致时间和运动成本高，且与特定任务目标紧密耦合，限制了其可迁移性。需要一种通用的一次性推理框架来直接推断最优观察视角。

Method: 提出包含数据收集流水线和最优视角预测网络的通用框架：1) 通过系统采样和评估候选视角定义最优视角；2) 通过领域随机化构建大规模训练数据集；3) 开发多模态最优视角预测网络，利用跨注意力对齐和融合多模态特征，直接预测相机位姿调整。

Result: 在视角受限环境下的机器人抓取任务中，该框架指导的主动感知显著提高了抓取成功率。真实世界评估显示抓取成功率接近翻倍，且无需额外微调即可实现无缝的仿真到现实迁移。

Conclusion: 该通用单次多模态主动感知框架有效解决了现有方法的时间成本高和可迁移性差的问题，通过解耦设计和多模态融合实现了高效的最优视角预测，显著提升了机器人操作性能。

Abstract: Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework.

</details>


### [500] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

TL;DR: 基于深度强化学习的无人机集群无通信协同导航控制器，通过局部感知实现隐式领导-跟随机制，在复杂障碍环境中实现鲁棒导航


<details>
  <summary>Details</summary>
Motivation: 解决无人机集群在通信被拒环境中协同导航的挑战，特别是在复杂障碍环境下缺乏通信和外部定位系统的情况

Method: 采用隐式领导-跟随框架，仅领导者掌握目标信息，跟随者通过机载LiDAR感知学习策略。使用LiDAR点云聚类和扩展卡尔曼滤波进行邻居跟踪，基于DRL控制器在GPU加速的Nvidia Isaac Sim中训练

Result: 通过大量仿真和真实世界实验验证了方法的鲁棒性和仿真到现实的迁移能力，五架无人机集群在多样室内外环境中成功实现无通信协同导航

Conclusion: 提出的DRL控制器能够在无通信和外部定位条件下，仅通过局部感知实现无人机集群的鲁棒协同导航，为通信受限环境中的自主集群系统提供了有效解决方案

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [501] [SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation](https://arxiv.org/abs/2601.13732)
*Andreas Wiedholz,Rafael Paintner,Julian Gleißner,Alwin Hoffmann,Tobias Huber*

Main category: cs.RO

TL;DR: SUNSET是一个基于ROS2的自适应系统范例，用于在动态机器人环境中评估架构级自适应性，支持不确定性场景下的可重复测试。


<details>
  <summary>Details</summary>
Motivation: 机器人在动态环境中部署增加，软件系统复杂性提升，需要应对不确定性环境下的自适应性需求。当前环境中存在症状易观察但根因模糊、多个不确定性并发出现等问题。

Method: 开发基于ROS2的SUNSET范例，实现传感器融合语义分割流水线，使用训练的ML模型，通过扰动输入预处理引入性能退化。系统暴露5个可观察症状，支持不同根因和并发不确定性，涵盖自愈和自优化。

Result: 提供包含分割流水线、训练ML模型、不确定性注入脚本、基线控制器以及逐步集成评估文档的完整工具集，支持可重复研究和公平比较。

Conclusion: SUNSET为架构级自适应性研究提供了严谨、可重复的评估平台，特别适用于处理动态机器人环境中的不确定性和并发问题。

Abstract: The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.

</details>


### [502] [RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure](https://arxiv.org/abs/2601.13737)
*Joon Lee,Jeongyoon Han,Doyoung Kim,Seokhwan Jeong*

Main category: cs.RO

TL;DR: RIM Hand是一种仿生机器人手，通过精确复制腕掌关节和采用超弹性镍钛合金线骨架，实现了类似人类手掌的柔性和变形能力，显著提升了抓握性能和负载能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够精确复制人类手腕掌关节解剖结构、具有高度柔性和变形能力的仿生机器人手，以提升抓握稳定性、负载能力和人机交互的自然性，适用于假肢和服务机器人应用。

Method: 1. 精确建模完整的腕骨-掌骨解剖结构，复制腕掌关节；2. 在整个骨骼框架中使用超弹性镍钛合金线；3. 采用肌腱驱动的手指设计实现手掌变形；4. 使用镍钛合金背侧伸肌支撑骨骼结构；5. 覆盖柔性硅胶皮肤增加接触摩擦和接触面积。

Result: 1. 手掌变形可达28%，匹配人类手的灵活性；2. 相比刚性手掌设计，负载能力提升两倍以上；3. 接触面积增加三倍；4. 能够稳定抓握多种形状的物体；5. 在灵巧性、顺应性和拟人化方面均有显著改进。

Conclusion: RIM Hand通过仿生设计和柔性材料实现了出色的手掌变形能力和抓握性能，在假肢和服务机器人领域具有广阔的应用前景，为机器人手的灵巧性、顺应性和拟人化设定了新标准。

Abstract: This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.

</details>


### [503] [Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System](https://arxiv.org/abs/2601.13777)
*Zvi Chapnik,Yizhar Or,Shai Revzen*

Main category: cs.RO

TL;DR: 比较四种建模方法从运动跟踪数据中学习"运动性映射"的能力，测试它们在不同步态和速度下的身体速度预测表现，发现简单方法在小数据集上更优，复杂方法在大数据集上更优


<details>
  <summary>Details</summary>
Motivation: 几何力学为生物和机器人系统如何通过形状变化在环境中移动提供了有价值的见解。在高摩擦环境中，整个相互作用由"运动性映射"捕捉。本文旨在比较从物理机器人运动跟踪数据中学习这种映射的方法。

Method: 创建了一个具有欠驱动自由度和难以建模的基底相互作用的物理机器人作为测试平台。比较了四种建模方法：测试它们从形状变化预测身体速度的能力，包括同一步态内、跨步态和跨速度的预测。

Result: 结果显示了一个权衡：更简单的方法在小训练数据集上表现更优，而更复杂的方法在更多训练数据可用时表现更优。

Conclusion: 根据可用训练数据量选择合适的建模方法很重要。简单方法在小数据集上更有效，而复杂方法需要更多数据但能提供更好的性能。

Abstract: Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.

</details>


### [504] [HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction](https://arxiv.org/abs/2601.13801)
*Yuhua Jin,Nikita Kuzmin,Georgii Demianchuk,Mariya Lezina,Fawad Mehboob,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HoverAI是一个将无人机移动性、独立视觉投影和实时对话AI结合的平台，通过激光投影、屏幕和摄像头感知用户，利用多模态管道实现意图识别和个性化对话，用于空间感知、社会响应的交互应用。


<details>
  <summary>Details</summary>
Motivation: 无人机在人类环境中缺乏有效的通信机制，导致意图不明确，需要一种能增强人机交互透明度和响应性的解决方案。

Method: 集成MEMS激光投影仪、机载半刚性屏幕和RGB摄像头，采用多模态管道：语音活动检测、Whisper语音识别、基于LLM的意图分类、RAG对话系统、人脸分析个性化、XTTS v2语音合成。

Result: 命令识别F1分数0.90，人口统计估计性别F1 0.89、年龄MAE 5.14年，语音转录WER 0.181，系统能通过口型同步虚拟形象适应不同用户特征。

Conclusion: HoverAI通过融合空中机器人、自适应对话AI和自主视觉输出，创造了新型空间感知、社会响应的具身智能体，适用于引导、协助和人本交互应用。

Abstract: Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction.

</details>


### [505] [DroneVLA: VLA based Aerial Manipulation](https://arxiv.org/abs/2601.13809)
*Fawad Mehboob,Monijesu James,Amir Habel,Jeffrin Sam,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种能够理解自然语言指令的自主空中操纵系统，通过VLA模型进行语义推理生成任务队列，结合Grounding DINO和目标检测、动态A*路径规划实现物体抓取和导航，并采用基于MediaPipe的人体姿态估计实现安全的人机交互交接。


<details>
  <summary>Details</summary>
Motivation: 随着空中平台从被动观察者演变为主动操纵者，需要设计直观的界面让非专业用户能够自然地命令这些系统。现有系统缺乏对高级自然语言指令的理解能力，难以实现安全自然的人机交互。

Method: 1) 集成MediaPipe、Grounding DINO和Vision-Language-Action (VLA)模型到定制无人机平台；2) VLA模型进行语义推理，将用户指令转换为优先级任务队列；3) Grounding DINO和动态A*路径规划用于导航和物体定位；4) MediaPipe提供实时人体姿态估计，驱动视觉伺服控制器实现安全交接。

Result: 通过真实世界实验验证了系统的有效性，定位和导航的最大欧几里得误差为0.164m，平均误差为0.070m，均方根误差为0.084m，证明了VLA模型在空中操纵操作中的可行性。

Conclusion: 该系统成功展示了将自然语言理解、计算机视觉和路径规划集成到空中操纵系统中的可行性，实现了从高级语言指令到安全物体交接的完整工作流程，为非专家用户提供了直观的空中操纵接口。

Abstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

</details>


### [506] [GuideTouch: An Obstacle Avoidance Device for Visually Impaired](https://arxiv.org/abs/2601.13813)
*Timofei Kozlov,Artem Trandofilov,Georgii Gazaryan,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: GuideTouch是一种用于视障人士自主避障的紧凑型可穿戴设备，采用ToF传感器进行三维环境感知，通过四点振动触觉反馈系统提供方向指引。


<details>
  <summary>Details</summary>
Motivation: 传统移动辅助工具难以检测头部高度的障碍物，对视障人士的安全导航构成严重挑战，需要一种能够检测三维空间障碍并提供直观反馈的解决方案。

Method: 系统集成两个垂直排列的ToF传感器实现三维环境感知，使用四个振动触觉执行器提供四点方向性触觉反馈。设备还包括离心自清洁光学盖机制和掉落位置报警系统以提高实用性。

Result: 在22名参与者中，系统显示不同振动模式感知准确率存在显著差异。单/双电机（主要方向）模式平均识别准确率达92.9%。在14名视障用户的初步实验中，主要方向提示识别准确率达93.75%。

Conclusion: GuideTouch能够实现直观的空间感知，可显著提高视障用户在独立导航时的安全性、自信心和自主性，为视障人士提供有效的头部障碍物检测解决方案。

Abstract: Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.

</details>


### [507] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: ANCHOR是一个模块化框架，通过显式的解耦和鲁棒性原语，将临时集成胶水转变为明确契约，支持AI系统在负载下的可控降级和自愈恢复。


<details>
  <summary>Details</summary>
Motivation: 随着具身AI系统从研究原型转向实际部署，系统快速演进时需要保持工作负载变化和部分故障下的可靠性。现有部署通常只部分解耦，导致接口漂移、跨模块干扰和大规模下的脆弱恢复。

Method: ANCHOR框架将解耦和鲁棒性作为显式系统级原语，分离(i)可演进的标准共享状态规范（规范记录）和(ii)用于多对多传播和反馈导向协调的通信总线，形成可检查的端到端循环。

Result: 在去标识化工作流实例上验证了闭环可行性，表征了不同负载大小和发布速率下的延迟分布，展示了即使在共享内存丢失的情况下，硬崩溃和重启后也能自动恢复流。

Conclusion: ANCHOR将临时集成胶水转变为明确契约，使AI系统在负载下能够可控降级并实现自愈恢复，支持闭环AI系统的可扩展部署。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [508] [Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects](https://arxiv.org/abs/2601.13979)
*Raffaele Mazza,Ciro Natale,Pietro Falco*

Main category: cs.RO

TL;DR: 提出了一种用于可变形线性物体3D形状重建的跨模态视觉-触觉感知框架，特别针对严重视觉遮挡下的电缆，通过整合基础模型视觉感知与自适应触觉探索来解决视觉遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉，在光照变化、背景杂乱或部分可见时性能下降，特别是对于严重视觉遮挡的可变形线性物体（如电缆）难以准确重建其3D形状。

Method: 1) 视觉管道：使用SAM进行实例分割，Florence进行语义细化，然后进行骨架化、端点检测和点云提取；2) 触觉探索：自动识别遮挡的电缆段，使用触觉传感器获取局部点云；3) 数据融合：通过欧几里得聚类和拓扑保持融合将视觉与触觉点云合并；4) 形状重建：使用端点引导的点排序驱动B样条插值，获得平滑完整的电缆形状。

Result: 实验验证表明，该框架能准确重建简单和高度弯曲的单根或多根电缆配置，即使大部分被遮挡。结果突出了基础模型增强的跨模态感知在推进可变形物体机器人操纵方面的潜力。

Conclusion: 该研究展示了结合基础模型视觉感知和自适应触觉探索的跨模态框架能有效解决严重视觉遮挡下可变形线性物体的3D形状重建问题，为机器人操纵可变形物体提供了新方法。

Abstract: This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.

</details>


### [509] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

TL;DR: GISD是一种无监督技能发现框架，通过显式嵌入群结构来利用环境几何对称性，减少冗余行为并提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法忽略了物理环境的几何对称性，导致行为冗余和样本效率低下。需要一种能够利用环境对称性结构的方法来提高技能发现效果。

Method: 提出群不变技能发现(GISD)框架，将群结构嵌入技能发现目标。理论证明在群对称环境中，标准Wasserstein依赖度量存在由等变策略和群不变评分函数组成的全局最优解。基于此，定义了群不变Wasserstein依赖度量，并使用群傅里叶表示参数化评分函数，通过等变潜在特征对齐定义内在奖励。

Result: 在基于状态和基于像素的移动基准测试中，GISD相比强基线实现了更广泛的状态空间覆盖和下游任务学习效率提升。

Conclusion: 通过显式建模环境对称性，GISD能够发现更通用、系统化的技能，提高无监督技能发现的效果和下游任务学习效率。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [510] [Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems](https://arxiv.org/abs/2601.14091)
*Hossein Naderi,Alireza Shojaei,Lifu Huang,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 使用轻量级开源大语言模型和视觉语言模型构建多智能体系统，提升建筑机器人的任务规划适应性和泛化能力，四智能体团队在多项指标上超越GPT-4o且成本降低十倍。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人面临高成本和动态任务适应性差的挑战，需要提升任务规划的适应性和泛化能力。基础模型为解决这些问题提供了潜力。

Method: 提出并实现了四种模型：一个单智能体和三个多智能体团队，使用轻量级开源LLMs和VLMs构建。多智能体通过协作创建机器人动作计划，在三个建筑角色（油漆工、安全检查员、铺砖工）上进行评估。

Result: 四智能体团队在大多数指标上优于最先进的GPT-4o，同时成本效益提高十倍。三和四智能体团队表现出更好的泛化能力。通过分析智能体行为对输出的影响，增强了对AI团队的理解。

Conclusion: 轻量级开源多智能体系统能有效提升建筑机器人任务规划的适应性和泛化能力，为未来在建筑及其他非结构化环境中的AI团队研究提供了支持。

Abstract: Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.

</details>


### [511] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

TL;DR: 论文提出了一种针对现实世界机器人系统的扩散引导后门攻击框架（DGBA），通过设计可打印的视觉补丁触发器，利用条件扩散模型生成多样化的触发器外观，并采用基于优势的投毒策略，成功在TurtleBot3移动机器人上实现了可靠的目标攻击激活。


<details>
  <summary>Details</summary>
Motivation: 现有的后门攻击主要在仿真环境中验证，而在真实机器人系统中的有效性尚不清楚。现实部署中的安全约束控制管道（如速度限制、动作平滑、碰撞避免）会抑制异常动作，导致传统后门攻击效果严重衰减。本研究旨在解决这一被忽视的问题。

Method: 1. 设计可打印的地面视觉补丁触发器；2. 使用条件扩散模型生成多样化外观的触发器以适应现实世界视觉变化；3. 将机器人控制堆栈视为黑盒系统；4. 引入基于优势的投毒策略，仅在决策关键的训练状态注入触发器。

Result: 在TurtleBot3移动机器人上评估该方法，证明了能够可靠激活目标攻击，同时保持正常任务性能。

Conclusion: 该研究首次系统地研究了现实世界机器人系统中的后门攻击问题，提出的DGBA框架能够克服安全约束控制管道的限制，有效实现真实环境中的后门攻击，揭示了机器人学习系统在现实部署中的安全风险。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [512] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出SandWorm仿生蠕动机器人及SWTac事件视觉触觉传感器，用于解决颗粒介质中的感知挑战，实现高效运动与高精度触觉成像


<details>
  <summary>Details</summary>
Motivation: 颗粒介质中粒子动态不可预测，导致感知困难，需要开发能够在这种复杂环境中有效感知和运动的机器人系统

Method: 开发SandWorm仿生螺旋驱动机器人，采用蠕动运动增强移动能力；设计SWTac事件触觉传感器，包含主动振动弹性体和弹簧隔离机制；提出IMU引导时间滤波算法，系统优化振动参数、事件相机设置和弹性体特性；使用U-Net进行接触表面估计

Result: SWTac实现0.2mm纹理分辨率、98%石块分类准确率、0.15N力估计误差；SandWorm在挑战性地形中达到12.5mm/s移动速度，管道清淤和地下探索成功率90%；MSNR提升24%

Conclusion: SandWorm和SWTac系统在颗粒介质中实现了有效的感知和运动能力，通过现场实验验证了实际应用性能，为解决复杂环境中的机器人感知问题提供了新方案

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>


### [513] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

TL;DR: TwinBrainVLA提出了一种新型视觉-语言-动作模型架构，通过将通用视觉语言模型与专门化的具身感知模型协同工作，解决了传统VLA模型在机器人控制中面临的语义理解与精细运动技能学习之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型在微调用于机器人控制时面临关键矛盾：既要保持高层次的通用语义理解能力，又要学习低层次的精细传感器运动技能，这通常导致模型出现"灾难性遗忘"，丧失原有的开放世界能力。

Method: 提出TwinBrainVLA架构，包含冻结的"左脑"（保持通用视觉推理能力）和可训练的"右脑"（专门用于具身感知），通过非对称混合变换器机制实现协同。右脑能动态查询左脑的语义知识，并与本体感觉状态融合，为流匹配动作专家提供丰富条件以生成精确连续控制。

Result: 在SimplerEnv和RoboCasa基准测试中，TwinBrainVLA相比现有最先进方法表现出更优越的操作性能，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA为解决通用语义理解与低级物理灵巧性之间的冲突提供了有前景的方向，为构建同时具备高层次语义理解和低层次物理操作能力的通用机器人开辟了新途径。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>
