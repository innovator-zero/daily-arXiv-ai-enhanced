<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.LG](#cs.LG) [Total: 56]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [AI-Based Culvert-Sewer Inspection](https://arxiv.org/abs/2601.15366)
*Christina Thrainer*

Main category: cs.CV

TL;DR: 该论文针对排水管道缺陷检测数据稀缺问题，提出了三种改进方法：数据增强策略、新型FORTRESS架构和少样本学习方案，显著提升了缺陷分割性能。


<details>
  <summary>Details</summary>
Motivation: 排水管道和涵洞的缺陷检测对公共安全和环境保护至关重要，但数据收集和标注困难且需要专业知识，导致大规模标注数据集难以获得，需要解决数据稀缺条件下的自动化缺陷分割问题。

Method: 1. 评估预处理策略：包括传统数据增强和动态标签注入技术；2. 提出FORTRESS架构：结合深度可分离卷积、自适应Kolmogorov-Arnold网络和多尺度注意力机制；3. 研究少样本语义分割：采用双向原型网络加注意力机制。

Result: 数据增强策略显著提高了分割性能（IoU和F1分数）；FORTRESS在涵洞管道缺陷数据集上达到最先进性能，同时大幅减少可训练参数和计算成本；少样本学习方法在各种评估指标上都取得了满意结果。

Conclusion: 该论文通过三种互补方法有效解决了排水管道缺陷分割中的数据稀缺问题，为实际应用场景提供了可行的解决方案，显著提升了自动化缺陷检测的准确性和效率。

Abstract: Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.
  First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.

</details>


### [2] [Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition](https://arxiv.org/abs/2601.15406)
*Hatef Otroshi Shahreza,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: 该论文对多模态大语言模型在异质人脸识别任务上的表现进行了系统评估，发现MLLMs在跨光谱条件下性能显著低于传统人脸识别系统


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型在视觉语言任务上表现出色，研究者对其在生物识别应用中的潜力产生兴趣。本文旨在系统评估MLLMs在异质人脸识别任务上的实际表现

Method: 使用多个开源MLLMs，在VIS-NIR、VIS-SWIR、VIS-THERMAL等跨模态场景下进行基准测试，采用生物识别协议和多种指标（获取率、等错误率、真实接受率）进行评估

Result: MLLMs在异质人脸识别任务上表现不佳，与传统人脸识别系统存在显著性能差距，特别是在具有挑战性的跨光谱条件下

Conclusion: 当前MLLMs在异质人脸识别方面存在局限性，在部署到人脸识别系统前需要进行严格的生物识别评估

Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.

</details>


### [3] [CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation](https://arxiv.org/abs/2601.15408)
*Pablo Messina,Andrés Villa,Juan León Alcázar,Karen Sánchez,Carlos Hinojosa,Denis Parra,Álvaro Soto,Bernard Ghanem*

Main category: cs.CV

TL;DR: CURE是一种错误感知课程学习框架，通过多阶段训练提升医学视觉语言模型在放射学报告生成中的视觉定位准确性和事实一致性，无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在生成放射学报告时存在视觉定位不准确和事实不一致的问题，导致预测结果不可靠或缺乏视觉证据支撑。

Method: CURE采用错误感知课程学习框架，在公开数据集上对多模态指令模型进行三阶段微调：短语定位、定位报告生成和解剖结构定位报告生成。通过动态调整样本采样策略，基于模型性能强调困难样本，改善空间和文本对齐。

Result: CURE将定位准确度提升+0.37 IoU，报告质量提高+0.188 CXRFEScore，幻觉减少18.6%。该框架数据高效，同时提升了定位准确性和报告可靠性。

Conclusion: CURE是一个无需额外数据的数据高效框架，通过错误感知课程学习显著改善了医学视觉语言模型在放射学报告生成中的视觉定位准确性和事实一致性。

Abstract: Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure

</details>


### [4] [DuFal: Dual-Frequency-Aware Learning for High-Fidelity Extremely Sparse-view CBCT Reconstruction](https://arxiv.org/abs/2601.15416)
*Cuong Tran Van,Trong-Thang Pham,Ngoc-Son Nguyen,Duy Minh Ho Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DuFal是一种用于稀疏视图锥束CT重建的双频感知学习框架，通过全局和局部高频增强傅里叶神经算子分别处理全局频率模式和局部空间信息，在极端稀疏视图条件下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图锥束CT重建面临的主要挑战是由于欠采样导致高频细粒度解剖细节难以恢复。传统CNN方法偏向学习低频信息，无法有效恢复高频结构。

Method: 提出DuFal框架，采用双路径架构整合频域和空间域处理。核心是高低频分解傅里叶神经算子，包含全局高频增强傅里叶神经算子和局部高频增强傅里叶神经算子两个互补分支。采用谱通道分解方案减少参数，通过交叉注意力频率融合模块整合特征，最后通过特征解码器和强度场解码管道重建CT体积。

Result: 在LUNA16和ToothFairy数据集上的实验结果表明，DuFal在保留高频解剖特征方面显著优于现有最先进方法，特别是在极端稀疏视图设置下表现优异。

Conclusion: DuFal通过双频感知学习有效解决了稀疏视图CT重建中高频信息恢复的难题，为医学影像重建提供了新的解决方案。

Abstract: Sparse-view Cone-Beam Computed Tomography reconstruction from limited X-ray projections remains a challenging problem in medical imaging due to the inherent undersampling of fine-grained anatomical details, which correspond to high-frequency components. Conventional CNN-based methods often struggle to recover these fine structures, as they are typically biased toward learning low-frequency information. To address this challenge, this paper presents DuFal (Dual-Frequency-Aware Learning), a novel framework that integrates frequency-domain and spatial-domain processing via a dual-path architecture. The core innovation lies in our High-Local Factorized Fourier Neural Operator, which comprises two complementary branches: a Global High-Frequency Enhanced Fourier Neural Operator that captures global frequency patterns and a Local High-Frequency Enhanced Fourier Neural Operator that processes spatially partitioned patches to preserve spatial locality that might be lost in global frequency analysis. To improve efficiency, we design a Spectral-Channel Factorization scheme that reduces the Fourier Neural Operator parameter count. We also design a Cross-Attention Frequency Fusion module to integrate spatial and frequency features effectively. The fused features are then decoded through a Feature Decoder to produce projection representations, which are subsequently processed through an Intensity Field Decoding pipeline to reconstruct a final Computed Tomography volume. Experimental results on the LUNA16 and ToothFairy datasets demonstrate that DuFal significantly outperforms existing state-of-the-art methods in preserving high-frequency anatomical features, particularly under extremely sparse-view settings.

</details>


### [5] [DevPrompt: Deviation-Based Prompt Learning for One-Normal ShotImage Anomaly Detection](https://arxiv.org/abs/2601.15453)
*Morteza Poudineh,Marc Lalonde*

Main category: cs.CV

TL;DR: 该论文提出了一种基于偏差引导的提示学习框架，用于少样本异常检测，结合了视觉语言模型的语义能力和基于偏差的统计评分机制，在MVTecAD和VISA基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 少样本异常检测任务面临有限监督和缺陷多样性的挑战。现有基于CLIP的方法存在正常与异常提示区分度弱、缺乏原则性的补丁级异常评分机制等问题。

Method: 提出偏差引导提示学习框架：1) 用可学习的上下文向量替代固定提示前缀，正常和异常提示共享；2) 异常特定后缀令牌实现类别感知对齐；3) 引入带Top-K多实例学习的偏差损失，将补丁级特征建模为从正态分布的偏差。

Result: 在MVTecAD和VISA基准测试中，相比PromptAD和其他基线方法，该方法在像素级检测性能上表现优越。消融研究验证了可学习提示、基于偏差的评分和Top-K MIL策略的有效性。

Conclusion: 该框架成功整合了视觉语言模型的语义能力与基于偏差的统计可靠性，通过偏差引导的提示学习和Top-K MIL策略，显著提高了少样本异常检测的区分能力和定位准确性。

Abstract: Few-normal shot anomaly detection (FNSAD) aims to detect abnormal regions in images using only a few normal training samples, making the task highly challenging due to limited supervision and the diversity of potential defects. Recent approaches leverage vision-language models such as CLIP with prompt-based learning to align image and text features. However, existing methods often exhibit weak discriminability between normal and abnormal prompts and lack principled scoring mechanisms for patch-level anomalies. We propose a deviation-guided prompt learning framework that integrates the semantic power of vision-language models with the statistical reliability of deviation-based scoring. Specifically, we replace fixed prompt prefixes with learnable context vectors shared across normal and abnormal prompts, while anomaly-specific suffix tokens enable class-aware alignment. To enhance separability, we introduce a deviation loss with Top-K Multiple Instance Learning (MIL), modeling patch-level features as Gaussian deviations from the normal distribution. This allows the network to assign higher anomaly scores to patches with statistically significant deviations, improving localization and interpretability. Experiments on the MVTecAD and VISA benchmarks demonstrate superior pixel-level detection performance compared to PromptAD and other baselines. Ablation studies further validate the effectiveness of learnable prompts, deviation-based scoring, and the Top-K MIL strategy.

</details>


### [6] [Seeing through Light and Darkness: Sensor-Physics Grounded Deblurring HDR NeRF from Single-Exposure Images and Events](https://arxiv.org/abs/2601.15475)
*Yunshan Qi,Lin Zhu,Nan Bao,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 提出一个统一的传感器物理基础NeRF框架，从单曝光模糊LDR图像和对应事件数据中合成锐利HDR新视角图像，解决现有方法忽略传感器物理不匹配的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用事件数据解决从模糊LDR图像合成HDR新视角的问题，但忽略了相机输出与物理世界辐射之间的传感器物理不匹配，导致HDR和去模糊效果不佳。

Method: 提出统一传感器物理基础NeRF框架：1) 使用NeRF直接表示HDR域中的3D场景实际辐射；2) 引入像素级RGB映射场对齐渲染像素值与传感器记录的LDR像素值；3) 设计事件映射场桥接物理场景动态与事件传感器输出；4) 联合优化两个映射场与NeRF网络，利用事件中的时空动态信息增强锐利HDR 3D表示学习。

Result: 在收集和公开数据集上的实验表明，该方法能够实现最先进的去模糊HDR新视角合成结果，仅使用单曝光模糊LDR图像和对应事件数据。

Conclusion: 提出的统一传感器物理基础NeRF框架通过建模传感器物理过程，有效解决了从模糊LDR图像合成锐利HDR新视角的挑战，显著提升了表示质量和合成效果。

Abstract: Novel view synthesis from low dynamic range (LDR) blurry images, which are common in the wild, struggles to recover high dynamic range (HDR) and sharp 3D representations in extreme lighting conditions. Although existing methods employ event data to address this issue, they ignore the sensor-physics mismatches between the camera output and physical world radiance, resulting in suboptimal HDR and deblurring results. To cope with this problem, we propose a unified sensor-physics grounded NeRF framework for sharp HDR novel view synthesis from single-exposure blurry LDR images and corresponding events. We employ NeRF to directly represent the actual radiance of the 3D scene in the HDR domain and model raw HDR scene rays hitting the sensor pixels as in the physical world. A pixel-wise RGB mapping field is introduced to align the above rendered pixel values with the sensor-recorded LDR pixel values of the input images. A novel event mapping field is also designed to bridge the physical scene dynamics and actual event sensor output. The two mapping fields are jointly optimized with the NeRF network, leveraging the spatial and temporal dynamic information in events to enhance the sharp HDR 3D representation learning. Experiments on the collected and public datasets demonstrate that our method can achieve state-of-the-art deblurring HDR novel view synthesis results with single-exposure blurry LDR images and corresponding events.

</details>


### [7] [Hybrid Vision Transformer_GAN Attribute Neutralizer for Mitigating Bias in Chest X_Ray Diagnosis](https://arxiv.org/abs/2601.15490)
*Jobeal Solomon,Ali Mohammed Mansoor Alsahag,Seyed Sahand Mohammadi Ziabari*

Main category: cs.CV

TL;DR: 本研究评估了在属性中性框架中用Vision Transformer替换U-Net卷积编码器，能否减少胸部X光分类器中的性别和年龄属性泄漏，同时保持诊断准确性。结果表明ViT中性器能更有效地抑制属性泄漏，且不牺牲临床效用。


<details>
  <summary>Details</summary>
Motivation: 胸部X光分类器中存在基于性别和年龄的偏见，导致少数亚组的系统误诊。先前基于卷积编码器的像素空间属性中性器在临床可用编辑强度下无法完全消除属性泄漏，需要探索更有效的解决方案。

Method: 使用Vision Transformer（DeiT-S）替换U-Net卷积编码器，在ChestX-ray14数据集上训练数据高效的中性器。生成11个编辑强度级别的图像，通过独立AI评估器测量属性泄漏，并通过卷积神经网络评估疾病预测性能。

Result: 在中等编辑强度（alpha=0.5）下，ViT中性器将患者性别识别AUC降至约0.80，比原始卷积U-Net编码器低约10个百分点。15个发现的宏观ROC AUC在未编辑基线5个百分点内，最差亚组AUC保持在0.70附近。

Conclusion: 全局自注意力视觉模型能进一步抑制属性泄漏而不牺牲临床实用性，为实现更公平的胸部X光AI提供了实用途径。Vision Transformer在减少偏见方面优于传统卷积架构。

Abstract: Bias in chest X-ray classifiers frequently stems from sex- and age-related shortcuts, leading to systematic underdiagnosis of minority subgroups. Previous pixel-space attribute neutralizers, which rely on convolutional encoders, lessen but do not fully remove this attribute leakage at clinically usable edit strengths. This study evaluates whether substituting the U-Net convolutional encoder with a Vision Transformer backbone in the Attribute-Neutral Framework can reduce demographic attribute leakage while preserving diagnostic accuracy. A data-efficient Image Transformer Small (DeiT-S) neutralizer was trained on the ChestX-ray14 dataset. Its edited images, generated across eleven edit-intensity levels, were evaluated with an independent AI judge for attribute leakage and with a convolutional neural network (ConvNet) for disease prediction. At a moderate edit level (alpha = 0.5), the Vision Transformer (ViT) neutralizer reduces patient sex-recognition area under the curve (AUC) to approximately 0.80, about 10 percentage points below the original framework's convolutional U-Net encoder, despite being trained for only half as many epochs. Meanwhile, macro receiver operating characteristic area under the curve (ROC AUC) across 15 findings stays within five percentage points of the unedited baseline, and the worst-case subgroup AUC remains near 0.70. These results indicate that global self-attention vision models can further suppress attribute leakage without sacrificing clinical utility, suggesting a practical route toward fairer chest X-ray AI.

</details>


### [8] [Controllable Layered Image Generation for Real-World Editing](https://arxiv.org/abs/2601.15507)
*Jinrui Yang,Qing Liu,Yijun Li,Mengwei Ren,Letian Zhang,Zhe Lin,Cihang Xie,Yuyin Zhou*

Main category: cs.CV

TL;DR: LASAGNA是一个统一框架，能同时生成图像及其组成层（背景和透明前景层），支持多种条件输入，提供更好的可控性和真实视觉效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在编辑特定元素时难以提供可控且一致的结果，分层表示方法又缺乏连贯的合成关系和真实视觉效果（如阴影和反射）。

Method: 提出LASAGNA框架，从多种条件输入（文本提示、前景、背景和位置掩码）中高效学习正确的图像合成，并引入LASAGNA-48K数据集和LASAGNABENCH基准测试。

Result: LASAGNA能同时生成多个图像层的高度一致和连贯结果，支持多样化的后期编辑应用，准确保持身份和视觉效果。

Conclusion: LASAGNA在层编辑方面表现出色，提供了更好的可控性，LASAGNA-48K数据集和LASAGNABENCH基准将公开以促进社区研究。

Abstract: Recent image generation models have shown impressive progress, yet they often struggle to yield controllable and consistent results when users attempt to edit specific elements within an existing image. Layered representations enable flexible, user-driven content creation, but existing approaches often fail to produce layers with coherent compositing relationships, and their object layers typically lack realistic visual effects such as shadows and reflections. To overcome these limitations, we propose LASAGNA, a novel, unified framework that generates an image jointly with its composing layers--a photorealistic background and a high-quality transparent foreground with compelling visual effects. Unlike prior work, LASAGNA efficiently learns correct image composition from a wide range of conditioning inputs--text prompts, foreground, background, and location masks--offering greater controllability for real-world applications. To enable this, we introduce LASAGNA-48K, a new dataset composed of clean backgrounds and RGBA foregrounds with physically grounded visual effects. We also propose LASAGNABENCH, the first benchmark for layer editing. We demonstrate that LASAGNA excels in generating highly consistent and coherent results across multiple image layers simultaneously, enabling diverse post-editing applications that accurately preserve identity and visual effects. LASAGNA-48K and LASAGNABENCH will be publicly released to foster open research in the community. The project page is https://rayjryang.github.io/LASAGNA-Page/.

</details>


### [9] [DeltaDorsal: Enhancing Hand Pose Estimation with Dorsal Features in Egocentric Views](https://arxiv.org/abs/2601.15516)
*William Huang,Siyou Pei,Leyi Zou,Eric J. Gonzalez,Ishan Chatterjee,Yang Zhang*

Main category: cs.CV

TL;DR: 提出了一种利用手背皮肤形变信息进行手部姿态估计的新方法，特别针对XR设备中常见的手指遮挡问题，通过对比动态手部与放松状态的差异来学习姿态，在遮挡场景下表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着XR设备的普及，第一人称视角的手部姿态估计变得至关重要，但这一视角经常面临手指遮挡的挑战。传统方法依赖完整的手部几何信息和大模型，在遮挡情况下效果受限。

Method: 提出双流差异编码器，利用密集视觉特征提取器获取的手背皮肤形变信息，通过对比动态手部姿态与放松基线状态的特征差异来学习手部姿态。该方法仅使用裁剪后的手背图像，不依赖完整手部几何信息。

Result: 在手指遮挡≥50%的场景下，该方法将平均关节角度误差(MPJAE)降低了18%，优于依赖完整手部几何和大模型骨架的现有先进技术。同时增强了食指捏合和点击估计的可靠性，还能检测等长力实现无可见移动的"点击"交互。

Conclusion: 该方法通过利用手背皮肤形变信息，有效解决了XR设备中手部姿态估计的遮挡问题，不仅提升了现有交互任务的可靠性，还开启了新的交互范式，同时保持了较小的模型规模。

Abstract: The proliferation of XR devices has made egocentric hand pose estimation a vital task, yet this perspective is inherently challenged by frequent finger occlusions. To address this, we propose a novel approach that leverages the rich information in dorsal hand skin deformation, unlocked by recent advances in dense visual featurizers. We introduce a dual-stream delta encoder that learns pose by contrasting features from a dynamic hand with a baseline relaxed position. Our evaluation demonstrates that, using only cropped dorsal images, our method reduces the Mean Per Joint Angle Error (MPJAE) by 18% in self-occluded scenarios (fingers >=50% occluded) compared to state-of-the-art techniques that depend on the whole hand's geometry and large model backbones. Consequently, our method not only enhances the reliability of downstream tasks like index finger pinch and tap estimation in occluded scenarios but also unlocks new interaction paradigms, such as detecting isometric force for a surface "click" without visible movement while minimizing model size.

</details>


### [10] [VIOLA: Towards Video In-Context Learning with Minimal Annotations](https://arxiv.org/abs/2601.15549)
*Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: VIOLA框架通过密度-不确定性加权采样和置信度感知机制，仅需最少专家标注即可实现视频MLLM的高效领域适应


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在真实世界部署时需要适应新的视频领域，但标注数据稀缺，特别是在工业或手术等专业环境中专家标注成本高昂。传统上下文学习方法需要大量标注数据，在实际应用中不切实际。

Method: 提出VIOLA框架：1) 密度-不确定性加权采样，结合密度估计选择同时具备多样性、代表性和信息性的样本；2) 构建混合池并使用置信度感知检索和提示机制，基于相似度和置信度复合分数检索演示，使MLLM能区分已验证真值和噪声伪标签。

Result: 在9个不同基准测试和4个MLLM上的广泛实验表明，该框架在低资源设置下显著优于各种基线方法，能以最少的标注成本实现鲁棒的领域适应。

Conclusion: VIOLA通过最小专家监督与大量未标注数据的协同作用，有效解决了视频MLLM在专业领域适应中的标注瓶颈问题，为实际部署提供了可行的解决方案。

Abstract: Generalizing Multimodal Large Language Models (MLLMs) to novel video domains is essential for real-world deployment but remains challenging due to the scarcity of labeled data. While In-Context Learning (ICL) offers a training-free adaptation path, standard methods rely on large annotated pools, which are often impractical in specialized environments like industrial or surgical settings since they require the experts' annotations. To bridge this gap, we introduce VIOLA (Video In-cOntext Learning with minimal Annotation), a label-efficient framework that synergizes minimal expert supervision with abundant unlabeled data. First, to maximize the efficiency of a strict annotation budget, we propose density-uncertainty-weighted sampling. Unlike standard diversity or uncertainty strategies that risk selecting visual outliers, our method leverages density estimation to identify samples that are simultaneously diverse, representative, and informative. Second, to utilize the remaining unlabeled data without noise propagation, we construct a hybrid pool and introduce confidence-aware retrieval and confidence-aware prompting. These mechanisms explicitly model label reliability, retrieving demonstrations based on a composite score of similarity and confidence while enabling the MLLM to adaptively distinguish between verified ground truths and noisy pseudo-labels. Extensive experiments across nine diverse benchmarks using four MLLMs demonstrate that our framework significantly outperforms various baselines in low-resource settings, achieving robust adaptation with minimal annotation costs.

</details>


### [11] [Relative Classification Accuracy: A Calibrated Metric for Identity Consistency in Fine-Grained K-pop Face Generation](https://arxiv.org/abs/2601.15560)
*Sylvey Lin,Eranki Vasistha*

Main category: cs.CV

TL;DR: 论文研究了在K-pop偶像人脸生成任务中，类条件DDPM模型的语义可控性问题，提出了一种新的评估指标RCA来检测身份一致性，发现模型在视觉质量高的同时存在严重的语义模式崩溃问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标如FID和IS在细粒度、单域任务中难以检测身份对齐问题，特别是在K-pop偶像人脸生成这种类间相似度高的领域，需要更精准的语义可控性评估方法。

Method: 使用类条件DDPM模型生成32x32的K-pop偶像人脸，提出相对分类准确率(RCA)指标，通过混淆矩阵分析失败模式，并与Oracle分类器的基线性能进行归一化比较。

Result: 模型获得了较高的视觉质量(FID 8.93)，但存在严重的语义模式崩溃(RCA 0.27)，特别是在视觉模糊的身份上；分辨率限制和类内性别模糊是主要原因。

Conclusion: 该框架为条件生成模型的身份一致性验证提供了严格标准，揭示了当前生成模型在细粒度语义控制上的局限性，需要在保持视觉质量的同时改进身份保真度。

Abstract: Denoising Diffusion Probabilistic Models (DDPMs) have achieved remarkable success in high-fidelity image generation. However, evaluating their semantic controllability-specifically for fine-grained, single-domain tasks-remains challenging. Standard metrics like FID and Inception Score (IS) often fail to detect identity misalignment in such specialized contexts. In this work, we investigate Class-Conditional DDPMs for K-pop idol face generation (32x32), a domain characterized by high inter-class similarity. We propose a calibrated metric, Relative Classification Accuracy (RCA), which normalizes generative performance against an oracle classifier's baseline. Our evaluation reveals a critical trade-off: while the model achieves high visual quality (FID 8.93), it suffers from severe semantic mode collapse (RCA 0.27), particularly for visually ambiguous identities. We analyze these failure modes through confusion matrices and attribute them to resolution constraints and intra-gender ambiguity. Our framework provides a rigorous standard for verifying identity consistency in conditional generative models.

</details>


### [12] [Region-aware Spatiotemporal Modeling with Collaborative Domain Generalization for Cross-Subject EEG Emotion Recognition](https://arxiv.org/abs/2601.15615)
*Weiwei Wu,Yueyang Li,Yuhu Shi,Weiming Zeng,Lang Qin,Yang Yang,Ke Zhou,Zhiguo Zhang,Wai Ting Siok,Nizhuan Wang*

Main category: cs.CV

TL;DR: 提出RSM-CoDG框架，通过脑功能分区先验构建区域级空间表征，结合多尺度时序建模和协作域泛化策略，解决跨被试EEG情感识别中的个体差异问题。


<details>
  <summary>Details</summary>
Motivation: 跨被试EEG情感识别面临两大挑战：1) 被试间差异导致的EEG信号分布偏移；2) 情感相关神经表征在空间组织和时间演化上的高度复杂性。现有方法通常单独改进空间建模、时序建模或泛化策略，难以在统一框架中同时对齐跨被试表征、捕捉多尺度动态并抑制被试特异性偏差。

Method: RSM-CoDG框架包含三个核心组件：1) 基于脑功能分区先验构建区域级空间表征，提升跨被试可比性；2) 多尺度时序建模，刻画情感诱发神经活动的动态演化；3) 协作域泛化策略，通过多维约束在完全未见目标被试设置下减少被试特异性偏差。

Result: 在SEED系列数据集上的大量实验结果表明，RSM-CoDG持续优于现有竞争方法，为提升跨被试EEG情感识别的鲁棒性提供了有效途径。

Conclusion: RSM-CoDG通过整合神经科学先验、多尺度时序建模和协作域泛化策略，有效解决了跨被试EEG情感识别中的关键挑战，实现了更好的泛化性能和鲁棒性。

Abstract: Cross-subject EEG-based emotion recognition (EER) remains challenging due to strong inter-subject variability, which induces substantial distribution shifts in EEG signals, as well as the high complexity of emotion-related neural representations in both spatial organization and temporal evolution. Existing approaches typically improve spatial modeling, temporal modeling, or generalization strategies in isolation, which limits their ability to align representations across subjects while capturing multi-scale dynamics and suppressing subject-specific bias within a unified framework. To address these gaps, we propose a Region-aware Spatiotemporal Modeling framework with Collaborative Domain Generalization (RSM-CoDG) for cross-subject EEG emotion recognition. RSM-CoDG incorporates neuroscience priors derived from functional brain region partitioning to construct region-level spatial representations, thereby improving cross-subject comparability. It also employs multi-scale temporal modeling to characterize the dynamic evolution of emotion-evoked neural activity. In addition, the framework employs a collaborative domain generalization strategy, incorporating multidimensional constraints to reduce subject-specific bias in a fully unseen target subject setting, which enhances the generalization to unknown individuals. Extensive experimental results on SEED series datasets demonstrate that RSM-CoDG consistently outperforms existing competing methods, providing an effective approach for improving robustness. The source code is available at https://github.com/RyanLi-X/RSM-CoDG.

</details>


### [13] [Explainable Deepfake Detection with RL Enhanced Self-Blended Images](https://arxiv.org/abs/2601.15624)
*Ning Jiang,Dingheng Zeng,Yanhong Liu,Haiyang Yi,Shijie Yu,Minghe Weng,Haifeng Shen,Ying Li*

Main category: cs.CV

TL;DR: 提出基于自混合图像(Self-Blended Images)的自动思维链(CoT)数据生成框架和强化学习增强的深度伪造检测框架，解决现有方法缺乏可解释性和高质量标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法缺乏可解释性输出，且高质量带详细伪造属性标注的数据集稀缺。同时，研究表明强化学习在视觉任务中能显著提升性能，特别是跨域泛化能力。

Method: 1) 基于自混合图像的自动思维链数据生成框架，降低标注成本；2) 强化学习增强的深度伪造检测框架，包含定制化奖励机制和反馈驱动的合成数据生成方法。

Result: 实验验证了CoT数据构建流程、奖励机制和反馈驱动合成数据生成方法的有效性。在多个跨数据集基准测试中，性能达到与最先进方法竞争的水平。

Conclusion: 该方法成功降低了多模态大语言模型在深度伪造检测中的标注成本，并探索了强化学习在该领域的潜力，为可解释性深度伪造检测提供了新思路。

Abstract: Most prior deepfake detection methods lack explainable outputs. With the growing interest in multimodal large language models (MLLMs), researchers have started exploring their use in interpretable deepfake detection. However, a major obstacle in applying MLLMs to this task is the scarcity of high-quality datasets with detailed forgery attribution annotations, as textual annotation is both costly and challenging - particularly for high-fidelity forged images or videos. Moreover, multiple studies have shown that reinforcement learning (RL) can substantially enhance performance in visual tasks, especially in improving cross-domain generalization. To facilitate the adoption of mainstream MLLM frameworks in deepfake detection with reduced annotation cost, and to investigate the potential of RL in this context, we propose an automated Chain-of-Thought (CoT) data generation framework based on Self-Blended Images, along with an RL-enhanced deepfake detection framework. Extensive experiments validate the effectiveness of our CoT data construction pipeline, tailored reward mechanism, and feedback-driven synthetic data generation approach. Our method achieves performance competitive with state-of-the-art (SOTA) approaches across multiple cross-dataset benchmarks. Implementation details are available at https://github.com/deon1219/rlsbi.

</details>


### [14] [Evolving Without Ending: Unifying Multimodal Incremental Learning for Continual Panoptic Perception](https://arxiv.org/abs/2601.15643)
*Bo Yuan,Danpei Zhao,Wentao Li,Tian Li,Zhiguo Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种持续全景感知（CPP）框架，将持续学习扩展到多模态多任务场景，通过跨模态编码器、知识继承模块和一致性约束解决灾难性遗忘和语义混淆问题，无需样本回放即可实现模型演化。


<details>
  <summary>Details</summary>
Motivation: 现有持续学习研究主要关注单任务场景，限制了在多任务和多模态应用中的潜力。多任务持续学习不仅面临灾难性遗忘问题，还会导致跨模态对齐的语义混淆，在增量训练步骤中造成严重的模型退化。

Method: 提出持续全景感知（CPP）框架，包含：1）协作跨模态编码器（CCE）用于多模态嵌入；2）通过对比特征蒸馏和实例蒸馏的可塑知识继承模块；3）跨模态一致性约束（CPP+）；4）非对称伪标签机制，无需样本回放。

Result: 在多模态数据集和多样持续学习任务上的大量实验表明，该模型具有优越性能，特别是在细粒度持续学习任务中表现突出。

Conclusion: 本文成功将持续学习扩展到多模态多任务场景，提出的CPP框架有效解决了灾难性遗忘和跨模态语义对齐问题，为全面图像感知提供了端到端的解决方案。

Abstract: Continual learning (CL) is a great endeavour in developing intelligent perception AI systems. However, the pioneer research has predominantly focus on single-task CL, which restricts the potential in multi-task and multimodal scenarios. Beyond the well-known issue of catastrophic forgetting, the multi-task CL also brings semantic obfuscation across multimodal alignment, leading to severe model degradation during incremental training steps. In this paper, we extend CL to continual panoptic perception (CPP), integrating multimodal and multi-task CL to enhance comprehensive image perception through pixel-level, instance-level, and image-level joint interpretation. We formalize the CL task in multimodal scenarios and propose an end-to-end continual panoptic perception model. Concretely, CPP model features a collaborative cross-modal encoder (CCE) for multimodal embedding. We also propose a malleable knowledge inheritance module via contrastive feature distillation and instance distillation, addressing catastrophic forgetting from task-interactive boosting manner. Furthermore, we propose a cross-modal consistency constraint and develop CPP+, ensuring multimodal semantic alignment for model updating under multi-task incremental scenarios. Additionally, our proposed model incorporates an asymmetric pseudo-labeling manner, enabling model evolving without exemplar replay. Extensive experiments on multimodal datasets and diverse CL tasks demonstrate the superiority of the proposed model, particularly in fine-grained CL tasks.

</details>


### [15] [SuperOcc: Toward Cohesive Temporal Modeling for Superquadric-based Occupancy Prediction](https://arxiv.org/abs/2601.15644)
*Zichen Yu,Quanli Liu,Wei Wang,Liyong Zhang,Xiaoguang Zhao*

Main category: cs.CV

TL;DR: SuperOcc是一个基于超二次曲面的3D占用预测框架，通过结合时间建模、多超二次曲面解码和高效投影方案，在保持稀疏性的同时提升几何表达能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有3D占用预测方法多采用密集场景表示，忽视了真实驾驶场景固有的稀疏性。超二次曲面表示虽然具有几何表达能力强且稀疏的优点，但现有框架存在时间建模不足、查询稀疏性与几何表达能力难以权衡、超二次曲面到体素投影效率低等问题。

Method: SuperOcc提出三个关键设计：1）结合视图中心和物体中心时间线索的协调时间建模机制；2）在不牺牲查询稀疏性的前提下增强几何表达能力的多超二次曲面解码策略；3）提高计算效率的高效超二次曲面到体素投影方案。

Result: 在SurroundOcc和Occ3D基准测试中，SuperOcc实现了最先进的性能，同时保持了卓越的效率。

Conclusion: SuperOcc通过创新的超二次曲面表示方法，有效解决了现有3D占用预测框架的局限性，在稀疏性、几何表达能力和计算效率之间取得了良好平衡，为自动驾驶环境感知提供了更优的解决方案。

Abstract: 3D occupancy prediction plays a pivotal role in the realm of autonomous driving, as it provides a comprehensive understanding of the driving environment. Most existing methods construct dense scene representations for occupancy prediction, overlooking the inherent sparsity of real-world driving scenes. Recently, 3D superquadric representation has emerged as a promising sparse alternative to dense scene representations due to the strong geometric expressiveness of superquadrics. However, existing superquadric frameworks still suffer from insufficient temporal modeling, a challenging trade-off between query sparsity and geometric expressiveness, and inefficient superquadric-to-voxel splatting. To address these issues, we propose SuperOcc, a novel framework for superquadric-based 3D occupancy prediction. SuperOcc incorporates three key designs: (1) a cohesive temporal modeling mechanism to simultaneously exploit view-centric and object-centric temporal cues; (2) a multi-superquadric decoding strategy to enhance geometric expressiveness without sacrificing query sparsity; and (3) an efficient superquadric-to-voxel splatting scheme to improve computational efficiency. Extensive experiments on the SurroundOcc and Occ3D benchmarks demonstrate that SuperOcc achieves state-of-the-art performance while maintaining superior efficiency. The code is available at https://github.com/Yzichen/SuperOcc.

</details>


### [16] [Event-VStream: Event-Driven Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2601.15655)
*Zhenghui Guo,Yuanbin Man,Junyuan Sheng,Bowen Lin,Ahmed Ahmed,Bo Jiang,Boyuan Zhang,Miao Yin,Sian Jin,Omprakash Gnawal,Chengming Zhang*

Main category: cs.CV

TL;DR: Event-VStream是一个事件感知的视频流理解框架，通过检测有意义的状态转换事件来触发语言生成，避免冗余帧处理，并利用持久记忆库实现长时推理。


<details>
  <summary>Details</summary>
Motivation: 现有的视频流理解系统存在两个主要问题：1) 固定间隔解码导致重复输出；2) 缓存修剪丢弃了关键的时序信息。多模态大语言模型在处理长视频流时面临冗余帧处理和快速遗忘历史上下文的问题。

Method: 提出事件感知框架，将连续视频表示为离散的语义连贯事件序列。通过整合运动、语义和预测线索来检测有意义的状态转换，仅在事件边界触发语言生成。每个事件嵌入被整合到持久记忆库中，支持长时程推理。

Result: 在OVOBench-Realtime基准上比VideoLLM-Online-8B基线提升10.4分；仅使用通用LLaMA-3-8B文本骨干就达到接近Flash-VStream-7B的性能；在2小时Ego4D流上保持约70%的GPT-5胜率。

Conclusion: Event-VStream通过事件驱动的视频表示和记忆机制，有效解决了长视频流理解中的冗余处理和遗忘问题，在保持低延迟的同时实现了竞争性的性能。

Abstract: Real-time understanding of long video streams remains challenging for multimodal large language models (VLMs) due to redundant frame processing and rapid forgetting of past context. Existing streaming systems rely on fixed-interval decoding or cache pruning, which either produce repetitive outputs or discard crucial temporal information. We introduce Event-VStream, an event-aware framework that represents continuous video as a sequence of discrete, semantically coherent events. Our system detects meaningful state transitions by integrating motion, semantic, and predictive cues, and triggers language generation only at those boundaries. Each event embedding is consolidated into a persistent memory bank, enabling long-horizon reasoning while maintaining low latency. Across OVOBench-Realtime, and long-form Ego4D evaluations, Event-VStream achieves competitive performance. It improves over a VideoLLM-Online-8B baseline by +10.4 points on OVOBench-Realtime, achieves performance close to Flash-VStream-7B despite using only a general-purpose LLaMA-3-8B text backbone, and maintains around 70% GPT-5 win rate on 2-hour Ego4D streams.

</details>


### [17] [Skywork UniPic 3.0: Unified Multi-Image Composition via Sequence Modeling](https://arxiv.org/abs/2601.15664)
*Hongyang Wei,Hongbo Liu,Zidong Wang,Yi Peng,Baixin Xu,Size Wu,Xuying Zhang,Xianglong He,Zexiang Liu,Peiyu Wang,Xuchen Song,Yangguang Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Skywork UniPic 3.0提出统一多模态框架，支持单图编辑和多图合成，通过新颖的数据管道和序列建模训练范式，在少量高质量训练样本下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 针对当前多图像合成任务在一致性和质量方面的挑战，特别是社区最关注的人-物交互（HOI）类别，现有模型缺乏高质量融合的具体方法细节披露。

Method: 1）设计全面的数据收集、过滤和合成管道；2）将多图像合成为序列建模问题，将条件生成转化为统一序列合成；3）在训练后阶段集成轨迹映射和分布匹配以加速推理。

Result: 模型仅用70万高质量训练样本实现强性能，推理仅需8步（比标准合成采样快12.5倍），在单图编辑基准上达到SOTA，在多图合成基准上超越Nano-Banana和Seedream 4.0。

Conclusion: Skywork UniPic 3.0验证了所提数据管道和训练范式的有效性，为多图像合成任务提供了统一解决方案，支持任意数量和分辨率的输入输出。

Abstract: The recent surge in popularity of Nano-Banana and Seedream 4.0 underscores the community's strong interest in multi-image composition tasks. Compared to single-image editing, multi-image composition presents significantly greater challenges in terms of consistency and quality, yet existing models have not disclosed specific methodological details for achieving high-quality fusion. Through statistical analysis, we identify Human-Object Interaction (HOI) as the most sought-after category by the community. We therefore systematically analyze and implement a state-of-the-art solution for multi-image composition with a primary focus on HOI-centric tasks. We present Skywork UniPic 3.0, a unified multimodal framework that integrates single-image editing and multi-image composition. Our model supports an arbitrary (1~6) number and resolution of input images, as well as arbitrary output resolutions (within a total pixel budget of 1024x1024). To address the challenges of multi-image composition, we design a comprehensive data collection, filtering, and synthesis pipeline, achieving strong performance with only 700K high-quality training samples. Furthermore, we introduce a novel training paradigm that formulates multi-image composition as a sequence-modeling problem, transforming conditional generation into unified sequence synthesis. To accelerate inference, we integrate trajectory mapping and distribution matching into the post-training stage, enabling the model to produce high-fidelity samples in just 8 steps and achieve a 12.5x speedup over standard synthesis sampling. Skywork UniPic 3.0 achieves state-of-the-art performance on single-image editing benchmark and surpasses both Nano-Banana and Seedream 4.0 on multi-image composition benchmark, thereby validating the effectiveness of our data pipeline and training paradigm. Code, models and dataset are publicly available.

</details>


### [18] [Consistency-Regularized GAN for Few-Shot SAR Target Recognition](https://arxiv.org/abs/2601.15681)
*Yikui Zhai,Shikuang Liu,Wenlve Zhou,Hongsheng Zhang,Zhiheng Zhou,Xiaolin Tian,C. L. Philip Chen*

Main category: cs.CV

TL;DR: 提出Cr-GAN框架，通过解耦对抗训练和表征学习的双分支判别器，解决SAR图像少样本识别中数据稀缺问题，在极端数据限制下合成高质量样本，显著提升少样本识别性能。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达(SAR)图像少样本识别面临极端数据稀缺问题。现有方法使用GAN合成数据再通过自监督学习预训练，但传统GAN本身需要大量数据训练，这与少样本学习的前提相矛盾。

Method: 提出一致性正则化生成对抗网络(Cr-GAN)：1) 双分支判别器将对抗训练与表征学习解耦；2) 通道级特征插值策略生成新潜在特征；3) 双域循环一致性机制确保语义完整性；4) 框架可适配多种GAN架构。

Result: 在MSTAR和SRSDD数据集上，8-shot设置下分别达到71.21%和51.64%的准确率，显著优于现有基线方法，且仅需约5%的参数量于最先进的扩散模型。

Conclusion: Cr-GAN成功解决了SAR图像少样本识别中的数据稀缺悖论，能够在极端数据限制下合成高质量多样样本，有效提升多种自监督学习算法性能，为实际应用提供了可行解决方案。

Abstract: Few-shot recognition in synthetic aperture radar (SAR) imagery remains a critical bottleneck for real-world applications due to extreme data scarcity. A promising strategy involves synthesizing a large dataset with a generative adversarial network (GAN), pre-training a model via self-supervised learning (SSL), and then fine-tuning on the few labeled samples. However, this approach faces a fundamental paradox: conventional GANs themselves require abundant data for stable training, contradicting the premise of few-shot learning. To resolve this, we propose the consistency-regularized generative adversarial network (Cr-GAN), a novel framework designed to synthesize diverse, high-fidelity samples even when trained under these severe data limitations. Cr-GAN introduces a dual-branch discriminator that decouples adversarial training from representation learning. This architecture enables a channel-wise feature interpolation strategy to create novel latent features, complemented by a dual-domain cycle consistency mechanism that ensures semantic integrity. Our Cr-GAN framework is adaptable to various GAN architectures, and its synthesized data effectively boosts multiple SSL algorithms. Extensive experiments on the MSTAR and SRSDD datasets validate our approach, with Cr-GAN achieving a highly competitive accuracy of 71.21% and 51.64%, respectively, in the 8-shot setting, significantly outperforming leading baselines, while requiring only ~5 of the parameters of state-of-the-art diffusion models. Code is available at: https://github.com/yikuizhai/Cr-GAN.

</details>


### [19] [Performance-guided Reinforced Active Learning for Object Detection](https://arxiv.org/abs/2601.15688)
*Zhixuan Liang,Xingyu Zeng,Rui Zhao,Ping Luo*

Main category: cs.CV

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 

Method: 

Result: 

Conclusion: 

Abstract: Active learning (AL) strategies aim to train high-performance models with minimal labeling efforts, only selecting the most informative instances for annotation. Current approaches to evaluating data informativeness predominantly focus on the data's distribution or intrinsic information content and do not directly correlate with downstream task performance, such as mean average precision (mAP) in object detection. Thus, we propose Performance-guided (i.e. mAP-guided) Reinforced Active Learning for Object Detection (MGRAL), a novel approach that leverages the concept of expected model output changes as informativeness. To address the combinatorial explosion challenge of batch sample selection and the non-differentiable correlation between model performance and selected batches, MGRAL skillfully employs a reinforcement learning-based sampling agent that optimizes selection using policy gradient with mAP improvement as reward. Moreover, to reduce the computational overhead of mAP estimation with unlabeled samples, MGRAL utilizes an unsupervised way with fast look-up tables, ensuring feasible deployment. We evaluate MGRAL's active learning performance on detection tasks over PASCAL VOC and COCO benchmarks. Our approach demonstrates the highest AL curve with convincing visualizations, establishing a new paradigm in reinforcement learning-driven active object detection.

</details>


### [20] [Beyond Visual Safety: Jailbreaking Multimodal Large Language Models for Harmful Image Generation via Semantic-Agnostic Inputs](https://arxiv.org/abs/2601.15698)
*Mingyu Yu,Lana Liu,Zhehao Zhao,Wei Wang,Sujuan Qin*

Main category: cs.CV

TL;DR: 提出BVS框架，通过"重构-生成"策略结合视觉拼接和归纳重组，成功诱导MLLMs生成有害图像，在GPT-5上实现98.21%的越狱成功率。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs安全研究对视觉安全边界探索不足，需要专门框架来探测MLLMs在图文安全交叉领域的脆弱性。

Method: 采用"重构-生成"策略：1）使用中性化视觉拼接技术；2）通过归纳重组将恶意意图从原始输入中解耦，从而诱导MLLMs生成有害图像。

Result: BVS在GPT-5（2026年1月12日发布）上实现了98.21%的越狱成功率，显著暴露了当前MLLMs视觉安全对齐的严重漏洞。

Conclusion: 当前MLLMs的视觉安全对齐存在关键漏洞，BVS框架有效揭示了这些安全边界，为未来模型安全加固提供了重要参考。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has introduced complex security challenges, particularly at the intersection of textual and visual safety. While existing schemes have explored the security vulnerabilities of MLLMs, the investigation into their visual safety boundaries remains insufficient. In this paper, we propose Beyond Visual Safety (BVS), a novel image-text pair jailbreaking framework specifically designed to probe the visual safety boundaries of MLLMs. BVS employs a "reconstruction-then-generation" strategy, leveraging neutralized visual splicing and inductive recomposition to decouple malicious intent from raw inputs, thereby leading MLLMs to be induced into generating harmful images. Experimental results demonstrate that BVS achieves a remarkable jailbreak success rate of 98.21\% against GPT-5 (12 January 2026 release). Our findings expose critical vulnerabilities in the visual safety alignment of current MLLMs.

</details>


### [21] [Keyframe-Based Feed-Forward Visual Odometry](https://arxiv.org/abs/2601.16020)
*Weichen Dai,Wenhan Su,Da Kong,Yuhang Ming,Wanzeng Kong*

Main category: cs.CV

TL;DR: 该论文提出了一种基于强化学习的自适应关键帧选择方法，用于改进视觉基础模型在视觉里程计中的性能，解决了现有方法处理原始图像序列时计算冗余和低视差帧导致性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉基础模型的VO方法（如VGGT-Long）通常不加区分地处理原始图像序列，导致计算冗余和性能下降，特别是当帧间视差较小时提供的立体信息有限。传统几何启发式方法难以集成到这些模型中，因为它们的性能依赖于高维潜在表示而非显式几何度量。

Method: 提出了一种基于关键帧的前馈VO方法，使用强化学习以数据驱动的方式推导自适应关键帧策略，使关键帧选择与基础模型的内在特性对齐，而不是依赖手工规则。

Result: 在TartanAir数据集上训练智能体，并在多个真实世界数据集上进行广泛评估。实验结果表明，该方法相比最先进的前馈VO方法实现了持续且显著的改进。

Conclusion: 通过强化学习实现的自适应关键帧选择策略能够有效提升基于视觉基础模型的VO方法的效率和精度，为传统几何启发式方法与现代深度学习模型的融合提供了新途径。

Abstract: The emergence of visual foundation models has revolutionized visual odometry~(VO) and SLAM, enabling pose estimation and dense reconstruction within a single feed-forward network. However, unlike traditional pipelines that leverage keyframe methods to enhance efficiency and accuracy, current foundation model based methods, such as VGGT-Long, typically process raw image sequences indiscriminately. This leads to computational redundancy and degraded performance caused by low inter-frame parallax, which provides limited contextual stereo information. Integrating traditional geometric heuristics into these methods is non-trivial, as their performance depends on high-dimensional latent representations rather than explicit geometric metrics. To bridge this gap, we propose a novel keyframe-based feed-forward VO. Instead of relying on hand-crafted rules, our approach employs reinforcement learning to derive an adaptive keyframe policy in a data-driven manner, aligning selection with the intrinsic characteristics of the underlying foundation model. We train our agent on TartanAir dataset and conduct extensive evaluations across several real-world datasets. Experimental results demonstrate that the proposed method achieves consistent and substantial improvements over state-of-the-art feed-forward VO methods.

</details>


### [22] [Enhanced LULC Segmentation via Lightweight Model Refinements on ALOS-2 SAR Data](https://arxiv.org/abs/2601.15705)
*Ali Caglayan,Nevrez Imamoglu,Toru Kouyama*

Main category: cs.CV

TL;DR: 本文提出三种轻量级改进方法，用于日本全国尺度的ALOS-2单极化SAR数据土地覆盖语义分割任务，解决了边界过度平滑、细长结构漏检和长尾分布下稀有类别性能下降等问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决SAR密集预测中的常见失败模式：边界过度平滑、细长/薄结构漏检、以及在长尾标签分布下稀有类别性能退化。这些问题的解决对于全国尺度的土地覆盖分类至关重要。

Method: 基于SAR-W-MixMAE自监督预训练，引入三种轻量级改进：(1) 在多尺度解码中注入高分辨率特征；(2) 渐进式细化上采样头，交替进行卷积细化和逐步上采样；(3) 在focal+dice目标函数中引入α缩放因子来调节类别重新加权。

Result: 在覆盖日本全国的ALOS-2土地覆盖基准测试中，模型获得了一致的改进，特别是对于代表性不足的类别，并在水检测任务上提高了标准评估指标的性能。

Conclusion: 通过三种轻量级改进方法，在不增加流程复杂性的情况下，有效解决了SAR密集预测中的关键问题，显著提升了全国尺度土地覆盖语义分割和水检测任务的性能。

Abstract: This work focuses on national-scale land-use/land-cover (LULC) semantic segmentation using ALOS-2 single-polarization (HH) SAR data over Japan, together with a companion binary water detection task. Building on SAR-W-MixMAE self-supervised pretraining [1], we address common SAR dense-prediction failure modes, boundary over-smoothing, missed thin/slender structures, and rare-class degradation under long-tailed labels, without increasing pipeline complexity. We introduce three lightweight refinements: (i) injecting high-resolution features into multi-scale decoding, (ii) a progressive refine-up head that alternates convolutional refinement and stepwise upsampling, and (iii) an $α$-scale factor that tempers class reweighting within a focal+dice objective. The resulting model yields consistent improvements on the Japan-wide ALOS-2 LULC benchmark, particularly for under-represented classes, and improves water detection across standard evaluation metrics.

</details>


### [23] [DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models](https://arxiv.org/abs/2601.16065)
*Chenyang Li,Jieyuan Liu,Bin Li,Bo Gao,Yilin Yuan,Yangfan He,Yuchen Li,Jingqun Tang*

Main category: cs.CV

TL;DR: 提出Distracting Token Pruning (DTP)框架，通过动态检测和修剪VLA模型中任务无关的"干扰token"来改善视觉注意力模式，提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在处理机器人操作任务时，会过度关注任务无关区域的图像token（即"干扰token"），这会影响模型生成期望动作token的能力，降低任务成功率。

Method: 提出简单有效的即插即用DTP框架，在不改变原始架构或增加额外输入的情况下，动态检测并修剪干扰图像token，修正模型的视觉注意力模式。

Result: 在SIMPLER Benchmark上的实验表明，该方法在不同类型的VLA模型上都能持续提升任务成功率，证明了其对基于transformer的VLA模型的通用性。分析显示任务成功率与任务无关区域注意力数量呈负相关。

Conclusion: DTP框架能有效提升VLA模型的性能，揭示了VLA模型中普遍存在的干扰token现象，为未来研究提供了指导方向。

Abstract: Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

</details>


### [24] [Zero-Shot Product Attribute Labeling with Vision-Language Models: A Three-Tier Evaluation Framework](https://arxiv.org/abs/2601.15711)
*Shubham Shukla,Kunal Sonalkar*

Main category: cs.CV

TL;DR: 该研究提出了一个三层评估框架来系统评估视觉语言模型在细粒度时尚属性预测任务上的表现，特别关注条件属性的适用性检测问题。


<details>
  <summary>Details</summary>
Motivation: 时尚零售应用需要细粒度属性预测，但现有视觉语言模型在条件属性（如"外层面料"在无外衣可见时未定义）上的系统评估不足，需要同时检测属性适用性和进行分类。

Method: 引入三层评估框架：1)包含NA类的整体任务性能；2)属性适用性检测；3)属性可确定时的细粒度分类。使用DeepFashion-MultiModal数据集，在5,000张图像上评估9个VLM模型，并与基于Fashion-CLIP嵌入的分类器对比。

Result: 零样本VLM达到64.0%的宏观F1，比基于Fashion-CLIP嵌入的逻辑回归提升三倍；在细粒度分类上表现优异（70.8% F1），但在适用性检测上表现较差（34.1% NA-F1）；高效模型能达到旗舰模型90%以上性能且成本更低。

Conclusion: 该诊断框架能帮助从业者识别错误来源（可见性检测或分类），指导生产系统的针对性改进。高效模型提供了实用的部署路径，但适用性检测仍是关键瓶颈。

Abstract: Fine-grained attribute prediction is essential for fashion retail applications including catalog enrichment, visual search, and recommendation systems. Vision-Language Models (VLMs) offer zero-shot prediction without task-specific training, yet their systematic evaluation on multi-attribute fashion tasks remains underexplored. A key challenge is that fashion attributes are often conditional. For example, "outer fabric" is undefined when no outer garment is visible. This requires models to detect attribute applicability before attempting classification. We introduce a three-tier evaluation framework that decomposes this challenge: (1) overall task performance across all classes (including NA class: suggesting attribute is not applicable) for all attributes, (2) attribute applicability detection, and (3) fine-grained classification when attributes are determinable. Using DeepFashion-MultiModal, which explicitly defines NA (meaning attribute doesn't exist or is not visible) within attribute label spaces, we benchmark nine VLMs spanning flagship (GPT-5, Gemini 2.5 Pro), efficient (GPT-5 Mini, Gemini 2.5 Flash), and ultra-efficient tiers (GPT-5 Nano, Gemini 2.5 Flash-Lite) against classifiers trained on pretrained Fashion-CLIP embeddings on 5,000 images across 18 attributes. Our findings reveal that: (1) zero-shot VLMs achieve 64.0% macro-F1, a threefold improvement over logistic regression on pretrained Fashion-CLIP embeddings; (2) VLMs excel at fine-grained classification (Tier 3: 70.8% F1) but struggle with applicability detection (Tier 2: 34.1% NA-F1), identifying a key bottleneck; (3) efficient models achieve over 90% of flagship performance at lower cost, offering practical deployment paths. This diagnostic framework enables practitioners to pinpoint whether errors stem from visibility detection or classification, guiding targeted improvements for production systems.

</details>


### [25] [VideoThinker: Building Agentic VideoLLMs with LLM-Guided Tool Reasoning](https://arxiv.org/abs/2601.15724)
*Chenglin Li,Qianglong Chen,Feng Han,Yikun Wang,Xingxi Yin,Yan Gong,Ruilin Li,Yin Zhang,Jiaqi Wang*

Main category: cs.CV

TL;DR: VideoThinker通过合成工具交互轨迹训练代理视频大语言模型，解决长视频理解中信息丢失问题，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型主要依赖均匀采样帧的静态推理，导致长视频中时间定位弱和信息丢失严重。代理工具（如时间检索、空间缩放、时间缩放）能够通过自适应探索关键时刻来克服这些限制，但构建代理视频理解数据需要已具备强长视频理解能力的模型，形成循环依赖问题。

Method: 提出VideoThinker，完全基于合成工具交互轨迹训练的代理视频大语言模型。核心思想是将视频转换为丰富描述，利用强大的代理语言模型在描述空间生成多步工具使用序列，然后将这些轨迹通过替换描述为对应帧的方式回接到视频，从而无需底层模型具备长视频理解能力即可获得大规模交错的视频和工具推理数据集。

Result: VideoThinker在长视频基准测试中显著优于仅使用描述的语言模型代理和强大的视频模型基线，展示了工具增强合成数据和自适应检索与缩放推理对长视频理解的有效性。

Conclusion: 通过合成工具交互轨迹训练代理视频大语言模型是解决长视频理解挑战的有效方法，VideoThinker展示了动态推理能力、自适应时间探索和多步工具使用的优势，为长视频理解提供了新思路。

Abstract: Long-form video understanding remains a fundamental challenge for current Video Large Language Models. Most existing models rely on static reasoning over uniformly sampled frames, which weakens temporal localization and leads to substantial information loss in long videos. Agentic tools such as temporal retrieval, spatial zoom, and temporal zoom offer a natural way to overcome these limitations by enabling adaptive exploration of key moments. However, constructing agentic video understanding data requires models that already possess strong long-form video comprehension, creating a circular dependency. We address this challenge with VideoThinker, an agentic Video Large Language Model trained entirely on synthetic tool interaction trajectories. Our key idea is to convert videos into rich captions and employ a powerful agentic language model to generate multi-step tool use sequences in caption space. These trajectories are subsequently grounded back to video by replacing captions with the corresponding frames, yielding a large-scale interleaved video and tool reasoning dataset without requiring any long-form understanding from the underlying model. Training on this synthetic agentic dataset equips VideoThinker with dynamic reasoning capabilities, adaptive temporal exploration, and multi-step tool use. Remarkably, VideoThinker significantly outperforms both caption-only language model agents and strong video model baselines across long-video benchmarks, demonstrating the effectiveness of tool augmented synthetic data and adaptive retrieval and zoom reasoning for long-form video understanding.

</details>


### [26] [FAIR-ESI: Feature Adaptive Importance Refinement for Electrophysiological Source Imaging](https://arxiv.org/abs/2601.15731)
*Linyong Zou,Liang Zhang,Xiongfei Wang,Jia-Hong Gao,Yi Sun,Shurong Sheng,Kuntao Xiao,Wanli Yang,Pengfei Teng,Guoming Luan,Zhao Lv,Zikang Xu*

Main category: cs.CV

TL;DR: FAIR-ESI是一种自适应多视图特征精炼的脑电溯源成像框架，通过FFT频谱特征、加权时域特征和自注意力patch特征精炼，提升脑部疾病诊断精度。


<details>
  <summary>Details</summary>
Motivation: 脑电溯源成像(ESI)是诊断脑部疾病的重要技术，但现有基于模型优化和深度学习的方法在特征选择和精炼方面仍面临挑战，影响ESI的精确性。

Method: 提出FAIR-ESI框架，自适应精炼多视图特征：1)基于FFT的频谱特征精炼；2)加权时域特征精炼；3)基于自注意力的patch-wise特征精炼。

Result: 在两个不同配置的仿真数据集和两个真实临床数据集上的广泛实验验证了框架的有效性，展示了其在脑部疾病诊断中的潜力。

Conclusion: FAIR-ESI通过自适应多视图特征精炼提升了脑电溯源成像的准确性，有望推动脑部疾病诊断发展，并为脑功能研究提供新见解。

Abstract: An essential technique for diagnosing brain disorders is electrophysiological source imaging (ESI). While model-based optimization and deep learning methods have achieved promising results in this field, the accurate selection and refinement of features remains a central challenge for precise ESI. This paper proposes FAIR-ESI, a novel framework that adaptively refines feature importance across different views, including FFT-based spectral feature refinement, weighted temporal feature refinement, and self-attention-based patch-wise feature refinement. Extensive experiments on two simulation datasets with diverse configurations and two real-world clinical datasets validate our framework's efficacy, highlighting its potential to advance brain disorder diagnosis and offer new insights into brain function.

</details>


### [27] [Sub-Region-Aware Modality Fusion and Adaptive Prompting for Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2601.15734)
*Shadi Alijani,Fereshteh Aghaee Meibodi,Homayoun Najjaran*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态医学影像基础模型适配框架，通过子区域感知模态注意力和自适应提示工程，显著提升了脑肿瘤分割性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型在多模态医学影像中的成功适配是一个关键但尚未解决的挑战。现有模型往往难以有效融合多源信息，并适应病理组织的异质性。

Method: 引入包含两个关键技术创新的框架：1) 子区域感知模态注意力机制，让模型学习每个肿瘤子区域的最优模态组合；2) 自适应提示工程策略，利用基础模型的内在能力来提升分割精度。

Result: 在BraTS 2020脑肿瘤分割数据集上验证，该方法显著优于基线方法，特别是在具有挑战性的坏死核心子区域表现出色。

Conclusion: 为多模态融合和提示提供了一种原则性且有效的途径，为医学影像中更准确、更鲁棒的基础模型解决方案铺平了道路。

Abstract: The successful adaptation of foundation models to multi-modal medical imaging is a critical yet unresolved challenge. Existing models often struggle to effectively fuse information from multiple sources and adapt to the heterogeneous nature of pathological tissues. To address this, we introduce a novel framework for adapting foundation models to multi-modal medical imaging, featuring two key technical innovations: sub-region-aware modality attention and adaptive prompt engineering. The attention mechanism enables the model to learn the optimal combination of modalities for each tumor sub-region, while the adaptive prompting strategy leverages the inherent capabilities of foundation models to refine segmentation accuracy. We validate our framework on the BraTS 2020 brain tumor segmentation dataset, demonstrating that our approach significantly outperforms baseline methods, particularly in the challenging necrotic core sub-region. Our work provides a principled and effective approach to multi-modal fusion and prompting, paving the way for more accurate and robust foundation model-based solutions in medical imaging.

</details>


### [28] [Breaking the Resolution Barrier: Arbitrary-resolution Deep Image Steganography Framework](https://arxiv.org/abs/2601.15739)
*Xinjue Hu,Chi Wang,Boyu Wang,Xiang Zhang,Zhenshan Tan,Zhangjie Fu*

Main category: cs.CV

TL;DR: ARDIS是首个任意分辨率深度图像隐写框架，解决了传统方法中秘密图像必须与载体图像分辨率相同的问题，实现了无需预先调整分辨率的盲恢复。


<details>
  <summary>Details</summary>
Motivation: 当前深度图像隐写方法要求秘密图像与载体图像分辨率一致，导致两个问题：1) 分辨率不匹配时需要重采样，造成细节损失；2) 当分辨率值未知时无法恢复原始分辨率。需要解决这些限制以实现更灵活的隐写方案。

Method: 提出ARDIS框架，采用频率解耦架构和隐式重建器：1) 隐藏阶段将秘密图像解耦为分辨率对齐的全局基和分辨率无关的高频潜在编码；2) 恢复阶段使用潜在引导的隐式重建器进行确定性恢复；3) 引入隐式分辨率编码策略，将离散分辨率值转换为密集特征图隐藏在特征域冗余空间中。

Result: 实验结果表明，ARDIS在不可见性和跨分辨率恢复保真度方面显著优于现有最先进方法。

Conclusion: ARDIS通过从离散映射到参考引导的连续信号重建的范式转变，成功解决了深度图像隐写中的分辨率限制问题，实现了任意分辨率的秘密图像隐藏和恢复。

Abstract: Deep image steganography (DIS) has achieved significant results in capacity and invisibility. However, current paradigms enforce the secret image to maintain the same resolution as the cover image during hiding and revealing. This leads to two challenges: secret images with inconsistent resolutions must undergo resampling beforehand which results in detail loss during recovery, and the secret image cannot be recovered to its original resolution when the resolution value is unknown. To address these, we propose ARDIS, the first Arbitrary Resolution DIS framework, which shifts the paradigm from discrete mapping to reference-guided continuous signal reconstruction. Specifically, to minimize the detail loss caused by resolution mismatch, we first design a Frequency Decoupling Architecture in hiding stage. It disentangles the secret into a resolution-aligned global basis and a resolution-agnostic high-frequency latent to hide in a fixed-resolution cover. Second, for recovery, we propose a Latent-Guided Implicit Reconstructor to perform deterministic restoration. The recovered detail latent code modulates a continuous implicit function to accurately query and render high-frequency residuals onto the recovered global basis, ensuring faithful restoration of original details. Furthermore, to achieve blind recovery, we introduce an Implicit Resolution Coding strategy. By transforming discrete resolution values into dense feature maps and hiding them in the redundant space of the feature domain, the reconstructor can correctly decode the secret's resolution directly from the steganographic representation. Experimental results demonstrate that ARDIS significantly outperforms state-of-the-art methods in both invisibility and cross-resolution recovery fidelity.

</details>


### [29] [White-Box mHC: Electromagnetic Spectrum-Aware and Interpretable Stream Interactions for Hyperspectral Image Classification](https://arxiv.org/abs/2601.15757)
*Yimin Zhu,Lincoln Linlin Xu,Zhengsen Xu,Zack Dewis,Mabel Heffring,Saeid Taleghanidoozdoozan,Motasem Alkayid,Quinn Ledingham,Megan Greenwood*

Main category: cs.CV

TL;DR: 论文提出了ES-mHC框架，通过电磁频谱感知的超连接结构实现高光谱图像分类的白盒化，提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在高光谱图像分类中依赖不透明的光谱-空间特征混合，限制了可解释性，阻碍了对内部决策机制的理解。

Method: 提出物理频谱感知白盒mHC框架（ES-mHC），使用结构化、定向矩阵显式建模不同电磁频谱分组之间的相互作用，分离特征表示与交互结构。

Result: 学习到的超连接矩阵展现出连贯的空间模式和非对称交互行为，揭示了模型内部动态机制；增加扩展率能加速结构化交互模式的出现。

Conclusion: ES-mHC将高光谱图像分类从纯粹的黑盒预测任务转变为结构透明、部分白盒的学习过程，提供了机制性洞察。

Abstract: In hyperspectral image classification (HSIC), most deep learning models rely on opaque spectral-spatial feature mixing, limiting their interpretability and hindering understanding of internal decision mechanisms. We present physical spectrum-aware white-box mHC, named ES-mHC, a hyper-connection framework that explicitly models interactions among different electromagnetic spectrum groupings (residual stream in mHC) interactions using structured, directional matrices. By separating feature representation from interaction structure, ES-mHC promotes electromagnetic spectrum grouping specialization, reduces redundancy, and exposes internal information flow that can be directly visualized and spatially analyzed. Using hyperspectral image classification as a representative testbed, we demonstrate that the learned hyper-connection matrices exhibit coherent spatial patterns and asymmetric interaction behaviors, providing mechanistic insight into the model internal dynamics. Furthermore, we find that increasing the expansion rate accelerates the emergence of structured interaction patterns. These results suggest that ES-mHC transforms HSIC from a purely black-box prediction task into a structurally transparent, partially white-box learning process.

</details>


### [30] [Atlas-Assisted Segment Anything Model for Fetal Brain MRI (FeTal-SAM)](https://arxiv.org/abs/2601.15759)
*Qi Zeng,Weide Liu,Bo Li,Ryne Didier,P. Ellen Grant,Davood Karimi*

Main category: cs.CV

TL;DR: FeTal-SAM通过整合基于图谱的提示和基础模型原理，为胎儿脑MRI分割提供了一种灵活的方法，无需为不同标签定义重新训练模型，同时能区分图像对比度与空间先验的影响。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法需要大量标注数据且针对固定标签集，当临床或研究需求变化时缺乏灵活性。此外，现有方法无法区分分割结果是由真实图像对比度驱动还是由学习的空间先验驱动。

Method: 结合多图谱配准生成空间对齐的标签模板作为密集提示，配合边界框提示，输入到SAM分割解码器。通过逐结构进行二值分割，最后融合重建完整的3D分割体积。

Result: 在两个数据集（dHCP和内部数据集）上评估，对于对比度良好的结构（如皮质板和小脑），Dice分数与针对特定数据集和标签定义训练的最先进基线相当。对于低对比度结构（如海马、杏仁核）精度稍低，但保持了分割任意用户指定解剖结构的能力。

Conclusion: FeTal-SAM展示了作为通用分割模型的潜力，无需大量重新训练即可适应临床需求变化，是迈向临床适应性胎儿脑MRI分析工具的有希望的一步。

Abstract: This paper presents FeTal-SAM, a novel adaptation of the Segment Anything Model (SAM) tailored for fetal brain MRI segmentation. Traditional deep learning methods often require large annotated datasets for a fixed set of labels, making them inflexible when clinical or research needs change. By integrating atlas-based prompts and foundation-model principles, FeTal-SAM addresses two key limitations in fetal brain MRI segmentation: (1) the need to retrain models for varying label definitions, and (2) the lack of insight into whether segmentations are driven by genuine image contrast or by learned spatial priors. We leverage multi-atlas registration to generate spatially aligned label templates that serve as dense prompts, alongside a bounding-box prompt, for SAM's segmentation decoder. This strategy enables binary segmentation on a per-structure basis, which is subsequently fused to reconstruct the full 3D segmentation volumes. Evaluations on two datasets, the dHCP dataset and an in-house dataset demonstrate FeTal-SAM's robust performance across gestational ages. Notably, it achieves Dice scores comparable to state-of-the-art baselines which were trained for each dataset and label definition for well-contrasted structures like cortical plate and cerebellum, while maintaining the flexibility to segment any user-specified anatomy. Although slightly lower accuracy is observed for subtle, low-contrast structures (e.g., hippocampus, amygdala), our results highlight FeTal-SAM's potential to serve as a general-purpose segmentation model without exhaustive retraining. This method thus constitutes a promising step toward clinically adaptable fetal brain MRI analysis tools.

</details>


### [31] [LL-GaussianMap: Zero-shot Low-Light Image Enhancement via 2D Gaussian Splatting Guided Gain Maps](https://arxiv.org/abs/2601.15766)
*Yuhan Chen,Ying Fang,Guofa Li,Wenxuan Yu,Yicui Shi,Jingrui Zhang,Kefei Qian,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: 本文提出了LL-GaussianMap，这是首个将2D高斯泼溅(2DGS)技术应用于低光照图像增强的无监督框架，通过将增强任务转化为由2DGS基元引导的增益图生成过程，实现了高质量的结构感知增强。


<details>
  <summary>Details</summary>
Motivation: 现有低光照图像增强方法大多在像素域操作或依赖隐式特征表示，忽略了图像内在的几何结构先验。2DGS作为一种显式场景表示技术，具有出色的结构拟合能力和高渲染效率，但在低层视觉任务中尚未被探索。

Method: 提出两阶段框架：1) 使用2DGS进行高保真结构重建；2) 通过创新的统一增强模块，利用高斯泼溅的光栅化机制渲染数据驱动的增强字典系数，生成增益图。采用无监督学习避免对配对数据的依赖。

Result: 实验结果表明，LL-GaussianMap在极低的存储占用下实现了优异的增强性能，验证了显式高斯表示在图像增强中的有效性。

Conclusion: 该研究首次将2DGS成功应用于低光照图像增强任务，通过将增强任务转化为增益图生成过程，有效结合了2DGS的结构感知能力，在保持边缘、抑制伪影方面表现出色，同时避免了配对数据依赖。

Abstract: Significant progress has been made in low-light image enhancement with respect to visual quality. However, most existing methods primarily operate in the pixel domain or rely on implicit feature representations. As a result, the intrinsic geometric structural priors of images are often neglected. 2D Gaussian Splatting (2DGS) has emerged as a prominent explicit scene representation technique characterized by superior structural fitting capabilities and high rendering efficiency. Despite these advantages, the utilization of 2DGS in low-level vision tasks remains unexplored. To bridge this gap, LL-GaussianMap is proposed as the first unsupervised framework incorporating 2DGS into low-light image enhancement. Distinct from conventional methodologies, the enhancement task is formulated as a gain map generation process guided by 2DGS primitives. The proposed method comprises two primary stages. First, high-fidelity structural reconstruction is executed utilizing 2DGS. Then, data-driven enhancement dictionary coefficients are rendered via the rasterization mechanism of Gaussian splatting through an innovative unified enhancement module. This design effectively incorporates the structural perception capabilities of 2DGS into gain map generation, thereby preserving edges and suppressing artifacts during enhancement. Additionally, the reliance on paired data is circumvented through unsupervised learning. Experimental results demonstrate that LL-GaussianMap achieves superior enhancement performance with an extremely low storage footprint, highlighting the effectiveness of explicit Gaussian representations for image enhancement.

</details>


### [32] [LL-GaussianImage: Efficient Image Representation for Zero-shot Low-Light Enhancement with 2D Gaussian Splatting](https://arxiv.org/abs/2601.15772)
*Yuhan Chen,Wenxuan Yu,Guofa Li,Yijun Xu,Ying Fang,Yicui Shi,Long Cao,Wenbo Chu,Keqiang Li*

Main category: cs.CV

TL;DR: 首个在2D高斯泼溅压缩表示域进行零样本无监督低光增强的框架，避免了传统解压-增强-再压缩流程的低效和二次退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有低光增强算法主要在像素域操作，处理2DGS压缩图像需要繁琐的解压-增强-再压缩流程，效率低下且会造成二次质量损失。

Method: 提出LL-GaussianImage框架：1）语义引导的专家混合增强框架，在2DGS稀疏属性空间应用动态自适应变换；2）多目标协作损失函数系统约束平滑性和保真度；3）两阶段优化过程确保基础表示精度和网络鲁棒性。

Result: 实现了在保持高压缩比的同时对低光图像进行高质量增强，验证了在压缩表示域直接处理范式的可行性和优越性。

Conclusion: 该研究首次实现了在2DGS压缩表示域进行零样本无监督低光增强，为压缩域图像处理提供了新范式，具有高效、高质量的优势。

Abstract: 2D Gaussian Splatting (2DGS) is an emerging explicit scene representation method with significant potential for image compression due to high fidelity and high compression ratios. However, existing low-light enhancement algorithms operate predominantly within the pixel domain. Processing 2DGS-compressed images necessitates a cumbersome decompression-enhancement-recompression pipeline, which compromises efficiency and introduces secondary degradation. To address these limitations, we propose LL-GaussianImage, the first zero-shot unsupervised framework designed for low-light enhancement directly within the 2DGS compressed representation domain. Three primary advantages are offered by this framework. First, a semantic-guided Mixture-of-Experts enhancement framework is designed. Dynamic adaptive transformations are applied to the sparse attribute space of 2DGS using rendered images as guidance to enable compression-as-enhancement without full decompression to a pixel grid. Second, a multi-objective collaborative loss function system is established to strictly constrain smoothness and fidelity during enhancement, suppressing artifacts while improving visual quality. Third, a two-stage optimization process is utilized to achieve reconstruction-as-enhancement. The accuracy of the base representation is ensured through single-scale reconstruction and network robustness is enhanced. High-quality enhancement of low-light images is achieved while high compression ratios are maintained. The feasibility and superiority of the paradigm for direct processing within the compressed representation domain are validated through experimental results.

</details>


### [33] [Diffusion Model-Based Data Augmentation for Enhanced Neuron Segmentation](https://arxiv.org/abs/2601.15779)
*Liuyun Jiang,Yanchao Zhang,Jinyue Guo,Yizhuo Lu,Ruining Zhou,Hua Han*

Main category: cs.CV

TL;DR: 提出基于扩散模型的神经元分割数据增强框架，在低标注数据情况下显著提升分割性能


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的神经元分割方法需要大量手动标注数据，传统数据增强方法生成的样本与原图像高度相关且缺乏结构多样性

Method: 采用分辨率感知的条件扩散模型，结合多尺度条件和电子显微镜分辨率先验，从3D掩码合成体素级图像；引入生物学引导的掩码重塑模块增强结构真实性

Result: 在AC3和AC4数据集上，结合两种不同后处理方法，ARAND指标分别提升32.1%和30.7%

Conclusion: 提出的扩散数据增强框架能生成多样且结构合理的图像-标签对，有效丰富训练集并提升神经元分割性能

Abstract: Neuron segmentation in electron microscopy (EM) aims to reconstruct the complete neuronal connectome; however, current deep learning-based methods are limited by their reliance on large-scale training data and extensive, time-consuming manual annotations. Traditional methods augment the training set through geometric and photometric transformations; however, the generated samples remain highly correlated with the original images and lack structural diversity. To address this limitation, we propose a diffusion-based data augmentation framework capable of generating diverse and structurally plausible image-label pairs for neuron segmentation. Specifically, the framework employs a resolution-aware conditional diffusion model with multi-scale conditioning and EM resolution priors to enable voxel-level image synthesis from 3D masks. It further incorporates a biology-guided mask remodeling module that produces augmented masks with enhanced structural realism. Together, these components effectively enrich the training set and improve segmentation performance. On the AC3 and AC4 datasets under low-annotation regimes, our method improves the ARAND metric by 32.1% and 30.7%, respectively, when combined with two different post-processing methods. Our code is available at https://github.com/HeadLiuYun/NeuroDiff.

</details>


### [34] [Assessing Situational and Spatial Awareness of VLMs with Synthetically Generated Video](https://arxiv.org/abs/2601.15780)
*Pascal Benschop,Justin Dauwels,Jan van Gemert*

Main category: cs.CV

TL;DR: 论文提出了一个评估视觉语言模型空间推理能力的合成基准，测试情境感知和空间感知两个互补技能，结果显示现有模型表现仅略高于随机猜测。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在涉及微妙时空或几何线索的语义理解上仍然脆弱，需要专门评估其空间推理能力。

Method: 设计了一个合成基准，通过最小视频对测试三个挑战：区分暴力与良性活动、跨视角绑定攻击者角色、判断细粒度轨迹对齐。

Result: 在训练免费设置下评估近期VLMs，结果显示各项任务性能仅略高于随机猜测。简单的稳定颜色线索部分减少了攻击者角色混淆，但未能解决根本弱点。

Conclusion: 通过发布数据和代码，为空间推理提供可复现的诊断基准，并探索轻量级空间先验作为大规模预训练的补充。

Abstract: Spatial reasoning in vision language models (VLMs) remains fragile when semantics hinge on subtle temporal or geometric cues. We introduce a synthetic benchmark that probes two complementary skills: situational awareness (recognizing whether an interaction is harmful or benign) and spatial awareness (tracking who does what to whom, and reasoning about relative positions and motion). Through minimal video pairs, we test three challenges: distinguishing violence from benign activity, binding assailant roles across viewpoints, and judging fine-grained trajectory alignment. While we evaluate recent VLMs in a training-free setting, the benchmark is applicable to any video classification model. Results show performance only slightly above chance across tasks. A simple aid, stable color cues, partly reduces assailant role confusions but does not resolve the underlying weakness. By releasing data and code, we aim to provide reproducible diagnostics and seed exploration of lightweight spatial priors to complement large-scale pretraining.

</details>


### [35] [A Mobile Application for Flower Recognition System Based on Convolutional Neural Networks](https://arxiv.org/abs/2601.15810)
*Mustafa Yurdakul,Enes Ayan,Fahrettin Horasan,Sakir Tasdemir*

Main category: cs.CV

TL;DR: 基于CNN的移动应用用于花卉识别，DenseNet-121+SGD模型表现最佳，准确率达95.84%


<details>
  <summary>Details</summary>
Motivation: 花卉识别需要专业知识，但专家并不总是可及。开发基于CNN的移动应用，为非专业人士提供快速便捷的花卉识别服务。

Method: 开发移动应用，使用三种CNN模型（MobileNet、DenseNet121、Xception）进行花卉分类，每种模型用七种优化算法训练评估。

Result: DenseNet-121架构结合SGD优化算法表现最佳，准确率95.84%，精确率、召回率和F1分数均为96.00%。

Conclusion: CNN可用于移动应用中的花卉分类，DenseNet-121+SGD是最有效的模型组合。

Abstract: A convolutional neural network (CNN) is a deep learning algorithm that has been specifically designed for computer vision applications. The CNNs proved successful in handling the increasing amount of data in many computer vision problems, where classical machine learning algorithms were insufficient. Flowers have many uses in our daily lives, from decorating to making medicines to detoxifying the environment. Identifying flower types requires expert knowledge. However, accessing experts at any time and in any location may not always be feasible. In this study a mobile application based on CNNs was developed to recognize different types of flowers to provide non-specialists with quick and easy access to information about flower types. The study employed three distinct CNN models, namely MobileNet, DenseNet121, and Xception, to determine the most suitable model for the mobile application. The classification performances of the models were evaluated by training them with seven different optimization algorithms. The DenseNet-121 architecture, which uses the stochastic gradient descent (SGD) optimization algorithm, was the most successful, achieving 95.84 % accuracy, 96.00% precision, recall, and F1-score. This result shows that CNNs can be used for flower classification in mobile applications.

</details>


### [36] [Beyond Off-the-Shelf Models: A Lightweight and Accessible Machine Learning Pipeline for Ecologists Working with Image Data](https://arxiv.org/abs/2601.15813)
*Clare Chemery,Hendrik Edelhoff,Ludwig Bothmann*

Main category: cs.CV

TL;DR: 本文介绍了一个轻量级实验流程，旨在降低生态研究中应用机器学习进行图像分类的门槛，让生态学家能够独立构建针对特定任务的分类器。


<details>
  <summary>Details</summary>
Motivation: 生态研究需要针对本地数据集和特定分类任务的机器学习模型，但现有现成模型无法满足这些需求。生态学家通常缺乏高级机器学习专业知识，需要更易用的工具来独立实验和定制模型。

Method: 开发了一个结合命令行界面（用于预处理、训练和评估）和图形界面（用于标注、错误分析和模型比较）的工具。作为概念验证，使用德国Veldenstein森林收集的3392张相机陷阱图像，通过4352张专家标注的裁剪图像，训练和评估了多种骨干架构、参数和数据增强策略。

Result: 最佳模型在年龄分类上达到90.77%准确率，在性别分类上达到96.15%准确率。证明了即使数据有限，也能实现可靠的种群统计分类，用于解决明确、具体的生态问题。

Conclusion: 该框架为生态学家提供了开发针对特定研究问题的机器学习模型的可访问工具，促进了机器学习在野生动物监测和种群分析中的更广泛采用。

Abstract: We introduce a lightweight experimentation pipeline designed to lower the barrier for applying machine learning (ML) methods for classifying images in ecological research. We enable ecologists to experiment with ML models independently, thus they can move beyond off-the-shelf models and generate insights tailored to local datasets and specific classification tasks and target variables. Our tool combines a simple command-line interface for preprocessing, training, and evaluation with a graphical interface for annotation, error analysis, and model comparison. This design enables ecologists to build and iterate on compact, task-specific classifiers without requiring advanced ML expertise. As a proof of concept, we apply the pipeline to classify red deer (Cervus elaphus) by age and sex from 3392 camera trap images collected in the Veldenstein Forest, Germany. Using 4352 cropped images containing individual deer labeled by experts, we trained and evaluated multiple backbone architectures with a wide variety of parameters and data augmentation strategies. Our best-performing models achieved 90.77% accuracy for age classification and 96.15% for sex classification. These results demonstrate that reliable demographic classification is feasible even with limited data to answer narrow, well-defined ecological problems. More broadly, the framework provides ecologists with an accessible tool for developing ML models tailored to specific research questions, paving the way for broader adoption of ML in wildlife monitoring and demographic analysis.

</details>


### [37] [Towards Realistic Remote Sensing Dataset Distillation with Discriminative Prototype-guided Diffusion](https://arxiv.org/abs/2601.15829)
*Yonghao Xu,Pedram Ghamisi,Qihao Weng*

Main category: cs.CV

TL;DR: 首次将数据集蒸馏引入遥感图像解释领域，使用文本到图像扩散模型将大规模遥感数据集压缩成紧凑的蒸馏数据集，通过分类器驱动指导和视觉风格指导提升合成样本质量。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感图像解释中依赖大规模训练数据带来两大挑战：(1)高存储和计算成本，(2)数据泄露风险（尤其涉及敏感类别）。需要找到一种方法既能保留数据集代表性又能大幅减少数据量。

Method: 1. 使用文本到图像扩散模型压缩大规模遥感数据集；2. 提出分类器驱动指导，通过预训练模型的分类一致性损失指导扩散训练；3. 考虑遥感图像语义复杂性，进行潜在空间聚类选择代表性原型作为视觉风格指导；4. 使用视觉语言模型提供聚合文本描述。

Result: 在三个高分辨率遥感场景分类基准测试中，该方法能够为下游模型训练蒸馏出真实且多样的样本。代码和预训练模型已在线公开。

Conclusion: 首次将数据集蒸馏引入遥感图像解释，提出的方法能有效压缩大规模遥感数据集，在保持样本真实性和多样性的同时降低存储计算成本和数据泄露风险，为遥感领域提供了新的数据高效学习途径。

Abstract: Recent years have witnessed the remarkable success of deep learning in remote sensing image interpretation, driven by the availability of large-scale benchmark datasets. However, this reliance on massive training data also brings two major challenges: (1) high storage and computational costs, and (2) the risk of data leakage, especially when sensitive categories are involved. To address these challenges, this study introduces the concept of dataset distillation into the field of remote sensing image interpretation for the first time. Specifically, we train a text-to-image diffusion model to condense a large-scale remote sensing dataset into a compact and representative distilled dataset. To improve the discriminative quality of the synthesized samples, we propose a classifier-driven guidance by injecting a classification consistency loss from a pre-trained model into the diffusion training process. Besides, considering the rich semantic complexity of remote sensing imagery, we further perform latent space clustering on training samples to select representative and diverse prototypes as visual style guidance, while using a visual language model to provide aggregated text descriptions. Experiments on three high-resolution remote sensing scene classification benchmarks show that the proposed method can distill realistic and diverse samples for downstream model training. Code and pre-trained models are available online (https://github.com/YonghaoXu/DPD).

</details>


### [38] [An IoT-Based Smart Plant Monitoring and Irrigation System with Real-Time Environmental Sensing, Automated Alerts, and Cloud Analytics](https://arxiv.org/abs/2601.15830)
*Abdul Hasib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 基于ESP32微控制器的智能植物监测系统，集成多种环境传感器和自动灌溉，通过云平台实现远程监控，降低40%用水量，成本仅45.20美元。


<details>
  <summary>Details</summary>
Motivation: 传统农业依赖人工观察和定期浇水，导致水资源浪费、植物生长不一致，且对环境变化响应延迟。可持续农业需要智能监测系统来优化资源利用和植物健康管理。

Method: 使用ESP32微控制器集成DHT22温湿度传感器、HC-SR04水位传感器和土壤湿度传感器，通过OLED显示屏提供视觉反馈，蜂鸣器提供听觉警报。所有传感器数据无线传输到ThingSpeak云平台进行远程监控、历史分析和自动警报生成。

Result: 系统在维持最佳土壤湿度水平方面达到92%准确率，提供实时环境监测，相比传统灌溉方法减少约40%的用水量。集成的网络仪表板可全面可视化植物健康参数，总实施成本为45.20美元。

Conclusion: 该系统为精准农业和智能农业提供了经济实惠、可扩展的解决方案，适用于小规模园艺和商业农业应用，有效促进可持续农业发展。

Abstract: The increasing global demand for sustainable agriculture necessitates intelligent monitoring systems that optimize resource utilization and plant health management. Traditional farming methods rely on manual observation and periodic watering, often leading to water wastage, inconsistent plant growth, and delayed response to environmental changes. This paper presents a comprehensive IoT-based smart plant monitoring system that integrates multiple environmental sensors with automated irrigation and cloud analytics. The proposed system utilizes an ESP32 microcontroller to collect real-time data from DHT22 (temperature/humidity), HC-SR04 (water level), and soil moisture sensors, with visual feedback through an OLED display and auditory alerts via a buzzer. All sensor data is wirelessly transmitted to the ThingSpeak cloud platform for remote monitoring, historical analysis, and automated alert generation. Experimental results demonstrate the system's effectiveness in maintaining optimal soil moisture levels (with 92\% accuracy), providing real-time environmental monitoring, and reducing water consumption by approximately 40\% compared to conventional irrigation methods. The integrated web dashboard offers comprehensive visualization of plant health parameters, making it suitable for both small-scale gardening and commercial agriculture applications. With a total implementation cost of \$45.20, this system provides an affordable, scalable solution for precision agriculture and smart farming.

</details>


### [39] [TinySense: Effective CSI Compression for Scalable and Accurate Wi-Fi Sensing](https://arxiv.org/abs/2601.15838)
*Toan Gian,Dung T. Tran,Viet Quoc Pham,Francesco Restuccia,Van-Dinh Nguyen*

Main category: cs.CV

TL;DR: TinySense是一个基于VQGAN的Wi-Fi CSI数据压缩框架，通过动态码本压缩和Transformer增强，在保持人体姿态估计精度的同时显著降低网络开销和延迟。


<details>
  <summary>Details</summary>
Motivation: 随着对无设备、隐私保护感知解决方案的需求增长，Wi-Fi感知成为人体姿态估计的有前景方法。但现有方法直接处理大量CSI数据，给网络资源带来压力，需要提高Wi-Fi感知的可扩展性。

Method: 提出TinySense压缩框架：1）使用VQGAN学习码本压缩CSI数据；2）采用K-means算法动态调整压缩比特率，将大规模预训练码本聚类为更小子集；3）结合Transformer模型减轻比特率损失，增强不可靠网络条件下的鲁棒性。

Result: 在Jetson Nano和Raspberry Pi实验平台上验证，TinySense显著优于现有压缩方案：在相同压缩率下达到1.5倍更高的HPE准确率（PCK20），延迟降低5倍，网络开销减少2.5倍。

Conclusion: TinySense通过高效的VQGAN压缩框架解决了Wi-Fi感知中的网络资源瓶颈问题，在保持感知精度的同时大幅提升了系统可扩展性，为实际部署提供了可行方案。

Abstract: With the growing demand for device-free and privacy-preserving sensing solutions, Wi-Fi sensing has emerged as a promising approach for human pose estimation (HPE). However, existing methods often process vast amounts of channel state information (CSI) data directly, ultimately straining networking resources. This paper introduces TinySense, an efficient compression framework that enhances the scalability of Wi-Fi-based human sensing. Our approach is based on a new vector quantization-based generative adversarial network (VQGAN). Specifically, by leveraging a VQGAN-learned codebook, TinySense significantly reduces CSI data while maintaining the accuracy required for reliable HPE. To optimize compression, we employ the K-means algorithm to dynamically adjust compression bitrates to cluster a large-scale pre-trained codebook into smaller subsets. Furthermore, a Transformer model is incorporated to mitigate bitrate loss, enhancing robustness in unreliable networking conditions. We prototype TinySense on an experimental testbed using Jetson Nano and Raspberry Pi to measure latency and network resource use. Extensive results demonstrate that TinySense significantly outperforms state-of-the-art compression schemes, achieving up to 1.5x higher HPE accuracy score (PCK20) under the same compression rate. It also reduces latency and networking overhead, respectively, by up to 5x and 2.5x. The code repository is available online at here.

</details>


### [40] [A Lightweight Brain-Inspired Machine Learning Framework for Coronary Angiography: Hybrid Neural Representation and Robust Learning Strategies](https://arxiv.org/abs/2601.15865)
*Jingsong Xia,Siqi Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种轻量级脑启发式深度学习框架，用于在计算资源受限的临床环境中实现稳健的冠状动脉造影图像分类。


<details>
  <summary>Details</summary>
Motivation: 真实临床环境中的冠状动脉造影图像存在复杂病变形态、严重类别不平衡、标签不确定性以及计算资源有限等挑战，传统深度学习方法在鲁棒性和泛化性方面面临困难。

Method: 基于预训练CNN构建轻量级混合神经表示，采用选择性神经可塑性训练策略，结合脑启发的注意力调制损失函数（Focal Loss + 标签平滑），使用类别不平衡感知采样和余弦退火热重启来模拟生物神经系统的节律调控和注意力分配机制。

Result: 提出的轻量级脑启发模型在二元冠状动脉造影分类中实现了强大且稳定的性能，获得了有竞争力的准确率、召回率、F1分数和AUC指标，同时保持了高计算效率。

Conclusion: 该研究验证了脑启发学习机制在轻量级医学图像分析中的有效性，为计算资源受限环境下的智能临床决策支持提供了生物学合理且可部署的解决方案。

Abstract: Background: Coronary angiography (CAG) is a cornerstone imaging modality for assessing coronary artery disease and guiding interventional treatment decisions. However, in real-world clinical settings, angiographic images are often characterized by complex lesion morphology, severe class imbalance, label uncertainty, and limited computational resources, posing substantial challenges to conventional deep learning approaches in terms of robustness and generalization.Methods: The proposed framework is built upon a pretrained convolutional neural network to construct a lightweight hybrid neural representation. A selective neural plasticity training strategy is introduced to enable efficient parameter adaptation. Furthermore, a brain-inspired attention-modulated loss function, combining Focal Loss with label smoothing, is employed to enhance sensitivity to hard samples and uncertain annotations. Class-imbalance-aware sampling and cosine annealing with warm restarts are adopted to mimic rhythmic regulation and attention allocation mechanisms observed in biological neural systems.Results: Experimental results demonstrate that the proposed lightweight brain-inspired model achieves strong and stable performance in binary coronary angiography classification, yielding competitive accuracy, recall, F1-score, and AUC metrics while maintaining high computational efficiency.Conclusion: This study validates the effectiveness of brain-inspired learning mechanisms in lightweight medical image analysis and provides a biologically plausible and deployable solution for intelligent clinical decision support under limited computational resources.

</details>


### [41] [Out-of-Distribution Detection Based on Total Variation Estimation](https://arxiv.org/abs/2601.15867)
*Dabiao Ma,Zhiba Su,Jian Yang,Haojun Fei*

Main category: cs.CV

TL;DR: TV-OOD是一种基于总变分网络估计器的新型OOD检测方法，通过计算输入对整体总变分的贡献来区分分布内外数据，在图像分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法虽然取得了一定成果，但在实际应用中面对分布漂移时仍需要更可靠的检测方法。TV-OOD旨在通过更精确地量化输入数据对模型分布变化的贡献，提高OOD检测的准确性和鲁棒性。

Method: TV-OOD利用总变分网络估计器计算每个输入对整体总变分的贡献，将其定义为总变分分数。通过这个分数来区分分布内和分布外数据，实现对OOD样本的有效检测。

Result: 该方法在多种模型和数据集上进行了测试，在图像分类任务中，TV-OOD在所有评估指标上都达到了与最先进的OOD检测技术相当或更优的性能。

Conclusion: TV-OOD方法为机器学习模型部署中的分布漂移问题提供了一种有效的解决方案，通过总变分分数机制实现了对OOD数据的高效检测，具有实际应用价值。

Abstract: This paper introduces a novel approach to securing machine learning model deployments against potential distribution shifts in practical applications, the Total Variation Out-of-Distribution (TV-OOD) detection method. Existing methods have produced satisfactory results, but TV-OOD improves upon these by leveraging the Total Variation Network Estimator to calculate each input's contribution to the overall total variation. By defining this as the total variation score, TV-OOD discriminates between in- and out-of-distribution data. The method's efficacy was tested across a range of models and datasets, consistently yielding results in image classification tasks that were either comparable or superior to those achieved by leading-edge out-of-distribution detection techniques across all evaluation metrics.

</details>


### [42] [PMPBench: A Paired Multi-Modal Pan-Cancer Benchmark for Medical Image Synthesis](https://arxiv.org/abs/2601.15884)
*Yifan Chen,Fei Yin,Hao Chen,Jia Wu,Chao Li*

Main category: cs.CV

TL;DR: 该论文提出了首个公开的、完全配对的、涵盖11个人体器官的泛癌症医学影像数据集，包含完整的DCE序列和CT对比度增强采集，并建立了全面的基准测试，以推动对比度增强图像合成研究。


<details>
  <summary>Details</summary>
Motivation: 目前对比度增强剂在影像诊断中至关重要，但并非所有患者都适用。现有AI图像翻译方法受限于数据不足：公共数据集主要集中在脑部MR、数据配对不完整、标签缺失、大量资源私有化。需要高质量数据集来推动安全有效的对比度增强合成研究。

Method: 创建了PMPBench数据集，包含11个人体器官的完全配对医学影像数据：MR数据包括完整的动态对比度增强序列（DCE1-DCE3），CT数据提供配对的非对比度和对比度增强采集。数据经过解剖对应性筛选，支持1对1、N对1、N对N等多种翻译场景评估。

Result: 建立了首个公开的泛癌症医学影像数据集和基准测试，报告了当代图像到图像翻译代表性基线的结果。该资源能够催化对比度增强合成研究，直接应用于多器官肿瘤影像工作流程。

Conclusion: 通过提供高质量、完全配对的医学影像数据集和基准测试，填补了现有研究空白，将推动AI在医学影像对比度增强合成方面的发展，减少患者对对比度增强剂的依赖，优化临床工作流程。

Abstract: Contrast medium plays a pivotal role in radiological imaging, as it amplifies lesion conspicuity and improves detection for the diagnosis of tumor-related diseases. However, depending on the patient's health condition or the medical resources available, the use of contrast medium is not always feasible. Recent work has explored AI-based image translation to synthesize contrast-enhanced images directly from non-contrast scans, aims to reduce side effects and streamlines clinical workflows. Progress in this direction has been constrained by data limitations: (1) existing public datasets focus almost exclusively on brain-related paired MR modalities; (2) other collections include partially paired data but suffer from missing modalities/timestamps and imperfect spatial alignment; (3) explicit labeling of CT vs. CTC or DCE phases is often absent; (4) substantial resources remain private. To bridge this gap, we introduce the first public, fully paired, pan-cancer medical imaging dataset spanning 11 human organs. The MR data include complete dynamic contrast-enhanced (DCE) sequences covering all three phases (DCE1-DCE3), while the CT data provide paired non-contrast and contrast-enhanced acquisitions (CTC). The dataset is curated for anatomical correspondence, enabling rigorous evaluation of 1-to-1, N-to-1, and N-to-N translation settings (e.g., predicting DCE phases from non-contrast inputs). Built upon this resource, we establish a comprehensive benchmark. We report results from representative baselines of contemporary image-to-image translation. We release the dataset and benchmark to catalyze research on safe, effective contrast synthesis, with direct relevance to multi-organ oncology imaging workflows. Our code and dataset are publicly available at https://github.com/YifanChen02/PMPBench.

</details>


### [43] [Understanding the Transfer Limits of Vision Foundation Models](https://arxiv.org/abs/2601.15888)
*Shiqi Huang,Yipei Wang,Natasha Thorley,Alexander Ng,Shaheer Saeed,Mark Emberton,Shonit Punwani,Veeru Kasivisvanathan,Dean Barratt,Daniel Alexander,Yipeng Hu*

Main category: cs.CV

TL;DR: 该研究发现视觉基础模型在下游任务中的表现不均衡主要源于预训练目标与下游任务需求的不匹配。通过评估两种视觉基础模型在五个前列腺多参数MRI任务上的表现，发现预训练与下游任务对齐度越高（用MMD等指标衡量），性能提升越大，收敛越快。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型虽然投入了大量计算资源，但在下游视觉任务中表现不均衡。作者认为这源于预训练目标（如掩码图像重建或对比学习）与下游任务需求（如分割、分类、图像合成）之间的不匹配。为了在具体临床领域验证这一假设，研究选择前列腺多参数MRI作为测试场景。

Method: 评估了两种视觉基础模型：基于MAE的重建模型ProFound和基于对比学习的模型ProViCNet。在五个前列腺多参数MRI任务上进行测试，使用最大均值差异（MMD）等简单发散度量来衡量预训练与下游任务的对齐度，分析这种对齐如何影响迁移性能。

Result: 研究发现预训练与下游任务对齐度越高，模型性能提升越大，收敛速度越快。通过MMD等指标可以有效地衡量这种对齐关系，为设计更具下游任务适用性的预训练目标提供了依据。

Conclusion: 视觉基础模型的预训练目标应与下游任务需求更好对齐。简单的发散度量如MMD可以有效衡量这种对齐关系，指导预训练策略的设计，从而提高模型在下游任务中的表现和收敛效率。

Abstract: Foundation models leverage large-scale pretraining to capture extensive knowledge, demonstrating generalization in a wide range of language tasks. By comparison, vision foundation models (VFMs) often exhibit uneven improvements across downstream tasks, despite substantial computational investment. We postulate that this limitation arises from a mismatch between pretraining objectives and the demands of downstream vision-and-imaging tasks. Pretraining strategies like masked image reconstruction or contrastive learning shape representations for tasks such as recovery of generic visual patterns or global semantic structures, which may not align with the task-specific requirements of downstream applications including segmentation, classification, or image synthesis. To investigate this in a concrete real-world clinical area, we assess two VFMs, a reconstruction-focused MAE-based model (ProFound) and a contrastive-learning-based model (ProViCNet), on five prostate multiparametric MR imaging tasks, examining how such task alignment influences transfer performance, i.e., from pretraining to fine-tuning. Our findings indicate that better alignment between pretraining and downstream tasks, measured by simple divergence metrics such as maximum-mean-discrepancy (MMD) between the same features before and after fine-tuning, correlates with greater performance improvements and faster convergence, emphasizing the importance of designing and analyzing pretraining objectives with downstream applicability in mind.

</details>


### [44] [RadJEPA: Radiology Encoder for Chest X-Rays via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2601.15891)
*Anas Anwarul Haq Khan,Mariam Husain,Kshitij Jadhav*

Main category: cs.CV

TL;DR: RadJEPA是一种自监督学习框架，无需语言监督，仅使用未标注的胸部X光图像进行预训练，通过预测掩码图像区域的潜在表示来学习医学视觉表示。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉语言模型依赖于配对的图像-文本数据进行监督学习，但这种数据获取受限。本文探索是否可以在不依赖语言监督的情况下学习稳健的放射学编码器。

Method: 提出RadJEPA框架，基于联合嵌入预测架构(JEPA)，通过自监督方式学习。模型仅使用未标注的胸部X光图像进行预训练，学习预测被掩码图像区域的潜在表示，而不是像DINO那样对齐全局表示。

Result: RadJEPA在疾病分类、语义分割和报告生成任务上均取得优异表现，性能超越了包括Rad-DINO在内的现有最先进方法。

Conclusion: 研究表明，无需语言监督，仅通过自监督学习就能获得强大的放射学编码器，RadJEPA框架在多种医学视觉任务上表现出色，为医学图像分析提供了新的有效方法。

Abstract: Recent advances in medical vision language models guide the learning of visual representations; however, this form of supervision is constrained by the availability of paired image text data, raising the question of whether robust radiology encoders can be learned without relying on language supervision. In this work, we introduce RadJEPA, a self-supervised framework built on a Joint Embedding Predictive Architecture that learns without language supervision. Pre-trained solely on unlabeled chest X-ray images, the model learns to predict latent representations of masked image regions. This predictive objective differs fundamentally from both image text pre-training and DINO-style self-distillation: rather than aligning global representations across views or modalities, RadJEPA explicitly models latent-space prediction. We evaluate the learned encoder on disease classification, semantic segmentation, and report generation tasks. Across benchmarks, RadJEPA achieves performance exceeding state-of-the-art approaches, including Rad-DINO.

</details>


### [45] [ThermoSplat: Cross-Modal 3D Gaussian Splatting with Feature Modulation and Geometry Decoupling](https://arxiv.org/abs/2601.15897)
*Zhaoqi Su,Shihai Chen,Xinyan Lin,Liqin Huang,Zhipeng Su,Xiaoqiang Lu*

Main category: cs.CV

TL;DR: ThermoSplat：首个通过主动特征调制和自适应几何解耦实现深度光谱感知重建的多模态3D高斯泼溅框架，在RGBT场景数据集上实现可见光和热红外光谱的最先进渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态3D高斯泼溅方法难以充分利用多模态数据的互补信息，通常要么忽略跨模态相关性，要么使用无法自适应处理光谱间复杂结构相关性和物理差异的共享表示。

Method: 1. 跨模态FiLM调制机制：利用热结构先验动态调节共享潜在特征，用可靠的跨模态几何线索指导可见纹理合成。2. 模态自适应几何解耦方案：学习独立的透明度偏移并为热分支执行独立光栅化。3. 混合渲染管道：结合显式球谐函数和隐式神经解码，确保语义一致性和高频细节保留。

Result: 在RGBT-Scenes数据集上的广泛实验表明，ThermoSplat在可见光和热红外光谱上都实现了最先进的渲染质量。

Conclusion: ThermoSplat通过创新的特征调制和几何解耦机制，成功解决了多模态3D高斯泼溅中的光谱感知重建挑战，为不同光照和天气条件下的鲁棒环境感知提供了有效解决方案。

Abstract: Multi-modal scene reconstruction integrating RGB and thermal infrared data is essential for robust environmental perception across diverse lighting and weather conditions. However, extending 3D Gaussian Splatting (3DGS) to multi-spectral scenarios remains challenging. Current approaches often struggle to fully leverage the complementary information of multi-modal data, typically relying on mechanisms that either tend to neglect cross-modal correlations or leverage shared representations that fail to adaptively handle the complex structural correlations and physical discrepancies between spectrums. To address these limitations, we propose ThermoSplat, a novel framework that enables deep spectral-aware reconstruction through active feature modulation and adaptive geometry decoupling. First, we introduce a Cross-Modal FiLM Modulation mechanism that dynamically conditions shared latent features on thermal structural priors, effectively guiding visible texture synthesis with reliable cross-modal geometric cues. Second, to accommodate modality-specific geometric inconsistencies, we propose a Modality-Adaptive Geometric Decoupling scheme that learns independent opacity offsets and executes an independent rasterization pass for the thermal branch. Additionally, a hybrid rendering pipeline is employed to integrate explicit Spherical Harmonics with implicit neural decoding, ensuring both semantic consistency and high-frequency detail preservation. Extensive experiments on the RGBT-Scenes dataset demonstrate that ThermoSplat achieves state-of-the-art rendering quality across both visible and thermal spectrums.

</details>


### [46] [Opening the Black Box: Preliminary Insights into Affective Modeling in Multimodal Foundation Models](https://arxiv.org/abs/2601.15906)
*Zhen Zhang,Runhao Zeng,Sicheng Zhao,Xiping Hu*

Main category: cs.CV

TL;DR: 研究发现多模态基础模型的情感能力主要由前馈门控机制（gate_proj）介导，而非注意力模块，仅需调整约24.5%的参数即可达到AffectGPT 96.6%的平均性能。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的情感模型在性能上表现优异，但大型基础模型中情感表征的具体位置和机制仍不清楚，尤其是多模态情感场景下的内部架构机制未被充分理解。

Method: 通过系统性的机制研究，分析多种架构、训练策略和情感任务下，情感导向的监督如何重塑模型内部参数。采用受控模块转移、针对性单模块适应和破坏性消融等方法进行验证。

Result: 研究揭示了一个清晰且稳健的模式：情感适应主要定位在前馈门控投影（gate_proj），而非注意力模块。gate_proj对于情感理解和生成是充分、高效且必要的。仅调整约24.5%的参数即可达到AffectGPT 96.6%的平均性能。

Conclusion: 基础模型的情感能力在结构上由前馈门控机制介导，gate_proj是情感建模的核心架构位置。这一发现为理解情感在多模态基础模型中的表征机制提供了实证证据。

Abstract: Understanding where and how emotions are represented in large-scale foundation models remains an open problem, particularly in multimodal affective settings. Despite the strong empirical performance of recent affective models, the internal architectural mechanisms that support affective understanding and generation are still poorly understood. In this work, we present a systematic mechanistic study of affective modeling in multimodal foundation models. Across multiple architectures, training strategies, and affective tasks, we analyze how emotion-oriented supervision reshapes internal model parameters. Our results consistently reveal a clear and robust pattern: affective adaptation does not primarily focus on the attention module, but instead localizes to the feed-forward gating projection (\texttt{gate\_proj}). Through controlled module transfer, targeted single-module adaptation, and destructive ablation, we further demonstrate that \texttt{gate\_proj} is sufficient, efficient, and necessary for affective understanding and generation. Notably, by tuning only approximately 24.5\% of the parameters tuned by AffectGPT, our approach achieves 96.6\% of its average performance across eight affective tasks, highlighting substantial parameter efficiency. Together, these findings provide empirical evidence that affective capabilities in foundation models are structurally mediated by feed-forward gating mechanisms and identify \texttt{gate\_proj} as a central architectural locus of affective modeling.

</details>


### [47] [The Latency Wall: Benchmarking Off-the-Shelf Emotion Recognition for Real-Time Virtual Avatars](https://arxiv.org/abs/2601.15914)
*Yarin Benyamin*

Main category: cs.CV

TL;DR: 在VR/HCI领域，实时情绪识别有望帮助自闭症谱系障碍患者改善社交技能，但需要严格的延迟-准确性权衡（MTP延迟需低于140ms）。研究评估了零样本面部表情识别模型在虚拟角色上的表现，发现虽然人脸检测在风格化虚拟形象上很鲁棒（100%准确率），但分类阶段存在"延迟墙"。YOLOv11n在检测阶段表现最佳（~54ms），而通用Transformer模型（CLIP、SigLIP）在实时循环中既无法达到可行准确率（<23%）也无法满足速度要求（>150ms）。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为自闭症谱系障碍（ASD）患者提供可访问的VR治疗，通过实时情绪识别改善其社交技能。由于VR环境需要严格的延迟约束（运动到光子延迟低于140ms以保持连续性），而现有深度学习模型通常优先考虑准确性而非硬件的时间限制，因此需要评估现有模型在满足实时性要求下的表现。

Method: 使用UIBVFED数据集对虚拟角色进行零样本面部表情识别（FER）的基准测试。评估了YOLO（v8、v11、v12）的中型和纳米变体用于人脸检测，以及通用视觉Transformer模型包括CLIP、SigLIP和ViT-FER。所有推理均在仅使用CPU的环境下进行，以模拟资源受限的消费级硬件条件。

Result: 人脸检测在风格化虚拟形象上表现出100%的准确率，但在分类阶段存在"延迟墙"。YOLOv11n架构在检测阶段提供了最佳平衡（约54ms延迟）。然而，通用Transformer模型如CLIP和SigLIP在实时循环中既无法达到可行准确率（<23%）也无法满足速度要求（>150ms延迟）。

Conclusion: 研究表明，通用视觉Transformer模型无法满足VR治疗环境中的实时性要求，需要开发轻量级、领域特定的架构来实现可访问的实时人工智能在治疗场景中的应用。YOLOv11n在检测阶段表现良好，但整体系统需要专门优化的分类模型来突破"延迟墙"。

Abstract: In the realm of Virtual Reality (VR) and Human-Computer Interaction (HCI), real-time emotion recognition shows promise for supporting individuals with Autism Spectrum Disorder (ASD) in improving social skills. This task requires a strict latency-accuracy trade-off, with motion-to-photon (MTP) latency kept below 140 ms to maintain contingency. However, most off-the-shelf Deep Learning models prioritize accuracy over the strict timing constraints of commodity hardware. As a first step toward accessible VR therapy, we benchmark State-of-the-Art (SOTA) models for Zero-Shot Facial Expression Recognition (FER) on virtual characters using the UIBVFED dataset. We evaluate Medium and Nano variants of YOLO (v8, v11, and v12) for face detection, alongside general-purpose Vision Transformers including CLIP, SigLIP, and ViT-FER.Our results on CPU-only inference demonstrate that while face detection on stylized avatars is robust (100% accuracy), a "Latency Wall" exists in the classification stage. The YOLOv11n architecture offers the optimal balance for detection (~54 ms). However, general-purpose Transformers like CLIP and SigLIP fail to achieve viable accuracy (<23%) or speed (>150 ms) for real-time loops. This study highlights the necessity for lightweight, domain-specific architectures to enable accessible, real-time AI in therapeutic settings.

</details>


### [48] [A Multi-View Pipeline and Benchmark Dataset for 3D Hand Pose Estimation in Surgery](https://arxiv.org/abs/2601.15918)
*Valery Fischer,Alan Magdaleno,Anna-Katharina Calek,Nicola Cavalcanti,Nathan Hoffman,Christoph Germann,Joschua Wüthrich,Max Krähenmann,Mazda Farshad,Philipp Fürnstahl,Lilian Calvet*

Main category: cs.CV

TL;DR: 提出无需领域微调的多视角3D手部姿态估计流程，适用于手术场景，并创建包含68,000帧的标注数据集，显著降低2D和3D误差。


<details>
  <summary>Details</summary>
Motivation: 手术场景中3D手部姿态估计对技能评估、机器人辅助干预等应用至关重要，但面临强烈光照、频繁遮挡、手套导致的统一外观以及标注数据稀缺等挑战。

Method: 提出基于现成预训练模型的多视角流程，包括可靠的人体检测、全身姿态估计、手部区域跟踪下的2D关键点预测，以及约束3D优化。同时创建包含68,000帧、3,000个手动标注2D手部姿态的手术基准数据集。

Result: 定量实验显示，该方法持续优于基线，2D平均关节误差降低31%，3D平均每关节位置误差降低76%。

Conclusion: 为手术场景的3D手部姿态估计建立了强基线，提供了无需训练的流程和全面的标注数据集，促进手术计算机视觉的后续研究。

Abstract: Purpose: Accurate 3D hand pose estimation supports surgical applications such as skill assessment, robot-assisted interventions, and geometry-aware workflow analysis. However, surgical environments pose severe challenges, including intense and localized lighting, frequent occlusions by instruments or staff, and uniform hand appearance due to gloves, combined with a scarcity of annotated datasets for reliable model training.
  Method: We propose a robust multi-view pipeline for 3D hand pose estimation in surgical contexts that requires no domain-specific fine-tuning and relies solely on off-the-shelf pretrained models. The pipeline integrates reliable person detection, whole-body pose estimation, and state-of-the-art 2D hand keypoint prediction on tracked hand crops, followed by a constrained 3D optimization. In addition, we introduce a novel surgical benchmark dataset comprising over 68,000 frames and 3,000 manually annotated 2D hand poses with triangulated 3D ground truth, recorded in a replica operating room under varying levels of scene complexity.
  Results: Quantitative experiments demonstrate that our method consistently outperforms baselines, achieving a 31% reduction in 2D mean joint error and a 76% reduction in 3D mean per-joint position error.
  Conclusion: Our work establishes a strong baseline for 3D hand pose estimation in surgery, providing both a training-free pipeline and a comprehensive annotated dataset to facilitate future research in surgical computer vision.

</details>


### [49] [Class Confidence Aware Reweighting for Long Tailed Learning](https://arxiv.org/abs/2601.15924)
*Brainard Philemon Jagati,Jitendra Tembhurne,Harsh Goud,Rudra Pratap Singh,Chandrashekhar Meshram*

Main category: cs.CV

TL;DR: 该论文提出了一种基于类别和置信度的重加权方案，用于解决长尾数据分布下的深度神经网络性能下降问题，该方法在损失级别进行调制，与现有的logit调整方法互补。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在长尾数据分布下性能显著下降，现有研究主要关注决策空间的调整（如logit级别修正来补偿类别先验偏差），而较少关注优化过程中样本间置信度差异带来的调整。需要一种更有效的重加权方案来改善长尾学习。

Method: 提出了一种类别和置信度感知的重加权方案，该方案纯粹基于损失级别，使用Ω(p_t, f_c)函数来调制对训练任务的贡献。该函数根据预测的置信度值以及对应类别的相对频率来调整权重，与现有的logit调整方法形成互补。

Result: 在CIFAR-100-LT、ImageNet-LT和iNaturalist2018数据集上进行了实验，在不同不平衡因子下均获得了显著的实验结果，验证了理论讨论的有效性。

Conclusion: 提出的类别和置信度感知重加权方案能够有效解决长尾学习问题，该方法在损失级别进行调制，与现有的logit调整方法形成互补，在多个基准数据集上表现出优越性能。

Abstract: Deep neural network models degrade significantly in the long-tailed data distribution, with the overall training data dominated by a small set of classes in the head, and the tail classes obtaining less training examples. Addressing the imbalance in the classes, attention in the related literature was given mainly to the adjustments carried out in the decision space in terms of either corrections performed at the logit level in order to compensate class-prior bias, with the least attention to the optimization process resulting from the adjustments introduced through the differences in the confidences among the samples. In the current study, we present the design of a class and confidence-aware re-weighting scheme for long-tailed learning. This scheme is purely based upon the loss level and has a complementary nature to the existing methods performing the adjustment of the logits. In the practical implementation stage of the proposed scheme, we use an Ω(p_t, f_c) function. This function enables the modulation of the contribution towards the training task based upon the confidence value of the prediction, as well as the relative frequency of the corresponding class. Our observations in the experiments are corroborated by significant experimental results performed on the CIFAR-100-LT, ImageNet-LT, and iNaturalist2018 datasets under various values of imbalance factors that clearly authenticate the theoretical discussions above.

</details>


### [50] [NeuroMamba: Multi-Perspective Feature Interaction with Visual Mamba for Neuron Segmentation](https://arxiv.org/abs/2601.15929)
*Liuyun Jiang,Yizhuo Lu,Yanchao Zhang,Jiazheng Liu,Hua Han*

Main category: cs.CV

TL;DR: 提出NeuroMamba框架，结合Mamba的线性复杂度进行全局建模和局部特征建模，解决神经元分割中边界模糊和细节丢失问题，在多个EM数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限：CNN缺乏长距离上下文导致边界模糊，Transformer因分块处理丢失体素级细节。需要同时解决全局依赖建模和细粒度细节保留的问题。

Method: 提出NeuroMamba多视角框架：1) BDFE通道门控边界判别特征提取器增强局部形态线索；2) SCFE空间连续特征提取器集成分辨率感知扫描机制，在Visual Mamba架构中自适应建模全局依赖；3) 跨调制机制协同融合多视角特征。

Result: 在四个公共EM数据集上实现最先进性能，验证了方法对各项同性和各向异性分辨率的优异适应性。

Conclusion: NeuroMamba通过结合Mamba的线性复杂度全局建模和局部特征建模，有效解决了神经元分割中的边界模糊和细节丢失问题，为神经元连接组重建提供了高效解决方案。

Abstract: Neuron segmentation is the cornerstone of reconstructing comprehensive neuronal connectomes, which is essential for deciphering the functional organization of the brain. The irregular morphology and densely intertwined structures of neurons make this task particularly challenging. Prevailing CNN-based methods often fail to resolve ambiguous boundaries due to the lack of long-range context, whereas Transformer-based methods suffer from boundary imprecision caused by the loss of voxel-level details during patch partitioning. To address these limitations, we propose NeuroMamba, a multi-perspective framework that exploits the linear complexity of Mamba to enable patch-free global modeling and synergizes this with complementary local feature modeling, thereby efficiently capturing long-range dependencies while meticulously preserving fine-grained voxel details. Specifically, we design a channel-gated Boundary Discriminative Feature Extractor (BDFE) to enhance local morphological cues. Complementing this, we introduce the Spatial Continuous Feature Extractor (SCFE), which integrates a resolution-aware scanning mechanism into the Visual Mamba architecture to adaptively model global dependencies across varying data resolutions. Finally, a cross-modulation mechanism synergistically fuses these multi-perspective features. Our method demonstrates state-of-the-art performance across four public EM datasets, validating its exceptional adaptability to both anisotropic and isotropic resolutions. The source code will be made publicly available.

</details>


### [51] [EVolSplat4D: Efficient Volume-based Gaussian Splatting for 4D Urban Scene Synthesis](https://arxiv.org/abs/2601.15951)
*Sheng Miao,Sijin Li,Pan Wang,Dongfeng Bai,Bingbing Liu,Yue Wang,Andreas Geiger,Yiyi Liao*

Main category: cs.CV

TL;DR: EvolSplat4D是一个前馈式4D高斯场景重建框架，通过三个专门分支统一基于体积和基于像素的高斯预测，用于静态和动态城市场景的新视角合成，在重建质量和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动驾驶仿真的静态和动态城市场景新视角合成中存在局限性：基于神经辐射场和3D高斯泼溅的方法需要耗时的逐场景优化，而前馈方法采用逐像素高斯表示在复杂动态环境中会导致3D不一致性。

Method: 提出三分支框架：1) 近距静态区域：从3D特征体积直接预测多帧一致的3D高斯几何，配合语义增强的图像渲染模块预测外观；2) 动态物体：利用物体中心规范空间和运动调整渲染模块聚合时间特征；3) 远景：使用高效的逐像素高斯分支确保全场景覆盖。

Result: 在KITTI-360、KITTI、Waymo和PandaSet数据集上的实验表明，EvolSplat4D在静态和动态环境重建中具有优越的准确性和一致性，超越了逐场景优化方法和最先进的前馈基线。

Conclusion: EvolSplat4D通过统一体积和像素高斯预测的三分支架构，实现了高质量、高效率的4D城市场景重建，解决了现有方法在重建时间与质量平衡上的挑战。

Abstract: Novel view synthesis (NVS) of static and dynamic urban scenes is essential for autonomous driving simulation, yet existing methods often struggle to balance reconstruction time with quality. While state-of-the-art neural radiance fields and 3D Gaussian Splatting approaches achieve photorealism, they often rely on time-consuming per-scene optimization. Conversely, emerging feed-forward methods frequently adopt per-pixel Gaussian representations, which lead to 3D inconsistencies when aggregating multi-view predictions in complex, dynamic environments. We propose EvolSplat4D, a feed-forward framework that moves beyond existing per-pixel paradigms by unifying volume-based and pixel-based Gaussian prediction across three specialized branches. For close-range static regions, we predict consistent geometry of 3D Gaussians over multiple frames directly from a 3D feature volume, complemented by a semantically-enhanced image-based rendering module for predicting their appearance. For dynamic actors, we utilize object-centric canonical spaces and a motion-adjusted rendering module to aggregate temporal features, ensuring stable 4D reconstruction despite noisy motion priors. Far-Field scenery is handled by an efficient per-pixel Gaussian branch to ensure full-scene coverage. Experimental results on the KITTI-360, KITTI, Waymo, and PandaSet datasets show that EvolSplat4D reconstructs both static and dynamic environments with superior accuracy and consistency, outperforming both per-scene optimization and state-of-the-art feed-forward baselines.

</details>


### [52] [HyperAlign: Hypernetwork for Efficient Test-Time Alignment of Diffusion Models](https://arxiv.org/abs/2601.15968)
*Xin Xie,Jiaxian Guo,Dong Gong*

Main category: cs.CV

TL;DR: HyperAlign：一种通过训练超网络动态生成低秩适配权重来调整扩散模型生成过程的新框架，解决现有对齐方法在多样性与计算效率之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然性能优异，但生成的图像常不符合人类偏好和意图，存在美学质量差和语义不一致的问题。现有对齐方法面临困难权衡：微调方法会导致多样性丧失和奖励过度优化，而测试时缩放方法计算开销大且优化不足。

Method: 提出HyperAlign框架，训练超网络在测试时动态生成低秩适配权重来调制扩散模型的生成算子，而不是修改潜在状态。通过输入潜在状态、时间步和提示来调整去噪轨迹，实现奖励条件对齐。设计了不同应用频率的变体以平衡性能与效率，并使用奖励分数目标结合偏好数据正则化来优化超网络，减少奖励黑客行为。

Result: 在Stable Diffusion和FLUX等多个生成范式上评估，HyperAlign在提升语义一致性和视觉吸引力方面显著优于现有的微调和测试时缩放基线方法。

Conclusion: HyperAlign通过超网络动态生成适配权重的创新方法，有效解决了扩散模型对齐中的多样性与计算效率权衡问题，在保持生成多样性的同时显著提升了对齐质量。

Abstract: Diffusion models achieve state-of-the-art performance but often fail to generate outputs that align with human preferences and intentions, resulting in images with poor aesthetic quality and semantic inconsistencies. Existing alignment methods present a difficult trade-off: fine-tuning approaches suffer from loss of diversity with reward over-optimization, while test-time scaling methods introduce significant computational overhead and tend to under-optimize. To address these limitations, we propose HyperAlign, a novel framework that trains a hypernetwork for efficient and effective test-time alignment. Instead of modifying latent states, HyperAlign dynamically generates low-rank adaptation weights to modulate the diffusion model's generation operators. This allows the denoising trajectory to be adaptively adjusted based on input latents, timesteps and prompts for reward-conditioned alignment. We introduce multiple variants of HyperAlign that differ in how frequently the hypernetwork is applied, balancing between performance and efficiency. Furthermore, we optimize the hypernetwork using a reward score objective regularized with preference data to reduce reward hacking. We evaluate HyperAlign on multiple extended generative paradigms, including Stable Diffusion and FLUX. It significantly outperforms existing fine-tuning and test-time scaling baselines in enhancing semantic consistency and visual appeal.

</details>


### [53] [PhysicsMind: Sim and Real Mechanics Benchmarking for Physical Reasoning and Prediction in Foundational VLMs and World Models](https://arxiv.org/abs/2601.16007)
*Chak-Wing Mak,Guanyu Zhu,Boyi Zhang,Hongji Li,Xiaowei Chi,Kevin Zhang,Yichen Wu,Yangfan He,Chun-Kai Fan,Wentao Lu,Kuangzhi Ge,Xinyu Fang,Hongyang He,Kuan Lu,Tianxiang Xu,Li Zhang,Yongxin Ni,Youhua Li,Shanghang Zhang*

Main category: cs.CV

TL;DR: 论文提出PhysicsMind基准测试，用于评估多模态大语言模型和视频世界模型对物理定律的理解能力，涵盖质心、杠杆平衡和牛顿第一定律三大物理原理。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型和视频世界模型在数学、常识和视觉推理方面进步显著，但对底层物理定律的理解仍未被充分探索。现有基准测试要么依赖合成的视觉问答模板，要么关注与物理定律一致性无关的感知视频质量。

Method: 引入PhysicsMind统一基准测试，包含真实和模拟环境，评估物理定律一致性的推理和生成能力。包含两个主要任务：1）视觉问答任务，测试模型能否从图像或短视频中推理物理量和数值；2）视频生成任务，评估预测的运动轨迹是否与地面真实数据遵循相同的质心、扭矩和惯性约束。

Result: 对多种最新模型和视频生成模型的评估发现，它们依赖外观启发式方法，经常违反基本力学原理。这些差距表明当前的扩展和训练仍然不足以实现稳健的物理理解。

Conclusion: PhysicsMind作为专注于物理感知多模态模型的测试平台，突显了当前模型在物理理解方面的不足，为未来研究提供了重要基准。

Abstract: Modern foundational Multimodal Large Language Models (MLLMs) and video world models have advanced significantly in mathematical, common-sense, and visual reasoning, but their grasp of the underlying physics remains underexplored. Existing benchmarks attempting to measure this matter rely on synthetic, Visual Question Answer templates or focus on perceptual video quality that is tangential to measuring how well the video abides by physical laws. To address this fragmentation, we introduce PhysicsMind, a unified benchmark with both real and simulation environments that evaluates law-consistent reasoning and generation over three canonical principles: Center of Mass, Lever Equilibrium, and Newton's First Law. PhysicsMind comprises two main tasks: i) VQA tasks, testing whether models can reason and determine physical quantities and values from images or short videos, and ii) Video Generation(VG) tasks, evaluating if predicted motion trajectories obey the same center-of-mass, torque, and inertial constraints as the ground truth. A broad range of recent models and video generation models is evaluated on PhysicsMind and found to rely on appearance heuristics while often violating basic mechanics. These gaps indicate that current scaling and training are still insufficient for robust physical understanding, underscoring PhysicsMind as a focused testbed for physics-aware multimodal models. Our data will be released upon acceptance.

</details>


### [54] [PAINT: Pathology-Aware Integrated Next-Scale Transformation for Virtual Immunohistochemistry](https://arxiv.org/abs/2601.16024)
*Rongze Ma,Mengkang Lu,Zhenyu Xiang,Yongsheng Pan,Yicheng Wu,Qingjie Zeng,Yong Xia*

Main category: cs.CV

TL;DR: PAINT是一个视觉自回归框架，通过结构优先的条件生成方法，从H&E图像合成虚拟免疫组化染色，解决了现有方法在语义一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 虚拟免疫组化(IHC)旨在从常规H&E图像计算合成分子染色模式，提供比传统物理染色更经济、更节省组织的方法。然而，该任务面临挑战：H&E形态学提供关于蛋白质表达的模糊线索，相似的组织结构可能对应不同的分子状态。现有方法大多关注直接外观合成以实现跨模态生成，常因结构先验不足导致语义不一致。

Method: 提出PAINT(Pathology-Aware Integrated Next-Scale Transformation)，一个视觉自回归框架，将合成过程重新定义为结构优先的条件生成任务。不同于直接的图像翻译，PAINT通过基于全局结构布局解析分子细节来强制执行因果顺序。核心是引入空间结构起始图(3S-Map)，将自回归初始化锚定在观察到的形态学上，确保确定性的空间对齐合成。

Result: 在IHC4BC和MIST数据集上的实验表明，PAINT在结构保真度和临床下游任务方面优于最先进的方法，验证了结构引导自回归建模的潜力。

Conclusion: PAINT通过结构优先的自回归方法有效解决了虚拟免疫组化合成中的语义不一致问题，为组织病理学中的跨模态生成提供了新思路。

Abstract: Virtual immunohistochemistry (IHC) aims to computationally synthesize molecular staining patterns from routine Hematoxylin and Eosin (H\&E) images, offering a cost-effective and tissue-efficient alternative to traditional physical staining. However, this task is particularly challenging: H\&E morphology provides ambiguous cues about protein expression, and similar tissue structures may correspond to distinct molecular states. Most existing methods focus on direct appearance synthesis to implicitly achieve cross-modal generation, often resulting in semantic inconsistencies due to insufficient structural priors. In this paper, we propose Pathology-Aware Integrated Next-Scale Transformation (PAINT), a visual autoregressive framework that reformulates the synthesis process as a structure-first conditional generation task. Unlike direct image translation, PAINT enforces a causal order by resolving molecular details conditioned on a global structural layout. Central to this approach is the introduction of a Spatial Structural Start Map (3S-Map), which grounds the autoregressive initialization in observed morphology, ensuring deterministic, spatially aligned synthesis. Experiments on the IHC4BC and MIST datasets demonstrate that PAINT outperforms state-of-the-art methods in structural fidelity and clinical downstream tasks, validating the potential of structure-guided autoregressive modeling.

</details>


### [55] [ProGiDiff: Prompt-Guided Diffusion-Based Medical Image Segmentation](https://arxiv.org/abs/2601.16060)
*Yuan Lin,Murong Xu,Marc Hölle,Chinmay Prabhakar,Andreas Maier,Vasileios Belagiannis,Bjoern Menze,Suprosanna Shit*

Main category: cs.CV

TL;DR: 提出ProGiDiff框架，利用现有图像生成模型进行医学图像分割，支持自然语言提示和多类别分割，可跨模态适应


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割方法主要是确定性的，缺乏自然语言提示能力、多提案估计、人机交互和跨模态适应能力。需要一种能利用现有预训练模型、支持语言交互的解决方案

Method: 提出ProGiDiff框架，采用ControlNet风格的调节机制，配合自定义编码器，引导预训练扩散模型输出分割掩码。支持多类别分割（通过提示目标器官），并可进行低秩少样本适应以跨模态迁移

Result: 在CT图像器官分割实验中表现优于先前方法，支持专家参与的多提案利用。学习到的调节机制可通过少量样本轻松迁移到MR图像分割

Conclusion: ProGiDiff成功将预训练扩散模型应用于医学图像分割，实现了语言提示交互、多提案估计和跨模态适应，为医学图像分析提供了灵活有效的解决方案

Abstract: Widely adopted medical image segmentation methods, although efficient, are primarily deterministic and remain poorly amenable to natural language prompts. Thus, they lack the capability to estimate multiple proposals, human interaction, and cross-modality adaptation. Recently, text-to-image diffusion models have shown potential to bridge the gap. However, training them from scratch requires a large dataset-a limitation for medical image segmentation. Furthermore, they are often limited to binary segmentation and cannot be conditioned on a natural language prompt. To this end, we propose a novel framework called ProGiDiff that leverages existing image generation models for medical image segmentation purposes. Specifically, we propose a ControlNet-style conditioning mechanism with a custom encoder, suitable for image conditioning, to steer a pre-trained diffusion model to output segmentation masks. It naturally extends to a multi-class setting simply by prompting the target organ. Our experiment on organ segmentation from CT images demonstrates strong performance compared to previous methods and could greatly benefit from an expert-in-the-loop setting to leverage multiple proposals. Importantly, we demonstrate that the learned conditioning mechanism can be easily transferred through low-rank, few-shot adaptation to segment MR images.

</details>


### [56] [DSFedMed: Dual-Scale Federated Medical Image Segmentation via Mutual Distillation Between Foundation and Lightweight Models](https://arxiv.org/abs/2601.16073)
*Hanwen Zhang,Qiaojin Shen,Yuxi Liu,Yuesheng Zhu,Guibo Luo*

Main category: cs.CV

TL;DR: DSFedMed是一个双尺度联邦框架，通过中心化基础模型与轻量级客户端模型之间的相互知识蒸馏，实现医疗图像分割的高效联邦学习，显著提升性能并降低通信和推理成本。


<details>
  <summary>Details</summary>
Motivation: 基础模型在视觉任务中表现出强大的泛化能力，但在联邦部署中面临计算需求高、通信开销大、推理成本高等挑战，特别是在资源有限的医疗环境中。

Method: 提出双尺度联邦框架，包括：1）生成高质量医疗图像替代真实公共数据集支持知识蒸馏；2）可学习性引导的样本选择策略提升双尺度蒸馏效率；3）基础模型与轻量级客户端模型之间的相互知识蒸馏机制。

Result: 在五个医疗图像分割数据集上评估显示：平均Dice分数提升2%，通信成本和推理时间减少近90%，相比现有联邦基础模型基准具有显著效率优势和可扩展性。

Conclusion: DSFedMed框架在保持高性能的同时大幅降低了联邦部署的资源需求，证明了其在资源有限环境中的显著效率优势和可扩展性，为医疗图像分割的联邦学习提供了实用解决方案。

Abstract: Foundation Models (FMs) have demonstrated strong generalization across diverse vision tasks. However, their deployment in federated settings is hindered by high computational demands, substantial communication overhead, and significant inference costs. We propose DSFedMed, a dual-scale federated framework that enables mutual knowledge distillation between a centralized foundation model and lightweight client models for medical image segmentation. To support knowledge distillation, a set of high-quality medical images is generated to replace real public datasets, and a learnability-guided sample selection strategy is proposed to enhance efficiency and effectiveness in dual-scale distillation. This mutual distillation enables the foundation model to transfer general knowledge to lightweight clients, while also incorporating client-specific insights to refine the foundation model. Evaluations on five medical imaging segmentation datasets show that DSFedMed achieves an average 2 percent improvement in Dice score while reducing communication costs and inference time by nearly 90 percent compared to existing federated foundation model baselines. These results demonstrate significant efficiency gains and scalability for resource-limited federated deployments.

</details>


### [57] [Masked Modeling for Human Motion Recovery Under Occlusions](https://arxiv.org/abs/2601.16079)
*Zhiyin Qian,Siwei Zhang,Bharat Lal Bhatnagar,Federica Bogo,Siyu Tang*

Main category: cs.CV

TL;DR: MoRo是一个基于掩码建模的端到端生成框架，用于从单目视频中鲁棒地重建被遮挡的人体运动，实现了实时推理（70 FPS）并显著提升了遮挡场景下的准确性和运动真实感。


<details>
  <summary>Details</summary>
Motivation: 单目视频人体运动重建在AR/VR、机器人等领域有广泛应用，但在真实场景中频繁遮挡下仍具挑战。现有方法存在局限性：回归方法对缺失观测脆弱；优化和扩散方法虽更鲁棒但推理速度慢、预处理复杂。需要一种既能处理遮挡又能高效推理的解决方案。

Method: 提出MoRo框架，将运动重建建模为视频条件任务。采用掩码建模处理遮挡，实现端到端推理。设计跨模态学习方案：1) 在MoCap数据上训练轨迹感知运动先验；2) 在图像-姿态数据上训练图像条件姿态先验；3) 视频条件掩码变换器融合运动和姿态先验，在视频-运动数据上微调以整合视觉线索与运动动态。

Result: 在EgoBody和RICH数据集上的实验表明，MoRo在遮挡场景下在准确性和运动真实感方面显著优于现有方法，在非遮挡场景下表现相当。在单张H200 GPU上实现70 FPS的实时推理速度。

Conclusion: MoRo通过掩码建模和跨模态先验学习，成功解决了遮挡场景下人体运动重建的鲁棒性和效率问题，实现了实时、准确、真实的运动恢复，为实际应用提供了可行解决方案。

Abstract: Human motion reconstruction from monocular videos is a fundamental challenge in computer vision, with broad applications in AR/VR, robotics, and digital content creation, but remains challenging under frequent occlusions in real-world settings.Existing regression-based methods are efficient but fragile to missing observations, while optimization- and diffusion-based approaches improve robustness at the cost of slow inference speed and heavy preprocessing steps. To address these limitations, we leverage recent advances in generative masked modeling and present MoRo: Masked Modeling for human motion Recovery under Occlusions. MoRo is an occlusion-robust, end-to-end generative framework that formulates motion reconstruction as a video-conditioned task, and efficiently recover human motion in a consistent global coordinate system from RGB videos. By masked modeling, MoRo naturally handles occlusions while enabling efficient, end-to-end inference. To overcome the scarcity of paired video-motion data, we design a cross-modality learning scheme that learns multi-modal priors from a set of heterogeneous datasets: (i) a trajectory-aware motion prior trained on MoCap datasets, (ii) an image-conditioned pose prior trained on image-pose datasets, capturing diverse per-frame poses, and (iii) a video-conditioned masked transformer that fuses motion and pose priors, finetuned on video-motion datasets to integrate visual cues with motion dynamics for robust inference. Extensive experiments on EgoBody and RICH demonstrate that MoRo substantially outperforms state-of-the-art methods in accuracy and motion realism under occlusions, while performing on-par in non-occluded scenarios. MoRo achieves real-time inference at 70 FPS on a single H200 GPU.

</details>


### [58] [SAMTok: Representing Any Mask with Two Words](https://arxiv.org/abs/2601.16093)
*Yikang Zhou,Tao Zhang,Dengxian Gong,Yuanzheng Wu,Ye Tian,Haochen Wang,Haobo Yuan,Jiacong Wang,Lu Qi,Hao Fei,Anran Wang,Zhuochen Wang,Yujing Wang,Cheng Chen,Shunping Ji,Xiangtai Li*

Main category: cs.CV

TL;DR: SAMTok提出了一种离散掩码标记器，将区域掩码转换为两个特殊标记，使多模态大语言模型能够通过标准的下一个标记预测学习像素级能力，无需修改架构。


<details>
  <summary>Details</summary>
Motivation: 像素级能力对构建交互式智能系统至关重要，但现有像素级多模态大语言模型难以扩展，因为需要复杂的区域级编码器、专门的分割解码器和不兼容的训练目标。

Method: 提出SAMTok离散掩码标记器，基于SAM2训练，使用掩码编码器和残差向量量化器将区域掩码转换为两个离散、紧凑、信息丰富的标记。通过标准的下一个标记预测和简单强化学习训练模型，无需架构修改。

Result: QwenVL-SAMTok在区域描述、区域VQA、接地对话、参考分割、场景图解析和多轮交互分割等任务上达到最先进或可比的结果。引入文本答案匹配奖励显著提升了GRES和GCG基准的性能。

Conclusion: SAMTok为多模态大语言模型提供了一种可扩展且简单的像素级能力增强范式，通过将掩码视为新的语言标记，实现了强大的像素级理解与生成能力。

Abstract: Pixel-wise capabilities are essential for building interactive intelligent systems. However, pixel-wise multi-modal LLMs (MLLMs) remain difficult to scale due to complex region-level encoders, specialized segmentation decoders, and incompatible training objectives. To address these challenges, we present SAMTok, a discrete mask tokenizer that converts any region mask into two special tokens and reconstructs the mask using these tokens with high fidelity. By treating masks as new language tokens, SAMTok enables base MLLMs (such as the QwenVL series) to learn pixel-wise capabilities through standard next-token prediction and simple reinforcement learning, without architectural modifications and specialized loss design. SAMTok builds on SAM2 and is trained on 209M diverse masks using a mask encoder and residual vector quantizer to produce discrete, compact, and information-rich tokens. With 5M SAMTok-formatted mask understanding and generation data samples, QwenVL-SAMTok attains state-of-the-art or comparable results on region captioning, region VQA, grounded conversation, referring segmentation, scene graph parsing, and multi-round interactive segmentation. We further introduce a textual answer-matching reward that enables efficient reinforcement learning for mask generation, delivering substantial improvements on GRES and GCG benchmarks. Our results demonstrate a scalable and straightforward paradigm for equipping MLLMs with strong pixel-wise capabilities. Our code and models are available.

</details>


### [59] [Clustering-Guided Spatial-Spectral Mamba for Hyperspectral Image Classification](https://arxiv.org/abs/2601.16098)
*Zack Dewis,Yimin Zhu,Zhengsen Xu,Mabel Heffring,Saeid Taleghanidoozdoozan,Quinn Ledingham,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: CSSMamba框架通过聚类引导的空间-光谱Mamba架构，解决了HSI分类中Mamba模型序列定义效率低和适应性差的问题，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Mamba模型在高光谱图像分类中面临关键挑战：需要高效且自适应的token序列定义来提升性能。现有方法在序列长度和特征学习能力方面存在局限。

Method: 1. 提出聚类引导的空间Mamba模块(CSpaMamba)，通过聚类机制减少序列长度并提升特征学习能力
2. 将CSpaMamba与光谱Mamba模块(SpeMamba)集成，构建完整的空间-光谱Mamba框架
3. 引入注意力驱动的token选择机制优化Mamba序列
4. 设计可学习的聚类模块，自适应学习聚类隶属关系

Result: 在Pavia University、Indian Pines和Liao-Ning 01数据集上的实验表明，CSSMamba相比最先进的CNN、Transformer和Mamba方法，实现了更高的准确率和更好的边界保持能力。

Conclusion: CSSMamba框架通过聚类引导的空间-光谱Mamba架构，有效解决了HSI分类中Mamba模型的序列定义问题，显著提升了分类性能。

Abstract: Although Mamba models greatly improve Hyperspectral Image (HSI) classification, they have critical challenges in terms defining efficient and adaptive token sequences for improve performance. This paper therefore presents CSSMamba (Clustering-guided Spatial-Spectral Mamba) framework to better address the challenges, with the following contributions. First, to achieve efficient and adaptive token sequences for improved Mamba performance, we integrate the clustering mechanism into a spatial Mamba architecture, leading to a cluster-guided spatial Mamba module (CSpaMamba) that reduces the Mamba sequence length and improves Mamba feature learning capability. Second, to improve the learning of both spatial and spectral information, we integrate the CSpaMamba module with a spectral mamba module (SpeMamba), leading to a complete clustering-guided spatial-spectral Mamba framework. Third, to further improve feature learning capability, we introduce an Attention-Driven Token Selection mechanism to optimize Mamba token sequencing. Last, to seamlessly integrate clustering into the Mamba model in a coherent manner, we design a Learnable Clustering Module that learns the cluster memberships in an adaptive manner. Experiments on the Pavia University, Indian Pines, and Liao-Ning 01 datasets demonstrate that CSSMamba achieves higher accuracy and better boundary preservation compared to state-of-the-art CNN, Transformer, and Mamba-based methods.

</details>


### [60] [Rethinking Composed Image Retrieval Evaluation: A Fine-Grained Benchmark from Image Editing](https://arxiv.org/abs/2601.16125)
*Tingyu Song,Yanzhao Zhang,Mingxin Li,Zhuoning Guo,Dingkun Long,Pengjun Xie,Siyue Zhang,Yilun Zhao,Shu Wu*

Main category: cs.CV

TL;DR: EDIR是一个新的细粒度组合图像检索基准，通过图像编辑技术构建了5000个高质量查询，覆盖5个主要类别和15个子类别，揭示了现有多模态嵌入模型的能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有组合图像检索基准存在查询类别有限、无法反映真实世界多样需求的问题，需要构建更全面、细粒度的评估基准来弥补这一评估差距。

Method: 利用图像编辑技术精确控制修改类型和内容，构建了一个能够合成广泛类别查询的流水线，基于此构建了EDIR基准，包含5000个高质量查询，涵盖5个主要类别和15个子类别。

Result: 对13个多模态嵌入模型的评估显示存在显著能力差距，即使最先进的模型（如RzenEmbed和GME）也难以在所有子类别上表现一致；同时揭示了现有基准的固有局限性，如模态偏差和类别覆盖不足。

Conclusion: EDIR基准为组合图像检索提供了更全面、细粒度的评估，揭示了当前模型的局限性，并通过域内训练实验区分了可通过针对性数据解决的问题和暴露模型架构固有局限性的问题。

Abstract: Composed Image Retrieval (CIR) is a pivotal and complex task in multimodal understanding. Current CIR benchmarks typically feature limited query categories and fail to capture the diverse requirements of real-world scenarios. To bridge this evaluation gap, we leverage image editing to achieve precise control over modification types and content, enabling a pipeline for synthesizing queries across a broad spectrum of categories. Using this pipeline, we construct EDIR, a novel fine-grained CIR benchmark. EDIR encompasses 5,000 high-quality queries structured across five main categories and fifteen subcategories. Our comprehensive evaluation of 13 multimodal embedding models reveals a significant capability gap; even state-of-the-art models (e.g., RzenEmbed and GME) struggle to perform consistently across all subcategories, highlighting the rigorous nature of our benchmark. Through comparative analysis, we further uncover inherent limitations in existing benchmarks, such as modality biases and insufficient categorical coverage. Furthermore, an in-domain training experiment demonstrates the feasibility of our benchmark. This experiment clarifies the task challenges by distinguishing between categories that are solvable with targeted data and those that expose intrinsic limitations of current model architectures.

</details>


### [61] [Learning to Watermark in the Latent Space of Generative Models](https://arxiv.org/abs/2601.16140)
*Sylvestre-Alvise Rebuffi,Tuan Tran,Valeriu Lacatusu,Pierre Fernandez,Tomáš Souček,Nikola Jovanović,Tom Sander,Hady Elsahar,Alexandre Mourachko*

Main category: cs.CV

TL;DR: DistSeal：一种在生成模型的潜在空间中进行水印的统一方法，支持扩散和自回归模型，通过训练潜在空间水印模型并蒸馏到生成模型或潜在解码器中，实现高效且鲁棒的水印。


<details>
  <summary>Details</summary>
Motivation: 现有基于像素空间的AI生成图像水印方法存在计算开销大、可能引入视觉伪影的问题，需要更高效且不影响图像质量的水印方案。

Method: 提出DistSeal方法，在生成模型的潜在空间中训练后处理水印模型，然后将这些潜在水印器蒸馏到生成模型本身或潜在解码器中，实现模型内水印。

Result: 潜在水印在保持竞争力的鲁棒性同时，提供与像素空间基线相似的不可感知性，速度提升高达20倍。蒸馏潜在水印器优于蒸馏像素空间水印器，提供更高效且更鲁棒的解决方案。

Conclusion: 潜在空间水印是AI生成图像水印的有效方向，DistSeal方法在扩散和自回归模型中实现了高效、鲁棒且不可感知的水印嵌入，为实际应用提供了实用解决方案。

Abstract: Existing approaches for watermarking AI-generated images often rely on post-hoc methods applied in pixel space, introducing computational overhead and potential visual artifacts. In this work, we explore latent space watermarking and introduce DistSeal, a unified approach for latent watermarking that works across both diffusion and autoregressive models. Our approach works by training post-hoc watermarking models in the latent space of generative models. We demonstrate that these latent watermarkers can be effectively distilled either into the generative model itself or into the latent decoder, enabling in-model watermarking. The resulting latent watermarks achieve competitive robustness while offering similar imperceptibility and up to 20x speedup compared to pixel-space baselines. Our experiments further reveal that distilling latent watermarkers outperforms distilling pixel-space ones, providing a solution that is both more efficient and more robust.

</details>


### [62] [ActionMesh: Animated 3D Mesh Generation with Temporal 3D Diffusion](https://arxiv.org/abs/2601.16148)
*Remy Sabathier,David Novotny,Niloy J. Mitra,Tom Monnier*

Main category: cs.CV

TL;DR: ActionMesh是一个生成式模型，能够以前馈方式生成可直接用于生产的动态3D网格，支持从单目视频、文本描述或带动画描述的3D网格等输入生成动画3D对象。


<details>
  <summary>Details</summary>
Motivation: 现有的3D对象生成方法在实践应用中存在诸多限制：设置复杂、运行时间长、质量有限。需要一种能够快速生成高质量、可直接用于生产的动态3D网格的方法。

Method: 提出"时序3D扩散"框架：1）改进现有3D扩散模型，增加时间轴生成同步的潜在序列表示独立变化的3D形状；2）设计时序3D自编码器，将独立形状序列转换为预定义参考形状的相应变形，从而构建动画。

Result: 在Consistent4D和Objaverse等标准视频到4D基准测试中，ActionMesh在几何精度和时序一致性方面均达到最先进性能，能够以前所未有的速度和质量生成动画3D网格。

Conclusion: ActionMesh能够快速生成可直接用于生产的动态3D网格，无需绑定骨骼且保持拓扑一致性，支持快速迭代和无缝应用（如纹理映射和重定向），在速度和质量方面均优于现有方法。

Abstract: Generating animated 3D objects is at the heart of many applications, yet most advanced works are typically difficult to apply in practice because of their limited setup, their long runtime, or their limited quality. We introduce ActionMesh, a generative model that predicts production-ready 3D meshes "in action" in a feed-forward manner. Drawing inspiration from early video models, our key insight is to modify existing 3D diffusion models to include a temporal axis, resulting in a framework we dubbed "temporal 3D diffusion". Specifically, we first adapt the 3D diffusion stage to generate a sequence of synchronized latents representing time-varying and independent 3D shapes. Second, we design a temporal 3D autoencoder that translates a sequence of independent shapes into the corresponding deformations of a pre-defined reference shape, allowing us to build an animation. Combining these two components, ActionMesh generates animated 3D meshes from different inputs like a monocular video, a text description, or even a 3D mesh with a text prompt describing its animation. Besides, compared to previous approaches, our method is fast and produces results that are rig-free and topology consistent, hence enabling rapid iteration and seamless applications like texturing and retargeting. We evaluate our model on standard video-to-4D benchmarks (Consistent4D, Objaverse) and report state-of-the-art performances on both geometric accuracy and temporal consistency, demonstrating that our model can deliver animated 3D meshes with unprecedented speed and quality.

</details>


### [63] [HVD: Human Vision-Driven Video Representation Learning for Text-Video Retrieval](https://arxiv.org/abs/2601.16155)
*Zequn Xie,Xin Liu,Boyun Zhang,Yuxiao Lin,Sihang Cai,Tao Jin*

Main category: cs.CV

TL;DR: 提出HVD模型解决文本-视频检索中的"盲目"特征交互问题，通过模仿人类认知行为实现从粗到细的对齐


<details>
  <summary>Details</summary>
Motivation: 当前CLIP-based方法存在"盲目"特征交互问题，模型难以从背景噪声中辨别关键视觉信息，这是由于文本查询的稀疏性导致的。需要模仿人类认知行为来改进特征对齐机制。

Method: 提出Human Vision-Driven (HVD)模型，包含两个核心组件：1) Frame Features Selection Module (FFSM)：模仿人类宏观感知能力，选择关键帧消除时间冗余；2) Patch Features Compression Module (PFCM)：模仿微观感知，通过高级注意力机制将补丁特征聚合成显著视觉实体，实现精确的实体级匹配。

Result: 在五个基准测试上进行广泛实验，HVD不仅能够捕捉类似人类的视觉焦点，而且实现了最先进的性能。

Conclusion: HVD模型通过模仿人类认知行为的从粗到细对齐机制，有效解决了文本-视频检索中的"盲目"特征交互问题，显著提升了检索性能。

Abstract: The success of CLIP has driven substantial progress in text-video retrieval. However, current methods often suffer from "blind" feature interaction, where the model struggles to discern key visual information from background noise due to the sparsity of textual queries. To bridge this gap, we draw inspiration from human cognitive behavior and propose the Human Vision-Driven (HVD) model. Our framework establishes a coarse-to-fine alignment mechanism comprising two key components: the Frame Features Selection Module (FFSM) and the Patch Features Compression Module (PFCM). FFSM mimics the human macro-perception ability by selecting key frames to eliminate temporal redundancy. Subsequently, PFCM simulates micro-perception by aggregating patch features into salient visual entities through an advanced attention mechanism, enabling precise entity-level matching. Extensive experiments on five benchmarks demonstrate that HVD not only captures human-like visual focus but also achieves state-of-the-art performance.

</details>


### [64] [360Anything: Geometry-Free Lifting of Images and Videos to 360°](https://arxiv.org/abs/2601.16192)
*Ziyi Wu,Daniel Watson,Andrea Tagliasacchi,David J. Fleet,Marcus A. Brubaker,Saurabh Saxena*

Main category: cs.CV

TL;DR: 360Anything：基于扩散Transformer的几何无关框架，无需相机标定即可从透视图像/视频生成360°全景图，实现最先进的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖透视图像与等距柱状投影（ERP）空间之间的显式几何对齐，需要已知相机元数据，限制了在野外数据中的应用，因为这类数据通常缺少或含有噪声的标定信息

Method: 提出几何无关框架360Anything，基于预训练扩散Transformer，将透视输入和全景目标视为token序列，以纯数据驱动方式学习透视到等距柱状投影的映射；引入Circular Latent Encoding解决ERP边界接缝问题

Result: 在图像和视频透视到360°生成任务上实现最先进性能，优于使用地面真实相机信息的先前工作；在零样本相机视场和方向估计基准测试中表现优异

Conclusion: 360Anything通过数据驱动方法实现了无需相机标定的高质量全景生成，展现了深度几何理解能力，并具有计算机视觉任务的更广泛实用性

Abstract: Lifting perspective images and videos to 360° panoramas enables immersive 3D world generation. Existing approaches often rely on explicit geometric alignment between the perspective and the equirectangular projection (ERP) space. Yet, this requires known camera metadata, obscuring the application to in-the-wild data where such calibration is typically absent or noisy. We propose 360Anything, a geometry-free framework built upon pre-trained diffusion transformers. By treating the perspective input and the panorama target simply as token sequences, 360Anything learns the perspective-to-equirectangular mapping in a purely data-driven way, eliminating the need for camera information. Our approach achieves state-of-the-art performance on both image and video perspective-to-360° generation, outperforming prior works that use ground-truth camera information. We also trace the root cause of the seam artifacts at ERP boundaries to zero-padding in the VAE encoder, and introduce Circular Latent Encoding to facilitate seamless generation. Finally, we show competitive results in zero-shot camera FoV and orientation estimation benchmarks, demonstrating 360Anything's deep geometric understanding and broader utility in computer vision tasks. Additional results are available at https://360anything.github.io/.

</details>


### [65] [Scaling Text-to-Image Diffusion Transformers with Representation Autoencoders](https://arxiv.org/abs/2601.16208)
*Shengbang Tong,Boyang Zheng,Ziteng Wang,Bingda Tang,Nanye Ma,Ellis Brown,Jihan Yang,Rob Fergus,Yann LeCun,Saining Xie*

Main category: cs.CV

TL;DR: 论文研究了将表示自编码器（RAEs）扩展到大规模文本到图像生成，发现RAEs在简化设计后，相比VAEs在多方面表现更优，收敛更快，生成质量更好，适合作为大规模T2I生成的基础框架。


<details>
  <summary>Details</summary>
Motivation: RAEs在ImageNet上的扩散建模已显示出优势，但能否扩展到大规模、自由形式的文本到图像生成尚不明确。本研究旨在验证RAEs框架在大规模T2I生成中的可扩展性，并与当前最优的FLUX VAE进行对比。

Method: 1. 在冻结的SigLIP-2表示编码器上扩展RAE解码器，使用网络、合成和文本渲染数据进行训练；2. 系统性地测试RAE在ImageNet上提出的设计选择；3. 在0.5B到9.8B参数的扩散变换器规模上，对RAE和FLUX VAE进行受控比较；4. 在高质量数据集上进行微调实验。

Result: 1. 扩展RAE解码器提升了通用保真度，但特定领域（如文本）需要针对性数据组合；2. 大规模扩展简化了RAE框架：维度相关的噪声调度依然关键，但架构复杂性（如宽扩散头和噪声增强解码）在大规模下效益可忽略；3. RAE在所有模型规模上都优于VAE；4. 微调时，VAE模型在64个epoch后灾难性过拟合，而RAE模型在256个epoch内保持稳定且性能更优；5. RAE模型收敛更快，生成质量更好。

Conclusion: RAEs相比VAEs是更简单、更强大的大规模文本到图像生成基础框架。其优势包括更好的性能、稳定性、收敛速度和生成质量。此外，由于视觉理解和生成可以在共享表示空间中操作，这为统一的多模态模型开辟了新可能性。

Abstract: Representation Autoencoders (RAEs) have shown distinct advantages in diffusion modeling on ImageNet by training in high-dimensional semantic latent spaces. In this work, we investigate whether this framework can scale to large-scale, freeform text-to-image (T2I) generation. We first scale RAE decoders on the frozen representation encoder (SigLIP-2) beyond ImageNet by training on web, synthetic, and text-rendering data, finding that while scale improves general fidelity, targeted data composition is essential for specific domains like text. We then rigorously stress-test the RAE design choices originally proposed for ImageNet. Our analysis reveals that scaling simplifies the framework: while dimension-dependent noise scheduling remains critical, architectural complexities such as wide diffusion heads and noise-augmented decoding offer negligible benefits at scale Building on this simplified framework, we conduct a controlled comparison of RAE against the state-of-the-art FLUX VAE across diffusion transformer scales from 0.5B to 9.8B parameters. RAEs consistently outperform VAEs during pretraining across all model scales. Further, during finetuning on high-quality datasets, VAE-based models catastrophically overfit after 64 epochs, while RAE models remain stable through 256 epochs and achieve consistently better performance. Across all experiments, RAE-based diffusion models demonstrate faster convergence and better generation quality, establishing RAEs as a simpler and stronger foundation than VAEs for large-scale T2I generation. Additionally, because both visual understanding and generation can operate in a shared representation space, the multimodal model can directly reason over generated latents, opening new possibilities for unified models.

</details>


### [66] [PyraTok: Language-Aligned Pyramidal Tokenizer for Video Understanding and Generation](https://arxiv.org/abs/2601.16210)
*Onkar Susladkar,Tushar Prakash,Adheesh Juvekar,Kiet A. Nguyen,Dong-Hwan Jang,Inderjit S Dhillon,Ismini Lourentzou*

Main category: cs.CV

TL;DR: PyraTok是一个语言对齐的金字塔视频分词器，通过多尺度时空分辨率的语义结构化离散潜在表示，显著提升视频生成和理解性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频VAE分词器通常只在单一尺度学习视觉码本，词汇量有限且语言监督浅层，导致跨模态对齐差和零样本迁移能力弱。

Method: 基于预训练视频VAE，引入语言对齐的金字塔量化模块，在多个深度离散化编码器特征，使用共享大型二进制码本生成紧凑而富有表现力的视频标记序列，并通过多尺度文本引导量化和标记层次结构的全局自回归目标联合优化。

Result: 在十个基准测试中实现最先进的视频重建，持续提升文本到视频生成质量，在视频分割、时序动作定位和视频理解的零样本任务中达到新SOTA，可扩展到4K/8K分辨率。

Conclusion: PyraTok通过语言对齐的金字塔分词方法，显著改善了视频离散表示的语义结构和跨模态对齐能力，为视频生成和理解系统提供了更强大的基础。

Abstract: Discrete video VAEs underpin modern text-to-video generation and video understanding systems, yet existing tokenizers typically learn visual codebooks at a single scale with limited vocabularies and shallow language supervision, leading to poor cross-modal alignment and zero-shot transfer. We introduce PyraTok, a language-aligned pyramidal tokenizer that learns semantically structured discrete latents across multiple spatiotemporal resolutions. PyraTok builds on a pretrained video VAE and a novel Language aligned Pyramidal Quantization (LaPQ) module that discretizes encoder features at several depths using a shared large binary codebook, yielding compact yet expressive video token sequences. To tightly couple visual tokens with language, PyraTok jointly optimizes multi-scale text-guided quantization and a global autoregressive objective over the token hierarchy. Across ten benchmarks, PyraTok delivers state-of-the-art (SOTA) video reconstruction, consistently improves text-to-video quality, and sets new SOTA zero-shot performance on video segmentation, temporal action localization, and video understanding, scaling robustly to up to 4K/8K resolutions.

</details>


### [67] [Why Can't I Open My Drawer? Mitigating Object-Driven Shortcuts in Zero-Shot Compositional Action Recognition](https://arxiv.org/abs/2601.16211)
*Geo Ahn,Inwoong Lee,Taeoh Kim,Minho Shim,Dongyoon Wee,Jinwoo Choi*

Main category: cs.CV

TL;DR: 论文提出RCORE框架解决零样本组合动作识别中的对象驱动动词捷径问题，通过组合感知增强和时间顺序正则化实现更好的组合泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有零样本组合动作识别模型存在对象驱动动词捷径问题，即模型过度依赖对象信息而忽略视觉证据，导致在未见动词-对象组合上泛化能力差

Method: 提出RCORE框架：1)组合感知增强：多样化动词-对象组合而不破坏运动线索；2)时间顺序正则化损失：通过显式建模时间结构惩罚捷径行为

Result: 在Sth-com和新构建的EK100-com基准上，RCORE显著提高了未见组合的准确率，减少了对共现偏见的依赖，获得了持续正面的组合差距

Conclusion: 对象驱动捷径是零样本组合动作识别的关键限制因素，解决这一问题对于实现稳健的组合视频理解至关重要

Abstract: We study Compositional Video Understanding (CVU), where models must recognize verbs and objects and compose them to generalize to unseen combinations. We find that existing Zero-Shot Compositional Action Recognition (ZS-CAR) models fail primarily due to an overlooked failure mode: object-driven verb shortcuts. Through systematic analysis, we show that this behavior arises from two intertwined factors: severe sparsity and skewness of compositional supervision, and the asymmetric learning difficulty between verbs and objects. As training progresses, the existing ZS-CAR model increasingly ignores visual evidence and overfits to co-occurrence statistics. Consequently, the existing model does not gain the benefit of compositional recognition in unseen verb-object compositions. To address this, we propose RCORE, a simple and effective framework that enforces temporally grounded verb learning. RCORE introduces (i) a composition-aware augmentation that diversifies verb-object combinations without corrupting motion cues, and (ii) a temporal order regularization loss that penalizes shortcut behaviors by explicitly modeling temporal structure. Across two benchmarks, Sth-com and our newly constructed EK100-com, RCORE significantly improves unseen composition accuracy, reduces reliance on co-occurrence bias, and achieves consistently positive compositional gaps. Our findings reveal object-driven shortcuts as a critical limiting factor in ZS-CAR and demonstrate that addressing them is essential for robust compositional video understanding.

</details>


### [68] [CamPilot: Improving Camera Control in Video Diffusion Model with Efficient Camera Reward Feedback](https://arxiv.org/abs/2601.16214)
*Wenhang Ge,Guibao Shen,Jiawei Feng,Luozhou Wang,Hao Lu,Xingye Tian,Xin Tao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 提出CamPilot方法，通过3D高斯解码器和相机感知奖励量化，显著提升视频扩散模型的相机控制能力


<details>
  <summary>Details</summary>
Motivation: 现有相机控制视频扩散模型虽然有所改进，但相机可控性仍然有限。直接采用现有ReFL方法面临三个挑战：1) 当前奖励模型缺乏评估视频-相机对齐的能力；2) 将潜在空间解码为RGB视频计算奖励开销大；3) 视频解码时通常忽略3D几何信息

Method: 提出高效的相机感知3D解码器，将视频潜在表示和相机姿态解码为3D高斯表示。相机姿态既作为输入又作为投影参数，视频潜在与相机姿态的不对齐会导致3D结构几何扭曲和模糊渲染。通过优化渲染新视角与真实视角的像素一致性作为奖励，并引入可见性项选择性监督几何扭曲确定的确定性区域

Result: 在RealEstate10K和WorldScore基准测试上进行广泛实验，证明了所提方法的有效性

Conclusion: CamPilot通过3D高斯解码和相机感知奖励量化，有效提升了视频扩散模型的相机控制能力，解决了现有ReFL方法面临的挑战

Abstract: Recent advances in camera-controlled video diffusion models have significantly improved video-camera alignment. However, the camera controllability still remains limited. In this work, we build upon Reward Feedback Learning and aim to further improve camera controllability. However, directly borrowing existing ReFL approaches faces several challenges. First, current reward models lack the capacity to assess video-camera alignment. Second, decoding latent into RGB videos for reward computation introduces substantial computational overhead. Third, 3D geometric information is typically neglected during video decoding. To address these limitations, we introduce an efficient camera-aware 3D decoder that decodes video latent into 3D representations for reward quantization. Specifically, video latent along with the camera pose are decoded into 3D Gaussians. In this process, the camera pose not only acts as input, but also serves as a projection parameter. Misalignment between the video latent and camera pose will cause geometric distortions in the 3D structure, resulting in blurry renderings. Based on this property, we explicitly optimize pixel-level consistency between the rendered novel views and ground-truth ones as reward. To accommodate the stochastic nature, we further introduce a visibility term that selectively supervises only deterministic regions derived via geometric warping. Extensive experiments conducted on RealEstate10K and WorldScore benchmarks demonstrate the effectiveness of our proposed method. Project page: \href{https://a-bigbao.github.io/CamPilot/}{CamPilot Page}.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [69] [Designing Persuasive Social Robots for Health Behavior Change: A Systematic Review of Behavior Change Strategies and Evaluation Methods](https://arxiv.org/abs/2601.15309)
*Jiaxin Xu,Chao Zhang,Raymond H. Cuijpers,Wijnand A. IJsselsteijn*

Main category: cs.RO

TL;DR: 该综述分析了39项研究，总结了社交机器人促进健康行为改变的四大策略类别，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 社交机器人作为健康行为改变干预措施的应用日益增多，但指导其设计和评估的可操作知识仍然有限。需要系统梳理现有研究中的行为改变策略和评估方法。

Method: 通过系统数据库检索和手动检索识别相关文献，对39项研究进行分析，归纳行为改变策略和评估方法。

Result: 识别出四大行为改变策略类别：指导策略、咨询策略、社会影响策略和增强说服力策略；同时总结了当前评估实践的关键特征，包括研究设计、设置、持续时间和结果测量。

Conclusion: 这些策略突出了社交机器人作为行为改变干预的独特优势，提供了有价值的设计启发。基于评估实践的分析，提出了未来人机交互研究的若干方向。

Abstract: Social robots are increasingly applied as health behavior change interventions, yet actionable knowledge to guide their design and evaluation remains limited. This systematic review synthesizes (1) the behavior change strategies used in existing HRI studies employing social robots to promote health behavior change, and (2) the evaluation methods applied to assess behavior change outcomes. Relevant literature was identified through systematic database searches and hand searches. Analysis of 39 studies revealed four overarching categories of behavior change strategies: coaching strategies, counseling strategies, social influence strategies, and persuasion-enhancing strategies. These strategies highlight the unique affordances of social robots as behavior change interventions and offer valuable design heuristics. The review also identified key characteristics of current evaluation practices, including study designs, settings, durations, and outcome measures, on the basis of which we propose several directions for future HRI research.

</details>


### [70] [Preparation and Motion Study of Magnetically Driven Micro Soft Robot Mimicking the Cownose Ray](https://arxiv.org/abs/2601.15349)
*Jiaqing Chang,Song Gao,Chaowei Dong,zhaobang Li,Yang Liu*

Main category: cs.RO

TL;DR: 本研究设计并制造了一种受牛鼻魟启发的磁响应微型软体机器人，使用三维亥姆霍兹线圈产生振荡谐波磁场驱动其游泳，在特定磁场参数下达到最快游泳速度，并能实现多种游泳模式。


<details>
  <summary>Details</summary>
Motivation: 在狭窄、非结构化的水下环境中，微型软体机器人因其灵活运动能力和小尺寸具有独特优势。但受限于小型化，这些机器人难以内部供电，通常需要无线供电方式。本研究旨在探索磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定基础。

Method: 1. 基于牛鼻魟游泳原理设计制造磁响应微型软体机器人，材料为特定比例的钕铁硼和PDMS；
2. 使用三维亥姆霍兹线圈产生振荡谐波磁场进行游泳实验；
3. 探索磁场参数对机器人游泳性能的影响；
4. 通过调整线圈电流方向和频率实现不同游泳模式；
5. 采用逐步调整方法减少响应误差对轨迹的影响。

Result: 1. 在B=5 mT和f=11 Hz条件下游泳速度最快，达到5.25 mm/s，约每秒0.5个体长；
2. 通过调整电流方向和频率，机器人能够执行直线游泳、转向游泳和定向游泳等不同模式；
3. 逐步调整方法能有效减少响应误差对机器人轨迹的影响。

Conclusion: 本研究展示了一种磁驱动微型软体机器人的方法，为无线驱动机器人在水下狭窄空间的应用奠定了基础。通过仿生设计和磁驱动技术，实现了微型软体机器人的可控游泳运动。

Abstract: In narrow, unstructured underwater environments such as environmental monitoring and minimally invasive medical procedures, micro soft robots exhibit unique advantages due to their flexible movement capabilities and small size. At the same time, applying bionic technology to the structural design of micro soft robots can significantly improve their swimming performance. However, limited by their miniaturization, these robots are difficult to power internally and usually adopt a wireless power supply method. This study designs and fabricates a magnetically responsive, cownose ray-inspired micro soft robot based on the swimming principle of the cownose ray. The robot is made of a certain proportion of NdFeB and PDMS. Then, a three-dimensional Helmholtz coil is used to generate an oscillating harmonic magnetic field to conduct swimming experiments on the robot, exploring the influence of magnetic field parameters on the robot's swimming performance. The experimental results show that the swimming speed is the fastest at B = 5 mT and f = 11 Hz, reaching 5.25 mm/s, which is about 0.5 body lengths per second. In addition, by adjusting the current direction and frequency of the coil, the robot can perform different swimming modes such as straight swimming, turning swimming, and directional swimming. By employing a stepwise adjustment method, the impact of response errors on the robot's trajectory can be effectively reduced. This study demonstrates a method for magnetically driven micro soft robots, laying a foundation for the application of wireless-driven robots in underwater narrow spaces.

</details>


### [71] [Learning a Unified Latent Space for Cross-Embodiment Robot Control](https://arxiv.org/abs/2601.15419)
*Yashuai Yan,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出了一个可扩展的跨具身人形机器人控制框架，通过共享潜在表征统一人类和多样化人形平台的运动，支持直接部署策略到新机器人而无需适应。


<details>
  <summary>Details</summary>
Motivation: 现有机器人控制方法通常针对特定机器人形态设计，缺乏跨不同具身形态（如单臂、双臂、有腿人形机器人）的统一控制框架，导致需要为每个新机器人重新训练策略，效率低下。

Method: 采用两阶段方法：1) 通过对比学习构建解耦的潜在空间，捕捉不同身体部位的局部运动模式，结合关节旋转和末端执行器位置的自定义相似度度量；2) 在潜在空间中训练目标条件控制策略，使用条件变分自编码器预测潜在空间位移，仅需人类数据。

Result: 训练的策略可直接部署到多个机器人上而无需适应，支持通过轻量级机器人特定嵌入层高效添加新机器人，实验证明该方法实现了稳健、可扩展、具身无关的机器人控制。

Conclusion: 该框架为跨具身人形机器人控制提供了一种统一、可扩展的解决方案，通过共享潜在表征实现了人类运动到多样化机器人平台的高效迁移，显著降低了新机器人整合成本。

Abstract: We present a scalable framework for cross-embodiment humanoid robot control by learning a shared latent representation that unifies motion across humans and diverse humanoid platforms, including single-arm, dual-arm, and legged humanoid robots. Our method proceeds in two stages: first, we construct a decoupled latent space that captures localized motion patterns across different body parts using contrastive learning, enabling accurate and flexible motion retargeting even across robots with diverse morphologies. To enhance alignment between embodiments, we introduce tailored similarity metrics that combine joint rotation and end-effector positioning for critical segments, such as arms. Then, we train a goal-conditioned control policy directly within this latent space using only human data. Leveraging a conditional variational autoencoder, our policy learns to predict latent space displacements guided by intended goal directions. We show that the trained policy can be directly deployed on multiple robots without any adaptation. Furthermore, our method supports the efficient addition of new robots to the latent space by learning only a lightweight, robot-specific embedding layer. The learned latent policies can also be directly applied to the new robots. Experimental results demonstrate that our approach enables robust, scalable, and embodiment-agnostic robot control across a wide range of humanoid platforms.

</details>


### [72] [Neural Collision Detection for Multi-arm Laparoscopy Surgical Robots Through Learning-from-Simulation](https://arxiv.org/abs/2601.15459)
*Sarvin Ghiasi,Majid Roshanfar,Jake Barralet,Liane S. Feldman,Amir Hooshiar*

Main category: cs.RO

TL;DR: 本文提出了一個整合框架，結合分析建模、即時模擬和機器學習，來提升腹腔鏡手術中機械臂的安全性和操作效率，特別針對碰撞檢測和最小距離估計問題。


<details>
  <summary>Details</summary>
Motivation: 腹腔鏡手術中機械臂的安全操作面臨碰撞檢測和最小距離估計的關鍵挑戰。現有方法需要更精確、更可靠的方法來確保機械臂在狹窄手術空間中的安全運行，避免對患者和設備造成損害。

Method: 1. 開發分析模型基於關節配置估計機械臂間最小距離，提供精確理論計算作為驗證基準
2. 創建3D模擬環境建模兩個7-DOF Kinova機械臂，生成多樣化配置數據集
3. 訓練深度神經網絡模型，以機械臂關節執行器和相對位置為輸入，預測最小距離

Result: 深度神經網絡模型在最小距離預測上達到平均絕對誤差282.2毫米，R平方值0.85。預測距離與實際距離高度一致，顯示模型能準確推廣空間關係。

Conclusion: 結合分析精度與機器學習算法能有效提升機械臂系統的精確性和可靠性。該框架為腹腔鏡手術中機械臂的安全操作提供了穩健解決方案，有助於減少手術風險和提高操作效率。

Abstract: This study presents an integrated framework for enhancing the safety and operational efficiency of robotic arms in laparoscopic surgery by addressing key challenges in collision detection and minimum distance estimation. By combining analytical modeling, real-time simulation, and machine learning, the framework offers a robust solution for ensuring safe robotic operations. An analytical model was developed to estimate the minimum distances between robotic arms based on their joint configurations, offering precise theoretical calculations that serve as both a validation tool and a benchmark. To complement this, a 3D simulation environment was created to model two 7-DOF Kinova robotic arms, generating a diverse dataset of configurations for collision detection and distance estimation. Using these insights, a deep neural network model was trained with joint actuators of robot arms and relative positions as inputs, achieving a mean absolute error of 282.2 mm and an R-squared value of 0.85. The close alignment between predicted and actual distances highlights the network's accuracy and its ability to generalize spatial relationships. This work demonstrates the effectiveness of combining analytical precision with machine learning algorithms to enhance the precision and reliability of robotic systems.

</details>


### [73] [A Universal Large Language Model -- Drone Command and Control Interface](https://arxiv.org/abs/2601.15486)
*Javier N. Ramos-Silva,Peter J. Burke*

Main category: cs.RO

TL;DR: 开发了基于模型上下文协议（MCP）的通用无人机控制接口，将大型语言模型（LLM）与无人机控制无缝集成，支持自然语言到无人机指令的转换。


<details>
  <summary>Details</summary>
Motivation: 现有LLM与无人机控制接口需要针对每个应用进行繁琐的人工适配，缺乏通用、易用的解决方案，阻碍了物理AI领域中无人机能力的充分发挥。

Method: 采用模型上下文协议（MCP）作为开放标准，开发云基Linux主机上的MCP服务器，支持Mavlink协议（Ardupilot/PX4框架通用无人机控制语言），并与Google Maps MCP服务器集成提供实时导航信息。

Result: 成功演示了真实无人机的飞行控制，并在模拟无人机中展示了广泛的飞行规划和控制能力，验证了该通用接口的有效性。

Conclusion: 提出了首个通用、多功能、全面且易用的无人机控制接口，实现了LLM与无人机指挥控制的标准化集成，为自然语言到无人机控制的转换提供了新范式。

Abstract: The use of artificial intelligence (AI) for drone control can have a transformative impact on drone capabilities, especially when real world information can be integrated with drone sensing, command, and control, part of a growing field of physical AI. Large language models (LLMs) can be advantageous if trained at scale on general knowledge, but especially and in particular when the training data includes information such as detailed map geography topology of the entire planet, as well as the ability to access real time situational data such as weather. However, challenges remain in the interface between drones and LLMs in general, with each application requiring a tedious, labor intensive effort to connect the LLM trained knowledge to drone command and control. Here, we solve that problem, using an interface strategy that is LLM agnostic and drone agnostic, providing the first universal, versatile, comprehensive and easy to use drone control interface. We do this using the new model context protocol (MCP) standard, an open standard that provides a universal way for AI systems to access external data, tools, and services. We develop and deploy a cloud based Linux machine hosting an MCP server that supports the Mavlink protocol, an ubiquitous drone control language used almost universally by millions of drones including Ardupilot and PX4 framework.We demonstrate flight control of a real unmanned aerial vehicle. In further testing, we demonstrate extensive flight planning and control capability in a simulated drone, integrated with a Google Maps MCP server for up to date, real time navigation information. This demonstrates a universal approach to integration of LLMs with drone command and control, a paradigm that leverages and exploits virtually all of modern AI industry with drone technology in an easy to use interface that translates natural language to drone control.

</details>


### [74] [CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation](https://arxiv.org/abs/2601.15541)
*Heng Zhang,Wei-Hsing Huang,Qiyi Tong,Gokhan Solak,Puze Liu,Sheng Liu,Jan Peters,Arash Ajoudani*

Main category: cs.RO

TL;DR: 提出CompliantVLA-adaptor，通过VLM-informed上下文感知可变阻抗控制增强VLA模型，提升接触密集型机器人操作任务的安全性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA系统（如RDT、Pi0、OpenVLA-oft）通常只输出位置控制，缺乏力感知适应能力，导致在涉及接触、顺应性或不确定性的物理任务中出现不安全或失败的情况。

Method: 提出CompliantVLA-adaptor，使用视觉语言模型（VLM）从图像和自然语言中解读任务上下文，自适应调整可变阻抗控制器（VIC）的刚度和阻尼参数，并利用实时力/力矩反馈调节这些参数以确保交互力保持在安全阈值内。

Result: 方法在仿真和真实硬件上的一系列复杂接触密集型任务中优于VLA基线，提高了成功率并减少了力违规。所有任务的整体成功率从9.86%提升到17.29%。

Conclusion: CompliantVLA-adaptor为使用VLA进行安全接触密集型操作提供了有前景的路径，代码、提示和力-力矩-阻抗-场景上下文数据集已开源。

Abstract: We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

</details>


### [75] [A Mobile Magnetic Manipulation Platform for Gastrointestinal Navigation with Deep Reinforcement Learning Control](https://arxiv.org/abs/2601.15545)
*Zhifan Yan,Chang Liu,Yiyang Jiang,Wenxuan Zheng,Xinhao Chen,Axel Krieger*

Main category: cs.RO

TL;DR: 使用深度强化学习的移动磁控平台，快速部署无需复杂模型校准，实现胃肠道大工作空间内精确磁控胶囊递送


<details>
  <summary>Details</summary>
Motivation: 胃肠道磁控机器人靶向给药有前景，但现有控制系统存在局限：固定磁系统工作空间有限，移动系统需要复杂预校准物理模型，存在"模型校准瓶颈"

Method: 开发紧凑低成本移动磁控平台，四电磁铁阵列安装在UR5协作机器人上，采用基于Soft Actor-Critic的深度强化学习控制策略，通过仿真到现实训练管道实现快速部署

Result: DRL控制器在15分钟内完成策略部署，显著减少设置时间。控制7mm磁胶囊沿2D轨迹运动，方形路径RMSE 1.18mm，圆形路径RMSE 1.50mm，在30cm×20cm临床相关工作空间成功追踪

Conclusion: 该工作展示了一种快速部署、无需模型的控制框架，能够在大工作空间内实现精确磁控操作，在2D胃肠道模型中得到验证，为胃肠道靶向给药提供实用解决方案

Abstract: Targeted drug delivery in the gastrointestinal (GI) tract using magnetic robots offers a promising alternative to systemic treatments. However, controlling these robots is a major challenge. Stationary magnetic systems have a limited workspace, while mobile systems (e.g., coils on a robotic arm) suffer from a "model-calibration bottleneck", requiring complex, pre-calibrated physical models that are time-consuming to create and computationally expensive. This paper presents a compact, low-cost mobile magnetic manipulation platform that overcomes this limitation using Deep Reinforcement Learning (DRL). Our system features a compact four-electromagnet array mounted on a UR5 collaborative robot. A Soft Actor-Critic (SAC)-based control strategy is trained through a sim-to-real pipeline, enabling effective policy deployment within 15 minutes and significantly reducing setup time. We validated the platform by controlling a 7-mm magnetic capsule along 2D trajectories. Our DRL-based controller achieved a root-mean-square error (RMSE) of 1.18~mm for a square path and 1.50~mm for a circular path. We also demonstrated successful tracking over a clinically relevant, 30 cm * 20 cm workspace. This work demonstrates a rapidly deployable, model-free control framework capable of precise magnetic manipulation in a large workspace,validated using a 2D GI phantom.

</details>


### [76] [Airflow Source Seeking on Small Quadrotors Using a Single Flow Sensor](https://arxiv.org/abs/2601.15607)
*Lenworth Thomas,Tjaden Bridges,Sarah Bergbreiter*

Main category: cs.RO

TL;DR: 该研究提出了一种用于小型四旋翼无人机（<100克）的化学羽流追踪方法，通过定制流量传感器结合气流源追踪行为来增强传统羽流追踪能力。


<details>
  <summary>Details</summary>
Motivation: 随着环境灾害日益频繁和严重，追踪污染物或有害颗粒物源头变得至关重要。小型四旋翼无人机可在人类周围和受限空间飞行，但受限于小型气体传感器的灵敏度差和响应时间长，羽流追踪面临挑战。

Method: 开发了能够感知气流大小和方向的定制流量传感器，并在小型四旋翼无人机上实现。采用改进的"Cast and Surge"算法，利用气流方向感知来定位和导航至气流源。

Result: 实验验证系统能在飞行中检测气流并重新定向无人机朝向气流。多次随机起始位置和方向的试验表明，源追踪算法能可靠地找到气流源。

Conclusion: 该工作为未来平台奠定了基础，使流量传感器能与其他传感器协同工作，实现更丰富的羽流追踪数据收集和源追踪能力。

Abstract: As environmental disasters happen more frequently and severely, seeking the source of pollutants or harmful particulates using plume tracking becomes even more important. Plume tracking on small quadrotors would allow these systems to operate around humans and fly in more confined spaces, but can be challenging due to poor sensitivity and long response times from gas sensors that fit on small quadrotors. In this work, we present an approach to complement chemical plume tracking with airflow source-seeking behavior using a custom flow sensor that can sense both airflow magnitude and direction on small quadrotors < 100 g. We use this sensor to implement a modified version of the `Cast and Surge' algorithm that takes advantage of flow direction sensing to find and navigate towards flow sources. A series of characterization experiments verified that the system can detect airflow while in flight and reorient the quadrotor toward the airflow. Several trials with random starting locations and orientations were used to show that our source-seeking algorithm can reliably find a flow source. This work aims to provide a foundation for future platforms that can use flow sensors in concert with other sensors to enable richer plume tracking data collection and source-seeking.

</details>


### [77] [AION: Aerial Indoor Object-Goal Navigation Using Dual-Policy Reinforcement Learning](https://arxiv.org/abs/2601.15614)
*Zichen Yan,Yuchen Hou,Shenao Wang,Yichao Gao,Rui Huang,Lin Zhao*

Main category: cs.RO

TL;DR: AION是一个用于空中物体目标导航的端到端双策略强化学习框架，将探索和到达目标行为解耦为两个专门策略，在AI2-THOR基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 虽然现有研究主要关注2D移动的零样本物体导航，但将其扩展到具有3D移动能力的空中平台仍未被充分探索。空中机器人具有优越的机动性和搜索效率，但也带来了空间感知、动态控制和安全保障方面的新挑战。

Method: 提出了AION框架，这是一个端到端的双策略强化学习系统，将探索和到达目标两种行为解耦为两个专门化的策略，不依赖外部定位或全局地图。

Result: 在AI2-THOR基准测试中表现出色，在探索、导航效率和安全性等综合评估指标上都取得了优越性能，并在IsaacSim中使用高保真无人机模型验证了实时性能。

Conclusion: AION成功解决了空中物体目标导航的挑战，通过解耦探索和到达目标策略实现了高效、安全的导航，为无人机自主导航提供了有效的解决方案。

Abstract: Object-Goal Navigation (ObjectNav) requires an agent to autonomously explore an unknown environment and navigate toward target objects specified by a semantic label. While prior work has primarily studied zero-shot ObjectNav under 2D locomotion, extending it to aerial platforms with 3D locomotion capability remains underexplored. Aerial robots offer superior maneuverability and search efficiency, but they also introduce new challenges in spatial perception, dynamic control, and safety assurance. In this paper, we propose AION for vision-based aerial ObjectNav without relying on external localization or global maps. AION is an end-to-end dual-policy reinforcement learning (RL) framework that decouples exploration and goal-reaching behaviors into two specialized policies. We evaluate AION on the AI2-THOR benchmark and further assess its real-time performance in IsaacSim using high-fidelity drone models. Experimental results show that AION achieves superior performance across comprehensive evaluation metrics in exploration, navigation efficiency, and safety. The video can be found at https://youtu.be/TgsUm6bb7zg.

</details>


### [78] [D-Optimality-Guided Reinforcement Learning for Efficient Open-Loop Calibration of a 3-DOF Ankle Rehabilitation Robot](https://arxiv.org/abs/2601.15707)
*Qifan Hu,Branko Celler,Weidong Mu,Steven W. Su*

Main category: cs.RO

TL;DR: 提出一个两阶段校准框架，用于三自由度踝关节康复机器人，通过D-最优性准则和PPO强化学习选择最优校准姿态，显著提高校准效率和参数估计精度。


<details>
  <summary>Details</summary>
Motivation: 多自由度康复机器人的精确对齐对于安全有效的患者训练至关重要，但现有校准方法效率低下，需要开发更高效的校准框架。

Method: 1. 开发基于Kronecker积的开环校准方法，将输入-输出对齐转化为线性参数识别问题；2. 将校准姿态选择建模为组合实验设计问题，采用D-最优性准则；3. 使用PPO强化学习代理从50个候选姿态中选择4个信息量最大的姿态。

Result: PPO选择的姿态组合比随机选择的信息矩阵行列式均值高出两个数量级以上，方差更低；仅用4个D-最优姿态识别的参数向量比50个非结构化姿态具有更强的跨会话预测一致性。

Conclusion: 该框架在保持稳健参数估计的同时提高了校准效率，为多自由度康复机器人的高精度对齐提供了实用指导。

Abstract: Accurate alignment of multi-degree-of-freedom rehabilitation robots is essential for safe and effective patient training. This paper proposes a two-stage calibration framework for a self-designed three-degree-of-freedom (3-DOF) ankle rehabilitation robot. First, a Kronecker-product-based open-loop calibration method is developed to cast the input-output alignment into a linear parameter identification problem, which in turn defines the associated experimental design objective through the resulting information matrix. Building on this formulation, calibration posture selection is posed as a combinatorial design-of-experiments problem guided by a D-optimality criterion, i.e., selecting a small subset of postures that maximises the determinant of the information matrix. To enable practical selection under constraints, a Proximal Policy Optimization (PPO) agent is trained in simulation to choose 4 informative postures from a candidate set of 50. Across simulation and real-robot evaluations, the learned policy consistently yields substantially more informative posture combinations than random selection: the mean determinant of the information matrix achieved by PPO is reported to be more than two orders of magnitude higher with reduced variance. In addition, real-world results indicate that a parameter vector identified from only four D-optimality-guided postures provides stronger cross-episode prediction consistency than estimates obtained from a larger but unstructured set of 50 postures. The proposed framework therefore improves calibration efficiency while maintaining robust parameter estimation, offering practical guidance for high-precision alignment of multi-DOF rehabilitation robots.

</details>


### [79] [DualShield: Safe Model Predictive Diffusion via Reachability Analysis for Interactive Autonomous Driving](https://arxiv.org/abs/2601.15729)
*Rui Yang,Lei Zheng,Ruoyu Yao,Jun Ma*

Main category: cs.RO

TL;DR: DualShield是一个利用Hamilton-Jacobi可达性值函数实现双重保护的规划控制框架，既作为扩散模型去噪过程的主动引导，又作为反应式安全屏障，在保持扩散模型丰富探索能力的同时提供安全保证。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在自动驾驶多模态运动规划中表现出色，但存在两个主要问题：难以强制执行车辆动力学约束，以及严重依赖对其他智能体的准确预测，在不确定交互下容易引发安全问题。

Method: 引入DualShield框架，利用Hamilton-Jacobi可达性值函数实现双重保护：1) 作为主动引导，将扩散去噪过程导向安全且动力学可行的区域；2) 作为反应式安全屏障，使用控制屏障值函数修改执行动作以确保安全。

Result: 在具有挑战性的无保护U型转弯场景模拟中，DualShield相比不同规划范式的主流方法，在不确定条件下显著提高了安全性和任务效率。

Conclusion: DualShield框架成功结合了扩散模型的丰富探索能力和Hamilton-Jacobi可达性分析的理论安全保证，解决了扩散模型在实际部署中的安全性和动力学可行性问题。

Abstract: Diffusion models have emerged as a powerful approach for multimodal motion planning in autonomous driving. However, their practical deployment is typically hindered by the inherent difficulty in enforcing vehicle dynamics and a critical reliance on accurate predictions of other agents, making them prone to safety issues under uncertain interactions. To address these limitations, we introduce DualShield, a planning and control framework that leverages Hamilton-Jacobi (HJ) reachability value functions in a dual capacity. First, the value functions act as proactive guidance, steering the diffusion denoising process towards safe and dynamically feasible regions. Second, they form a reactive safety shield using control barrier-value functions (CBVFs) to modify the executed actions and ensure safety. This dual mechanism preserves the rich exploration capabilities of diffusion models while providing principled safety assurance under uncertain and even adversarial interactions. Simulations in challenging unprotected U-turn scenarios demonstrate that DualShield significantly improves both safety and task efficiency compared to leading methods from different planning paradigms under uncertainty.

</details>


### [80] [Glove2UAV: A Wearable IMU-Based Glove for Intuitive Control of UAV](https://arxiv.org/abs/2601.15775)
*Amir Habel,Ivan Snegirev,Elizaveta Semenyakina,Miguel Altamirano Cabrera,Jeffrin Sam,Fawad Mehboob,Roohan Ahmed Khan,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: Glove2UAV是一个可穿戴IMU手套接口，通过手势控制无人机，并利用振动触觉警告速度超限，实现直观的无人机控制。


<details>
  <summary>Details</summary>
Motivation: 开发一个轻量级、易于部署的可穿戴接口，用于实现直观的无人机手势控制，并通过触觉反馈提升动态飞行中的安全性和可预测性。

Method: 使用IMU手套实时采集惯性测量数据，通过中值滤波去除异常值和Madgwick算法估计手掌和手指方向，将运动估计映射为飞行控制基本指令，并通过振动触觉反馈提供速度超限警告。

Result: 在模拟和真实飞行中验证了实时可行性，结果显示快速的手势命令执行、手势动态与平台运动的稳定耦合、核心命令集的正确操作，以及振动警告的及时传递。

Conclusion: Glove2UAV提供了一个有效的手势控制无人机接口，结合触觉反馈增强了操作安全性和直观性，为可穿戴无人机控制提供了实用解决方案。

Abstract: This paper presents Glove2UAV, a wearable IMU-glove interface for intuitive UAV control through hand and finger gestures, augmented with vibrotactile warnings for exceeding predefined speed thresholds. To promote safer and more predictable interaction in dynamic flight, Glove2UAV is designed as a lightweight and easily deployable wearable interface intended for real-time operation. Glove2UAV streams inertial measurements in real time and estimates palm and finger orientations using a compact processing pipeline that combines median-based outlier suppression with Madgwick-based orientation estimation. The resulting motion estimations are mapped to a small set of control primitives for directional flight (forward/backward and lateral motion) and, when supported by the platform, to object-interaction commands. Vibrotactile feedback is triggered when flight speed exceeds predefined threshold values, providing an additional alert channel during operation. We validate real-time feasibility by synchronizing glove signals with UAV telemetry in both simulation and real-world flights. The results show fast gesture-based command execution, stable coupling between gesture dynamics and platform motion, correct operation of the core command set in our trials, and timely delivery of vibratile warning cues.

</details>


### [81] [A Beacon Based Solution for Autonomous UUVs GNSS-Denied Stealthy Navigation](https://arxiv.org/abs/2601.15802)
*Alexandre Albore,Humbert Fiorino,Damien Pellier*

Main category: cs.RO

TL;DR: 该论文提出了一种在GNSS拒止环境下，利用空中或水面无人机部署信标网络，为无人水下航行器(UUV)舰队提供隐蔽导航的系统。


<details>
  <summary>Details</summary>
Motivation: 在沿海区域进行军事和民用隐蔽行动时，UUV无法依赖支援船只或GNSS系统。当水面通道不可用且需要在受限环境（如保护区或危险区域）进行隐蔽导航时，GNSS拒止导航至关重要，因为浮出水面会暴露UUV。

Method: 通过空中或水面无人机部署信标星座网络，建立合成地标网络。这些信标（沉没或漂浮）发射声学信号用于UUV定位和导航。采用分层规划器生成自适应路线，无人机执行原始动作，同时持续监控并在需要时重新规划以保持轨迹精度。

Result: 系统能够在GNSS拒止环境下为UUV舰队提供从大陆架到岸上目标的优化路径导航，实现隐蔽、精确的定位和导航能力。

Conclusion: 该研究提出了一种有效的UUV隐蔽导航解决方案，通过部署信标网络和自适应路径规划，解决了GNSS拒止环境下的导航挑战，适用于军事和民用的隐蔽沿海行动。

Abstract: Autonomous Unmanned Underwater Vehicles (UUVs) enable military and civilian covert operations in coastal areas without relying on support vessels or Global Navigation Satellite Systems (GNSS). Such operations are critical when surface access is not possible and stealthy navigation is required in restricted environments such as protected zones or dangerous areas under access ban. GNSS denied navigation is then essential to maintaining concealment as surfacing could expose UUVs to detection. To ensure a precise fleet positioning a constellation of beacons deployed by aerial or surface drones establish a synthetic landmark network that will guide the fleet of UUVs along an optimized path from the continental shelf to the goal on the shore. These beacons either submerged or floating emit acoustic signals for UUV localisation and navigation. A hierarchical planner generates an adaptive route for the drones executing primitive actions while continuously monitoring and replanning as needed to maintain trajectory accuracy.

</details>


### [82] [TeNet: Text-to-Network for Compact Policy Synthesis](https://arxiv.org/abs/2601.15912)
*Ariyan Bighashdel,Kevin Sebastian Luck*

Main category: cs.RO

TL;DR: TeNet框架利用大语言模型文本嵌入生成紧凑的实时机器人策略，仅在策略实例化时使用语言，实现高效控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法要么依赖高层手工设计接口，要么使用难以实时部署的大型端到端模型的问题，需要更实用的语言驱动机器人控制方案。

Method: 使用超网络架构，通过预训练大语言模型产生的文本嵌入来生成完全可执行的策略，策略仅操作低维状态输入；训练时可选择性地通过对齐文本嵌入与演示动作来增强泛化。

Result: 在MuJoCo和Meta-World基准测试中，TeNet生成的策略比序列基线小几个数量级，在多任务和元学习设置中表现强劲，支持高频控制。

Conclusion: 文本条件超网络为资源受限、需要实时响应的机器人控制任务提供了构建紧凑、语言驱动控制器的实用方法。

Abstract: Robots that follow natural-language instructions often either plan at a high level using hand-designed interfaces or rely on large end-to-end models that are difficult to deploy for real-time control. We propose TeNet (Text-to-Network), a framework for instantiating compact, task-specific robot policies directly from natural language descriptions. TeNet conditions a hypernetwork on text embeddings produced by a pretrained large language model (LLM) to generate a fully executable policy, which then operates solely on low-dimensional state inputs at high control frequencies. By using the language only once at the policy instantiation time, TeNet inherits the general knowledge and paraphrasing robustness of pretrained LLMs while remaining lightweight and efficient at execution time. To improve generalization, we optionally ground language in behavior during training by aligning text embeddings with demonstrated actions, while requiring no demonstrations at inference time. Experiments on MuJoCo and Meta-World benchmarks show that TeNet produces policies that are orders of magnitude smaller than sequence-based baselines, while achieving strong performance in both multi-task and meta-learning settings and supporting high-frequency control. These results show that text-conditioned hypernetworks offer a practical way to build compact, language-driven controllers for ressource-constrained robot control tasks with real-time requirements.

</details>


### [83] [Accurate Calibration and Robust LiDAR-Inertial Odometry for Spinning Actuated LiDAR Systems](https://arxiv.org/abs/2601.15946)
*Zijie Chen,Xiaowei Liu,Yong Xu,Shenghai Yuan,Jianping Li,Lihua Xie*

Main category: cs.RO

TL;DR: 该论文提出了LM-Calibr标定方法和EVA-LIO自适应定位方法，解决了旋转驱动LiDAR系统的通用标定和无特征区域鲁棒定位问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要针对不同安装配置参数化外参，泛化性有限；旋转驱动LiDAR不可避免会扫描无特征区域，难以平衡扫描覆盖率和定位鲁棒性。

Method: 1. LM-Calibr：基于Denavit-Hartenberg约定的无目标LiDAR-电机标定方法，支持多种安装配置；2. EVA-LIO：根据空间尺度自适应选择下采样率和地图分辨率的环境自适应LiDAR惯性里程计。

Result: LM-Calibr在不同场景、安装角度和初始值下均表现出高精度和收敛性；EVA-LIO使执行器能以最大速度运行，增强扫描完整性，同时在LiDAR短暂扫描无特征区域时确保鲁棒定位。

Conclusion: 提出的方法解决了旋转驱动LiDAR系统的通用标定和鲁棒定位问题，提高了系统的实用性和性能，代码和硬件设计已开源。

Abstract: Accurate calibration and robust localization are fundamental for downstream tasks in spinning actuated LiDAR applications. Existing methods, however, require parameterizing extrinsic parameters based on different mounting configurations, limiting their generalizability. Additionally, spinning actuated LiDAR inevitably scans featureless regions, which complicates the balance between scanning coverage and localization robustness. To address these challenges, this letter presents a targetless LiDAR-motor calibration (LM-Calibr) on the basis of the Denavit-Hartenberg convention and an environmental adaptive LiDAR-inertial odometry (EVA-LIO). LM-Calibr supports calibration of LiDAR-motor systems with various mounting configurations. Extensive experiments demonstrate its accuracy and convergence across different scenarios, mounting angles, and initial values. Additionally, EVA-LIO adaptively selects downsample rates and map resolutions according to spatial scale. This adaptivity enables the actuator to operate at maximum speed, thereby enhancing scanning completeness while ensuring robust localization, even when LiDAR briefly scans featureless areas. The source code and hardware design are available on GitHub: \textcolor{blue}{\href{https://github.com/zijiechenrobotics/lm_calibr}{github.com/zijiechenrobotics/lm\_calibr}}. The video is available at \textcolor{blue}{\href{https://youtu.be/cZyyrkmeoSk}{youtu.be/cZyyrkmeoSk}}

</details>


### [84] [PUMA: Perception-driven Unified Foothold Prior for Mobility Augmented Quadruped Parkour](https://arxiv.org/abs/2601.15995)
*Liang Wang,Kanzhong Yao,Yang Liu,Weikai Qin,Jun Wu,Zhe Sun,Qiuguo Zhu*

Main category: cs.RO

TL;DR: PUMA是一个用于四足机器人跑酷任务的端到端学习框架，通过视觉感知和立足点先验的单阶段训练，实现机器人在复杂地形中的敏捷运动。


<details>
  <summary>Details</summary>
Motivation: 人类运动员能有效感知环境特征选择合适立足点，但赋予腿式机器人类似感知能力仍具挑战。现有方法依赖分层控制器和预计算立足点，限制了机器人的实时适应性和强化学习的探索潜力。

Method: 提出PUMA端到端学习框架，将视觉感知和立足点先验整合到单阶段训练中。利用地形特征估计自我中心极坐标立足点先验（相对距离和方向），指导机器人进行主动姿态适应。

Result: 在模拟和真实环境的各种离散复杂地形中进行广泛实验，证明PUMA在挑战性场景中具有卓越的敏捷性和鲁棒性。

Conclusion: PUMA通过端到端学习成功解决了四足机器人跑酷任务中的感知和适应问题，展示了在复杂地形中实现敏捷运动的潜力。

Abstract: Parkour tasks for quadrupeds have emerged as a promising benchmark for agile locomotion. While human athletes can effectively perceive environmental characteristics to select appropriate footholds for obstacle traversal, endowing legged robots with similar perceptual reasoning remains a significant challenge. Existing methods often rely on hierarchical controllers that follow pre-computed footholds, thereby constraining the robot's real-time adaptability and the exploratory potential of reinforcement learning. To overcome these challenges, we present PUMA, an end-to-end learning framework that integrates visual perception and foothold priors into a single-stage training process. This approach leverages terrain features to estimate egocentric polar foothold priors, composed of relative distance and heading, guiding the robot in active posture adaptation for parkour tasks. Extensive experiments conducted in simulation and real-world environments across various discrete complex terrains, demonstrate PUMA's exceptional agility and robustness in challenging scenarios.

</details>


### [85] [Collision-Free Humanoid Traversal in Cluttered Indoor Scenes](https://arxiv.org/abs/2601.16035)
*Han Xue,Sikai Liang,Zhikai Zhang,Zicheng Zeng,Yun Liu,Yunrui Lian,Jilong Wang,Qingtao Liu,Xuesong Shi,Li Yi*

Main category: cs.RO

TL;DR: 提出HumanoidPF表示方法，通过编码人形机器人与障碍物的碰撞规避关系，促进RL学习复杂室内环境中的穿越技能，实现从仿真到现实的低差距迁移。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在杂乱室内场景（如跨越障碍、蹲行通过、挤过窄道）中无碰撞穿越的问题。现有方法缺乏有效表示人形机器人与障碍物在避碰中的关系，导致难以直接学习相应的穿越技能映射。

Method: 提出Humanoid Potential Field (HumanoidPF)表示方法，将人形机器人与障碍物的关系编码为无碰撞运动方向，显著促进基于强化学习的穿越技能学习。同时提出混合场景生成方法，结合真实3D室内场景片段和程序化合成障碍物，以生成多样且具挑战性的训练环境。

Result: HumanoidPF作为感知表示表现出惊人的低仿真-现实差距。成功将策略迁移到现实世界，并开发了遥操作系统，用户只需单次点击即可指挥人形机器人在杂乱室内场景中穿越。在仿真和现实世界中进行了广泛实验验证方法有效性。

Conclusion: HumanoidPF有效解决了人形机器人在复杂室内环境中无碰撞穿越的表示学习问题，实现了从仿真到现实的低差距迁移，并提供了实用的遥操作系统，为人形机器人在现实世界中的应用提供了重要进展。

Abstract: We study the problem of collision-free humanoid traversal in cluttered indoor scenes, such as hurdling over objects scattered on the floor, crouching under low-hanging obstacles, or squeezing through narrow passages. To achieve this goal, the humanoid needs to map its perception of surrounding obstacles with diverse spatial layouts and geometries to the corresponding traversal skills. However, the lack of an effective representation that captures humanoid-obstacle relationships during collision avoidance makes directly learning such mappings difficult. We therefore propose Humanoid Potential Field (HumanoidPF), which encodes these relationships as collision-free motion directions, significantly facilitating RL-based traversal skill learning. We also find that HumanoidPF exhibits a surprisingly negligible sim-to-real gap as a perceptual representation. To further enable generalizable traversal skills through diverse and challenging cluttered indoor scenes, we further propose a hybrid scene generation method, incorporating crops of realistic 3D indoor scenes and procedurally synthesized obstacles. We successfully transfer our policy to the real world and develop a teleoperation system where users could command the humanoid to traverse in cluttered indoor scenes with just a single click. Extensive experiments are conducted in both simulation and the real world to validate the effectiveness of our method. Demos and code can be found in our website: https://axian12138.github.io/CAT/.

</details>


### [86] [DextER: Language-driven Dexterous Grasp Generation with Embodied Reasoning](https://arxiv.org/abs/2601.16046)
*Junha Lee,Eunha Park,Minsu Cho*

Main category: cs.RO

TL;DR: DextER提出了一种基于接触推理的灵巧抓取生成方法，通过预测手部链接与物体表面的接触点作为中间表示，显著提升了任务语义理解与物理约束的结合能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型的灵巧抓取生成方法直接映射观察结果到抓取参数，缺乏对物理交互的中间推理过程。这限制了模型对任务语义、3D几何和复杂手-物体交互的理解能力。

Method: DextER采用接触驱动的具身推理方法，分两个阶段生成抓取：首先自回归生成具身接触标记，指定哪些手指链接接触物体表面的哪些位置；然后生成编码手部配置的抓取标记。

Result: 在DexGYS数据集上，DextER实现了67.14%的成功率，比现有最佳方法提升了3.83个百分点，任务意图对齐度提高了96.4%。此外，该方法支持通过部分接触规范进行可控生成。

Conclusion: 基于接触的具身推理为灵巧抓取生成提供了有效的中间表示，成功桥接了任务语义与物理约束，实现了更准确、可控的抓取生成，显著超越了现有方法。

Abstract: Language-driven dexterous grasp generation requires the models to understand task semantics, 3D geometry, and complex hand-object interactions. While vision-language models have been applied to this problem, existing approaches directly map observations to grasp parameters without intermediate reasoning about physical interactions. We present DextER, Dexterous Grasp Generation with Embodied Reasoning, which introduces contact-based embodied reasoning for multi-finger manipulation. Our key insight is that predicting which hand links contact where on the object surface provides an embodiment-aware intermediate representation bridging task semantics with physical constraints. DextER autoregressively generates embodied contact tokens specifying which finger links contact where on the object surface, followed by grasp tokens encoding the hand configuration. On DexGYS, DextER achieves 67.14% success rate, outperforming state-of-the-art by 3.83%p with 96.4% improvement in intention alignment. We also demonstrate steerable generation through partial contact specification, providing fine-grained control over grasp synthesis.

</details>


### [87] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Theoretical Analysis](https://arxiv.org/abs/2601.16062)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文分析了SE2(3)李群框架在导航建模中的自主误差传播特性，发现在考虑地球旋转和惯性器件偏差的高精度导航中难以保持自主性，并提出了一种新的建模方法以接近完全自主。


<details>
  <summary>Details</summary>
Motivation: 现有SE2(3)李群框架在低精度导航（如MEMS集成导航）中已证明具有误差传播自主性，但在考虑地球旋转和惯性器件偏差的高精度导航状态下，保持自主性极为困难。需要解决非惯性系中由速度引入的科里奥利力项带来的限制。

Method: 1) 分别在惯性系、地球系和世界系下对SE2(3)群高精度导航模型进行自主性理论分析；2) 识别传统SE2(3)群导航建模方法的局限性（科里奥利力项问题）；3) 提出一种新的SE2(3)群导航模型构建方法，使导航模型更接近完全自主。

Result: 理论分析发现传统SE2(3)群导航建模方法的局限性在于非惯性系中速度引入的科里奥利力项。通过提出的新构建方法，导航模型能够更接近完全自主状态。

Conclusion: SE2(3)李群框架在高精度导航中面临自主性挑战，主要源于非惯性系中的科里奥利力项。提出的新建模方法能够显著提升导航模型的自主性，为高精度导航状态估计提供了改进方案。

Abstract: One of core advantages of the SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. Current research on Lie group based extended Kalman filters has demonstrated that error propagation autonomy holds in low-precision applications, such as in micro electromechanical system (MEMS) based integrated navigation without considering earth rotation and inertial device biases. However, in high-precision navigation state estimation, maintaining autonomy is extremely difficult when considering with earth rotation and inertial device biases. This paper presents the theoretical analysis on the autonomy of SE2(3) group based high-precision navigation models under inertial, earth and world frame respectively. Through theoretical analysis, we find that the limitation of the traditional, trivial SE2(3) group navigation modeling method is that the presence of Coriolis force terms introduced by velocity in non-inertial frame. Therefore, a construction method for SE2(3) group navigation models is proposed, which brings the navigation models closer to full autonomy.

</details>


### [88] [Improve the autonomy of the SE2(3) group based Extended Kalman Filter for Integrated Navigation: Application](https://arxiv.org/abs/2601.16078)
*Jiarui Cui,Maosong Wang,Wenqi Wu,Peiqi Li,Xianfei Pan*

Main category: cs.RO

TL;DR: 本文通过实际SINS/ODO实验和蒙特卡洛仿真，验证了改进的SE2(3)群导航模型的高精度性能，补充了前文的理论分析。


<details>
  <summary>Details</summary>
Motivation: SE2(3)李群框架在导航建模中的核心优势在于误差传播的自主性。前文已从理论上分析了惯性系、地球系和世界系中导航模型的自主性特性，并提出了改进非惯性导航模型以实现完全自主性的SE2(3)群导航模型构建方法。本文作为前文的补充，需要通过实际实验验证该改进模型的实际性能。

Method: 1. 采用改进的SE2(3)群高精度导航模型；2. 进行真实世界的捷联惯性导航系统(SINS)/里程计(ODO)实验；3. 进行蒙特卡洛仿真分析。

Result: 通过实际实验和仿真验证了改进的SE2(3)群导航模型的高精度性能，证明了该模型在实际应用中的有效性。

Conclusion: 改进的SE2(3)群导航模型在实际应用中表现出优异的性能，验证了前文理论分析的正确性，为高精度导航系统提供了有效的建模方法。

Abstract: One of the core advantages of SE2(3) Lie group framework for navigation modeling lies in the autonomy of error propagation. In the previous paper, the theoretical analysis of autonomy property of navigation model in inertial, earth and world frames was given. A construction method for SE2(3) group navigation model is proposed to improve the non-inertial navigation model toward full autonomy. This paper serves as a counterpart to previous paper and conducts the real-world strapdown inertial navigation system (SINS)/odometer(ODO) experiments as well as Monte-Carlo simulations to demonstrate the performance of improved SE2(3) group based high-precision navigation models.

</details>


### [89] [Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision](https://arxiv.org/abs/2601.16109)
*Yashuai Yan,Tobias Egle,Christian Ott,Dongheui Lee*

Main category: cs.RO

TL;DR: 提出结合模型控制与残差强化学习的双足机器人控制框架，通过模型基控制器作为基础策略，用带领域随机化的RL训练残差策略，并引入特权监督机制提高学习效率，实现鲁棒的自适应行走。


<details>
  <summary>Details</summary>
Motivation: 解决双足机器人在真实世界中面临的不确定性挑战，包括动力学建模不准确和传感器噪声等问题，提高行走的鲁棒性和适应性。

Method: 整合模型基双足运动控制与残差强化学习：1）使用DCM轨迹规划器和全身控制器作为基础策略；2）通过带领域随机化的RL训练残差策略；3）引入特权监督机制，利用能访问真实动力学的模型基oracle策略监督残差策略学习。

Result: 方法在多种随机化条件下表现出更好的鲁棒性和泛化能力，为双足机器人的仿真到现实迁移提供了可扩展的解决方案。

Conclusion: 该框架通过结合模型控制与残差学习，有效补偿未建模效应，减少奖励工程需求，为应对真实世界不确定性的双足机器人控制提供了高效解决方案。

Abstract: We propose a control framework that integrates model-based bipedal locomotion with residual reinforcement learning (RL) to achieve robust and adaptive walking in the presence of real-world uncertainties. Our approach leverages a model-based controller, comprising a Divergent Component of Motion (DCM) trajectory planner and a whole-body controller, as a reliable base policy. To address the uncertainties of inaccurate dynamics modeling and sensor noise, we introduce a residual policy trained through RL with domain randomization. Crucially, we employ a model-based oracle policy, which has privileged access to ground-truth dynamics during training, to supervise the residual policy via a novel supervised loss. This supervision enables the policy to efficiently learn corrective behaviors that compensate for unmodeled effects without extensive reward shaping. Our method demonstrates improved robustness and generalization across a range of randomized conditions, offering a scalable solution for sim-to-real transfer in bipedal locomotion.

</details>


### [90] [IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance](https://arxiv.org/abs/2601.16207)
*Jongwoo Park,Kanchana Ranasinghe,Jinhyeok Jang,Cristina Mata,Yoo Sung Jang,Michael S Ryoo*

Main category: cs.RO

TL;DR: IVRA是一种轻量级、无需训练的方法，通过利用视觉编码器内置的亲和性提示，改善VLA模型的空间理解能力，提升机器人操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前Vision-Language-Action模型将图像块展平为1D token序列，削弱了精确操作所需的2D空间线索，需要更好的空间理解方法。

Method: IVRA通过选择性注入视觉编码器中的亲和性信号到语言模型层，在推理时重新对齐视觉token交互，保持几何结构，所有模型参数保持不变。

Result: 在2D VIMA基准测试中，IVRA比基线LLaRA平均成功率提升+4.2%；在3D LIBERO基准测试中，对OpenVLA和FLOWER基线均带来一致提升，包括从96.3%到97.1%的饱和性能改进。

Conclusion: IVRA作为一种无需训练、轻量级的推理时干预方法，能有效改善多种VLA架构的空间理解能力，在模拟和真实机器人任务中均表现出显著性能提升。

Abstract: Many Vision-Language-Action (VLA) models flatten image patches into a 1D token sequence, weakening the 2D spatial cues needed for precise manipulation. We introduce IVRA, a lightweight, training-free method that improves spatial understanding by exploiting affinity hints already available in the model's built-in vision encoder, without requiring any external encoder or retraining. IVRA selectively injects these affinity signals into a language-model layer in which instance-level features reside. This inference-time intervention realigns visual-token interactions and better preserves geometric structure while keeping all model parameters fixed. We demonstrate the generality of IVRA by applying it to diverse VLA architectures (LLaRA, OpenVLA, and FLOWER) across simulated benchmarks spanning both 2D and 3D manipulation (VIMA and LIBERO) and on various real-robot tasks. On 2D VIMA, IVRA improves average success by +4.2% over the baseline LLaRA in a low-data regime. On 3D LIBERO, it yields consistent gains over the OpenVLA and FLOWER baselines, including improvements when baseline accuracy is near saturation (96.3% to 97.1%). All code and models will be released publicly. Visualizations are available at: jongwoopark7978.github.io/IVRA

</details>


### [91] [Point Bridge: 3D Representations for Cross Domain Policy Learning](https://arxiv.org/abs/2601.16212)
*Siddhant Haldar,Lars Johannsmeier,Lerrel Pinto,Abhishek Gupta,Dieter Fox,Yashraj Narang,Ajay Mandlekar*

Main category: cs.RO

TL;DR: Point Bridge 框架利用统一的点云表示实现零样本仿真到现实的策略迁移，无需视觉或对象级对齐，通过合成数据训练真实世界机器人操作能力。


<details>
  <summary>Details</summary>
Motivation: 机器人基础模型需要大规模真实世界操作数据，但这类数据稀缺。仿真和合成数据生成虽然可扩展，但受限于仿真与现实之间的视觉领域差距。

Method: 结合视觉语言模型自动提取点云表示、基于Transformer的策略学习，以及高效的推理时流水线，仅使用合成数据训练真实世界操作智能体。还可通过少量真实演示数据进行协同训练进一步提升性能。

Result: 在零样本仿真到现实迁移中实现高达44%的性能提升，结合少量真实数据时提升高达66%。在单任务和多任务设置中均优于之前的视觉基仿真与真实协同训练方法。

Conclusion: Point Bridge 通过领域无关的点云表示有效解决了仿真与现实之间的视觉领域差距问题，为仅使用合成数据训练真实世界机器人操作智能体提供了可行方案。

Abstract: Robot foundation models are beginning to deliver on the promise of generalist robotic agents, yet progress remains constrained by the scarcity of large-scale real-world manipulation datasets. Simulation and synthetic data generation offer a scalable alternative, but their usefulness is limited by the visual domain gap between simulation and reality. In this work, we present Point Bridge, a framework that leverages unified, domain-agnostic point-based representations to unlock synthetic datasets for zero-shot sim-to-real policy transfer, without explicit visual or object-level alignment. Point Bridge combines automated point-based representation extraction via Vision-Language Models (VLMs), transformer-based policy learning, and efficient inference-time pipelines to train capable real-world manipulation agents using only synthetic data. With additional co-training on small sets of real demonstrations, Point Bridge further improves performance, substantially outperforming prior vision-based sim-and-real co-training methods. It achieves up to 44% gains in zero-shot sim-to-real transfer and up to 66% with limited real data across both single-task and multitask settings. Videos of the robot are best viewed at: https://pointbridge3d.github.io/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [92] [Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference](https://arxiv.org/abs/2601.15333)
*Xuanning Hu,Anchen Li,Qianli Xing,Jinglong Ji,Hao Tuo,Bo Yang*

Main category: cs.LG

TL;DR: ELILLM框架将LLM生成过程重新解释为编码、隐空间探索和解码流程，通过贝叶斯优化引导探索未知区域，知识引导解码确保化学有效性，在药物设计任务中表现优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型具有强大的表示和推理能力，但在基于结构的药物设计中应用受限，主要因为对蛋白质结构理解不足和分子生成不可预测。

Method: 提出ELILLM框架：1) 将LLM生成过程重新解释为编码、隐空间探索和解码流程；2) 使用贝叶斯优化系统探索隐空间嵌入；3) 位置感知代理模型预测结合亲和力分布；4) 知识引导解码减少随机性并保证化学有效性。

Result: 在CrossDocked2020基准测试中，ELILLM表现出强大的受控探索能力和高结合亲和力评分，优于七种基准方法。

Conclusion: ELILLM能够有效增强大语言模型在基于结构的药物设计中的能力，通过系统探索未知区域和知识引导解码，生成化学有效且合成合理的分子。

Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.

</details>


### [93] [Language Models Entangle Language and Culture](https://arxiv.org/abs/2601.15337)
*Shourya Jain,Paras Chopra*

Main category: cs.LG

TL;DR: 研究发现大型语言模型在不同语言间的回答质量存在差异，低资源语言用户获得较低质量回答，且语言选择影响模型使用的文化背景信息。


<details>
  <summary>Details</summary>
Motivation: 用户不应因其使用的交互语言而在LLM使用中处于系统性劣势，所有语言用户都应获得相似质量的回答。当前需要评估LLM是否因查询语言不同而提供不同质量的回答，以及语言和文化如何相互影响。

Method: 基于WildChat数据集分析创建真实世界的开放式问题集；使用LLM-as-a-Judge方法识别回答中的文化背景；在多个语言上评估CulturalBench基准的翻译子集。

Result: LLM在低资源语言的开放式问题上提供较低质量的回答；语言显著影响模型使用的文化背景；这种文化背景差异影响下游回答的质量。

Conclusion: 语言选择确实影响LLM回答质量和文化背景，低资源语言用户面临系统性劣势，需要改进LLM的多语言公平性。

Abstract: Users should not be systemically disadvantaged by the language they use for interacting with LLMs; i.e. users across languages should get responses of similar quality irrespective of language used. In this work, we create a set of real-world open-ended questions based on our analysis of the WildChat dataset and use it to evaluate whether responses vary by language, specifically, whether answer quality depends on the language used to query the model. We also investigate how language and culture are entangled in LLMs such that choice of language changes the cultural information and context used in the response by using LLM-as-a-Judge to identify the cultural context present in responses. To further investigate this, we evaluate LLMs on a translated subset of the CulturalBench benchmark across multiple languages. Our evaluations reveal that LLMs consistently provide lower quality answers to open-ended questions in low resource languages. We find that language significantly impacts the cultural context used by the model. This difference in context impacts the quality of the downstream answer.

</details>


### [94] [Improving MoE Compute Efficiency by Composing Weight and Data Sparsity](https://arxiv.org/abs/2601.15370)
*Maciej Kilian,Oleg Mkrtchyan,Luke Zettlemoyer,Akshat Shrivastava,Armen Aghajanyan*

Main category: cs.LG

TL;DR: 本文提出了一种在因果token-choice MoE中实现数据稀疏性的方法，通过引入零计算（null）专家来创建数据稀疏性，同时避免自回归模型中的因果性违反问题。


<details>
  <summary>Details</summary>
Motivation: 现有MoE层主要通过权重稀疏性（每个token只激活部分专家）实现计算效率，但数据稀疏性（每个专家只处理部分token）是另一个潜在的效率维度。专家选择路由直接实现数据稀疏性，但在自回归模型中违反因果性，导致训练-推理不匹配。

Method: 在因果token-choice MoE的路由池中引入零计算（null）专家。当token路由到null专家时，这些槽位不消耗计算。通过标准的负载均衡目标训练模型均匀使用所有专家（真实和null），从而在期望上创建数据稀疏性而不违反因果性。

Result: 在视觉语言模型训练中，组合权重稀疏性和数据稀疏性比单独使用权重稀疏性产生更高效的计算前沿，在训练损失和下游性能上都有提升。模型学习到隐式的模态感知分配，将视觉token更积极地路由到null专家。

Conclusion: 通过引入null专家在因果token-choice MoE中实现数据稀疏性是可行的，避免了专家选择路由的因果性违反问题。这种方法在处理异构数据（如视觉语言模型）时特别有效，模型能够自动学习模态感知的路由策略，提高计算效率。

Abstract: Mixture-of-Experts layers achieve compute efficiency through weight sparsity: each token activates only a subset of experts. Data sparsity, where each expert processes only a subset of tokens, offers a complementary axis. Expert-choice routing implements data sparsity directly but violates causality in autoregressive models, creating train-inference mismatch. We recover data sparsity within causal token-choice MoE by leveraging zero-compute (null) experts within the routing pool. When a token routes to null experts, those slots consume no compute. The standard load balancing objective trains the model to uniformly use all experts (real and null) therefore creating data sparsity in expectation without the causality violations. We evaluate on vision-language model training, where data heterogeneity is pronounced: vision encoders produce many low-information tokens while text tokens are denser. At matched expected FLOPs, composing weight and data sparsity yields a more compute-efficient frontier than weight sparsity alone, with gains in training loss and downstream performance. The model learns implicit modality-aware allocation, routing vision tokens to null experts more aggressively than text, without explicit modality routing.

</details>


### [95] [You Need Better Attention Priors](https://arxiv.org/abs/2601.15380)
*Elon Litman,Gabe Guo*

Main category: cs.LG

TL;DR: 论文提出GOAT：一种基于熵最优运输的广义注意力机制，通过可学习的连续先验替代标准注意力的均匀先验假设，保持FlashAttention兼容性，解决注意力沉没问题，并实现长度泛化。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制隐含地假设了均匀先验分布，这限制了其表达能力。通过熵最优运输视角重新审视注意力，可以发现这种假设的局限性，并需要更灵活的先验建模来提升注意力性能。

Method: 将注意力机制形式化为熵最优运输问题，提出GOAT框架：1）用可学习的连续先验替代均匀先验；2）保持与优化内核（如FlashAttention）的兼容性；3）通过EOT理论解释注意力沉没问题并提供解决方案；4）将空间信息融入核心注意力计算，学习可外推的先验。

Result: GOAT在保持高效计算的同时，解决了注意力沉没问题，避免了标准注意力中的表示权衡，并实现了类似学习位置嵌入的灵活性和固定编码的长度泛化能力。

Conclusion: 通过熵最优运输框架，GOAT提供了更通用的注意力机制，突破了标准注意力的限制，为注意力机制的设计提供了新的理论基础和实践方案。

Abstract: We generalize the attention mechanism by viewing it through the lens of Entropic Optimal Transport, revealing that standard attention corresponds to a transport problem regularized by an implicit uniform prior. We introduce Generalized Optimal transport Attention with Trainable priors (GOAT), a new attention mechanism that replaces this naive assumption with a learnable, continuous prior. This prior maintains full compatibility with optimized kernels such as FlashAttention. GOAT also provides an EOT-based explanation of attention sinks and materializes a solution for them, avoiding the representational trade-offs of standard attention. Finally, by absorbing spatial information into the core attention computation, GOAT learns an extrapolatable prior that combines the flexibility of learned positional embeddings with the length generalization of fixed encodings.

</details>


### [96] [FedUMM: A General Framework for Federated Learning with Unified Multimodal Models](https://arxiv.org/abs/2601.15390)
*Zhaolong Su,Leheng Zhao,Xiaoying Wu,Ziyue Xu,Jindong Wang*

Main category: cs.LG

TL;DR: FedUMM是一个用于统一多模态模型（UMMs）的联邦学习框架，在非独立同分布多模态数据下实现低通信成本训练


<details>
  <summary>Details</summary>
Motivation: 现有统一多模态模型通常在集中式设置中训练，限制了在隐私敏感和地理分布场景中的部署，需要开发隐私保护的联邦学习方案

Method: 基于NVIDIA FLARE构建FedUMM框架，采用参数高效微调方法：客户端训练轻量级LoRA适配器并冻结基础模型，服务器仅聚合适配器更新

Result: 在VQA v2和GenEval基准测试中，随着客户端数量和异质性增加，性能略有下降但仍保持与集中式训练竞争力；适配器联邦将每轮通信减少一个数量级以上

Conclusion: FedUMM为隐私保护的联邦统一多模态模型提供了实用的训练框架和实证经验，展示了在保持性能的同时显著降低通信成本的可能性

Abstract: Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting the deployment in privacy-sensitive and geographically distributed scenarios. In this paper, we present FedUMM, a general federated learning framework for UMMs under non-IID multimodal data with low communication cost. Built on NVIDIA FLARE, FedUMM instantiates federation for a BLIP3o backbone via parameter-efficient fine-tuning: clients train lightweight LoRA adapters while freezing the foundation models, and the server aggregates only adapter updates. We evaluate on VQA v2 and the GenEval compositional generation benchmarks under Dirichlet-controlled heterogeneity with up to 16 clients. Results show slight degradation as client count and heterogeneity increase, while remaining competitive with centralized training. We further analyze computation--communication trade-offs and demonstrate that adapter-only federation reduces per-round communication by over an order of magnitude compared to full fine-tuning, enabling practical federated UMM training. This work provides empirical experience for future research on privacy-preserving federated unified multimodal models.

</details>


### [97] [Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC](https://arxiv.org/abs/2601.15399)
*Ashna Nawar Ahmed,Banooqa Banday,Terry Jones,Tanzima Z. Islam*

Main category: cs.LG

TL;DR: 提出一种基于注意力机制嵌入的替代模型，结合多目标贝叶斯优化，用于HPC调度中节点数量选择的自动化决策，平衡运行时间和功耗。


<details>
  <summary>Details</summary>
Motivation: HPC调度器需要在用户性能和资源约束之间取得平衡，核心挑战是选择作业的最佳节点数量。传统方法难以有效捕捉性能动态，需要更智能的数据驱动方法。

Method: 采用替代辅助的多目标贝叶斯优化框架，使用基于注意力的作业遥测嵌入来构建替代模型，结合智能样本采集策略以提高数据效率。

Result: 在两个生产HPC数据集上，嵌入方法相比基线能识别更高质量的运行时间-功耗帕累托前沿，智能采样策略大幅降低训练成本并提高结果稳定性。

Conclusion: 这是首个成功将嵌入信息替代模型应用于HPC调度问题的多目标贝叶斯优化框架，能联合优化生产工作负载的性能和功耗。

Abstract: High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this complex decision. Our core hypothesis is that surrogate models informed by attention-based embeddings of job telemetry can capture performance dynamics more effectively than standard regression techniques. We pair this with an intelligent sample acquisition strategy to ensure the approach is data-efficient. On two production HPC datasets, our embedding-informed method consistently identified higher-quality Pareto fronts of runtime-power trade-offs compared to baselines. Furthermore, our intelligent data sampling strategy drastically reduced training costs while improving the stability of the results. To our knowledge, this is the first work to successfully apply embedding-informed surrogates in a MOBO framework to the HPC scheduling problem, jointly optimizing for performance and power on production workloads.

</details>


### [98] [Ambient Dataloops: Generative Models for Dataset Refinement](https://arxiv.org/abs/2601.15417)
*Adrián Rodríguez-Muñoz,William Daspit,Adam Klivans,Antonio Torralba,Constantinos Daskalakis,Giannis Daras*

Main category: cs.LG

TL;DR: 提出Ambient Dataloops框架，通过迭代优化数据集质量来提升扩散模型性能，避免自耗循环问题


<details>
  <summary>Details</summary>
Motivation: 现代数据集包含质量差异很大的样本，直接在异构数据上训练通常会产生次优模型

Method: 提出数据集-模型协同进化过程：每轮迭代中，数据集质量逐步提高，模型相应改进；通过将合成改进样本视为噪声（但比前一轮噪声水平略低），并使用Ambient Diffusion技术进行腐蚀学习，避免破坏性自耗循环

Result: 在无条件/文本条件图像生成和蛋白质从头设计中实现最先进性能；为数据循环过程提供了理论依据

Conclusion: Ambient Dataloops框架通过迭代优化数据集质量，有效提升扩散模型在各种任务中的性能

Abstract: We propose Ambient Dataloops, an iterative framework for refining datasets that makes it easier for diffusion models to learn the underlying data distribution. Modern datasets contain samples of highly varying quality, and training directly on such heterogeneous data often yields suboptimal models. We propose a dataset-model co-evolution process; at each iteration of our method, the dataset becomes progressively higher quality, and the model improves accordingly. To avoid destructive self-consuming loops, at each generation, we treat the synthetically improved samples as noisy, but at a slightly lower noisy level than the previous iteration, and we use Ambient Diffusion techniques for learning under corruption. Empirically, Ambient Dataloops achieve state-of-the-art performance in unconditional and text-conditional image generation and de novo protein design. We further provide a theoretical justification for the proposed framework that captures the benefits of the data looping procedure.

</details>


### [99] [Lattice: A Confidence-Gated Hybrid System for Uncertainty-Aware Sequential Prediction with Behavioral Archetypes](https://arxiv.org/abs/2601.15423)
*Lorian Bannis*

Main category: cs.LG

TL;DR: Lattice是一个混合顺序预测系统，通过二元置信度门控有条件地激活学习到的行为结构，在推荐系统、科学时间序列和金融市场等多个领域验证有效。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中管理认知不确定性，需要一种能够智能激活或拒绝使用学习到的行为结构的机制，避免在不确定或分布偏移时产生错误预测。

Method: 系统将行为窗口聚类为行为原型，使用二元置信度门控机制：当置信度超过阈值时激活基于原型的评分，否则回退到基线预测。在LSTM和Transformer骨干网络上验证。

Result: 在MovieLens上，Lattice相比LSTM基线HR@10提升31.9%；在LIGO和金融数据上，系统能正确拒绝原型激活（分布偏移时）；在Transformer骨干上保持中性（0.0%改进），优雅地推迟激活。

Conclusion: 置信度门控是一个有前景的架构原则，能够在适用时激活模式、不适用时拒绝、冗余时推迟，有效管理安全关键应用中的认知不确定性。

Abstract: We introduce Lattice, a hybrid sequential prediction system that conditionally activates learned behavioral structure using binary confidence gating. The system clusters behavior windows into behavioral archetypes and uses binary confidence gating to activate archetype-based scoring only when confidence exceeds a threshold, falling back to baseline predictions when uncertain. We validate Lattice on recommendation systems (MovieLens), scientific time-series (LIGO), and financial markets, using LSTM and transformer backbones. On MovieLens with LSTM, Lattice achieves +31.9% improvement over LSTM baseline in HR@10 (p < 3.29 x 10^-25, 30 seeds), outperforming transformer baselines by 109.4% over SASRec and 218.6% over BERT4Rec. On LIGO and financial data, the system correctly refuses archetype activation when distribution shift occurs - a successful outcome demonstrating confidence gating prevents false activation. On transformer backbones, Lattice provides 0.0% improvement (neutral, no degradation), gracefully deferring when structure is already present. This bidirectional validation - activating when patterns apply, refusing when they don't, and deferring when redundant - supports confidence gating as a promising architectural principle for managing epistemic uncertainty in safety-critical applications.

</details>


### [100] [CASL: Concept-Aligned Sparse Latents for Interpreting Diffusion Models](https://arxiv.org/abs/2601.15441)
*Zhenghao He,Guangzhi Xiong,Boyang Wang,Sanchit Sinha,Aidong Zhang*

Main category: cs.LG

TL;DR: CASL提出监督框架，将扩散模型的稀疏潜在维度与语义概念对齐，通过CASL-Steer进行因果探测，并引入EPR指标评估编辑精度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的内部激活编码丰富语义信息但难以解释。现有基于稀疏自编码器的方法采用无监督方式，无法将稀疏特征与人类可理解概念对齐，限制了语义控制生成图像的能力。

Method: CASL首先在冻结的U-Net激活上训练稀疏自编码器获得解耦潜在表示，然后学习轻量级线性映射，将每个概念与少量相关潜在维度关联。通过CASL-Steer进行受控潜在干预，沿学习的概念轴移动激活，作为因果探测揭示概念对齐潜在对生成内容的影响。

Result: 实验表明该方法在编辑精度和可解释性方面优于现有方法。引入了编辑精度比（EPR）联合测量概念特异性和无关属性保留。

Conclusion: 这是首个在扩散模型中实现潜在表示与语义概念监督对齐的工作，为理解扩散模型内部表示和实现更可靠的语义控制提供了新方法。

Abstract: Internal activations of diffusion models encode rich semantic information, but interpreting such representations remains challenging. While Sparse Autoencoders (SAEs) have shown promise in disentangling latent representations, existing SAE-based methods for diffusion model understanding rely on unsupervised approaches that fail to align sparse features with human-understandable concepts. This limits their ability to provide reliable semantic control over generated images. We introduce CASL (Concept-Aligned Sparse Latents), a supervised framework that aligns sparse latent dimensions of diffusion models with semantic concepts. CASL first trains an SAE on frozen U-Net activations to obtain disentangled latent representations, and then learns a lightweight linear mapping that associates each concept with a small set of relevant latent dimensions. To validate the semantic meaning of these aligned directions, we propose CASL-Steer, a controlled latent intervention that shifts activations along the learned concept axis. Unlike editing methods, CASL-Steer is used solely as a causal probe to reveal how concept-aligned latents influence generated content. We further introduce the Editing Precision Ratio (EPR), a metric that jointly measures concept specificity and the preservation of unrelated attributes. Experiments show that our method achieves superior editing precision and interpretability compared to existing approaches. To the best of our knowledge, this is the first work to achieve supervised alignment between latent representations and semantic concepts in diffusion models.

</details>


### [101] [Learning from Synthetic Data: Limitations of ERM](https://arxiv.org/abs/2601.15468)
*Kareem Amin,Alex Bie,Weiwei Kong,Umar Syed,Sergei Vassilvitskii*

Main category: cs.LG

TL;DR: 论文研究了在LLM生成内容污染自然数据的学习理论问题，发现传统ERM方法在估计均值时虽然收敛但效率较低，在PAC学习中可能无法收敛到正确概念，但存在能处理任意污染程度的算法。


<details>
  <summary>Details</summary>
Motivation: LLM的普及和低成本导致合成内容泛滥，自然数据被LLM生成内容污染。需要研究在这种混合数据场景下的学习理论问题，学习算法无法区分每个样本的来源。

Method: 将场景建模为一系列学习任务，输入是自然和合成数据的混合。研究ERM在此设置下的可能性与局限性，并与为不同代数据分配非均匀权重的算法进行比较。对于PAC学习，探索能处理任意VC类和任意污染程度的算法。

Result: 1. 均值估计问题：ERM收敛到真实均值，但被分配非均匀权重的算法超越；2. PAC学习：ERM有时无法收敛到正确概念（类似模型崩溃现象），但存在算法能学习任意VC类的正确假设，且能处理任意污染程度。

Conclusion: 在LLM生成内容污染数据的学习场景中，传统ERM方法存在局限性，需要开发能更好处理合成数据污染的算法。论文为这一新兴领域提供了理论基础和算法设计方向。

Abstract: The prevalence and low cost of LLMs have led to a rise of synthetic content. From review sites to court documents, ``natural'' content has been contaminated by data points that appear similar to natural data, but are in fact LLM-generated. In this work we revisit fundamental learning theory questions in this, now ubiquitous, setting. We model this scenario as a sequence of learning tasks where the input is a mix of natural and synthetic data, and the learning algorithms are oblivious to the origin of any individual example.
  We study the possibilities and limitations of ERM in this setting. For the problem of estimating the mean of an arbitrary $d$-dimensional distribution, we find that while ERM converges to the true mean, it is outperformed by an algorithm that assigns non-uniform weights to examples from different generations of data. For the PAC learning setting, the disparity is even more stark. We find that ERM does not always converge to the true concept, echoing the model collapse literature. However, we show there are algorithms capable of learning the correct hypothesis for arbitrary VC classes and arbitrary amounts of contamination.

</details>


### [102] [Panther: Faster and Cheaper Computations with Randomized Numerical Linear Algebra](https://arxiv.org/abs/2601.15473)
*Fahd Seddik,Abdulrahman Elbedewy,Gaser Sami,Mohamed Abdelmoniem,Yahia Zakaria*

Main category: cs.LG

TL;DR: Panther是一个PyTorch兼容的RandNLA库，通过优化算法实现深度学习的GPU内存节省，替换标准层可减少75%内存且保持性能。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习训练受GPU内存和计算限制，RandNLA技术虽有压缩模型潜力，但缺乏统一的生产级库阻碍了广泛应用。

Method: 开发Panther库，集成经典RandNLA算法，提供优化的C++/CUDA后端(pawX)，支持CPU/GPU运行，包含线性层、卷积、注意力等模块的drop-in替换。

Result: 只需几行代码替换PyTorch标准层，即可在BERT模型上实现高达75%的内存节省，同时保持相当的损失性能。

Conclusion: Panther为RandNLA技术提供了高效易用的实现，显著降低深度学习训练的内存需求，促进这些技术的广泛采用。

Abstract: Training modern deep learning models is increasingly constrained by GPU memory and compute limits. While Randomized Numerical Linear Algebra (RandNLA) offers proven techniques to compress these models, the lack of a unified, production-grade library prevents widely adopting these methods. We present Panther, a PyTorch-compatible library that consolidates established RandNLA algorithms into a single high-performance framework. Panther engineers efficient, drop-in replacements for standard components including sketched linear layers, 2D convolution, multi-head attention, and randomized matrix decompositions (such as pivoted CholeskyQR). By implementing a custom C++/CUDA backend (pawX), Panther provides an optimized implementation that can run on both CPUs and GPUs. We demonstrate the effectiveness of RandNLA techniques and Panther's ease of adoption. By replacing standard PyTorch linear layers with Panther layers (requiring only a few lines of code) we achieve significant memory savings (up to 75%) on BERT while maintaining comparable loss. Source code is available (MIT License) at https://github.com/FahdSeddik/panther, along with demonstration video at https://youtu.be/7M3RQb4KWxs.

</details>


### [103] [Multi-Targeted Graph Backdoor Attack](https://arxiv.org/abs/2601.15474)
*Md Nabi Newaz Khan,Abdullah Arafat Miah,Yu Bi*

Main category: cs.LG

TL;DR: 该论文提出了首个针对图分类任务的多目标后门攻击方法，通过子图注入而非替换的方式，在保持原始图结构的同时植入多个触发器，实现将预测重定向到不同目标标签。


<details>
  <summary>Details</summary>
Motivation: 现有图分类后门攻击研究仅限于单目标攻击，使用基于子图替换的机制，攻击者只能向GNN模型植入单个触发器。本文旨在填补多目标后门攻击在GNN领域的空白。

Method: 提出子图注入方法（而非子图替换）来保持原始图结构，同时毒化干净图。设计多个触发器同时将预测重定向到不同目标标签，构成多目标后门攻击框架。

Result: 在五个数据集上的实验表明，该攻击对所有目标标签都实现了高攻击成功率，同时对干净准确率影响最小。在四种GNN模型上验证了攻击的泛化能力，无论GNN架构和训练参数设置如何都有效。攻击设计参数（注入方法、连接数、触发器大小、边密度、毒化比例）的影响分析显示攻击的鲁棒性。

Conclusion: 这项工作揭示了图神经网络在图分类任务中对多目标后门攻击的脆弱性，提出的攻击方法对现有防御技术（随机平滑和精细剪枝）具有鲁棒性，为GNN安全研究提供了重要启示。

Abstract: Graph neural network (GNN) have demonstrated exceptional performance in solving critical problems across diverse domains yet remain susceptible to backdoor attacks. Existing studies on backdoor attack for graph classification are limited to single target attack using subgraph replacement based mechanism where the attacker implants only one trigger into the GNN model. In this paper, we introduce the first multi-targeted backdoor attack for graph classification task, where multiple triggers simultaneously redirect predictions to different target labels. Instead of subgraph replacement, we propose subgraph injection which preserves the structure of the original graphs while poisoning the clean graphs. Extensive experiments demonstrate the efficacy of our approach, where our attack achieves high attack success rates for all target labels with minimal impact on the clean accuracy. Experimental results on five dataset demonstrate the superior performance of our attack framework compared to the conventional subgraph replacement-based attack. Our analysis on four GNN models confirms the generalization capability of our attack which is effective regardless of the GNN model architectures and training parameters settings. We further investigate the impact of the attack design parameters including injection methods, number of connections, trigger sizes, trigger edge density and poisoning ratios. Additionally, our evaluation against state-of-the-art defenses (randomized smoothing and fine-pruning) demonstrates the robustness of our proposed multi-target attacks. This work highlights the GNN vulnerability against multi-targeted backdoor attack in graph classification task. Our source codes will be available at https://github.com/SiSL-URI/Multi-Targeted-Graph-Backdoor-Attack.

</details>


### [104] [Early predicting of hospital admission using machine learning algorithms: Priority queues approach](https://arxiv.org/abs/2601.15481)
*Jakub Antczak,James Montgomery,Małgorzata O'Reilly,Zbigniew Palmowski,Richard Turner*

Main category: cs.LG

TL;DR: 本研究比较了SARIMAX、XGBoost和LSTM三种模型预测急诊科每日到达人数的性能，发现所有模型均优于季节性朴素基线，XGBoost在总入院预测上表现最佳，SARIMAX在复杂病例预测上略优，但所有模型都低估了突发的患者激增。


<details>
  <summary>Details</summary>
Motivation: 急诊科过度拥挤会危及患者安全和运营效率，需要准确的需求预测来进行有效的资源分配。现有研究需要更精细的需求分解和应对COVID-19数据异常的解决方案。

Method: 使用2017-2021年澳大利亚三级转诊医院数据，将需求分解为8个病房类别并按临床复杂性分层患者。为处理COVID-19期间的数据失真，使用Prophet模型生成异常期的合成反事实值。比较SARIMAX、XGBoost和LSTM三种模型预测7天急诊到达量的性能。

Result: 所有三种模型都一致优于季节性朴素基线。XGBoost在预测每日总入院量上表现最佳（MAE=6.63），SARIMAX在预测主要复杂性病例上略优（MAE=3.77）。但所有模型都存在低估突发、罕见患者激增的共同局限性。

Conclusion: 虽然这些技术成功再现了日常规律模式，但都存在低估突发患者激增的局限性。未来的急诊需求预测模型需要更好地处理罕见但重要的患者激增事件。

Abstract: Emergency Department overcrowding is a critical issue that compromises patient safety and operational efficiency, necessitating accurate demand forecasting for effective resource allocation. This study evaluates and compares three distinct predictive models: Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), EXtreme Gradient Boosting (XGBoost) and Long Short-Term Memory (LSTM) networks for forecasting daily ED arrivals over a seven-day horizon. Utilizing data from an Australian tertiary referral hospital spanning January 2017 to December 2021, this research distinguishes itself by decomposing demand into eight specific ward categories and stratifying patients by clinical complexity. To address data distortions caused by the COVID-19 pandemic, the study employs the Prophet model to generate synthetic counterfactual values for the anomalous period. Experimental results demonstrate that all three proposed models consistently outperform a seasonal naive baseline. XGBoost demonstrated the highest accuracy for predicting total daily admissions with a Mean Absolute Error of 6.63, while the statistical SARIMAX model proved marginally superior for forecasting major complexity cases with an MAE of 3.77. The study concludes that while these techniques successfully reproduce regular day-to-day patterns, they share a common limitation in underestimating sudden, infrequent surges in patient volume.

</details>


### [105] [Martingale Foresight Sampling: A Principled Approach to Inference-Time LLM Decoding](https://arxiv.org/abs/2601.15482)
*Huayu Li,ZhengXiao He,Siyuan Tian,Jinghao Wen,Ao Li*

Main category: cs.LG

TL;DR: 提出Martingale Foresight Sampling (MFS)，将LLM解码重新表述为识别最优随机过程的问题，使用鞅理论设计理论基础的算法，提升推理准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 标准自回归解码是短视的，难以找到全局最优推理路径；现有的前瞻采样方法依赖启发式规则进行路径评估和剪枝，缺乏理论基础。

Method: 将推理路径质量建模为随机过程，应用鞅理论：1) 使用Doob分解定理进行步骤评估；2) 使用可选停止理论进行路径选择；3) 基于鞅收敛定理设计自适应停止规则。

Result: 在六个推理基准测试中，MFS在准确性上超越最先进方法，同时显著提高计算效率。

Conclusion: MFS为LLM解码提供了理论基础的框架，通过鞅理论取代启发式方法，实现了更好的推理性能和计算效率。

Abstract: Standard autoregressive decoding in large language models (LLMs) is inherently short-sighted, often failing to find globally optimal reasoning paths due to its token-by-token generation process. While inference-time strategies like foresight sampling attempt to mitigate this by simulating future steps, they typically rely on ad-hoc heuristics for valuing paths and pruning the search space. This paper introduces Martingale Foresight Sampling (MFS), a principled framework that reformulates LLM decoding as a problem of identifying an optimal stochastic process. By modeling the quality of a reasoning path as a stochastic process, we leverage Martingale theory to design a theoretically-grounded algorithm. Our approach replaces heuristic mechanisms with principles from probability theory: step valuation is derived from the Doob Decomposition Theorem to measure a path's predictable advantage, path selection uses Optional Stopping Theory for principled pruning of suboptimal candidates, and an adaptive stopping rule based on the Martingale Convergence Theorem terminates exploration once a path's quality has provably converged. Experiments on six reasoning benchmarks demonstrate that MFS surpasses state-of-the-art methods in accuracy while significantly improving computational efficiency. Code will be released at https://github.com/miraclehetech/EACL2026-Martingale-Foresight-Sampling.

</details>


### [106] [MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498)
*Jingwei Song,Xinyu Wang,Hanbin Wang,Xiaoxuan Lei,Bill Shi,Shixin Han,Eric Yang,Xiao-Wen Chang,Lynn Ai*

Main category: cs.LG

TL;DR: 该论文提出Margin-Aware Speculative Verification，一种训练免费、领域无关的验证策略，通过适应目标模型的局部决策稳定性来改进推测解码中的验证效率。


<details>
  <summary>Details</summary>
Motivation: 现代LLM常在低边际区域运行，目标模型对top候选token偏好较弱。传统严格token级拒绝采样在这种情况下信息增益有限却产生显著回滚成本，导致验证效率低下。

Method: 提出基于边际感知的推测验证，根据目标模型logits直接测量的决策稳定性来条件化验证，仅在严格验证提供最小收益时放宽拒绝规则。该方法仅修改验证规则，完全兼容现有目标耦合推测解码框架。

Result: 在8B到235B模型规模的广泛实验中，该方法相比最先进基线实现了一致且显著的推理加速，同时在多样化基准测试中保持了生成质量。

Conclusion: Margin-Aware Speculative Verification通过适应目标模型的局部决策性，解决了推测解码验证阶段的根本低效问题，为LLM推理加速提供了有效且通用的解决方案。

Abstract: Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying on strict token-level rejection sampling. In practice, modern LLMs frequently operate in low-margin regimes where the target model exhibits weak preference among top candidates. In such cases, rejecting plausible runner-up tokens yields negligible information gain while incurring substantial rollback cost, leading to a fundamental inefficiency in verification. We propose Margin-Aware Speculative Verification, a training-free and domain-agnostic verification strategy that adapts to the target model's local decisiveness. Our method conditions verification on decision stability measured directly from the target logits and relaxes rejection only when strict verification provides minimal benefit. Importantly, the approach modifies only the verification rule and is fully compatible with existing target-coupled speculative decoding frameworks. Extensive experiments across model scales ranging from 8B to 235B demonstrate that our method delivers consistent and significant inference speedups over state-of-the-art baselines while preserving generation quality across diverse benchmarks.

</details>


### [107] [Data-driven Lake Water Quality Forecasting for Time Series with Missing Data using Machine Learning](https://arxiv.org/abs/2601.15503)
*Rishit Chatterjee,Tahiya Chowdhury*

Main category: cs.LG

TL;DR: 针对湖泊志愿者监测数据不完整问题，研究使用岭回归预测透明度，确定达到全历史精度95%所需最小样本量（约176个）和特征数（4个），提出联合可行性函数指导监测方案设计。


<details>
  <summary>Details</summary>
Motivation: 志愿者主导的湖泊监测产生不规则的季节性时间序列，存在许多由冰盖、天气限制和人为错误造成的缺口，这使得有害藻华预测和预警变得复杂。

Method: 使用MICE处理缺失数据，在30个湖泊数据集上评估6种模型，以岭回归为最佳，通过向后近期历史协议确定最小样本量和特征集。

Result: 岭回归表现最佳，达到全历史精度95%需要约176个训练样本和4个特征；联合可行性分析显示只需64个近期样本和1个预测因子即可满足5%精度目标。

Conclusion: 提出的联合可行性策略将近期历史长度和特征选择统一在固定精度目标下，为湖泊研究人员提供了设定采样工作和测量优先级的简单高效规则。

Abstract: Volunteer-led lake monitoring yields irregular, seasonal time series with many gaps arising from ice cover, weather-related access constraints, and occasional human errors, complicating forecasting and early warning of harmful algal blooms. We study Secchi Disk Depth (SDD) forecasting on a 30-lake, data-rich subset drawn from three decades of in situ records collected across Maine lakes. Missingness is handled via Multiple Imputation by Chained Equations (MICE), and we evaluate performance with a normalized Mean Absolute Error (nMAE) metric for cross-lake comparability. Among six candidates, ridge regression provides the best mean test performance. Using ridge regression, we then quantify the minimal sample size, showing that under a backward, recent-history protocol, the model reaches within 5% of full-history accuracy with approximately 176 training samples per lake on average. We also identify a minimal feature set, where a compact four-feature subset matches the thirteen-feature baseline within the same 5% tolerance. Bringing these results together, we introduce a joint feasibility function that identifies the minimal training history and fewest predictors sufficient to achieve the target of staying within 5% of the complete-history, full-feature baseline. In our study, meeting the 5% accuracy target required about 64 recent samples and just one predictor per lake, highlighting the practicality of targeted monitoring. Hence, our joint feasibility strategy unifies recent-history length and feature choice under a fixed accuracy target, yielding a simple, efficient rule for setting sampling effort and measurement priorities for lake researchers.

</details>


### [108] [SAGE-FM: A lightweight and interpretable spatial transcriptomics foundation model](https://arxiv.org/abs/2601.15504)
*Xianghao Zhan,Jingyu Xu,Yuanning Zheng,Zinaida Good,Olivier Gevaert*

Main category: cs.LG

TL;DR: SAGE-FM是一个基于图卷积网络的轻量级空间转录组学基础模型，通过掩码中心点预测任务训练，在416个人类Visium样本上学习空间一致的嵌入表示，在基因恢复、聚类分析和下游任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学能够提供空间基因表达谱，这促使需要能够捕捉空间条件化调控关系的计算模型。现有方法在空间信息的建模和利用方面存在不足。

Method: SAGE-FM基于图卷积网络(GCNs)，采用掩码中心点预测任务进行训练。模型在416个人类Visium样本（涵盖15个器官）上进行训练，学习空间一致的嵌入表示。

Result: 1. 91%的掩码基因显示出显著相关性(p < 0.05)
2. 在无监督聚类和生物异质性保留方面优于MOFA和现有空间转录组学方法
3. 在下游任务中：口咽鳞状细胞癌病理学定义的spot标注准确率达81%，胶质母细胞瘤亚型预测优于MOFA
4. 体外扰动实验显示模型能捕捉方向性配体-受体和上下游调控效应

Conclusion: 简单、参数高效的图卷积网络可以作为大规模空间转录组学的生物学可解释且空间感知的基础模型。

Abstract: Spatial transcriptomics enables spatial gene expression profiling, motivating computational models that capture spatially conditioned regulatory relationships. We introduce SAGE-FM, a lightweight spatial transcriptomics foundation model based on graph convolutional networks (GCNs) trained with a masked central spot prediction objective. Trained on 416 human Visium samples spanning 15 organs, SAGE-FM learns spatially coherent embeddings that robustly recover masked genes, with 91% of masked genes showing significant correlations (p < 0.05). The embeddings generated by SAGE-FM outperform MOFA and existing spatial transcriptomics methods in unsupervised clustering and preservation of biological heterogeneity. SAGE-FM generalizes to downstream tasks, enabling 81% accuracy in pathologist-defined spot annotation in oropharyngeal squamous cell carcinoma and improving glioblastoma subtype prediction relative to MOFA. In silico perturbation experiments further demonstrate that the model captures directional ligand-receptor and upstream-downstream regulatory effects consistent with ground truth. These results demonstrate that simple, parameter-efficient GCNs can serve as biologically interpretable and spatially aware foundation models for large-scale spatial transcriptomics.

</details>


### [109] [Machine learning-enhanced non-amnestic Alzheimer's disease diagnosis from MRI and clinical features](https://arxiv.org/abs/2601.15530)
*Megan A. Witherow,Michael L. Evans,Ahmed Temtam,Hamid Okhravi,Khan M. Iftekharuddin*

Main category: cs.LG

TL;DR: 开发机器学习方法，利用临床测试和MRI数据区分非典型阿尔茨海默病（atAD）与非AD认知障碍，提高atAD诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 虽然典型AD（tAD）可通过临床评估和海马体积准确诊断，但非典型AD（atAD）患者常被误诊。目前基于生物标志物（PET/CSF）的诊断方法侵入性强，而标准临床评估对atAD诊断准确性有限。

Method: 使用机器学习方法，基于临床测试数据和MRI特征（包括海马体积和全脑MRI特征）进行atAD与非AD分类。从三个数据集（一个私有数据集、NACC和ADNI）收集1410名受试者数据。采用Boruta统计方法识别区分诊断组的重要脑区特征。

Result: 最佳性能通过纳入额外重要MRI特征实现，优于仅使用海马体积。atAD病例正确诊断率（召回率）从52%提升至69%（NACC）和从34%提升至77%（ADNI），同时保持高精度。

Conclusion: 该方法仅使用临床测试和MRI数据即可显著提高非典型AD在临床环境中的诊断准确性，对改善atAD患者的临床诊断具有重要价值。

Abstract: Alzheimer's disease (AD), defined as an abnormal buildup of amyloid plaques and tau tangles in the brain can be diagnosed with high accuracy based on protein biomarkers via PET or CSF analysis. However, due to the invasive nature of biomarker collection, most AD diagnoses are made in memory clinics using cognitive tests and evaluation of hippocampal atrophy based on MRI. While clinical assessment and hippocampal volume show high diagnostic accuracy for amnestic or typical AD (tAD), a substantial subgroup of AD patients with atypical presentation (atAD) are routinely misdiagnosed. To improve diagnosis of atAD patients, we propose a machine learning approach to distinguish between atAD and non-AD cognitive impairment using clinical testing battery and MRI data collected as standard-of-care. We develop and evaluate our approach using 1410 subjects across four groups (273 tAD, 184 atAD, 235 non-AD, and 685 cognitively normal) collected from one private data set and two public data sets from the National Alzheimer's Coordinating Center (NACC) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). We perform multiple atAD vs. non-AD classification experiments using clinical features and hippocampal volume as well as a comprehensive set of MRI features from across the brain. The best performance is achieved by incorporating additional important MRI features, which outperforms using hippocampal volume alone. Furthermore, we use the Boruta statistical approach to identify and visualize significant brain regions distinguishing between diagnostic groups. Our ML approach improves the percentage of correctly diagnosed atAD cases (the recall) from 52% to 69% for NACC and from 34% to 77% for ADNI, while achieving high precision. The proposed approach has important implications for improving diagnostic accuracy for non-amnestic atAD in clinical settings using only clinical testing battery and MRI.

</details>


### [110] [QUAIL: Quantization Aware Unlearning for Mitigating Misinformation in LLMs](https://arxiv.org/abs/2601.15538)
*Himanshu Mishra,Kanwal Mehreen*

Main category: cs.LG

TL;DR: 本文研究了量化如何破坏机器学习模型的遗忘效果，并提出了量化感知的遗忘方法来确保在低比特量化后依然能有效移除特定知识。


<details>
  <summary>Details</summary>
Motivation: 实际部署中模型常被量化（如4位）以节省资源，但研究发现量化会灾难性地恢复已遗忘的知识。现有遗忘方法在量化后失效，需要解决量化对遗忘效果的破坏问题。

Method: 首先分析量化如何破坏遗忘：通过计算权重变化统计和量化桶重叠，发现典型遗忘更新太小无法跨越量化阈值。基于此提出logits空间铰链损失：对每个遗忘样本，强制未学习模型的输出logits与原始模型相差至少半个量化步长，确保量化后遗忘样本仍可区分。

Result: 在语言和分类任务（包括Twitter虚假信息数据集）上评估，该方法在4位量化下能保持遗忘效果，而现有方法几乎完全恢复了被遗忘的知识。

Conclusion: 量化会严重破坏模型遗忘效果，但通过量化感知的遗忘方法（特别是logits空间铰链损失）可以确保在低比特量化部署中依然有效移除特定知识。

Abstract: Machine unlearning aims to remove specific knowledge (e.g., copyrighted or private data) from a trained model without full retraining. In practice, models are often quantized (e.g., 4-bit) for deployment, but we find that quantization can catastrophically restore forgotten information [1]. In this paper, we (1) analyze why low-bit quantization undermines unlearning, and (2) propose a quantization-aware unlearning method to mitigate this. We first compute weight-change statistics and bucket overlaps in quantization to show that typical unlearning updates are too small to cross quantization thresholds. Building on this insight, we introduce a logits space hinge loss: for each forget example, we force the output logits of the unlearned model to differ from the original model by at least a margin (half the quantization step). This ensures forgotten examples remain distinguishable even after quantization. We evaluate on language and classification tasks (including a Twitter misinformation dataset) and show our method preserves forgetting under 4-bit quantization, whereas existing methods almost entirely recover the forgotten knowledge.

</details>


### [111] [PRISM: Deriving the Transformer as a Signal-Denoising Operator via Maximum Coding Rate Reduction](https://arxiv.org/abs/2601.15540)
*Dongchen Huang*

Main category: cs.LG

TL;DR: 提出Prism架构，基于MCR²原理，通过几何约束实现无监督功能解耦，在TinyStories上验证了注意力头自发分化为低频（长程因果）和高频（局部句法）的谱分离现象。


<details>
  <summary>Details</summary>
Motivation: 针对Transformer等深度学习模型缺乏可解释性的"黑箱"问题，希望构建一个基于几何原理的白盒注意力架构，证明可解释性和性能可以统一而非权衡。

Method: 提出Prism架构，将注意力机制建模为信号-噪声流形上的梯度上升过程，引入两个物理约束：1) 过完备字典扩展表示相空间；2) π-RoPE无理频率分离强制信号与噪声子空间不相干。

Result: 在TinyStories测试中，Prism的注意力头自发分化为谱分离状态：低频头捕获长程因果依赖（信号），高频头处理局部句法约束（噪声），验证了谱动态特性。

Conclusion: 几何归纳偏置可作为物理约束，足以诱导无监督功能解耦，表明通过原则性几何构造可以实现可解释性与性能的统一，而非权衡关系。

Abstract: Deep learning models, particularly Transformers, are often criticized as "black boxes" and lack interpretability. We propose Prism, a white-box attention-based architecture derived from the principles of Maximizing Coding Rate Reduction ($\text{MCR}^2$). By modeling the attention mechanism as a gradient ascent process on a distinct signal-noise manifold, we introduce two physical constraints: an overcomplete dictionary to expand the representational phase space, and an irrational frequency separation ($π$-RoPE) to enforce incoherence between signal and noise subspaces. We demonstrate that these geometric inductive biases can be viewed as a physical constraint and they are sufficient to induce unsupervised functional disentanglement alone. Using TinyStories as a controlled testbed for verifying spectral dynamics, we observe that Prism spontaneously specializes its attention heads into spectrally distinct regimes: low-frequency heads capturing long-range causal dependencies (signal) and high-frequency heads handling local syntactic constraints (noise). Our results suggest that interpretability and performance are not a trade-off, but can be unified through principled geometric construction.

</details>


### [112] [RDumb++: Drift-Aware Continual Test-Time Adaptation](https://arxiv.org/abs/2601.15544)
*Himanshu Mishra*

Main category: cs.LG

TL;DR: RDumb++是一种持续测试时适应方法，通过两种漂移检测机制和自适应重置策略，在长时分布变化中防止模型崩溃，相比RDumb提升约3%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法如Tent、EATA等在短期分布变化中表现良好，但在快速变化或极长时域测试分布下表现不佳，特别是在CCC基准测试中面对750万样本的持续变化时容易崩溃。

Method: 提出RDumb++方法，扩展了RDumb框架，引入两种漂移检测机制：基于熵的漂移评分和KL散度漂移评分，结合自适应重置策略，在检测到累积适应有害时及时恢复模型。

Result: 在CCC-medium基准测试中，RDumb++在三个速度和三个种子的九次运行中均优于RDumb，获得约3%的绝对准确率提升，并在整个数据流中保持稳定的适应性能。

Conclusion: 漂移感知的重置机制对于防止模型崩溃和实现可靠的长期CTTA至关重要，RDumb++通过有效的漂移检测和自适应恢复策略，在长时域持续适应中表现出色。

Abstract: Continual Test-Time Adaptation (CTTA) seeks to update a pretrained model during deployment using only the incoming, unlabeled data stream. Although prior approaches such as Tent, EATA etc. provide meaningful improvements under short evolving shifts, they struggle when the test distribution changes rapidly or over extremely long horizons. This challenge is exemplified by the CCC benchmark, where models operate over streams of 7.5M samples with continually changing corruption types and severities. We propose RDumb++, a principled extension of RDumb that introduces two drift-detection mechanisms i.e entropy-based drift scoring and KL-divergence drift scoring, together with adaptive reset strategies. These mechanisms allow the model to detect when accumulated adaptation becomes harmful and to recover before prediction collapse occurs. Across CCC-medium with three speeds and three seeds (nine runs, each containing one million samples), RDumb++ consistently surpasses RDumb, yielding approx 3% absolute accuracy gains while maintaining stable adaptation throughout the entire stream. Ablation experiments on drift thresholds and reset strengths further show that drift-aware resetting is essential for preventing collapse and achieving reliable long-horizon CTTA.

</details>


### [113] [Beyond validation loss: Clinically-tailored optimization metrics improve a model's clinical performance](https://arxiv.org/abs/2601.15546)
*Charles B. Delahunt,Courosh Mehanian,Daniel E. Shea,Matthew P. Horning*

Main category: cs.LG

TL;DR: 该论文提出在医疗AI模型优化中使用临床定制指标优于传统验证损失，能更好地满足临床需求。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习使用验证损失来优化模型，但医疗AI的目标是满足具体临床要求而非最小化训练损失函数。临床需求可以通过定制指标更精确地捕捉。

Method: 设计两个受控实验，比较使用临床定制指标与传统验证损失在模型优化中的效果。

Result: 实验结果显示，使用临床定制指标进行优化相比验证损失能获得更好的临床任务性能。

Conclusion: 尽管定义和编码临床相关指标需要额外努力，但这种方法能产生更符合医疗AI核心目标——在临床中表现优秀的模型。

Abstract: A key task in ML is to optimize models at various stages, e.g. by choosing hyperparameters or picking a stopping point. A traditional ML approach is to use validation loss, i.e. to apply the training loss function on a validation set to guide these optimizations. However, ML for healthcare has a distinct goal from traditional ML: Models must perform well relative to specific clinical requirements, vs. relative to the loss function used for training. These clinical requirements can be captured more precisely by tailored metrics. Since many optimization tasks do not require the driving metric to be differentiable, they allow a wider range of options, including the use of metrics tailored to be clinically-relevant. In this paper we describe two controlled experiments which show how the use of clinically-tailored metrics provide superior model optimization compared to validation loss, in the sense of better performance on the clinical task. The use of clinically-relevant metrics for optimization entails some extra effort, to define the metrics and to code them into the pipeline. But it can yield models that better meet the central goal of ML for healthcare: strong performance in the clinic.

</details>


### [114] [Learning Neural Operators from Partial Observations via Latent Autoregressive Modeling](https://arxiv.org/abs/2601.15547)
*Jingren Hou,Hong Wang,Pengyu Xu,Chang Gao,Huafeng Liu,Liping Jing*

Main category: cs.LG

TL;DR: 该论文提出了首个从部分观测数据学习神经算子的系统框架，解决了实际应用中观测数据不完整的问题，通过掩码预测训练和物理感知潜在传播器在部分观测条件下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实科学应用中经常遇到观测数据不完整的问题，而现有神经算子方法假设完全观测的空间输入，严重限制了在实际应用中的适用性。需要开发能够处理部分观测数据的神经算子学习框架。

Method: 提出了Latent Autoregressive Neural Operator (LANO)框架，包含两个核心组件：(1) 掩码预测训练策略，通过战略性地掩码观测区域创建人工监督；(2) 物理感知潜在传播器，在潜在空间通过边界优先的自回归生成重建解场。还开发了POBench-PDE基准测试。

Result: 在部分观测条件下，LANO在所有基准测试中实现了18-69%的相对L2误差减少，包括真实世界的气候预测。该方法能有效处理高达75%缺失率的情况，在补丁式缺失且缺失率低于50%时表现最佳。

Conclusion: 该研究填补了理想化研究设置与真实世界科学计算复杂性之间的差距，为处理部分观测数据提供了有效的神经算子学习框架，显著提升了在实际应用中的适用性。

Abstract: Real-world scientific applications frequently encounter incomplete observational data due to sensor limitations, geographic constraints, or measurement costs. Although neural operators significantly advanced PDE solving in terms of computational efficiency and accuracy, their underlying assumption of fully-observed spatial inputs severely restricts applicability in real-world applications. We introduce the first systematic framework for learning neural operators from partial observation. We identify and formalize two fundamental obstacles: (i) the supervision gap in unobserved regions that prevents effective learning of physical correlations, and (ii) the dynamic spatial mismatch between incomplete inputs and complete solution fields. Specifically, our proposed Latent Autoregressive Neural Operator~(\ours) introduces two novel components designed explicitly to address the core difficulties of partial observations: (i) a mask-to-predict training strategy that creates artificial supervision by strategically masking observed regions, and (ii) a Physics-Aware Latent Propagator that reconstructs solutions through boundary-first autoregressive generation in latent space. Additionally, we develop POBench-PDE, a dedicated and comprehensive benchmark designed specifically for evaluating neural operators under partial observation conditions across three PDE-governed tasks. \ours achieves state-of-the-art performance with 18--69$\%$ relative L2 error reduction across all benchmarks under patch-wise missingness with less than 50$\%$ missing rate, including real-world climate prediction. Our approach effectively addresses practical scenarios involving up to 75$\%$ missing rate, to some extent bridging the existing gap between idealized research settings and the complexities of real-world scientific computing.

</details>


### [115] [BanditLP: Large-Scale Stochastic Optimization for Personalized Recommendations](https://arxiv.org/abs/2601.15552)
*Phuc Nguyen,Benjamin Zelditch,Joyce Chen,Rohit Patra,Changshuai Wei*

Main category: cs.LG

TL;DR: BanditLP是一个可扩展的多利益相关方上下文bandit框架，结合了神经Thompson Sampling学习目标特定结果和大规模线性规划进行约束动作选择，在LinkedIn邮件营销系统中实现业务增长。


<details>
  <summary>Details</summary>
Motivation: 现有系统需要同时处理多个利益相关方的约束条件，并在web规模下实现有效的探索-利用平衡，传统方法难以在保持可扩展性的同时处理复杂约束。

Method: 1. 使用神经Thompson Sampling学习目标特定的结果；2. 通过大规模线性规划在服务时进行约束动作选择；3. 框架应用无关，兼容任意神经架构；4. LP求解器能处理数十亿变量。

Result: 1. 在公开基准和合成数据上相比强基线获得持续增益；2. 在LinkedIn邮件营销系统中成功应用并展示业务成果；3. 验证了集成探索和约束优化在生产环境中的价值。

Conclusion: BanditLP框架成功统一了神经Thompson Sampling和大规模线性规划，在web规模下实现了有效的多利益相关方决策，证明了集成探索与约束优化在生产系统中的实际价值。

Abstract: We present BanditLP, a scalable multi-stakeholder contextual bandit framework that unifies neural Thompson Sampling for learning objective-specific outcomes with a large-scale linear program for constrained action selection at serving time. The methodology is application-agnostic, compatible with arbitrary neural architectures, and deployable at web scale, with an LP solver capable of handling billions of variables. Experiments on public benchmarks and synthetic data show consistent gains over strong baselines. We apply this approach in LinkedIn's email marketing system and demonstrate business win, illustrating the value of integrated exploration and constrained optimization in production.

</details>


### [116] [Deep Learning for Perishable Inventory Systems with Human Knowledge](https://arxiv.org/abs/2601.15589)
*Xuan Liao,Zhenkang Peng,Ying Rong*

Main category: cs.LG

TL;DR: 提出了一种基于深度学习的易腐品库存管理方法，通过边际成本核算方案实现端到端学习，并开发了三种变体，证明了结合启发式策略结构能提升学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 易腐品库存管理面临需求不确定、提前期随机且分布未知的挑战，传统方法在数据有限时表现不佳。需要开发能够利用有限历史数据、协变量和系统状态的学习型策略。

Method: 采用边际成本核算方案，为每个订单分配单一生命周期成本，形成统一的端到端损失函数。开发了三种深度学习策略：纯黑盒直接输出订单量（E2E-BB）、嵌入投影库存水平策略的指导方法（E2E-PIL）、以及通过齐次性启发的增强策略（E2E-BPIL）。

Result: 实验表明性能排序：E2E-BB < E2E-PIL < E2E-BPIL。嵌入启发式策略结构能降低有效模型复杂度，提高学习效率，且灵活性损失有限。

Conclusion: 深度学习决策工具在结合人类知识（库存理论）指导下更有效和稳健，强调了先进分析与库存理论整合的价值。

Abstract: Managing perishable products with limited lifetimes is a fundamental challenge in inventory management, as poor ordering decisions can quickly lead to stockouts or excessive waste. We study a perishable inventory system with random lead times in which both the demand process and the lead time distribution are unknown. We consider a practical setting where orders are placed using limited historical data together with observed covariates and current system states. To improve learning efficiency under limited data, we adopt a marginal cost accounting scheme that assigns each order a single lifetime cost and yields a unified loss function for end-to-end learning. This enables training a deep learning-based policy that maps observed covariates and system states directly to order quantities. We develop two end-to-end variants: a purely black-box approach that outputs order quantities directly (E2E-BB), and a structure-guided approach that embeds the projected inventory level (PIL) policy, capturing inventory effects through explicit computation rather than additional learning (E2E-PIL). We further show that the objective induced by E2E-PIL is homogeneous of degree one, enabling a boosting technique from operational data analytics (ODA) that yields an enhanced policy (E2E-BPIL). Experiments on synthetic and real data establish a robust performance ordering: E2E-BB is dominated by E2E-PIL, which is further improved by E2E-BPIL. Using an excess-risk decomposition, we show that embedding heuristic policy structure reduces effective model complexity and improves learning efficiency with only a modest loss of flexibility. More broadly, our results suggest that deep learning-based decision tools are more effective and robust when guided by human knowledge, highlighting the value of integrating advanced analytics with inventory theory.

</details>


### [117] [Neural Nonlinear Shrinkage of Covariance Matrices for Minimum Variance Portfolio Optimization](https://arxiv.org/abs/2601.15597)
*Liusha Yang,Siqi Zhao,Shuqi Chai*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经网络的非线性收缩协方差矩阵估计器，用于最小方差投资组合优化，结合统计估计与机器学习，通过轻量级Transformer网络学习特征值的非线性收缩函数。


<details>
  <summary>Details</summary>
Motivation: 传统的协方差矩阵估计方法（如Ledoit-Wolf线性收缩）在最小方差投资组合优化中可能不是最优的，因为线性收缩可能无法充分捕捉协方差矩阵的复杂结构。需要一种能直接针对投资组合风险最小化目标的方法。

Method: 从Ledoit-Wolf收缩估计器出发，将其协方差矩阵分解为特征值和特征向量，然后使用轻量级Transformer神经网络学习特征值的非线性收缩函数。训练时以投资组合风险作为损失函数，使得估计的精度矩阵直接针对风险最小化目标。

Result: 在标普500指数成分股的日收益率数据上，该方法在样本外实现的风险持续低于基准方法，表明其在最小方差投资组合优化中的有效性。

Conclusion: 该方法成功地将结构统计模型与数据驱动学习相结合，为协方差矩阵估计提供了新思路，在投资组合优化中展现出良好性能。

Abstract: This paper introduces a neural network-based nonlinear shrinkage estimator of covariance matrices for the purpose of minimum variance portfolio optimization. It is a hybrid approach that integrates statistical estimation with machine learning. Starting from the Ledoit-Wolf (LW) shrinkage estimator, we decompose the LW covariance matrix into its eigenvalues and eigenvectors, and apply a lightweight transformer-based neural network to learn a nonlinear eigenvalue shrinkage function. Trained with portfolio risk as the loss function, the resulting precision matrix (the inverse covariance matrix) estimator directly targets portfolio risk minimization. By conditioning on the sample-to-dimension ratio, the approach remains scalable across different sample sizes and asset universes. Empirical results on stock daily returns from Standard & Poor's 500 Index (S&P500) demonstrate that the proposed method consistently achieves lower out-of-sample realized risk than benchmark approaches. This highlights the promise of integrating structural statistical models with data-driven learning.

</details>


### [118] [When Sharpening Becomes Collapse: Sampling Bias and Semantic Coupling in RL with Verifiable Rewards](https://arxiv.org/abs/2601.15609)
*Mingyuan Fan,Weiguang Han,Daixin Wang,Cen Chen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: RLVR训练可能导致过锐化现象，使策略塌缩到有限模式，抑制有效替代方案。作者提出逆成功优势校准和分布级校准来改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管RLVR在逻辑密集型领域取得了经验成功，但尚不清楚它是激发了新能力还是仅仅锐化了现有知识的分布。作者研究RLVR是否会导致过锐化现象，即策略塌缩到有限模式，抑制有效替代方案。

Method: 1) 形式化过锐化现象；2) 发现有限批次更新固有地偏向采样模式，引发全局传播的塌缩；3) 提出逆成功优势校准来优先处理困难查询；4) 提出分布级校准通过记忆网络多样化采样。

Result: 经验评估验证了所提策略能有效改善泛化能力。

Conclusion: RLVR训练存在过锐化问题，通过提出的校准方法可以缓解这一问题，提高模型的泛化性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a central paradigm for turning large language models (LLMs) into reliable problem solvers, especially in logic-heavy domains. Despite its empirical success, it remains unclear whether RLVR elicits novel capabilities or merely sharpens the distribution over existing knowledge. We study this by formalizing over-sharpening, a phenomenon where the policy collapses onto limited modes, suppressing valid alternatives. At a high level, we discover finite-batch updates intrinsically bias learning toward sampled modes, triggering a collapse that propagates globally via semantic coupling. To mitigate this, we propose inverse-success advantage calibration to prioritize difficult queries and distribution-level calibration to diversify sampling via a memory network. Empirical evaluations validate that our strategies can effectively improve generalization.

</details>


### [119] [Closing the Gap on the Sample Complexity of 1-Identification](https://arxiv.org/abs/2601.15620)
*Zitian Li,Wang Chi Cheung*

Main category: cs.LG

TL;DR: 本文研究1-识别问题——一种多臂赌博机中的纯探索问题，旨在高效识别是否存在均值不低于阈值μ₀的合格臂，或在没有时输出None，同时保证正确概率≥1-δ并最小化期望总拉动次数𝔼τ。


<details>
  <summary>Details</summary>
Motivation: 1-识别是多臂赌博机中的基础纯探索问题，现有文献在存在多个合格臂时对期望总拉动次数𝔼τ的分析存在不足，这是历史文献留下的开放问题。

Method: 采用优化公式推导新的下界，并设计新算法获得紧上界，上界与下界的差距在所有问题实例中最多为对数因子的多项式。

Result: 当存在至少一个合格臂时，推导出𝔼τ的新下界；设计的新算法在所有问题实例上获得紧上界，填补了历史文献在存在多个合格臂时对𝔼τ分析的空白。

Conclusion: 本文通过优化公式和算法设计，解决了1-识别问题中关于期望总拉动次数的理论分析，特别是填补了存在多个合格臂时的分析空白，实现了理论上的紧致性。

Abstract: 1-identification is a fundamental multi-armed bandit formulation on pure exploration. An agent aims to determine whether there exists a qualified arm whose mean reward is not less than a known threshold $μ_0$, or to output \textsf{None} if it believes such an arm does not exist. The agent needs to guarantee its output is correct with probability at least $1-δ$, while making expected total pulling times $\mathbb{E}τ$ as small as possible. We work on 1-identification with two main contributions. (1) We utilize an optimization formulation to derive a new lower bound of $\mathbb{E}τ$, when there is at least one qualified arm. (2) We design a new algorithm, deriving tight upper bounds whose gap to lower bounds are up to a polynomial of logarithm factor across all problem instance. Our result complements the analysis of $\mathbb{E}τ$ when there are multiple qualified arms, which is an open problem left by history literature.

</details>


### [120] [Robust Tool Use via Fission-GRPO: Learning to Recover from Execution Errors](https://arxiv.org/abs/2601.15625)
*Zhiwei Zhang,Fei Zhao,Rui Wang,Zezhong Wang,Bin Liang,Jiakang Wang,Yao Hu,Shaosheng Cao,Kam-Fai Wong*

Main category: cs.LG

TL;DR: Fission-GRPO框架通过将执行错误转化为纠正性监督，在RL训练循环中提升LLMs在工具调用错误后的自我纠正能力，显著提高了多轮工具使用的错误恢复率和整体准确率。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在工具调用中存在多轮执行的脆弱性：遇到错误后，小模型往往陷入重复无效调用，无法解释错误反馈并进行自我纠正。现有方法存在局限性：标准RL将错误视为稀疏负奖励，无法提供恢复指导；预收集的合成错误纠正数据集与模型在线策略的错误模式存在分布不匹配问题。

Method: 提出Fission-GRPO框架，核心机制是将每个失败轨迹通过微调的错误模拟器生成的诊断反馈进行"分裂"，创建新的训练实例，然后在策略上重新采样恢复轨迹。这使得模型能够从自身探索过程中的具体错误中学习，而不是从静态的预收集错误案例中学习。

Result: 在BFCL v4 Multi-Turn基准测试中，Fission-GRPO将Qwen3-8B的错误恢复率提高了5.7%绝对值，整体准确率从42.75%提升至46.75%（提高4%），优于GRPO和专门的工具使用代理。

Conclusion: Fission-GRPO通过将执行错误转化为在线策略的纠正性监督，有效解决了LLMs在多轮工具调用中的错误恢复问题，为实际部署中不可避免的执行错误提供了可靠的自我纠正能力。

Abstract: Large language models (LLMs) can call tools effectively, yet they remain brittle in multi-turn execution: following a tool call error, smaller models often degenerate into repetitive invalid re-invocations, failing to interpret error feedback and self-correct. This brittleness hinders reliable real-world deployment, where the execution errors are inherently inevitable during tool interaction procedures. We identify a key limitation of current approaches: standard reinforcement learning (RL) treats errors as sparse negative rewards, providing no guidance on how to recover, while pre-collected synthetic error-correction datasets suffer from distribution mismatch with the model's on-policy error modes. To bridge this gap, we propose Fission-GRPO, a framework that converts execution errors into corrective supervision within the RL training loop. Our core mechanism fissions each failed trajectory into a new training instance by augmenting it with diagnostic feedback from a finetuned Error Simulator, then resampling recovery rollouts on-policy. This enables the model to learn from the precise errors it makes during exploration, rather than from static, pre-collected error cases. On the BFCL v4 Multi-Turn, Fission-GRPO improves the error recovery rate of Qwen3-8B by 5.7% absolute, crucially, yielding a 4% overall accuracy gain (42.75% to 46.75%) over GRPO and outperforming specialized tool-use agents.

</details>


### [121] [An Empirical Study on Ensemble-Based Transfer Learning Bayesian Optimisation with Mixed Variable Types](https://arxiv.org/abs/2601.15640)
*Natasha Trinkle,Huong Ha,Jeffrey Chan*

Main category: cs.LG

TL;DR: 对基于集成的迁移学习贝叶斯优化方法进行实证分析，提出基于正则化回归的权重策略和正权重约束，并创建三个新的实时迁移学习贝叶斯优化基准。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化是寻找昂贵黑盒目标函数全局最优值的样本高效方法，但可以利用相关问题的历史数据集通过迁移学习来提高贝叶斯优化性能。

Method: 采用基于集成的迁移学习贝叶斯优化方法，提出两种关键组件：1) 基于正则化回归的集成代理模型预测权重策略，约束权重为正；2) 处理迁移学习未改善性能情况的相关组件。同时创建三个新的实时迁移学习贝叶斯优化基准。

Result: 研究发现，两种组件有助于改善迁移学习贝叶斯优化性能：热启动初始化和约束集成代理模型权重为正。这些方法在实验中表现出有效性。

Conclusion: 通过实证分析确定了改善迁移学习贝叶斯优化的关键组件，为正则化回归权重策略和正权重约束提供了支持，并为该领域贡献了新的基准测试。

Abstract: Bayesian optimisation is a sample efficient method for finding a global optimum of expensive black-box objective functions. Historic datasets from related problems can be exploited to help improve performance of Bayesian optimisation by adapting transfer learning methods to various components of the Bayesian optimisation pipeline. In this study we perform an empirical analysis of various ensemble-based transfer learning Bayesian optimisation methods and pipeline components. We expand on previous work in the literature by contributing some specific pipeline components, and three new real-time transfer learning Bayesian optimisation benchmarks. In particular we propose to use a weighting strategy for ensemble surrogate model predictions based on regularised regression with weights constrained to be positive, and a related component for handling the case when transfer learning is not improving Bayesian optimisation performance. We find that in general, two components that help improve transfer learning Bayesian optimisation performance are warm start initialisation and constraining weights used with ensemble surrogate model to be positive.

</details>


### [122] [Integrating Knowledge Distillation Methods: A Sequential Multi-Stage Framework](https://arxiv.org/abs/2601.15657)
*Yinxi Tian,Changwu Huang,Ke Tang,Xin Yao*

Main category: cs.LG

TL;DR: SMSKD是一个顺序多阶段知识蒸馏框架，通过分阶段顺序集成异构KD方法，使用冻结参考模型防止遗忘，结合基于TCP的自适应权重机制，实现了灵活高效的知识整合。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法（如基于响应、特征、关系的方法）各自捕捉教师模型的不同知识方面，但整合多种方法时面临实现复杂、组合不灵活、灾难性遗忘等问题，限制了实际应用效果。

Method: 提出SMSKD框架：1）顺序多阶段蒸馏，每个阶段使用特定蒸馏方法训练学生模型；2）使用前一阶段的冻结参考模型锚定已学知识以减轻遗忘；3）基于教师真实类别概率（TCP）的自适应权重机制，动态调整每个样本的参考损失以平衡知识保留与整合。

Result: SMSKD在各种教师-学生架构和方法组合中均能持续提升学生模型准确率，优于现有基线方法。消融实验表明，阶段式蒸馏和参考模型监督是性能提升的主要贡献因素，TCP自适应权重提供补充优势。

Conclusion: SMSKD是一个实用且资源高效的异构知识蒸馏方法整合解决方案，支持任意方法组合和阶段数量，计算开销可忽略，为解决KD方法整合中的挑战提供了有效框架。

Abstract: Knowledge distillation (KD) transfers knowledge from large teacher models to compact student models, enabling efficient deployment on resource constrained devices. While diverse KD methods, including response based, feature based, and relation based approaches, capture different aspects of teacher knowledge, integrating multiple methods or knowledge sources is promising but often hampered by complex implementation, inflexible combinations, and catastrophic forgetting, which limits practical effectiveness.
  This work proposes SMSKD (Sequential Multi Stage Knowledge Distillation), a flexible framework that sequentially integrates heterogeneous KD methods. At each stage, the student is trained with a specific distillation method, while a frozen reference model from the previous stage anchors learned knowledge to mitigate forgetting. In addition, we introduce an adaptive weighting mechanism based on the teacher true class probability (TCP) that dynamically adjusts the reference loss per sample to balance knowledge retention and integration.
  By design, SMSKD supports arbitrary method combinations and stage counts with negligible computational overhead. Extensive experiments show that SMSKD consistently improves student accuracy across diverse teacher student architectures and method combinations, outperforming existing baselines. Ablation studies confirm that stage wise distillation and reference model supervision are primary contributors to performance gains, with TCP based adaptive weighting providing complementary benefits. Overall, SMSKD is a practical and resource efficient solution for integrating heterogeneous KD methods.

</details>


### [123] [Dualformer: Time-Frequency Dual Domain Learning for Long-term Time Series Forecasting](https://arxiv.org/abs/2601.15669)
*Jingjing Bai,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: Dualformer是一个针对长时序预测设计的双域Transformer框架，通过分层频率采样和周期性感知权重机制，解决了传统Transformer在高频信息衰减问题上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在长时序预测中存在固有的低通滤波效应，导致高频信息在层间传播过程中逐渐衰减，限制了模型捕捉细粒度时间变化的能力。

Method: 提出Dualformer框架，包含三个核心组件：1）时域和频域并行的双分支架构；2）分层频率采样模块，为不同层分配不同频段；3）基于谐波能量比的周期性感知权重机制。

Result: 在8个常用基准测试上的广泛实验表明，Dualformer表现出强大的鲁棒性和优越性能，特别是在异构或弱周期性数据上表现突出。

Conclusion: Dualformer通过结构化频率建模和时频特征的自适应集成，有效保留了高频信息并增强了泛化能力，为长时序预测提供了更有效的解决方案。

Abstract: Transformer-based models, despite their promise for long-term time series forecasting (LTSF), suffer from an inherent low-pass filtering effect that limits their effectiveness. This issue arises due to undifferentiated propagation of frequency components across layers, causing a progressive attenuation of high-frequency information crucial for capturing fine-grained temporal variations. To address this limitation, we propose Dualformer, a principled dual-domain framework that rethinks frequency modeling from a layer-wise perspective. Dualformer introduces three key components: (1) a dual-branch architecture that concurrently models complementary temporal patterns in both time and frequency domains; (2) a hierarchical frequency sampling module that allocates distinct frequency bands to different layers, preserving high-frequency details in lower layers while modeling low-frequency trends in deeper layers; and (3) a periodicity-aware weighting mechanism that dynamically balances contributions from the dual branches based on the harmonic energy ratio of inputs, supported theoretically by a derived lower bound. This design enables structured frequency modeling and adaptive integration of time-frequency features, effectively preserving high-frequency information and enhancing generalization. Extensive experiments conducted on eight widely used benchmarks demonstrate Dualformer's robustness and superior performance, particularly on heterogeneous or weakly periodic data. Our code is publicly available at https://github.com/Akira-221/Dualformer.

</details>


### [124] [Beyond Hard Writes and Rigid Preservation: Soft Recursive Least-Squares for Lifelong LLM Editing](https://arxiv.org/abs/2601.15686)
*Xinyu Wang,Sicheng Lyu,Yu Gu,Jerry Huang,Peng Lu,Yufei Cui,Xiao-Wen Chang*

Main category: cs.LG

TL;DR: RLSEdit 提出一种递归最小二乘法编辑器，用于大规模顺序模型编辑，通过在线二次优化解决可塑性-稳定性困境，在10K编辑规模下保持稳定性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型编辑方法在长期顺序编辑中存在可塑性-稳定性困境：硬写入方法会随时间累积干扰，而硬保护方法只能保护明确约束的内容，可能导致过去编辑被覆盖，未约束行为可能偏离，在多编辑场景下降低模型通用能力。

Method: RLSEdit 将编辑建模为带软约束的在线二次优化问题，最小化累积键值拟合目标，包含两个正则化项：控制与预训练权重的偏差和与指定锚映射的偏差。通过Woodbury恒等式实现高效在线递归，每个编辑成本独立于历史长度，仅与当前编辑规模相关。

Result: 实验显示RLSEdit在多个模型系列上能稳定扩展到10K次编辑，在编辑成功率和整体稳定性方面优于基线方法，关键能保留早期编辑，并在GLUE和保留的推理/代码基准测试中保持通用能力。

Conclusion: RLSEdit通过在线二次优化框架有效解决了长期顺序模型编辑中的可塑性-稳定性困境，提供了可扩展的编辑方法，能在大规模编辑场景下保持模型性能稳定性。

Abstract: Model editing updates a pre-trained LLM with new facts or rules without re-training, while preserving unrelated behavior. In real deployment, edits arrive as long streams, and existing editors often face a plasticity-stability dilemma: locate-then-edit "hard writes" can accumulate interference over time, while null-space-style "hard preservation" preserves only what is explicitly constrained, so past edits can be overwritten and unconstrained behaviors may deviate, degrading general capabilities in the many-edits regime. We propose RLSEdit, a recursive least-squares editor for long sequential editing. RLSEdit formulates editing as an online quadratic optimization with soft constraints, minimizing a cumulative key-value fitting objective with two regularizers that control for both deviation from the pre-trained weights and from a designated anchor mapping. The resulting update admits an efficient online recursion via the Woodbury identity, with per-edit cost independent of history length and scaling only with the current edit size. We further provide deviation bounds and an asymptotic characterization of the adherence-preservation trade-off in the many-edits regime. Experiments on multiple model families demonstrate stable scaling to 10K edits, outperforming strong baselines in both edit success and holistic stability -- crucially retaining early edits, and preserving general capabilities on GLUE and held-out reasoning/code benchmarks.

</details>


### [125] [Even GPT-5.2 Can't Count to Five: The Case for Zero-Error Horizons in Trustworthy LLMs](https://arxiv.org/abs/2601.15714)
*Ryoma Sato*

Main category: cs.LG

TL;DR: 提出Zero-Error Horizon（ZEH）概念，用于评估LLMs的无错误解决能力范围，发现即使是先进模型在简单问题上也会出错，这对安全关键应用有重要启示。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs虽然能力强大，但在简单问题上仍会出错，这对安全关键领域的应用构成风险。需要一种系统方法来评估模型的无错误能力范围，以更好地理解和信任LLMs。

Method: 提出ZEH概念，即模型能够无错误解决的最大问题范围。通过评估GPT-5.2和Qwen2.5等先进模型的ZEH，分析其在不同类型简单问题上的表现差异。

Result: 发现GPT-5.2在简单问题上也会出错（如计算11000的奇偶性、判断括号平衡），ZEH与准确率相关但行为模式不同，ZEH能揭示算法能力的涌现。同时开发了树结构和在线softmax方法，可将计算成本降低一个数量级。

Conclusion: ZEH为评估LLMs的可靠性和无错误能力提供了重要工具，揭示了即使是先进模型在简单任务上也可能出错，这对安全关键应用具有重要启示。同时提出的优化方法显著降低了计算成本。

Abstract: We propose Zero-Error Horizon (ZEH) for trustworthy LLMs, which represents the maximum range that a model can solve without any errors. While ZEH itself is simple, we demonstrate that evaluating the ZEH of state-of-the-art LLMs yields abundant insights. For example, by evaluating the ZEH of GPT-5.2, we found that GPT-5.2 cannot even compute the parity of a short string like 11000, and GPT-5.2 cannot determine whether the parentheses in ((((()))))) are balanced. This is surprising given the excellent capabilities of GPT-5.2. The fact that LLMs make mistakes on such simple problems serves as an important lesson when applying LLMs to safety-critical domains. By applying ZEH to Qwen2.5 and conducting detailed analysis, we found that while ZEH correlates with accuracy, the detailed behaviors differ, and ZEH provides clues about the emergence of algorithmic capabilities. Finally, while computing ZEH incurs significant computational cost, we discuss how to mitigate this cost by achieving up to one order of magnitude speedup using tree structures and online softmax.

</details>


### [126] [Communication-efficient Federated Graph Classification via Generative Diffusion Modeling](https://arxiv.org/abs/2601.15722)
*Xiuling Wang,Xin Huang,Haibo Hu,Jianliang Xu*

Main category: cs.LG

TL;DR: CeFGC是一种新颖的联邦图神经网络范式，通过仅需3轮通信来高效处理非IID图数据，利用生成扩散模型减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦图神经网络面临两大挑战：多轮参数交换带来的高通信开销，以及客户端间非独立同分布的数据特性。这些限制阻碍了联邦图神经网络在实际分布式场景中的高效应用。

Method: CeFGC的核心思想是利用生成扩散模型最小化客户端与服务器之间的直接通信。每个客户端训练一个捕捉其本地图分布的生成扩散模型，上传到服务器，服务器再分发给所有客户端。客户端使用这些生成模型生成合成图，结合本地图训练本地GNN模型，最后上传模型权重进行服务器端聚合。

Result: 理论分析表明CeFGC将通信轮次减少到仅3轮的常数级别。在多个真实图数据集上的实验证明，CeFGC在非IID图数据上相比现有方法具有优越的性能和效率，通过对齐本地和全局模型目标并丰富训练集的图多样性来提升效果。

Conclusion: CeFGC通过创新的生成扩散模型方法，成功解决了联邦图神经网络中的通信开销和非IID数据挑战，为分布式图学习提供了一种高效实用的解决方案。

Abstract: Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs face two significant challenges: high communication overhead from multiple rounds of parameter exchanges and non-IID data characteristics across clients. To address these issues, we introduce CeFGC, a novel FGNN paradigm that facilitates efficient GNN training over non-IID data by limiting communication between the server and clients to three rounds only. The core idea of CeFGC is to leverage generative diffusion models to minimize direct client-server communication. Each client trains a generative diffusion model that captures its local graph distribution and shares this model with the server, which then redistributes it back to all clients. Using these generative models, clients generate synthetic graphs combined with their local graphs to train local GNN models. Finally, clients upload their model weights to the server for aggregation into a global GNN model. We theoretically analyze the I/O complexity of communication volume to show that CeFGC reduces to a constant of three communication rounds only. Extensive experiments on several real graph datasets demonstrate the effectiveness and efficiency of CeFGC against state-of-the-art competitors, reflecting our superior performance on non-IID graphs by aligning local and global model objectives and enriching the training set with diverse graphs.

</details>


### [127] [Towards Automated Kernel Generation in the Era of LLMs](https://arxiv.org/abs/2601.15727)
*Yang Yu,Peiyu Zang,Chi Hsu Tsai,Haiming Wu,Yixin Shen,Jialing Zhang,Haoyu Wang,Zhiyou Xiao,Jingze Shi,Yuyu Luo,Wentao Zhang,Chunlei Men,Guang Liu,Yonghua Lin*

Main category: cs.LG

TL;DR: 该论文是一篇关于LLM驱动内核生成的系统性综述，分析了如何利用大语言模型和智能体系统自动化内核优化，并提供了该领域的结构化概述、数据集基准和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统的性能受限于底层内核的质量，而内核工程需要硬件架构和编程模型的专家知识，这一过程耗时且难以扩展。LLM和智能体系统为自动化内核生成和优化提供了新的可能性，但目前该领域缺乏系统性视角。

Method: 通过系统性的文献综述方法，对LLM驱动内核生成领域进行结构化分析，包括：1) LLM-based方法；2) 智能体优化工作流；3) 支撑学习和评估的数据集与基准测试。

Result: 提供了该领域的全面结构化概述，系统整理了现有方法、数据集和评估基准，识别了关键挑战，并建立了开源GitHub仓库持续跟踪领域进展。

Conclusion: LLM和智能体系统在自动化内核优化方面展现出巨大潜力，但需要建立更系统的研究框架。该综述为下一代自动化内核优化提供了全面参考，并指出了未来研究方向。

Abstract: The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.

</details>


### [128] [Rethinking Drug-Drug Interaction Modeling as Generalizable Relation Learning](https://arxiv.org/abs/2601.15771)
*Dong Xu,Jiantao Wu,Qihua Pan,Sisi Yuan,Zexuan Zhu,Junkai Ji*

Main category: cs.LG

TL;DR: GenRel-DDI将药物相互作用预测重构为关系中心学习问题，通过独立于药物身份学习交互表示，提升对未见药物和新药对的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有药物相互作用预测方法虽然在标准基准上表现良好，但在实际部署场景中泛化能力不足，特别是面对未见药物和稀缺验证交互时。现有分子中心模型在嵌入空间中的邻近性不能可靠对应交互标签，仅增加模型容量无法改善泛化。

Method: 提出GenRel-DDI框架，将DDI预测重构为关系中心学习问题。该方法独立于药物身份学习交互表示，通过关系级抽象捕获可迁移的交互模式，从而泛化到未见药物和新药对。

Result: 在多个基准测试中，GenRel-DDI一致且显著优于最先进方法，特别是在严格的实体分离评估中取得大幅提升，证明了关系学习对稳健DDI预测的有效性和实际效用。

Conclusion: 关系中心学习方法能有效提升药物相互作用预测的泛化能力，特别是对未见药物和新药对，为解决现实世界DDI预测中的泛化问题提供了有前景的解决方案。

Abstract: Drug-drug interaction (DDI) prediction is central to drug discovery and clinical development, particularly in the context of increasingly prevalent polypharmacy. Although existing computational methods achieve strong performance on standard benchmarks, they often fail to generalize to realistic deployment scenarios, where most candidate drug pairs involve previously unseen drugs and validated interactions are scarce. We demonstrate that proximity in the embedding spaces of prevailing molecule-centric DDI models does not reliably correspond to interaction labels, and that simply scaling up model capacity therefore fails to improve generalization. To address these limitations, we propose GenRel-DDI, a generalizable relation learning framework that reformulates DDI prediction as a relation-centric learning problem, in which interaction representations are learned independently of drug identities. This relation-level abstraction enables the capture of transferable interaction patterns that generalize to unseen drugs and novel drug pairs. Extensive experiments across multiple benchmark demonstrate that GenRel-DDI consistently and significantly outperforms state-of-the-art methods, with particularly large gains on strict entity-disjoint evaluations, highlighting the effectiveness and practical utility of relation learning for robust DDI prediction. The code is available at https://github.com/SZU-ADDG/GenRel-DDI.

</details>


### [129] [Next Generation Active Learning: Mixture of LLMs in the Loop](https://arxiv.org/abs/2601.15773)
*Yuanyuan Qi,Xiaohao Yang,Jueqing Lu,Guoxiang Guo,Joanne Enticott,Gang Liu,Lan Du*

Main category: cs.LG

TL;DR: 提出Mixture of LLMs in the Loop Active Learning框架，使用多个LLM混合标注模型替代人工标注，通过聚合不同LLM优势提升标注鲁棒性，并引入标注差异性和负学习处理噪声标签。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在主动学习中被用作标注器以降低标注成本，但LLM生成的标注质量往往达不到实际应用要求，需要提升LLM标注的鲁棒性和可靠性。

Method: 1. 提出Mixture-of-LLMs标注模型，聚合多个LLM的优势；2. 引入标注差异性识别不可靠标注；3. 采用负学习增强学习效果；4. 基于轻量级LLM实现本地部署。

Result: 实验表明该框架性能接近人工标注，优于单LLM基线和其他LLM集成方法，且能完全在本地机器上运行。

Conclusion: 该框架有效解决了LLM标注质量不足的问题，通过多LLM混合和噪声处理机制，在保持低成本的同时实现了接近人工标注的性能。

Abstract: With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall short of real-world applicability. To address this, we propose a novel active learning framework, Mixture of LLMs in the Loop Active Learning, replacing human annotators with labels generated through a Mixture-of-LLMs-based annotation model, aimed at enhancing LLM-based annotation robustness by aggregating the strengths of multiple LLMs. To further mitigate the impact of the noisy labels, we introduce annotation discrepancy and negative learning to identify the unreliable annotations and enhance learning effectiveness. Extensive experiments demonstrate that our framework achieves performance comparable to human annotation and consistently outperforms single-LLM baselines and other LLM-ensemble-based approaches. Moreover, our framework is built on lightweight LLMs, enabling it to operate fully on local machines in real-world applications.

</details>


### [130] [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)
*Fengheng Chu,Jiahao Chen,Yuhong Wang,Jun Wang,Zhihui Fu,Shouling Ji,Songze Li*

Main category: cs.LG

TL;DR: 本文提出GOSV框架，通过全局优化识别LLM中的安全关键注意力头，发现对齐LLM具有分离的安全功能通路，并基于此开发新型白盒越狱攻击方法。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）的安全防护措施在面对越狱攻击时仍显脆弱，这表明我们对模型安全机制的理解有限。现有方法依赖局部贪婪归因，假设组件独立贡献，但忽略了LLM中不同组件（如注意力头）之间的协同交互作用。

Method: 提出GOSV（全局优化安全向量提取）框架，通过全局优化同时对所有注意力头进行分析。采用两种互补的激活重修补策略：有害修补和零消融。这些策略识别出空间上不同的两组安全向量：恶意注入向量和安全抑制向量。

Result: 研究发现对齐LLM为安全目的维护着分离的功能通路。系统分析表明，当所有模型中约30%的总注意力头被重修补时，会发生完全的安全崩溃。基于这些发现开发的新型推理时白盒越狱方法在所有测试模型中显著优于现有白盒攻击。

Conclusion: GOSV框架为LLM安全可解释性提供了有效方法，证明了通过全局优化识别安全关键组件的重要性，并为理解LLM安全机制提供了新视角。

Abstract: While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. However, they overlook the cooperative interactions between different components in LLMs, such as attention heads, which jointly contribute to safety mechanisms. We propose \textbf{G}lobal \textbf{O}ptimization for \textbf{S}afety \textbf{V}ector Extraction (GOSV), a framework that identifies safety-critical attention heads through global optimization over all heads simultaneously. We employ two complementary activation repatching strategies: Harmful Patching and Zero Ablation. These strategies identify two spatially distinct sets of safety vectors with consistently low overlap, termed Malicious Injection Vectors and Safety Suppression Vectors, demonstrating that aligned LLMs maintain separate functional pathways for safety purposes. Through systematic analyses, we find that complete safety breakdown occurs when approximately 30\% of total heads are repatched across all models. Building on these insights, we develop a novel inference-time white-box jailbreak method that exploits the identified safety vectors through activation repatching. Our attack substantially outperforms existing white-box attacks across all test models, providing strong evidence for the effectiveness of the proposed GOSV framework on LLM safety interpretability.

</details>


### [131] [Uncertainty-guided Generation of Dark-field Radiographs](https://arxiv.org/abs/2601.15859)
*Lina Felsner,Henriette Bast,Tina Dorosti,Florian Schaff,Franz Pfeiffer,Daniela Pfeiffer,Julia Schnabel*

Main category: cs.LG

TL;DR: 该研究提出首个从标准衰减胸部X光生成暗场图像的框架，使用不确定性引导的渐进生成对抗网络，解决了暗场数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: X射线暗场成像能通过小角度散射可视化微观组织变化，提供与常规衰减成像互补的诊断信息。然而，这类数据的有限可用性给开发稳健的深度学习模型带来了挑战。

Method: 提出了一个不确定性引导的渐进生成对抗网络框架，该模型同时结合了偶然不确定性和认知不确定性，以提高可解释性和可靠性。

Result: 实验表明生成的图像具有高结构保真度，各阶段的定量指标持续改善。分布外评估证实了模型的良好泛化能力。

Conclusion: 不确定性引导的生成建模能够实现逼真的暗场图像合成，为未来的临床应用提供了可靠基础。

Abstract: X-ray dark-field radiography provides complementary diagnostic information to conventional attenuation imaging by visualizing microstructural tissue changes through small-angle scattering. However, the limited availability of such data poses challenges for developing robust deep learning models. In this work, we present the first framework for generating dark-field images directly from standard attenuation chest X-rays using an Uncertainty-Guided Progressive Generative Adversarial Network. The model incorporates both aleatoric and epistemic uncertainty to improve interpretability and reliability. Experiments demonstrate high structural fidelity of the generated images, with consistent improvement of quantitative metrics across stages. Furthermore, out-of-distribution evaluation confirms that the proposed model generalizes well. Our results indicate that uncertainty-guided generative modeling enables realistic dark-field image synthesis and provides a reliable foundation for future clinical applications.

</details>


### [132] [Why Inference in Large Models Becomes Decomposable After Training](https://arxiv.org/abs/2601.15871)
*Jidong Jin*

Main category: cs.LG

TL;DR: 提出一种后训练结构分析方法，通过统计准则和结构退火移除未支持的参数依赖，揭示稳定子结构，实现结构化并行推理。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型的推理成本随模型规模不可持续增长，这并非源于模型容量不足，而是因为现有系统将推理视为整体操作，忽略了训练过程中形成的内部结构。

Method: 基于梯度更新事件高度局部化和选择性的观察，提出后训练统计准则和结构退火程序，移除统计上无法区分的参数依赖，揭示稳定独立的子结构。

Result: 建立了后训练、模型无关的推理系统结构视图，能够在不改变模型功能或接口的情况下实现结构化并行推理。

Conclusion: 通过利用训练过程中形成的内部结构，可以显著降低大规模AI模型的推理成本和系统复杂度，实现可持续的模型扩展。

Abstract: Inference in large-scale AI models is typically performed on dense parameter matrices, leading to inference cost and system complexity that scale unsustainably with model size. This limitation does not arise from insufficient model capacity, but from treating post-training inference systems as monolithic operators while ignoring internal structures formed during learning. We show that gradient update events in large models are highly localized and selective, leaving many parameter dependencies statistically indistinguishable from their initialization distribution after training. As a result, post-training inference systems are structurally non-uniform and inherently decomposable. Based on this observation, we introduce a post-training statistical criterion and a structural annealing procedure that removes unsupported dependencies and reveals stable, independent substructures. This work establishes a post-training, model-agnostic structural view of inference systems and enables structured, parallel inference without modifying model functionality or interfaces.

</details>


### [133] [SoK: Challenges in Tabular Membership Inference Attacks](https://arxiv.org/abs/2601.15874)
*Cristina Pêra,Tânia Carvalho,Maxime Cordy,Luís Antunes*

Main category: cs.LG

TL;DR: 该论文全面分析了成员推理攻击在表格数据和联邦学习中的表现，发现现有攻击方法在表格数据上效果不佳，但能有效识别单一特征记录，且使用不同替代模型可提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 尽管成员推理攻击是目前评估机器学习隐私的主要方法，但在表格数据方面存在未探索的问题，特别是在集中式和联邦学习两种范式下的表现差异。

Method: 1) 对集中式和联邦学习中的成员推理攻击进行全面回顾和分类；2) 在表格数据上测试多种攻击策略及防御方法；3) 在联邦学习中考虑外部攻击者威胁；4) 分析单一特征记录对攻击的脆弱性；5) 研究攻击在不同模型架构间的迁移性。

Result: 1) 成员推理攻击在表格数据上整体表现不佳，与之前研究结果形成对比；2) 即使攻击性能有限，仍能成功暴露大量单一特征记录；3) 使用不同替代模型可使攻击更有效。

Conclusion: 该研究揭示了成员推理攻击在表格数据上的局限性，强调了单一特征记录的特殊脆弱性，并提出了使用多样化替代模型来提升攻击效果的方法，为隐私保护提供了新的见解。

Abstract: Membership Inference Attacks (MIAs) are currently a dominant approach for evaluating privacy in machine learning applications. Despite their significance in identifying records belonging to the training dataset, several concerns remain unexplored, particularly with regard to tabular data. In this paper, first, we provide an extensive review and analysis of MIAs considering two main learning paradigms: centralized and federated learning. We extend and refine the taxonomy for both. Second, we demonstrate the efficacy of MIAs in tabular data using several attack strategies, also including defenses. Furthermore, in a federated learning scenario, we consider the threat posed by an outsider adversary, which is often neglected. Third, we demonstrate the high vulnerability of single-outs (records with a unique signature) to MIAs. Lastly, we explore how MIAs transfer across model architectures. Our results point towards a general poor performance of these attacks in tabular data which contrasts with previous state-of-the-art. Notably, even attacks with limited attack performance can still successfully expose a large portion of single-outs. Moreover, our findings suggest that using different surrogate models makes MIAs more effective.

</details>


### [134] [Iterative Amortized Hierarchical VAE](https://arxiv.org/abs/2601.15894)
*Simon W. Penninga,Ruud J. G. van Sloun*

Main category: cs.LG

TL;DR: 本文提出迭代摊销分层变分自编码器(IA-HVAE)，通过结合摊销推断的初始猜测和解码器梯度的迭代优化，在变换域中构建线性可分离解码器，实现实时应用和高模型深度，相比传统HVAE实现35倍加速。


<details>
  <summary>Details</summary>
Motivation: 传统分层变分自编码器(HVAE)在推断过程中存在计算效率问题，特别是在需要高模型深度的实时应用中。完全摊销推断虽然快速但精度有限，完全迭代推断精度高但计算代价大。需要一种能兼顾速度和精度的混合推断方案。

Method: 提出IA-HVAE架构，采用混合推断方案：1）初始阶段使用摊销推断生成粗略估计；2）后续通过解码器梯度进行迭代优化。关键创新是在变换域（如傅里叶空间）构建线性可分离的解码器，这使得模型能够在保持高深度的同时实现实时计算。

Result: 1）实现35倍于传统HVAE的迭代推断加速；2）在精度和速度上分别优于完全摊销和完全迭代的对应方法；3）在去模糊和去噪等逆问题中，相比原始HVAE展现出更好的重建质量。

Conclusion: IA-HVAE通过混合摊销-迭代推断架构，在变换域中实现线性可分离解码器，有效平衡了推断速度和精度，特别适用于需要高模型深度的实时逆问题应用，为变分自编码器在计算效率方面提供了重要改进。

Abstract: In this paper we propose the Iterative Amortized Hierarchical Variational Autoencoder (IA-HVAE), which expands on amortized inference with a hybrid scheme containing an initial amortized guess and iterative refinement with decoder gradients. We achieve this by creating a linearly separable decoder in a transform domain (e.g. Fourier space), enabling real-time applications with very high model depths. The architectural change leads to a 35x speed-up for iterative inference with respect to the traditional HVAE. We show that our hybrid approach outperforms fully amortized and fully iterative equivalents in accuracy and speed respectively. Moreover, the IAHVAE shows improved reconstruction quality over a vanilla HVAE in inverse problems such as deblurring and denoising.

</details>


### [135] [Predicting Healthcare System Visitation Flow by Integrating Hospital Attributes and Population Socioeconomics with Human Mobility Data](https://arxiv.org/abs/2601.15977)
*Binbin Lin,Lei Zou,Hao Tian,Heng Cai,Yifan Yang,Bing Zhou*

Main category: cs.LG

TL;DR: 该研究整合医院属性、社会经济因素和空间流动性，预测医疗访问模式，发现Deep Gravity模型最佳，医院容量、ICU占用率、评级和流行度对访问模式有显著影响，且影响随距离而异。


<details>
  <summary>Details</summary>
Motivation: 现有研究对医疗访问模式的影响因素（医院属性、社会经济、空间因素）往往采用碎片化方法单独分析，本研究旨在整合这些因素，全面预测和分析医疗访问流动模式。

Method: 使用四年的SafeGraph移动性数据和Google Maps Reviews的用户体验数据，训练五种流量预测模型（朴素回归、梯度提升、MLP、Deep Gravity、HGNN），应用于休斯顿地区。采用SHAP分析和PDP方法检验不同因素对访问模式的综合影响。

Result: Deep Gravity模型表现最佳。医院容量、ICU占用率、评级和流行度显著影响访问模式，且影响随旅行距离变化：短距离访问主要由便利性驱动，长距离访问受医院评级影响更大。不同种族/社会经济群体对医院评级的敏感性不同，少数族裔和特定年龄群体医院访问更频繁。

Conclusion: 医疗访问模式受多因素综合影响，需整合医院属性、社会经济和空间因素进行全面分析。研究结果为医疗资源分配和健康公平政策提供了重要见解，特别是需要考虑不同人口群体的差异化需求和访问障碍。

Abstract: Healthcare visitation patterns are influenced by a complex interplay of hospital attributes, population socioeconomics, and spatial factors. However, existing research often adopts a fragmented approach, examining these determinants in isolation. This study addresses this gap by integrating hospital capacities, occupancy rates, reputation, and popularity with population SES and spatial mobility patterns to predict visitation flows and analyze influencing factors. Utilizing four years of SafeGraph mobility data and user experience data from Google Maps Reviews, five flow prediction models, Naive Regression, Gradient Boosting, Multilayer Perceptrons (MLPs), Deep Gravity, and Heterogeneous Graph Neural Networks (HGNN),were trained and applied to simulate visitation flows in Houston, Texas, U.S. The Shapley additive explanation (SHAP) analysis and the Partial Dependence Plot (PDP) method were employed to examine the combined impacts of different factors on visitation patterns. The findings reveal that Deep Gravity outperformed other models. Hospital capacities, ICU occupancy rates, ratings, and popularity significantly influence visitation patterns, with their effects varying across different travel distances. Short-distance visits are primarily driven by convenience, whereas long-distance visits are influenced by hospital ratings. White-majority areas exhibited lower sensitivity to hospital ratings for short-distance visits, while Asian populations and those with higher education levels prioritized hospital rating in their visitation decisions. SES further influence these patterns, as areas with higher proportions of Hispanic, Black, under-18, and over-65 populations tend to have more frequent hospital visits, potentially reflecting greater healthcare needs or limited access to alternative medical services.

</details>


### [136] [Partially Lazy Gradient Descent for Smoothed Online Learning](https://arxiv.org/abs/2601.15984)
*Naram Mhaisen,George Iosifidis*

Main category: cs.LG

TL;DR: k-lazyGD算法在平滑在线凸优化中建立了懒惰性与性能的权衡谱系，证明了在一定懒惰程度内仍能保持最优动态遗憾


<details>
  <summary>Details</summary>
Motivation: 传统在线梯度下降（OGD）具有反应性更新但稳定性差，而懒惰GD/双重平均（lazy GD/dual-averaging）稳定性好但跟踪能力有限。本文旨在填补这两种极端方法之间的空白，探索懒惰程度与性能之间的权衡关系。

Method: 提出k-lazyGD算法，在贪婪OGD（k=1）和懒惰GD（k=T）之间创建连续谱系。基于FTRL框架进行分析，建立懒惰程度k与比较器路径长度P_T的关系，证明当k达到Θ(√(T/P_T))时仍能保持最优动态遗憾。

Result: k-lazyGD实现了最优动态遗憾O(√((P_T+1)T))，懒惰程度k可达Θ(√(T/P_T))。建立了懒惰程度与比较器路径长度之间的理论联系，并给出了匹配的下界。通过集成不同懒惰程度的多个学习器，实现了在稳定性和敏捷性之间的自适应平衡。

Conclusion: 懒惰性可以在不牺牲命中性能的情况下实现，k-lazyGD算法正式连接了允许的懒惰程度与比较器的变化，证明了懒惰方法可以在保持较小移动的同时不损害跟踪能力，为在线学习提供了自适应稳定性的新方法。

Abstract: We introduce $k$-lazyGD, an online learning algorithm that bridges the gap between greedy Online Gradient Descent (OGD, for $k=1$) and lazy GD/dual-averaging (for $k=T$), creating a spectrum between reactive and stable updates. We analyze this spectrum in Smoothed Online Convex Optimization (SOCO), where the learner incurs both hitting and movement costs. Our main contribution is establishing that laziness is possible without sacrificing hitting performance: we prove that $k$-lazyGD achieves the optimal dynamic regret $\mathcal{O}(\sqrt{(P_T+1)T})$ for any laziness slack $k$ up to $Θ(\sqrt{T/P_T})$, where $P_T$ is the comparator path length. This result formally connects the allowable laziness to the comparator's shifts, showing that $k$-lazyGD can retain the inherently small movements of lazy methods without compromising tracking ability. We base our analysis on the Follow the Regularized Leader (FTRL) framework, and derive a matching lower bound. Since the slack depends on $P_T$, an ensemble of learners with various slacks is used, yielding a method that is provably stable when it can be, and agile when it must be.

</details>


### [137] [Data-Driven Conditional Flexibility Index](https://arxiv.org/abs/2601.16028)
*Moritz Wedemeyer,Eike Cramer,Alexander Mitsos,Manuel Dahmen*

Main category: cs.LG

TL;DR: 该论文提出了条件灵活性指数（CFI），通过利用历史数据和上下文信息（如预测）来构建条件化的容许不确定性集，从而比传统灵活性指数提供更准确的灵活性评估。


<details>
  <summary>Details</summary>
Motivation: 随着流程灵活性增强，确定鲁棒的调度决策变得重要。传统灵活性指数使用简单容许不确定性集（如超立方体）来近似容许不确定性区域，但未考虑可用的上下文信息（如预测）来定义这些集合。

Method: 提出条件灵活性指数（CFI）：1）使用归一化流从历史数据学习参数化的容许不确定性集；2）利用上下文信息使容许不确定性集条件化。具体方法是通过归一化流学习从高斯基分布到数据分布的双射映射，在潜在空间中构建超球体作为容许潜在不确定性集，然后映射回数据空间。

Result: 通过案例研究表明：1）不能一概而论数据驱动的容许不确定性集优于简单集，或条件集优于无条件集；2）但数据驱动和条件容许不确定性集能确保只考虑包含实际实现的参数空间区域。在安全约束机组组合案例中，CFI通过纳入时间信息提高了调度质量。

Conclusion: 条件灵活性指数通过结合历史数据和上下文信息，提供了比传统方法更信息丰富的灵活性估计，能够在给定条件下定义更相关区域的容许不确定性集，从而改善调度决策质量。

Abstract: With the increasing flexibilization of processes, determining robust scheduling decisions has become an important goal. Traditionally, the flexibility index has been used to identify safe operating schedules by approximating the admissible uncertainty region using simple admissible uncertainty sets, such as hypercubes. Presently, available contextual information, such as forecasts, has not been considered to define the admissible uncertainty set when determining the flexibility index. We propose the conditional flexibility index (CFI), which extends the traditional flexibility index in two ways: by learning the parametrized admissible uncertainty set from historical data and by using contextual information to make the admissible uncertainty set conditional. This is achieved using a normalizing flow that learns a bijective mapping from a Gaussian base distribution to the data distribution. The admissible latent uncertainty set is constructed as a hypersphere in the latent space and mapped to the data space. By incorporating contextual information, the CFI provides a more informative estimate of flexibility by defining admissible uncertainty sets in regions that are more likely to be relevant under given conditions. Using an illustrative example, we show that no general statement can be made about data-driven admissible uncertainty sets outperforming simple sets, or conditional sets outperforming unconditional ones. However, both data-driven and conditional admissible uncertainty sets ensure that only regions of the uncertain parameter space containing realizations are considered. We apply the CFI to a security-constrained unit commitment example and demonstrate that the CFI can improve scheduling quality by incorporating temporal information.

</details>


### [138] [CLASP: An online learning algorithm for Convex Losses And Squared Penalties](https://arxiv.org/abs/2601.16072)
*Ricardo N. Ferreira,Cláudia Soares,João Xavier*

Main category: cs.LG

TL;DR: CLASP算法用于约束在线凸优化，通过平方惩罚项处理约束，在强凸问题中首次实现对数级遗憾和惩罚保证。


<details>
  <summary>Details</summary>
Motivation: 研究约束在线凸优化问题，其中学习者在迭代选择动作时面临未预期的凸损失和凸约束，需要同时最小化累积损失和约束违反惩罚。

Method: 提出CLASP算法，结合累积损失和约束违反的平方惩罚项，利用凸投影算子的严格非扩展性进行理论分析。

Result: 对于凸损失，CLASP获得O(T^{max{β,1-β}})遗憾和O(T^{1-β})累积平方惩罚；对于强凸问题，首次实现O(log T)的遗憾和累积平方惩罚对数保证。

Conclusion: CLASP算法在约束在线凸优化中表现优异，特别是在强凸问题中实现了对数级性能保证，为相关研究提供了新的理论框架。

Abstract: We study Constrained Online Convex Optimization (COCO), where a learner chooses actions iteratively, observes both unanticipated convex loss and convex constraint, and accumulates loss while incurring penalties for constraint violations. We introduce CLASP (Convex Losses And Squared Penalties), an algorithm that minimizes cumulative loss together with squared constraint violations. Our analysis departs from prior work by fully leveraging the firm non-expansiveness of convex projectors, a proof strategy not previously applied in this setting. For convex losses, CLASP achieves regret $O\left(T^{\max\{β,1-β\}}\right)$ and cumulative squared penalty $O\left(T^{1-β}\right)$ for any $β\in (0,1)$. Most importantly, for strongly convex problems, CLASP provides the first logarithmic guarantees on both regret and cumulative squared penalty. In the strongly convex case, the regret is upper bounded by $O( \log T )$ and the cumulative squared penalty is also upper bounded by $O( \log T )$.

</details>


### [139] [Explainable AI to Improve Machine Learning Reliability for Industrial Cyber-Physical Systems](https://arxiv.org/abs/2601.16074)
*Annemarie Jutte,Uraz Odyurt*

Main category: cs.LG

TL;DR: 本研究将可解释AI（XAI）应用于工业信息物理系统（CPS）的机器学习模型，通过SHAP值分析时间序列数据分解组件对预测的影响，发现训练中上下文信息不足的问题，并通过增大数据窗口尺寸提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 工业CPS在安全和经济效益方面都是敏感基础设施，其可靠性至关重要。虽然机器学习（特别是深度学习）越来越多地集成到工业CPS中，但ML模型的固有复杂性导致其操作不透明。需要严格评估以防止模型在未来未见数据上表现出意外行为。

Method: 使用可解释AI（XAI）技术，具体通过SHAP值分析时间序列数据分解的各个组件对模型预测的影响。通过XAI发现模型训练中上下文信息不足的问题，进而基于这些发现增加数据实例的窗口大小。

Result: 通过XAI分析发现了模型训练中缺乏足够上下文信息的证据。基于XAI的发现，通过增大数据窗口尺寸，成功提升了模型的预测性能。

Conclusion: XAI不仅可以揭示机器学习模型的推理过程，还能指导模型改进。在工业CPS应用中，通过XAI分析时间序列数据分解组件的影响，识别出训练数据中的局限性，并通过调整数据窗口尺寸有效提升了模型性能，增强了工业CPS中ML应用的可靠性和透明度。

Abstract: Industrial Cyber-Physical Systems (CPS) are sensitive infrastructure from both safety and economics perspectives, making their reliability critically important. Machine Learning (ML), specifically deep learning, is increasingly integrated in industrial CPS, but the inherent complexity of ML models results in non-transparent operation. Rigorous evaluation is needed to prevent models from exhibiting unexpected behaviour on future, unseen data. Explainable AI (XAI) can be used to uncover model reasoning, allowing a more extensive analysis of behaviour. We apply XAI to to improve predictive performance of ML models intended for industrial CPS. We analyse the effects of components from time-series data decomposition on model predictions using SHAP values. Through this method, we observe evidence on the lack of sufficient contextual information during model training. By increasing the window size of data instances, informed by the XAI findings, we are able to improve model performance.

</details>


### [140] [Probably Approximately Correct Maximum A Posteriori Inference](https://arxiv.org/abs/2601.16083)
*Matthew Shorvon,Frederik Mallmann-Trenn,David S. Watson*

Main category: cs.LG

TL;DR: 提出PAC-MAP算法，为MAP推理提供可证明的最优解，具有计算预算保证，基于信息论度量，通过概率电路实现


<details>
  <summary>Details</summary>
Motivation: MAP推理是概率推断的基本任务，但通常难以计算，即使在许多常见结构约束和近似方案下仍然困难。需要提供理论保证的MAP推理方法

Method: 引入PAC（probably approximately correct）算法进行MAP推理，使用信息论度量刻画可处理性条件，通过概率电路实现随机化策略

Result: PAC-MAP算法在变量和固定计算预算下提供可证明的最优解，可单独使用或改进现有启发式方法，实验在多个基准测试中验证了有效性

Conclusion: PAC-MAP为MAP推理提供了理论保证的解决方案，通过信息论度量和概率电路实现，既可作为独立方法也可增强现有启发式方法的可靠性

Abstract: Computing the conditional mode of a distribution, better known as the $\mathit{maximum\ a\ posteriori}$ (MAP) assignment, is a fundamental task in probabilistic inference. However, MAP estimation is generally intractable, and remains hard even under many common structural constraints and approximation schemes. We introduce $\mathit{probably\ approximately\ correct}$ (PAC) algorithms for MAP inference that provide provably optimal solutions under variable and fixed computational budgets. We characterize tractability conditions for PAC-MAP using information theoretic measures that can be estimated from finite samples. Our PAC-MAP solvers are efficiently implemented using probabilistic circuits with appropriate architectures. The randomization strategies we develop can be used either as standalone MAP inference techniques or to improve on popular heuristics, fortifying their solutions with rigorous guarantees. Experiments confirm the benefits of our method in a range of benchmarks.

</details>


### [141] [Benchmarking Deep Learning Models for Raman Spectroscopy Across Open-Source Datasets](https://arxiv.org/abs/2601.16107)
*Adithya Sineesh,Akshita Kamsali*

Main category: cs.LG

TL;DR: 首次系统性地对多个Raman光谱深度学习分类器在开源数据集上进行基准测试，比较了五种代表性架构在统一训练协议下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前Raman光谱深度学习分类器虽然声称优于传统化学计量学方法，但缺乏在共享开源数据集上对专门为Raman光谱设计的深度学习模型的直接比较。

Method: 在三个开源Raman数据集上，采用统一的训练和超参数调优协议，评估了五种代表性的深度学习架构，支持标准评估、微调和显式分布偏移测试。

Result: 报告了分类准确率和宏平均F1分数，为Raman光谱分类的深度学习模型提供了公平且可复现的比较基准。

Conclusion: 该研究填补了Raman光谱深度学习模型系统性比较的空白，为未来研究提供了可复现的基准测试框架。

Abstract: Deep learning classifiers for Raman spectroscopy are increasingly reported to outperform classical chemometric approaches. However their evaluations are often conducted in isolation or compared against traditional machine learning methods or trivially adapted vision-based architectures that were not originally proposed for Raman spectroscopy. As a result, direct comparisons between existing deep learning models developed specifically for Raman spectral analysis on shared open-source datasets remain scarce. To the best of our knowledge, this study presents one of the first systematic benchmarks comparing three or more published Raman-specific deep learning classifiers across multiple open-source Raman datasets. We evaluate five representative deep learning architectures under a unified training and hyperparameter tuning protocol across three open-source Raman datasets selected to support standard evaluation, fine-tuning, and explicit distribution-shift testing. We report classification accuracies and macro-averaged F1 scores to provide a fair and reproducible comparison of deep learning models for Raman spectra based classification.

</details>


### [142] [Variable Splitting Binary Tree Models Based on Bayesian Context Tree Models for Time Series Segmentation](https://arxiv.org/abs/2601.16112)
*Yuta Nakahara,Shota Saito,Kohei Horinouchi,Koshi Shimada,Naoki Ichijo,Manabu Kobayashi,Toshiyasu Matsushima*

Main category: cs.LG

TL;DR: 提出基于贝叶斯上下文树（BCT）模型的变量分裂二叉树（VSBT），用于时间序列分割，通过递归逻辑回归表示区间划分，支持任意位置的分割点，并开发了结合局部变分近似和上下文树加权（CTW）的高效推理算法。


<details>
  <summary>Details</summary>
Motivation: 传统BCT模型在时间序列分割中的应用有限，其树结构通常表示符号序列而非时间域划分。需要一种能够灵活表示任意分割位置且结构紧凑的模型，以更有效地进行时间序列分割。

Method: 提出VSBT模型：1）将BCT树结构重新解释为时间域上的区间划分；2）使用递归逻辑回归模型表示区间划分，通过调整回归系数可在区间内任意位置设置分割点；3）开发推理算法，结合局部变分近似处理逻辑回归，并集成CTW算法同时估计分割位置和树深度。

Result: 在合成数据上的数值实验表明，所提模型和算法能够有效进行时间序列分割，相比传统方法具有更紧凑的树表示能力，并能准确识别分割位置。

Conclusion: VSBT模型成功将BCT框架扩展到时间序列分割任务，通过递归逻辑回归实现了灵活的分割点表示，所提推理算法能够有效同时估计分割位置和树结构深度，为时间序列分析提供了新工具。

Abstract: We propose a variable splitting binary tree (VSBT) model based on Bayesian context tree (BCT) models for time series segmentation. Unlike previous applications of BCT models, the tree structure in our model represents interval partitioning on the time domain. Moreover, interval partitioning is represented by recursive logistic regression models. By adjusting logistic regression coefficients, our model can represent split positions at arbitrary locations within each interval. This enables more compact tree representations. For simultaneous estimation of both split positions and tree depth, we develop an effective inference algorithm that combines local variational approximation for logistic regression with the context tree weighting (CTW) algorithm. We present numerical examples on synthetic data demonstrating the effectiveness of our model and algorithm.

</details>


### [143] [On the Intrinsic Dimensions of Data in Kernel Learning](https://arxiv.org/abs/2601.16139)
*Rustem Takhanov*

Main category: cs.LG

TL;DR: 该论文研究核岭回归（KRR）在低本征维度下的泛化性能，提出了两种本征维度定义（Minkowski维度和有效维度），分析了它们与Kolmogorov n-宽度和特征值衰减的关系，并给出了泛化误差界和维度估计算法。


<details>
  <summary>Details</summary>
Motivation: 流形假设认为当输入分布的本征维度较低时，机器学习方法的泛化性能会显著提升。本文旨在研究核岭回归（KRR）中本征维度的不同定义及其对泛化性能的影响，特别关注如何通过Kolmogorov n-宽度和积分算子特征值来量化这种关系。

Method: 1. 定义两种本征维度：d_ρ（基于核诱导度量的Minkowski维度）和d_K（基于Kolmogorov n-宽度衰减的有效维度）
2. 分析Kolmogorov n-宽度与积分算子特征值的关系，证明n-宽度刻画了所有概率测度下的最坏特征值衰减
3. 推导约束KRR的泛化误差界：O(n^{-(2+d_K)/(2+2d_K)+ε})
4. 提出基于有限样本估计n-宽度上界的算法
5. 对均匀分布附近的分布，证明使用O(ε^{-d_ρ}log(1/ε))样本可高概率计算ε-准确的上界
6. 计算分形集的有效维度并进行数值实验

Result: 1. 证明了Kolmogorov n-宽度能刻画所有概率测度下的最坏特征值衰减
2. 获得了约束KRR的泛化误差界O(n^{-(2+d_K)/(2+2d_K)+ε})
3. 提出了有效的n-宽度估计算法，对接近均匀的分布只需O(ε^{-d_ρ}log(1/ε))样本
4. 数值结果表明，对于拉普拉斯核等核函数，有效维度d_K可以显著小于Minkowski维度d_ρ，尽管在规则域上两者相等

Conclusion: 该研究为理解核岭回归在低本征维度下的泛化性能提供了理论框架，证明了有效维度d_K（而非Minkowski维度d_ρ）决定了泛化误差的衰减速率。提出的估计算法能够从有限样本中有效估计本征维度，特别适用于分形集等复杂结构，为实际应用提供了理论指导。

Abstract: The manifold hypothesis suggests that the generalization performance of machine learning methods improves significantly when the intrinsic dimension of the input distribution's support is low. In the context of KRR, we investigate two alternative notions of intrinsic dimension. The first, denoted $d_ρ$, is the upper Minkowski dimension defined with respect to the canonical metric induced by a kernel function $K$ on a domain $Ω$. The second, denoted $d_K$, is the effective dimension, derived from the decay rate of Kolmogorov $n$-widths associated with $K$ on $Ω$. Given a probability measure $μ$ on $Ω$, we analyze the relationship between these $n$-widths and eigenvalues of the integral operator $φ\to \int_ΩK(\cdot,x)φ(x)dμ(x)$. We show that, for a fixed domain $Ω$, the Kolmogorov $n$-widths characterize the worst-case eigenvalue decay across all probability measures $μ$ supported on $Ω$. These eigenvalues are central to understanding the generalization behavior of constrained KRR, enabling us to derive an excess error bound of order $O(n^{-\frac{2+d_K}{2+2d_K} + ε})$ for any $ε> 0$, when the training set size $n$ is large. We also propose an algorithm that estimates upper bounds on the $n$-widths using only a finite sample from $μ$. For distributions close to uniform, we prove that $ε$-accurate upper bounds on all $n$-widths can be computed with high probability using at most $O\left(ε^{-d_ρ}\log\frac{1}ε\right)$ samples, with fewer required for small $n$. Finally, we compute the effective dimension $d_K$ for various fractal sets and present additional numerical experiments. Our results show that, for kernels such as the Laplace kernel, the effective dimension $d_K$ can be significantly smaller than the Minkowski dimension $d_ρ$, even though $d_K = d_ρ$ provably holds on regular domains.

</details>


### [144] [Beat-ssl: Capturing Local ECG Morphology through Heartbeat-level Contrastive Learning with Soft Targets](https://arxiv.org/abs/2601.16147)
*Muhammad Ilham Rizqyawan,Peter Macfarlane,Stathis Hadjidemetriou,Fani Deligianni*

Main category: cs.LG

TL;DR: Beat-SSL是一个针对ECG信号的双上下文对比学习框架，通过节奏级和心跳级对比结合软目标进行预训练，在小样本下游任务中表现优异


<details>
  <summary>Details</summary>
Motivation: ECG标记数据获取困难，现有对比学习方法要么只关注全局上下文，要么未充分利用ECG特异性特征，且依赖硬对比目标无法捕捉ECG特征的连续相似性

Method: 提出Beat-SSL对比学习框架，通过节奏级和心跳级的双上下文对比学习，采用软目标来捕捉ECG特征的连续相似性

Result: 在多标签分类任务中达到ECG基础模型93%的性能，在分割任务中超越所有其他方法4%，包括ECG基础模型

Conclusion: Beat-SSL通过ECG特定的双上下文对比学习和软目标，在有限标记数据下实现了有效的表示学习，在ECG分析任务中表现出色

Abstract: Obtaining labelled ECG data for developing supervised models is challenging. Contrastive learning (CL) has emerged as a promising pretraining approach that enables effective transfer learning with limited labelled data. However, existing CL frameworks either focus solely on global context or fail to exploit ECG-specific characteristics. Furthermore, these methods rely on hard contrastive targets, which may not adequately capture the continuous nature of feature similarity in ECG signals. In this paper, we propose Beat-SSL, a contrastive learning framework that performs dual-context learning through both rhythm-level and heartbeat-level contrasting with soft targets. We evaluated our pretrained model on two downstream tasks: 1) multilabel classification for global rhythm assessment, and 2) ECG segmentation to assess its capacity to learn representations across both contexts. We conducted an ablation study and compared the best configuration with three other methods, including one ECG foundation model. Despite the foundation model's broader pretraining, Beat-SSL reached 93% of its performance in multilabel classification task and surpassed all other methods in the segmentation task by 4%.

</details>


### [145] [Learning to Discover at Test Time](https://arxiv.org/abs/2601.16175)
*Mert Yuksekgonul,Daniel Koceja,Xinhao Li,Federico Bianchi,Jed McCaleb,Xiaolong Wang,Jan Kautz,Yejin Choi,James Zou,Carlos Guestrin,Yu Sun*

Main category: cs.LG

TL;DR: TTT-Discover 是一种通过测试时强化学习让LLM持续训练以发现特定问题最优解的方法，在多个科学领域取得了新的SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有测试时扩展方法（如AlphaEvolve）使用冻结的LLM进行搜索，无法针对具体测试问题持续学习。需要一种能让LLM在测试时通过强化学习不断优化，专注于生成特定问题的最佳解决方案的方法。

Method: 提出TTT-Discover方法：在测试时进行强化学习，让LLM能够针对具体问题持续训练。设计专门的学习目标和搜索子程序，优先考虑最有希望的解决方案。专注于连续奖励问题，使用开源模型OpenAI gpt-oss-120b，通过Tinker API以较低成本实现。

Result: 在数学（Erdős最小重叠问题和自相关不等式）、GPU内核工程（比现有技术快2倍）、算法设计（AtCoder竞赛）和生物学（单细胞分析去噪问题）等多个领域几乎都取得了新的SOTA结果。所有结果均经过专家或组织者评审，且使用开源模型和公开代码可复现。

Conclusion: TTT-Discover通过测试时训练实现了在多个科学领域的突破性进展，证明了使用开源模型和较低成本就能超越之前需要封闭前沿模型才能达到的最佳结果，为AI辅助科学发现提供了新的有效方法。

Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific to the test problem. This form of continual learning is quite special, because its goal is to produce one great solution rather than many good ones on average, and to solve this very problem rather than generalize to other problems. Therefore, our learning objective and search subroutine are designed to prioritize the most promising solutions. We call this method Test-Time Training to Discover (TTT-Discover). Following prior work, we focus on problems with continuous rewards. We report results for every problem we attempted, across mathematics, GPU kernel engineering, algorithm design, and biology. TTT-Discover sets the new state of the art in almost all of them: (i) Erdős' minimum overlap problem and an autocorrelation inequality; (ii) a GPUMode kernel competition (up to $2\times$ faster than prior art); (iii) past AtCoder algorithm competitions; and (iv) denoising problem in single-cell analysis. Our solutions are reviewed by experts or the organizers. All our results are achieved with an open model, OpenAI gpt-oss-120b, and can be reproduced with our publicly available code, in contrast to previous best results that required closed frontier models. Our test-time training runs are performed using Tinker, an API by Thinking Machines, with a cost of only a few hundred dollars per problem.

</details>


### [146] [Provable Robustness in Multimodal Large Language Models via Feature Space Smoothing](https://arxiv.org/abs/2601.16200)
*Song Xia,Meiwen Ding,Chenqi Kong,Wenhan Yang,Xudong Jiang*

Main category: cs.LG

TL;DR: 提出特征空间平滑方法为多模态大语言模型提供可证明的鲁棒性保证，通过高斯噪声平滑特征编码器，并结合纯化平滑映射模块提升鲁棒性分数


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在各种应用中表现出强大能力，但对对抗性扰动仍然脆弱，这些扰动会扭曲特征表示并导致错误预测，需要理论保证的鲁棒性方法

Method: 提出特征空间平滑方法，通过高斯噪声将特征编码器转换为平滑变体，保证在ℓ₂有界攻击下特征余弦相似度的认证下界；引入纯化平滑映射模块提升高斯鲁棒性分数

Result: 在各种多模态大语言模型和下游任务中，FS-PSM将各种白盒攻击的成功率从近90%降低到约1%，表现出优于对抗训练的性能

Conclusion: 特征空间平滑方法不仅提供强大的理论鲁棒性保证，而且在实际应用中表现出卓越的实证性能，有效保护多模态大语言模型免受对抗性攻击

Abstract: Multimodal large language models (MLLMs) exhibit strong capabilities across diverse applications, yet remain vulnerable to adversarial perturbations that distort their feature representations and induce erroneous predictions. To address this vulnerability, we propose the Feature-space Smoothing (FS) and theoretically prove that FS offers certified robustness on the feature representations of MLLMs. Specifically, FS transforms any feature encoder into a smoothed variant that is guaranteed to maintain a certified lower bound on the feature cosine similarity between clean and adversarial representations under $\ell_2$-bounded attacks. Moreover, we indicate that the value of this Feature Cosine Similarity Bound (FCSB) derived from FS can be improved by enlarging the defined Gaussian robustness score on the vanilla encoder. Building upon this, we introduce the Purifier and Smoothness Mapper (PSM), a plug-and-play module that improves the Gaussian robustness score of MLLMs and thus enhances their certified robustness under FS, without requiring any retraining on MLLMs. We demonstrate that the FS with PSM not only provides a strong theoretical robustness guarantee but also exhibits superior empirical performance compared to adversarial training. Extensive experiments across diverse MLLMs and downstream tasks indicate the effectiveness of the FS-PSM, reducing the Attack Success Rate (ASR) of various white-box attacks from nearly 90\% to about 1\%.

</details>


### [147] [Counterfactual Training: Teaching Models Plausible and Actionable Explanations](https://arxiv.org/abs/2601.16205)
*Patrick Altmeyer,Aleksander Buszydlik,Arie van Deursen,Cynthia C. S. Liem*

Main category: cs.LG

TL;DR: 提出了一种名为"反事实训练"的新训练范式，利用反事实解释来增强模型的可解释能力。该方法在训练阶段使用反事实来最小化学到的表示与合理、可操作的解释之间的差异。


<details>
  <summary>Details</summary>
Motivation: 反事实解释已成为不透明机器学习模型的流行事后解释方法，但在实际决策系统中，反事实需要具备合理性和可操作性。现有研究主要关注事后生成满足这些要求的反事实，而本文希望让模型直接对期望的最终目标负责。

Method: 提出反事实训练方法，在训练阶段使用反事实来最小化学到的表示与合理、可操作的解释之间的差异。通过理论分析和实证验证，使模型能够提供内在理想的反事实解释。

Result: 实验和理论证明表明，该方法能够训练出提供内在理想反事实解释的模型，同时还表现出改进的对抗鲁棒性。

Conclusion: 反事实训练是一种有效的训练范式，能够增强模型的可解释性和鲁棒性，为构建更可信、更可靠的机器学习系统提供了新途径。

Abstract: We propose a novel training regime termed counterfactual training that leverages counterfactual explanations to increase the explanatory capacity of models. Counterfactual explanations have emerged as a popular post-hoc explanation method for opaque machine learning models: they inform how factual inputs would need to change in order for a model to produce some desired output. To be useful in real-world decision-making systems, counterfactuals should be plausible with respect to the underlying data and actionable with respect to the feature mutability constraints. Much existing research has therefore focused on developing post-hoc methods to generate counterfactuals that meet these desiderata. In this work, we instead hold models directly accountable for the desired end goal: counterfactual training employs counterfactuals during the training phase to minimize the divergence between learned representations and plausible, actionable explanations. We demonstrate empirically and theoretically that our proposed method facilitates training models that deliver inherently desirable counterfactual explanations and additionally exhibit improved adversarial robustness.

</details>
